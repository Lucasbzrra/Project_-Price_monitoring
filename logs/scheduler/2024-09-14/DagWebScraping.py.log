[2024-09-14T21:13:06.117+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:13:06.117+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:13:06.120+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:13:06.120+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:13:06.578+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:13:06.563+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:13:06.579+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:13:06.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.484 seconds
[2024-09-14T21:13:36.812+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:13:36.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:13:36.823+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:13:36.822+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:13:37.369+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:13:37.341+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:13:37.371+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:13:37.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.590 seconds
[2024-09-14T21:14:08.153+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:14:08.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:14:08.156+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:14:08.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:14:08.336+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:14:08.329+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:14:08.337+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:14:08.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.209 seconds
[2024-09-14T21:14:38.430+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:14:38.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:14:38.433+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:14:38.433+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:14:38.619+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:14:38.612+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:14:38.620+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:14:38.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-09-14T21:15:08.743+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:15:08.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:15:08.747+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:15:08.747+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:15:08.927+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:15:08.918+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:15:08.928+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:15:08.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.214 seconds
[2024-09-14T21:15:39.494+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:15:39.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:15:39.497+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:15:39.497+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:15:39.673+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:15:39.666+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:15:39.674+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:15:39.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.203 seconds
[2024-09-14T21:16:09.800+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:16:09.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:16:09.803+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:16:09.802+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:16:09.976+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:16:09.969+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:16:09.977+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:16:09.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.200 seconds
[2024-09-14T21:16:40.147+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:16:40.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:16:40.150+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:16:40.150+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:16:40.331+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:16:40.323+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:16:40.333+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:16:40.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.209 seconds
[2024-09-14T21:17:10.880+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:17:10.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:17:10.883+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:17:10.883+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:17:11.057+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:17:11.051+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:17:11.059+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:17:11.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.202 seconds
[2024-09-14T21:17:41.801+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:17:41.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:17:41.804+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:17:41.803+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:17:41.984+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:17:41.976+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:17:41.986+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:17:42.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.210 seconds
[2024-09-14T21:18:12.175+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:18:12.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:18:12.179+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:18:12.179+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:18:12.363+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:18:12.355+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:18:12.365+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:18:12.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-09-14T21:18:42.442+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:18:42.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:18:42.446+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:18:42.446+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:18:42.618+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:18:42.611+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:18:42.619+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:18:42.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.199 seconds
[2024-09-14T21:19:13.280+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:19:13.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:19:13.283+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:19:13.283+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:19:13.456+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:19:13.450+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:19:13.457+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:19:13.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.201 seconds
[2024-09-14T21:19:44.100+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:19:44.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:19:44.103+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:19:44.103+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:19:44.282+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:19:44.275+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:19:44.284+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:19:44.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.208 seconds
[2024-09-14T21:20:14.453+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:20:14.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:20:14.456+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:20:14.455+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:20:14.628+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:20:14.622+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:20:14.629+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:20:14.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.198 seconds
[2024-09-14T21:20:44.803+0000] {processor.py:186} INFO - Started process (PID=259) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:20:44.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:20:44.806+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:20:44.806+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:20:44.979+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:20:44.973+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:20:44.980+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:20:44.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.201 seconds
[2024-09-14T21:21:15.053+0000] {processor.py:186} INFO - Started process (PID=271) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:21:15.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:21:15.057+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:21:15.056+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:21:15.234+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:21:15.226+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:21:15.235+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:21:15.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.209 seconds
[2024-09-14T21:21:45.305+0000] {processor.py:186} INFO - Started process (PID=283) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:21:45.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:21:45.309+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:21:45.309+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:21:45.503+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:21:45.497+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:21:45.504+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:21:45.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.228 seconds
[2024-09-14T21:22:16.406+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:22:16.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:22:16.409+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:22:16.409+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:22:16.591+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:22:16.584+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:22:16.592+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:22:16.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.210 seconds
[2024-09-14T21:22:46.671+0000] {processor.py:186} INFO - Started process (PID=307) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:22:46.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:22:46.674+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:22:46.673+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:22:46.854+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:22:46.847+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:22:46.856+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:22:46.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.208 seconds
[2024-09-14T21:23:16.985+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:23:16.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:23:16.988+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:23:16.987+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:23:17.160+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:23:17.154+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:23:17.162+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:23:17.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.201 seconds
[2024-09-14T21:23:47.327+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:23:47.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:23:47.330+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:23:47.330+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:23:47.504+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:23:47.498+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:23:47.506+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:23:47.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.201 seconds
[2024-09-14T21:24:17.622+0000] {processor.py:186} INFO - Started process (PID=343) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:24:17.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:24:17.625+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:24:17.625+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:24:17.799+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:24:17.793+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:24:17.800+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:24:17.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.202 seconds
[2024-09-14T21:24:48.032+0000] {processor.py:186} INFO - Started process (PID=355) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:24:48.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:24:48.036+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:24:48.036+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:24:48.223+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:24:48.217+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:24:48.224+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:24:48.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-09-14T21:25:18.339+0000] {processor.py:186} INFO - Started process (PID=367) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:25:18.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:25:18.342+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:25:18.342+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:25:18.517+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:25:18.509+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:25:18.518+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:25:18.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.202 seconds
[2024-09-14T21:25:49.224+0000] {processor.py:186} INFO - Started process (PID=379) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:25:49.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:25:49.228+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:25:49.227+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:25:49.407+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:25:49.400+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:25:49.408+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:25:49.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.208 seconds
[2024-09-14T21:26:20.061+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:26:20.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:26:20.064+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:26:20.064+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:26:20.238+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:26:20.231+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:26:20.239+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:26:20.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.201 seconds
[2024-09-14T21:26:50.945+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:26:50.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:26:50.948+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:26:50.948+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:26:51.142+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:26:51.136+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:26:51.144+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:26:51.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.228 seconds
[2024-09-14T21:27:21.750+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:27:21.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:27:21.755+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:27:21.754+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:27:21.943+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:27:21.937+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:27:21.945+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:27:21.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.230 seconds
[2024-09-14T21:27:52.024+0000] {processor.py:186} INFO - Started process (PID=429) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:27:52.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:27:52.028+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:27:52.027+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:27:52.199+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:27:52.192+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:27:52.201+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:27:52.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.202 seconds
[2024-09-14T21:28:22.344+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:28:22.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:28:22.347+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:28:22.347+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:28:22.520+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:28:22.514+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:28:22.521+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:28:22.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.200 seconds
[2024-09-14T21:28:53.194+0000] {processor.py:186} INFO - Started process (PID=452) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:28:53.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:28:53.198+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:28:53.197+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:28:53.382+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:28:53.375+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:28:53.383+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:28:53.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.212 seconds
[2024-09-14T21:29:23.929+0000] {processor.py:186} INFO - Started process (PID=464) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:29:23.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:29:23.934+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:29:23.934+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:29:24.120+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:29:24.113+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:29:24.121+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:29:24.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-09-14T21:29:54.172+0000] {processor.py:186} INFO - Started process (PID=477) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:29:54.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:29:54.175+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:29:54.174+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:29:54.356+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:29:54.347+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:29:54.357+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:29:54.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-09-14T21:30:25.035+0000] {processor.py:186} INFO - Started process (PID=488) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:30:25.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:30:25.039+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:30:25.038+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:30:25.214+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:30:25.207+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:30:25.215+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:30:25.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.204 seconds
[2024-09-14T21:30:55.758+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:30:55.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:30:55.761+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:30:55.761+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:30:55.956+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:30:55.950+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:30:55.957+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:30:55.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.222 seconds
[2024-09-14T21:31:26.679+0000] {processor.py:186} INFO - Started process (PID=513) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:31:26.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:31:26.683+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:31:26.682+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:31:26.875+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:31:26.870+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:31:26.876+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:31:26.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-09-14T21:31:57.382+0000] {processor.py:186} INFO - Started process (PID=525) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:31:57.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:31:57.386+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:31:57.386+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:31:57.563+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:31:57.556+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:31:57.564+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:31:57.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.204 seconds
[2024-09-14T21:32:28.205+0000] {processor.py:186} INFO - Started process (PID=537) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:32:28.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:32:28.208+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:32:28.207+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:32:28.381+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:32:28.374+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:32:28.383+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:32:28.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.200 seconds
[2024-09-14T21:32:58.938+0000] {processor.py:186} INFO - Started process (PID=549) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:32:58.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:32:58.941+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:32:58.940+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:32:59.114+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:32:59.107+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:32:59.116+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:32:59.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.201 seconds
[2024-09-14T21:33:29.177+0000] {processor.py:186} INFO - Started process (PID=561) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:33:29.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:33:29.180+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:33:29.180+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:33:29.396+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:33:29.389+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:33:29.397+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:33:29.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-14T21:33:59.520+0000] {processor.py:186} INFO - Started process (PID=574) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:33:59.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:33:59.524+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:33:59.523+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:33:59.691+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:33:59.685+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:33:59.693+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:33:59.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.195 seconds
[2024-09-14T21:34:29.874+0000] {processor.py:186} INFO - Started process (PID=586) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:34:29.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:34:29.877+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:34:29.876+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:34:30.085+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:34:30.080+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:34:30.086+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:34:30.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.241 seconds
[2024-09-14T21:35:00.596+0000] {processor.py:186} INFO - Started process (PID=597) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:35:00.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:35:00.600+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:35:00.599+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:35:00.828+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:35:00.822+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:35:00.829+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:35:00.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-14T21:35:31.526+0000] {processor.py:186} INFO - Started process (PID=609) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:35:31.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:35:31.529+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:35:31.529+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:35:31.703+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:35:31.696+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:35:31.704+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:35:31.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.200 seconds
[2024-09-14T21:36:50.143+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:36:50.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:36:50.147+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:36:50.146+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:36:50.609+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:36:50.601+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:36:50.611+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:36:50.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.501 seconds
[2024-09-14T21:37:10.853+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:37:10.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:37:10.856+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:37:10.855+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:37:11.176+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:37:11.170+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:37:11.177+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:37:11.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.346 seconds
[2024-09-14T21:37:41.232+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:37:41.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:37:41.238+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:37:41.238+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:37:41.570+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:37:41.564+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:37:41.571+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:37:41.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.361 seconds
[2024-09-14T21:38:12.228+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:38:12.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:38:12.231+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:38:12.231+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:38:12.411+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:38:12.404+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:38:12.413+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:38:12.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.209 seconds
[2024-09-14T21:38:24.802+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:38:24.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:38:24.806+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:38:24.805+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:38:24.992+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:38:24.984+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:38:24.993+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:38:25.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-09-14T21:39:32.482+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:39:32.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:39:32.486+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:39:32.485+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:39:32.945+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:39:32.938+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:39:32.946+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:39:32.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.489 seconds
[2024-09-14T21:40:03.035+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:40:03.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:40:03.042+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:40:03.042+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:40:03.446+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:40:03.437+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:40:03.448+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:40:03.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.438 seconds
[2024-09-14T21:40:33.637+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:40:33.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:40:33.640+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:40:33.640+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:40:33.814+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:40:33.808+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:40:33.816+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:40:33.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.202 seconds
[2024-09-14T21:41:04.012+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:41:04.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:41:04.015+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:41:04.014+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:41:04.195+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:41:04.188+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:41:04.196+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:41:04.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.208 seconds
[2024-09-14T21:41:34.321+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:41:34.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:41:34.324+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:41:34.323+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:41:34.497+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:41:34.491+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-14T21:41:34.498+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:41:34.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.200 seconds
[2024-09-14T21:42:04.614+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:42:04.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:42:04.617+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:42:04.617+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:42:04.810+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:42:04.954+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:42:04.954+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:42:04.986+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:42:04.986+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-13 00:00:00+00:00, run_after=2024-09-14 00:00:00+00:00
[2024-09-14T21:42:05.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.404 seconds
[2024-09-14T21:42:54.545+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:42:54.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:42:54.556+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:42:54.556+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:42:54.979+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:42:55.003+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:42:55.002+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:42:55.028+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:42:55.028+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:42:55.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.511 seconds
[2024-09-14T21:43:25.212+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:43:25.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:43:25.215+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:43:25.215+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:43:25.549+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:43:25.570+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:43:25.570+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:43:25.591+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:43:25.591+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:43:25.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.404 seconds
[2024-09-14T21:43:55.741+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:43:55.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:43:55.745+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:43:55.744+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:43:56.223+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:43:56.244+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:43:56.244+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:43:56.268+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:43:56.268+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:43:56.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.562 seconds
[2024-09-14T21:44:26.487+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:44:26.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:44:26.489+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:44:26.489+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:44:26.668+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:44:26.688+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:44:26.688+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:44:26.710+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:44:26.710+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:44:26.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-14T21:44:57.439+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:44:57.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:44:57.443+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:44:57.443+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:44:57.621+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:44:57.642+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:44:57.642+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:44:57.662+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:44:57.662+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:44:57.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-14T21:45:27.880+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:45:27.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:45:27.884+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:45:27.884+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:45:28.061+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:45:28.081+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:45:28.081+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:45:28.102+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:45:28.102+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:45:28.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-14T21:45:58.186+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:45:58.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:45:58.189+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:45:58.188+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:45:58.363+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:45:58.383+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:45:58.383+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:45:58.404+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:45:58.404+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:45:58.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-09-14T21:46:28.955+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:46:28.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:46:28.958+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:46:28.958+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:46:29.131+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:46:29.151+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:46:29.151+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:46:29.171+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:46:29.171+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:46:29.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.239 seconds
[2024-09-14T21:46:59.763+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:46:59.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:46:59.766+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:46:59.765+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:46:59.951+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:46:59.971+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:46:59.971+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:46:59.994+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:46:59.994+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:47:00.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-14T21:48:39.479+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:48:39.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:48:39.486+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:48:39.486+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:48:39.876+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:48:40.000+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:48:40.000+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:48:40.022+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:48:40.022+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:48:40.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.578 seconds
[2024-09-14T21:49:10.277+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:49:10.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:49:10.283+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:49:10.283+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:49:10.616+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:49:10.635+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:49:10.635+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:49:10.656+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:49:10.655+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-13 00:00:00+00:00, run_after=2024-09-14 00:00:00+00:00
[2024-09-14T21:49:10.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.406 seconds
[2024-09-14T21:49:41.044+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:49:41.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:49:41.048+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:49:41.048+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:49:41.236+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:49:41.257+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:49:41.257+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:49:41.282+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:49:41.282+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:49:41.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-09-14T21:50:11.804+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:50:11.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:50:11.808+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:50:11.807+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:50:12.007+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:50:12.031+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:50:12.031+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:50:12.056+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:50:12.056+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:50:12.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.290 seconds
[2024-09-14T21:50:42.591+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:50:42.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:50:42.594+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:50:42.594+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:50:42.788+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:50:42.810+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:50:42.810+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:50:42.831+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:50:42.831+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:50:42.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-14T21:51:12.923+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:51:12.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:51:12.927+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:51:12.927+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:51:13.106+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:51:13.129+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:51:13.128+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:51:13.150+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:51:13.150+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:51:13.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-09-14T21:51:43.609+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:51:43.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:51:43.612+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:51:43.612+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:51:43.793+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:51:43.814+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:51:43.814+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:51:43.836+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:51:43.835+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:51:43.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-09-14T21:52:14.408+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:52:14.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:52:14.411+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:52:14.411+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:52:14.628+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:52:14.653+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:52:14.653+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:52:14.678+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:52:14.678+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:52:14.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.301 seconds
[2024-09-14T21:52:45.264+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:52:45.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:52:45.267+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:52:45.267+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:52:45.442+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:52:45.462+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:52:45.462+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:52:45.486+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:52:45.486+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:52:45.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-14T21:53:15.709+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:53:15.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:53:15.712+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:53:15.711+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:53:15.887+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:53:15.908+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:53:15.908+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:53:15.930+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:53:15.930+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:53:15.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-14T21:53:46.081+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:53:46.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:53:46.084+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:53:46.084+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:53:46.254+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:53:46.276+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:53:46.276+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:53:46.297+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:53:46.296+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:53:46.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-09-14T21:54:16.732+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:54:16.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:54:16.736+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:54:16.736+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:54:16.911+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:54:16.932+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:54:16.932+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:54:16.953+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:54:16.953+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:54:16.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-14T21:54:47.602+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:54:47.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:54:47.604+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:54:47.604+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:54:47.800+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:54:47.822+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:54:47.821+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:54:47.843+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:54:47.843+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:54:47.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-14T21:55:18.358+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:55:18.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:55:18.362+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:55:18.362+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:55:18.542+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:55:18.563+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:55:18.562+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:55:18.585+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:55:18.585+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:55:18.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-09-14T21:55:48.666+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:55:48.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:55:48.669+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:55:48.669+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:55:48.850+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:55:48.873+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:55:48.872+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:55:48.896+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:55:48.896+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:55:48.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-09-14T21:56:19.028+0000] {processor.py:186} INFO - Started process (PID=254) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:56:19.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:56:19.031+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:56:19.031+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:56:19.204+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:56:19.226+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:56:19.226+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:56:19.248+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:56:19.247+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:56:19.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.442 seconds
[2024-09-14T21:56:50.262+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:56:50.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:56:50.266+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:56:50.265+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:56:50.458+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:56:50.479+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:56:50.479+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:56:50.500+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:56:50.500+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:56:50.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T21:57:20.557+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:57:20.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:57:20.560+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:57:20.559+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:57:20.728+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:57:20.749+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:57:20.749+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:57:20.770+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:57:20.769+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:57:20.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.408 seconds
[2024-09-14T21:57:51.610+0000] {processor.py:186} INFO - Started process (PID=291) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:57:51.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:57:51.613+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:57:51.613+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:57:51.800+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:57:51.820+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:57:51.820+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:57:51.841+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:57:51.841+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:57:51.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-09-14T21:58:22.501+0000] {processor.py:186} INFO - Started process (PID=303) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:58:22.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:58:22.503+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:58:22.503+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:58:22.680+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:58:22.701+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:58:22.701+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:58:22.722+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:58:22.722+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:58:22.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-14T21:58:53.466+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:58:53.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:58:53.469+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:58:53.468+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:58:53.655+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:58:53.676+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:58:53.675+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:58:53.698+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:58:53.697+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:58:53.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-14T21:59:24.372+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:59:24.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:59:24.375+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:59:24.375+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:59:24.563+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:59:24.585+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:59:24.585+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:59:24.606+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:59:24.605+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:59:24.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-14T21:59:55.343+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:59:55.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T21:59:55.346+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:59:55.345+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:59:55.526+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T21:59:55.547+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:59:55.547+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T21:59:55.568+0000] {logging_mixin.py:190} INFO - [2024-09-14T21:59:55.568+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T21:59:55.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-14T22:00:26.336+0000] {processor.py:186} INFO - Started process (PID=352) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:00:26.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:00:26.339+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:00:26.339+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:00:26.503+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:00:26.523+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:00:26.523+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:00:26.543+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:00:26.543+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:00:26.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.228 seconds
[2024-09-14T22:00:57.229+0000] {processor.py:186} INFO - Started process (PID=364) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:00:57.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:00:57.232+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:00:57.232+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:00:57.397+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:00:57.417+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:00:57.417+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:00:57.437+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:00:57.437+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:00:57.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.233 seconds
[2024-09-14T22:01:27.492+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:01:27.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:01:27.495+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:01:27.495+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:01:27.667+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:01:27.688+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:01:27.688+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:01:27.709+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:01:27.709+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:01:27.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.241 seconds
[2024-09-14T22:01:28.780+0000] {processor.py:186} INFO - Started process (PID=377) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:01:28.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:01:28.783+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:01:28.783+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:01:28.964+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:01:29.085+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:01:29.085+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:01:29.104+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:01:29.104+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:01:29.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.358 seconds
[2024-09-14T22:01:59.785+0000] {processor.py:186} INFO - Started process (PID=389) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:01:59.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:01:59.788+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:01:59.788+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:01:59.959+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:01:59.980+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:01:59.980+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:02:00.001+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:02:00.001+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:02:00.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-09-14T22:03:15.805+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:03:15.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:03:15.809+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:03:15.809+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:03:16.320+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:03:16.353+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:03:16.353+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:03:16.387+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:03:16.386+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:03:16.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.621 seconds
[2024-09-14T22:03:46.651+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:03:46.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:03:46.654+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:03:46.654+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:03:46.942+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:03:46.961+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:03:46.961+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:03:46.980+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:03:46.980+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:03:46.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.352 seconds
[2024-09-14T22:04:17.119+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:04:17.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:04:17.122+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:04:17.122+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:04:17.300+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:04:17.327+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:04:17.327+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:04:17.350+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:04:17.350+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:04:17.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-14T22:04:47.454+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:04:47.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:04:47.457+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:04:47.456+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:04:47.629+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:04:47.650+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:04:47.650+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:04:47.673+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:04:47.672+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:04:47.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.283 seconds
[2024-09-14T22:05:55.738+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:05:55.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:05:55.742+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:05:55.741+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:05:56.132+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:05:56.158+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:05:56.158+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:05:56.197+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:05:56.196+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:05:56.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.495 seconds
[2024-09-14T22:06:26.271+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:06:26.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:06:26.277+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:06:26.277+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:06:26.575+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:06:26.593+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:06:26.593+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:06:26.617+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:06:26.617+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:06:26.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.368 seconds
[2024-09-14T22:06:56.723+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:06:56.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:06:56.727+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:06:56.726+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:06:56.902+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:06:56.922+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:06:56.922+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:06:56.943+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:06:56.943+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:06:56.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-14T22:07:27.636+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:07:27.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:07:27.640+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:07:27.640+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:07:27.818+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:07:27.851+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:07:27.850+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:07:27.872+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:07:27.872+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:07:27.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-09-14T22:07:58.319+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:07:58.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:07:58.323+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:07:58.322+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:07:58.506+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:07:58.529+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:07:58.529+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:07:58.551+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:07:58.550+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:07:58.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-14T22:08:29.174+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:08:29.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:08:29.177+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:08:29.177+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:08:29.353+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:08:29.375+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:08:29.375+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:08:29.399+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:08:29.399+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:08:29.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-14T22:09:38.706+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:09:38.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:09:38.710+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:09:38.710+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:09:39.096+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:09:39.120+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:09:39.120+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:09:39.144+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:09:39.144+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:09:39.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.469 seconds
[2024-09-14T22:11:52.565+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:11:52.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:11:52.569+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:11:52.569+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:11:52.977+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:11:52.997+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:11:52.996+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:11:53.019+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:11:53.019+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:11:53.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.486 seconds
[2024-09-14T22:12:23.534+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:12:23.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:12:23.540+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:12:23.540+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:12:23.852+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:12:23.875+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:12:23.874+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:12:23.896+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:12:23.896+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-13 00:00:00+00:00, run_after=2024-09-14 00:00:00+00:00
[2024-09-14T22:12:24.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.665 seconds
[2024-09-14T22:12:54.347+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:12:54.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:12:54.350+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:12:54.350+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:12:54.657+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:12:54.678+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:12:54.678+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:12:54.719+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:12:54.719+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:12:54.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.400 seconds
[2024-09-14T22:15:19.465+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:15:19.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:15:19.468+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:15:19.468+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:15:19.871+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:15:19.891+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:15:19.891+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:15:19.917+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:15:19.917+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:15:19.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.477 seconds
[2024-09-14T22:15:50.027+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:15:50.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:15:50.033+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:15:50.033+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:15:50.373+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:15:50.392+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:15:50.392+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:15:50.413+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:15:50.412+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:15:50.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.410 seconds
[2024-09-14T22:16:21.082+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:16:21.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:16:21.086+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:16:21.085+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:16:21.421+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:16:21.441+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:16:21.441+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:16:21.462+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:16:21.462+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:16:21.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.406 seconds
[2024-09-14T22:16:52.393+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:16:52.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:16:52.396+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:16:52.396+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:16:52.703+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:16:52.722+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:16:52.721+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:16:52.744+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:16:52.744+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:16:52.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.377 seconds
[2024-09-14T22:17:23.114+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:17:23.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:17:23.117+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:17:23.117+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:17:23.419+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:17:23.439+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:17:23.439+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:17:23.462+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:17:23.462+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:17:23.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.370 seconds
[2024-09-14T22:17:53.612+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:17:53.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:17:53.615+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:17:53.615+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:17:53.930+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:17:53.951+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:17:53.951+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:17:53.973+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:17:53.972+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:17:53.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.386 seconds
[2024-09-14T22:18:24.067+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:18:24.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:18:24.072+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:18:24.071+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:18:24.381+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:18:24.402+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:18:24.401+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:18:24.423+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:18:24.423+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:18:24.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.382 seconds
[2024-09-14T22:18:55.214+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:18:55.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:18:55.338+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:18:55.338+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:18:55.507+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:18:55.526+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:18:55.525+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:18:55.545+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:18:55.545+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:18:55.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.355 seconds
[2024-09-14T22:19:26.490+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:19:26.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:19:26.493+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:19:26.493+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:19:26.672+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:19:26.694+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:19:26.694+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:19:26.717+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:19:26.717+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:19:26.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-14T22:19:57.352+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:19:57.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:19:57.355+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:19:57.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:19:57.547+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:19:57.568+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:19:57.567+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:19:57.590+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:19:57.590+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:19:57.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T22:22:06.974+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:22:06.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:22:06.978+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:22:06.978+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:22:07.369+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:22:07.396+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:22:07.396+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:22:07.420+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:22:07.420+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-13 00:00:00+00:00, run_after=2024-09-14 00:00:00+00:00
[2024-09-14T22:22:07.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.477 seconds
[2024-09-14T22:22:37.610+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:22:37.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:22:37.616+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:22:37.616+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:22:37.911+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:22:37.938+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:22:37.938+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:22:37.962+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:22:37.962+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:22:37.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.377 seconds
[2024-09-14T22:23:08.871+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:23:08.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:23:08.874+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:23:08.874+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:23:09.138+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:23:09.172+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:23:09.171+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:23:09.199+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:23:09.198+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:23:09.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.355 seconds
[2024-09-14T22:23:40.088+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:23:40.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:23:40.092+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:23:40.091+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:23:40.288+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:23:40.314+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:23:40.314+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:23:40.345+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:23:40.344+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:23:40.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.285 seconds
[2024-09-14T22:24:11.277+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:24:11.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:24:11.280+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:24:11.280+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:24:11.468+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:24:11.491+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:24:11.491+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:24:11.513+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:24:11.513+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:24:11.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-14T22:24:42.278+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:24:42.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:24:42.283+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:24:42.282+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:24:42.471+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:24:42.493+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:24:42.493+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:24:42.516+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:24:42.516+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:24:42.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-09-14T22:25:13.175+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:25:13.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:25:13.178+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:25:13.178+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:25:13.423+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:25:13.446+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:25:13.445+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:25:13.471+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:25:13.471+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:25:13.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.325 seconds
[2024-09-14T22:25:44.373+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:25:44.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:25:44.376+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:25:44.376+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:25:44.564+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:25:44.587+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:25:44.586+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:25:44.609+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:25:44.609+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:25:44.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T22:26:15.410+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:26:15.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:26:15.416+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:26:15.415+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:26:15.597+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:26:15.620+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:26:15.620+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:26:15.648+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:26:15.648+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:26:15.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T22:29:08.575+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:29:08.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:29:08.580+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:29:08.580+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:29:09.000+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:29:09.021+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:29:09.021+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:29:09.043+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:29:09.043+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:29:09.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.497 seconds
[2024-09-14T22:29:39.659+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:29:39.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:29:39.665+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:29:39.665+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:29:39.992+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:29:40.015+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:29:40.015+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:29:40.037+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:29:40.036+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:29:40.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.505 seconds
[2024-09-14T22:30:10.339+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:30:10.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:30:10.344+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:30:10.344+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:30:10.671+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:30:10.690+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:30:10.690+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:30:10.710+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:30:10.710+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-13 00:00:00+00:00, run_after=2024-09-14 00:00:00+00:00
[2024-09-14T22:30:10.730+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.396 seconds
[2024-09-14T22:30:40.807+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:30:40.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:30:40.810+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:30:40.809+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:30:41.120+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:30:41.138+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:30:41.138+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:30:41.158+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:30:41.158+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:30:41.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.379 seconds
[2024-09-14T22:31:11.404+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:31:11.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:31:11.407+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:31:11.407+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:31:11.713+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:31:11.733+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:31:11.733+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:31:11.754+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:31:11.754+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:31:11.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.375 seconds
[2024-09-14T22:31:42.087+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:31:42.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:31:42.090+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:31:42.090+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:31:42.385+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:31:42.405+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:31:42.405+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:31:42.425+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:31:42.425+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:31:42.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.360 seconds
[2024-09-14T22:32:12.478+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:32:12.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:32:12.481+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:32:12.481+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:32:12.782+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:32:12.805+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:32:12.805+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:32:12.824+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:32:12.824+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:32:12.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.367 seconds
[2024-09-14T22:32:43.842+0000] {processor.py:186} INFO - Started process (PID=170) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:32:43.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:32:43.980+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:32:43.980+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:32:44.151+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:32:44.171+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:32:44.170+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:32:44.191+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:32:44.191+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:32:44.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.373 seconds
[2024-09-14T22:33:14.592+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:33:14.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:33:14.595+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:33:14.595+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:33:14.804+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:33:14.825+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:33:14.825+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:33:14.849+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:33:14.849+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:33:14.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.287 seconds
[2024-09-14T22:33:45.467+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:33:45.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:33:45.472+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:33:45.472+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:33:45.668+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:33:45.691+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:33:45.691+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:33:45.714+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:33:45.714+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:33:45.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.272 seconds
[2024-09-14T22:34:16.583+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:34:16.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:34:16.588+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:34:16.588+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:34:16.790+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:34:16.812+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:34:16.812+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:34:16.836+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:34:16.836+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:34:16.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.279 seconds
[2024-09-14T22:34:47.418+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:34:47.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:34:47.421+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:34:47.420+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:34:47.601+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:34:47.623+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:34:47.623+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:34:47.645+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:34:47.645+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:34:47.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-09-14T22:35:18.219+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:35:18.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:35:18.223+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:35:18.222+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:35:18.401+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:35:18.423+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:35:18.423+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:35:18.445+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:35:18.444+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:35:18.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-09-14T22:35:48.520+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:35:48.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:35:48.522+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:35:48.522+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:35:48.694+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:35:48.716+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:35:48.716+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:35:48.739+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:35:48.739+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:35:48.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-14T22:36:19.376+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:36:19.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:36:19.380+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:36:19.379+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:36:19.556+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:36:19.577+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:36:19.577+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:36:19.599+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:36:19.598+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:36:19.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-14T22:36:50.310+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:36:50.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:36:50.315+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:36:50.315+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:36:50.501+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:36:50.523+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:36:50.523+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:36:50.544+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:36:50.544+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:36:50.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T22:37:20.626+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:37:20.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:37:20.630+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:37:20.630+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:37:20.816+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:37:20.837+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:37:20.837+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:37:20.859+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:37:20.859+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:37:20.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-14T22:37:50.955+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:37:50.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:37:50.958+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:37:50.958+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:37:51.143+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:37:51.164+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:37:51.163+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:37:51.185+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:37:51.185+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:37:51.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-14T22:38:21.860+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:38:21.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:38:21.863+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:38:21.863+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:38:22.046+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:38:22.067+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:38:22.067+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:38:22.089+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:38:22.089+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:38:22.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-09-14T22:38:52.181+0000] {processor.py:186} INFO - Started process (PID=318) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:38:52.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:38:52.185+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:38:52.185+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:38:52.367+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:38:52.391+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:38:52.390+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:38:52.417+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:38:52.416+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:38:52.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T22:39:23.277+0000] {processor.py:186} INFO - Started process (PID=337) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:39:23.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:39:23.280+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:39:23.279+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:39:23.458+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:39:23.481+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:39:23.480+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:39:23.503+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:39:23.503+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:39:23.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-14T22:39:53.611+0000] {processor.py:186} INFO - Started process (PID=349) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:39:53.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:39:53.614+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:39:53.614+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:39:53.807+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:39:53.830+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:39:53.830+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:39:53.853+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:39:53.852+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:39:53.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-09-14T22:40:24.007+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:40:24.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:40:24.010+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:40:24.010+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:40:24.196+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:40:24.217+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:40:24.217+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:40:24.244+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:40:24.244+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:40:24.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-14T22:40:54.366+0000] {processor.py:186} INFO - Started process (PID=373) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:40:54.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:40:54.369+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:40:54.369+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:40:54.539+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:40:54.560+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:40:54.560+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:40:54.581+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:40:54.581+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:40:54.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-14T22:41:24.755+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:41:24.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:41:24.759+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:41:24.758+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:41:24.962+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:41:24.988+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:41:24.988+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:41:25.014+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:41:25.013+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:41:25.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.293 seconds
[2024-09-14T22:41:55.165+0000] {processor.py:186} INFO - Started process (PID=397) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:41:55.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:41:55.168+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:41:55.168+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:41:55.351+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:41:55.373+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:41:55.373+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:41:55.396+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:41:55.396+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:41:55.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-14T22:42:25.573+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:42:25.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:42:25.576+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:42:25.576+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:42:25.761+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:42:25.785+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:42:25.785+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:42:25.807+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:42:25.807+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:42:25.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.272 seconds
[2024-09-14T22:42:56.070+0000] {processor.py:186} INFO - Started process (PID=421) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:42:56.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:42:56.073+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:42:56.072+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:42:56.257+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:42:56.279+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:42:56.279+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:42:56.301+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:42:56.301+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:42:56.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-09-14T22:43:26.975+0000] {processor.py:186} INFO - Started process (PID=433) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:43:26.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:43:26.979+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:43:26.979+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:43:27.165+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:43:27.187+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:43:27.187+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:43:27.210+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:43:27.210+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:43:27.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T22:43:57.289+0000] {processor.py:186} INFO - Started process (PID=445) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:43:57.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:43:57.292+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:43:57.292+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:43:57.479+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:43:57.501+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:43:57.500+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:43:57.523+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:43:57.522+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:43:57.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T22:44:28.470+0000] {processor.py:186} INFO - Started process (PID=457) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:44:28.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:44:28.473+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:44:28.472+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:44:28.648+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:44:28.670+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:44:28.670+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:44:28.694+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:44:28.693+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:44:28.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-14T22:44:58.769+0000] {processor.py:186} INFO - Started process (PID=469) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:44:58.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:44:58.773+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:44:58.773+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:44:58.956+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:44:58.980+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:44:58.980+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:44:59.002+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:44:59.002+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:44:59.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-14T22:45:29.194+0000] {processor.py:186} INFO - Started process (PID=481) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:45:29.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:45:29.198+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:45:29.197+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:45:29.384+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:45:29.406+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:45:29.406+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:45:29.429+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:45:29.429+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:45:29.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T22:45:59.576+0000] {processor.py:186} INFO - Started process (PID=493) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:45:59.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:45:59.579+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:45:59.579+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:45:59.766+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:45:59.788+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:45:59.788+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:45:59.811+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:45:59.811+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:45:59.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-09-14T22:46:29.974+0000] {processor.py:186} INFO - Started process (PID=505) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:46:29.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:46:29.977+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:46:29.976+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:46:30.162+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:46:30.185+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:46:30.184+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:46:30.207+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:46:30.207+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:46:30.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-09-14T22:47:00.967+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:47:00.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:47:00.970+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:47:00.970+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:47:01.161+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:47:01.183+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:47:01.183+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:47:01.206+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:47:01.206+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:47:01.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-09-14T22:47:31.400+0000] {processor.py:186} INFO - Started process (PID=529) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:47:31.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:47:31.405+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:47:31.404+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:47:31.598+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:47:31.623+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:47:31.623+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:47:31.647+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:47:31.647+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:47:31.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-09-14T22:48:01.878+0000] {processor.py:186} INFO - Started process (PID=541) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:48:01.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:48:01.882+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:48:01.881+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:48:02.059+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:48:02.082+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:48:02.082+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:48:02.105+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:48:02.104+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:48:02.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-14T22:48:32.247+0000] {processor.py:186} INFO - Started process (PID=554) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:48:32.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:48:32.250+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:48:32.250+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:48:32.438+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:48:32.460+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:48:32.460+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:48:32.484+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:48:32.484+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:48:32.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-09-14T22:49:03.437+0000] {processor.py:186} INFO - Started process (PID=566) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:49:03.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:49:03.446+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:49:03.445+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:49:03.701+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:49:03.724+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:49:03.724+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:49:03.750+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:49:03.750+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:49:03.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.347 seconds
[2024-09-14T22:49:34.722+0000] {processor.py:186} INFO - Started process (PID=578) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:49:34.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:49:34.726+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:49:34.726+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:49:34.913+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:49:34.936+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:49:34.936+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:49:34.959+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:49:34.959+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:49:34.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-14T22:50:05.134+0000] {processor.py:186} INFO - Started process (PID=590) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:50:05.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:50:05.137+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:50:05.136+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:50:05.330+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:50:05.353+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:50:05.353+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:50:05.377+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:50:05.377+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:50:05.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-09-14T22:50:35.476+0000] {processor.py:186} INFO - Started process (PID=602) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:50:35.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:50:35.480+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:50:35.480+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:50:35.664+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:50:35.687+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:50:35.687+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:50:35.711+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:50:35.711+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:50:35.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-09-14T22:51:06.529+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:51:06.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:51:06.533+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:51:06.532+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:51:06.717+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:51:06.740+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:51:06.739+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:51:06.763+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:51:06.763+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:51:06.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-09-14T22:51:37.502+0000] {processor.py:186} INFO - Started process (PID=627) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:51:37.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:51:37.506+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:51:37.505+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:51:37.687+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:51:37.709+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:51:37.709+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:51:37.731+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:51:37.731+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:51:37.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-14T22:52:08.472+0000] {processor.py:186} INFO - Started process (PID=639) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:52:08.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:52:08.476+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:52:08.476+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:52:08.657+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:52:08.679+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:52:08.679+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:52:08.701+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:52:08.700+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:52:08.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-14T22:52:38.793+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:52:38.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:52:38.796+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:52:38.796+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:52:38.986+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:52:39.009+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:52:39.009+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:52:39.032+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:52:39.032+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:52:39.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-14T22:53:09.213+0000] {processor.py:186} INFO - Started process (PID=663) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:53:09.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:53:09.216+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:53:09.216+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:53:09.396+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:53:09.417+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:53:09.417+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:53:09.440+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:53:09.439+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:53:09.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-09-14T22:53:39.551+0000] {processor.py:186} INFO - Started process (PID=675) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:53:39.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:53:39.556+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:53:39.554+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:53:39.745+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:53:39.769+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:53:39.768+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:53:39.795+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:53:39.795+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:53:39.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-09-14T22:54:10.029+0000] {processor.py:186} INFO - Started process (PID=687) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:54:10.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:54:10.032+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:54:10.032+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:54:10.215+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:54:10.239+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:54:10.239+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:54:10.261+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:54:10.260+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:54:10.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-14T22:54:41.095+0000] {processor.py:186} INFO - Started process (PID=699) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:54:41.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:54:41.098+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:54:41.098+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:54:41.283+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:54:41.307+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:54:41.307+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:54:41.331+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:54:41.331+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:54:41.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T22:55:11.446+0000] {processor.py:186} INFO - Started process (PID=711) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:55:11.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:55:11.450+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:55:11.449+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:55:11.641+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:55:11.664+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:55:11.664+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:55:11.689+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:55:11.688+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:55:11.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-09-14T22:55:41.778+0000] {processor.py:186} INFO - Started process (PID=723) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:55:41.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:55:41.783+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:55:41.782+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:55:41.969+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:55:41.991+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:55:41.991+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:55:42.015+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:55:42.014+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:55:42.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-09-14T22:56:12.768+0000] {processor.py:186} INFO - Started process (PID=735) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:56:12.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:56:12.772+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:56:12.772+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:56:12.954+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:56:12.975+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:56:12.975+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:56:12.997+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:56:12.997+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:56:13.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-09-14T22:56:43.090+0000] {processor.py:186} INFO - Started process (PID=746) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:56:43.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:56:43.093+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:56:43.092+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:56:43.279+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:56:43.303+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:56:43.302+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:56:43.324+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:56:43.324+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:56:43.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-14T22:57:14.105+0000] {processor.py:186} INFO - Started process (PID=757) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:57:14.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:57:14.108+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:57:14.108+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:57:14.293+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:57:14.317+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:57:14.317+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:57:14.339+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:57:14.339+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:57:14.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-14T22:57:44.551+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:57:44.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:57:44.554+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:57:44.553+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:57:44.737+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:57:44.758+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:57:44.758+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:57:44.782+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:57:44.781+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:57:44.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-14T22:58:14.913+0000] {processor.py:186} INFO - Started process (PID=781) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:58:14.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:58:14.917+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:58:14.917+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:58:15.104+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:58:15.126+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:58:15.126+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:58:15.150+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:58:15.150+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:58:15.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-09-14T22:58:45.247+0000] {processor.py:186} INFO - Started process (PID=793) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:58:45.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:58:45.251+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:58:45.251+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:58:45.435+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:58:45.457+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:58:45.457+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:58:45.483+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:58:45.483+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:58:45.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-14T22:59:15.751+0000] {processor.py:186} INFO - Started process (PID=805) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:59:15.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:59:15.754+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:59:15.754+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:59:15.940+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:59:15.963+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:59:15.963+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:59:15.985+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:59:15.985+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:59:16.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-14T22:59:46.165+0000] {processor.py:186} INFO - Started process (PID=817) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:59:46.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T22:59:46.169+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:59:46.168+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:59:46.357+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T22:59:46.378+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:59:46.378+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T22:59:46.401+0000] {logging_mixin.py:190} INFO - [2024-09-14T22:59:46.401+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T22:59:46.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T23:00:17.082+0000] {processor.py:186} INFO - Started process (PID=829) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:00:17.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:00:17.086+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:00:17.086+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:00:17.281+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:00:17.302+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:00:17.302+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:00:17.325+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:00:17.325+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:00:17.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-09-14T23:00:48.240+0000] {processor.py:186} INFO - Started process (PID=841) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:00:48.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:00:48.243+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:00:48.243+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:00:48.435+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:00:48.457+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:00:48.456+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:00:48.478+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:00:48.478+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:00:48.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-14T23:01:19.341+0000] {processor.py:186} INFO - Started process (PID=853) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:01:19.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:01:19.344+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:01:19.343+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:01:19.525+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:01:19.546+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:01:19.546+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:01:19.569+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:01:19.568+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:01:19.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-14T23:01:50.470+0000] {processor.py:186} INFO - Started process (PID=865) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:01:50.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:01:50.474+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:01:50.474+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:01:50.665+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:01:50.688+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:01:50.688+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:01:50.710+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:01:50.710+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:01:50.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-09-14T23:02:20.877+0000] {processor.py:186} INFO - Started process (PID=877) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:02:20.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:02:20.881+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:02:20.881+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:02:21.072+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:02:21.095+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:02:21.095+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:02:21.119+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:02:21.118+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:02:21.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-09-14T23:02:51.212+0000] {processor.py:186} INFO - Started process (PID=889) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:02:51.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:02:51.215+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:02:51.215+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:02:51.403+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:02:51.426+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:02:51.426+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:02:51.451+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:02:51.450+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:02:51.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-09-14T23:03:21.750+0000] {processor.py:186} INFO - Started process (PID=901) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:03:21.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:03:21.753+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:03:21.753+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:03:21.933+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:03:21.956+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:03:21.956+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:03:21.979+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:03:21.979+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:03:22.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-14T23:03:52.095+0000] {processor.py:186} INFO - Started process (PID=913) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:03:52.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:03:52.101+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:03:52.100+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:03:52.292+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:03:52.318+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:03:52.318+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:03:52.341+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:03:52.341+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:03:52.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-09-14T23:04:23.240+0000] {processor.py:186} INFO - Started process (PID=925) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:04:23.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:04:23.243+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:04:23.243+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:04:23.422+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:04:23.442+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:04:23.442+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:04:23.463+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:04:23.463+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:04:23.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-14T23:04:54.404+0000] {processor.py:186} INFO - Started process (PID=937) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:04:54.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:04:54.407+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:04:54.407+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:04:54.585+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:04:54.606+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:04:54.605+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:04:54.627+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:04:54.626+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:04:54.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-09-14T23:05:25.312+0000] {processor.py:186} INFO - Started process (PID=955) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:05:25.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:05:25.316+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:05:25.315+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:05:25.496+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:05:25.517+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:05:25.517+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:05:25.538+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:05:25.538+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:05:25.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-14T23:05:56.152+0000] {processor.py:186} INFO - Started process (PID=967) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:05:56.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:05:56.156+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:05:56.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:05:56.346+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:05:56.368+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:05:56.368+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:05:56.389+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:05:56.389+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:05:56.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-14T23:06:26.496+0000] {processor.py:186} INFO - Started process (PID=979) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:06:26.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:06:26.499+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:06:26.499+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:06:26.688+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:06:26.713+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:06:26.712+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:06:26.737+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:06:26.737+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:06:26.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-09-14T23:06:56.879+0000] {processor.py:186} INFO - Started process (PID=991) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:06:56.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:06:56.882+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:06:56.882+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:06:57.069+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:06:57.091+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:06:57.090+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:06:57.116+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:06:57.116+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:06:57.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-09-14T23:07:28.109+0000] {processor.py:186} INFO - Started process (PID=1003) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:07:28.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:07:28.112+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:07:28.112+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:07:28.291+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:07:28.315+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:07:28.314+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:07:28.336+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:07:28.336+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:07:28.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-14T23:07:58.498+0000] {processor.py:186} INFO - Started process (PID=1015) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:07:58.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:07:58.502+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:07:58.501+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:07:58.695+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:07:58.718+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:07:58.717+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:07:58.740+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:07:58.740+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:07:58.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.320 seconds
[2024-09-14T23:08:29.543+0000] {processor.py:186} INFO - Started process (PID=1027) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:08:29.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:08:29.547+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:08:29.547+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:08:29.730+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:08:29.751+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:08:29.751+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:08:29.774+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:08:29.773+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:08:29.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-14T23:09:00.673+0000] {processor.py:186} INFO - Started process (PID=1039) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:09:00.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:09:00.677+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:09:00.676+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:09:00.859+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:09:00.881+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:09:00.881+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:09:00.904+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:09:00.904+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:09:00.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-14T23:09:31.038+0000] {processor.py:186} INFO - Started process (PID=1051) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:09:31.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:09:31.043+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:09:31.042+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:09:31.225+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:09:31.246+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:09:31.246+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:09:31.268+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:09:31.268+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:09:31.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-14T23:10:01.349+0000] {processor.py:186} INFO - Started process (PID=1064) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:10:01.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:10:01.354+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:10:01.354+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:10:01.544+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:10:01.571+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:10:01.571+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:10:01.593+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:10:01.593+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:10:01.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-09-14T23:10:31.693+0000] {processor.py:186} INFO - Started process (PID=1076) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:10:31.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:10:31.696+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:10:31.695+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:10:31.888+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:10:31.910+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:10:31.910+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:10:31.932+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:10:31.932+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:10:31.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-09-14T23:11:02.687+0000] {processor.py:186} INFO - Started process (PID=1088) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:11:02.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:11:02.690+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:11:02.690+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:11:02.862+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:11:02.883+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:11:02.883+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:11:02.904+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:11:02.903+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:11:02.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-09-14T23:11:33.754+0000] {processor.py:186} INFO - Started process (PID=1100) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:11:33.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:11:33.757+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:11:33.756+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:11:33.930+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:11:33.952+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:11:33.952+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:11:33.974+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:11:33.973+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:11:33.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-14T23:12:04.170+0000] {processor.py:186} INFO - Started process (PID=1112) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:12:04.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:12:04.174+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:12:04.174+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:12:04.349+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:12:04.370+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:12:04.370+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:12:04.392+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:12:04.392+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:12:04.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-14T23:12:34.612+0000] {processor.py:186} INFO - Started process (PID=1124) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:12:34.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:12:34.615+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:12:34.615+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:12:34.791+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:12:34.813+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:12:34.813+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:12:34.835+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:12:34.835+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:12:34.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-14T23:13:05.397+0000] {processor.py:186} INFO - Started process (PID=1136) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:13:05.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:13:05.400+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:13:05.400+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:13:05.573+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:13:05.595+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:13:05.595+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:13:05.617+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:13:05.617+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:13:05.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-14T23:13:36.287+0000] {processor.py:186} INFO - Started process (PID=1149) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:13:36.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:13:36.290+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:13:36.290+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:13:36.475+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:13:36.496+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:13:36.496+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:13:36.518+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:13:36.517+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:13:36.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-09-14T23:14:06.647+0000] {processor.py:186} INFO - Started process (PID=1161) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:14:06.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:14:06.650+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:14:06.649+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:14:06.832+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:14:06.854+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:14:06.853+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:14:06.877+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:14:06.876+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:14:06.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-14T23:14:37.127+0000] {processor.py:186} INFO - Started process (PID=1173) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:14:37.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:14:37.130+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:14:37.130+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:14:37.312+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:14:37.334+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:14:37.334+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:14:37.357+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:14:37.357+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:14:37.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-09-14T23:15:07.635+0000] {processor.py:186} INFO - Started process (PID=1184) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:15:07.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:15:07.638+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:15:07.638+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:15:07.824+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:15:07.846+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:15:07.846+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:15:07.869+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:15:07.869+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:15:07.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-09-14T23:15:38.384+0000] {processor.py:186} INFO - Started process (PID=1196) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:15:38.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:15:38.387+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:15:38.387+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:15:38.572+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:15:38.595+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:15:38.595+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:15:38.617+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:15:38.617+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:15:38.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-14T23:16:09.222+0000] {processor.py:186} INFO - Started process (PID=1208) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:16:09.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:16:09.226+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:16:09.225+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:16:09.411+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:16:09.432+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:16:09.431+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:16:09.453+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:16:09.453+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:16:09.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-14T23:16:40.019+0000] {processor.py:186} INFO - Started process (PID=1220) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:16:40.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:16:40.024+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:16:40.024+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:16:40.213+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:16:40.235+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:16:40.235+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:16:40.257+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:16:40.257+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:16:40.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-09-14T23:17:10.325+0000] {processor.py:186} INFO - Started process (PID=1232) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:17:10.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:17:10.328+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:17:10.328+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:17:10.506+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:17:10.527+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:17:10.526+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:17:10.549+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:17:10.549+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:17:10.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-14T23:17:40.858+0000] {processor.py:186} INFO - Started process (PID=1244) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:17:40.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:17:40.861+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:17:40.861+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:17:41.048+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:17:41.073+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:17:41.073+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:17:41.095+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:17:41.095+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:17:41.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-09-14T23:18:11.796+0000] {processor.py:186} INFO - Started process (PID=1256) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:18:11.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:18:11.800+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:18:11.800+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:18:11.986+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:18:12.009+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:18:12.009+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:18:12.034+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:18:12.034+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:18:12.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-14T23:18:42.739+0000] {processor.py:186} INFO - Started process (PID=1268) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:18:42.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:18:42.742+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:18:42.742+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:18:42.930+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:18:42.971+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:18:42.971+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:18:43.007+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:18:43.007+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:18:43.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.300 seconds
[2024-09-14T23:19:13.299+0000] {processor.py:186} INFO - Started process (PID=1280) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:19:13.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:19:13.302+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:19:13.301+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:19:13.480+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:19:13.502+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:19:13.502+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:19:13.523+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:19:13.523+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:19:13.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-09-14T23:19:44.192+0000] {processor.py:186} INFO - Started process (PID=1292) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:19:44.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:19:44.196+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:19:44.195+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:19:44.375+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:19:44.397+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:19:44.397+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:19:44.419+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:19:44.419+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:19:44.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-14T23:20:14.496+0000] {processor.py:186} INFO - Started process (PID=1304) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:20:14.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:20:14.500+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:20:14.499+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:20:14.684+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:20:14.706+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:20:14.706+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:20:14.729+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:20:14.729+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:20:14.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-09-14T23:20:44.939+0000] {processor.py:186} INFO - Started process (PID=1316) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:20:44.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:20:44.943+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:20:44.943+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:20:45.126+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:20:45.150+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:20:45.150+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:20:45.173+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:20:45.172+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:20:45.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-14T23:21:15.787+0000] {processor.py:186} INFO - Started process (PID=1328) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:21:15.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:21:15.791+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:21:15.791+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:21:15.972+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:21:15.996+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:21:15.995+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:21:16.018+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:21:16.018+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:21:16.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-14T23:21:46.482+0000] {processor.py:186} INFO - Started process (PID=1341) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:21:46.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:21:46.485+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:21:46.485+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:21:46.657+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:21:46.679+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:21:46.678+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:21:46.700+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:21:46.700+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:21:46.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-14T23:22:17.266+0000] {processor.py:186} INFO - Started process (PID=1353) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:22:17.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:22:17.269+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:22:17.269+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:22:17.445+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:22:17.466+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:22:17.466+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:22:17.488+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:22:17.488+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:22:17.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-14T23:22:47.650+0000] {processor.py:186} INFO - Started process (PID=1365) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:22:47.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:22:47.654+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:22:47.654+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:22:47.830+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:22:47.851+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:22:47.851+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:22:47.875+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:22:47.875+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:22:47.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-14T23:23:18.029+0000] {processor.py:186} INFO - Started process (PID=1377) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:23:18.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:23:18.032+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:23:18.032+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:23:18.213+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:23:18.235+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:23:18.235+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:23:18.258+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:23:18.258+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:23:18.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-14T23:23:48.450+0000] {processor.py:186} INFO - Started process (PID=1390) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:23:48.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:23:48.453+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:23:48.453+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:23:48.628+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:23:48.650+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:23:48.650+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:23:48.672+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:23:48.671+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:23:48.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-14T23:24:18.777+0000] {processor.py:186} INFO - Started process (PID=1402) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:24:18.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:24:18.781+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:24:18.780+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:24:19.023+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:24:19.044+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:24:19.043+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:24:19.065+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:24:19.065+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:24:19.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.311 seconds
[2024-09-14T23:24:49.640+0000] {processor.py:186} INFO - Started process (PID=1414) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:24:49.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:24:49.644+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:24:49.643+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:24:49.821+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:24:49.842+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:24:49.842+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:24:49.864+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:24:49.863+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:24:49.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-14T23:25:20.551+0000] {processor.py:186} INFO - Started process (PID=1426) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:25:20.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:25:20.554+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:25:20.553+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:25:20.736+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:25:20.758+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:25:20.758+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:25:20.780+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:25:20.779+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:25:20.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-14T23:25:51.242+0000] {processor.py:186} INFO - Started process (PID=1438) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:25:51.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:25:51.245+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:25:51.245+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:25:51.425+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:25:51.448+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:25:51.448+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:25:51.472+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:25:51.471+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:25:51.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-09-14T23:26:21.939+0000] {processor.py:186} INFO - Started process (PID=1450) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:26:21.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:26:21.942+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:26:21.942+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:26:22.127+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:26:22.151+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:26:22.151+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:26:22.173+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:26:22.173+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:26:22.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-09-14T23:26:52.862+0000] {processor.py:186} INFO - Started process (PID=1462) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:26:52.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:26:52.866+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:26:52.866+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:26:53.042+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:26:53.065+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:26:53.065+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:26:53.087+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:26:53.086+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:26:53.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-14T23:27:23.650+0000] {processor.py:186} INFO - Started process (PID=1475) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:27:23.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:27:23.655+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:27:23.654+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:27:23.833+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:27:23.855+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:27:23.855+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:27:23.876+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:27:23.876+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:27:23.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-14T23:27:54.484+0000] {processor.py:186} INFO - Started process (PID=1487) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:27:54.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:27:54.487+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:27:54.486+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:27:54.668+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:27:54.689+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:27:54.688+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:27:54.710+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:27:54.710+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:27:54.730+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-14T23:28:24.811+0000] {processor.py:186} INFO - Started process (PID=1499) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:28:24.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:28:24.814+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:28:24.814+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:28:24.994+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:28:25.016+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:28:25.016+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:28:25.039+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:28:25.039+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:28:25.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-14T23:28:55.187+0000] {processor.py:186} INFO - Started process (PID=1511) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:28:55.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:28:55.190+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:28:55.190+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:28:55.369+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:28:55.392+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:28:55.391+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:28:55.414+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:28:55.414+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:28:55.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-09-14T23:29:25.504+0000] {processor.py:186} INFO - Started process (PID=1522) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:29:25.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:29:25.508+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:29:25.507+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:29:25.685+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:29:25.708+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:29:25.707+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:29:25.731+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:29:25.730+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:29:25.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-14T23:29:56.343+0000] {processor.py:186} INFO - Started process (PID=1534) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:29:56.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:29:56.347+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:29:56.346+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:29:56.532+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:29:56.556+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:29:56.556+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:29:56.578+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:29:56.578+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:29:56.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-09-14T23:30:27.061+0000] {processor.py:186} INFO - Started process (PID=1552) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:30:27.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:30:27.064+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:30:27.063+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:30:27.262+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:30:27.283+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:30:27.283+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:30:27.305+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:30:27.305+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:30:27.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-09-14T23:30:57.390+0000] {processor.py:186} INFO - Started process (PID=1564) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:30:57.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:30:57.393+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:30:57.393+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:30:57.569+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:30:57.591+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:30:57.591+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:30:57.613+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:30:57.613+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:30:57.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-14T23:31:27.867+0000] {processor.py:186} INFO - Started process (PID=1576) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:31:27.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:31:27.871+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:31:27.871+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:31:28.051+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:31:28.073+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:31:28.073+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:31:28.095+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:31:28.095+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:31:28.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-14T23:31:58.633+0000] {processor.py:186} INFO - Started process (PID=1588) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:31:58.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:31:58.637+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:31:58.636+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:31:58.820+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:31:58.843+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:31:58.842+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:31:58.864+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:31:58.864+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:31:58.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-09-14T23:32:29.420+0000] {processor.py:186} INFO - Started process (PID=1600) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:32:29.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:32:29.424+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:32:29.423+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:32:29.598+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:32:29.620+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:32:29.620+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:32:29.642+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:32:29.641+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:32:29.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-14T23:33:00.178+0000] {processor.py:186} INFO - Started process (PID=1611) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:33:00.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:33:00.181+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:33:00.181+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:33:00.364+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:33:00.386+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:33:00.385+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:33:00.407+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:33:00.407+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:33:00.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-14T23:33:30.962+0000] {processor.py:186} INFO - Started process (PID=1623) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:33:30.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:33:30.966+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:33:30.966+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:33:31.149+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:33:31.170+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:33:31.170+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:33:31.193+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:33:31.192+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:33:31.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-14T23:34:01.825+0000] {processor.py:186} INFO - Started process (PID=1635) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:34:01.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:34:01.829+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:34:01.829+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:34:02.004+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:34:02.026+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:34:02.026+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:34:02.049+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:34:02.048+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:34:02.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-14T23:34:32.196+0000] {processor.py:186} INFO - Started process (PID=1647) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:34:32.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:34:32.199+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:34:32.198+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:34:32.372+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:34:32.394+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:34:32.393+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:34:32.415+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:34:32.415+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:34:32.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-09-14T23:35:02.769+0000] {processor.py:186} INFO - Started process (PID=1659) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:35:02.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:35:02.772+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:35:02.772+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:35:02.945+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:35:02.965+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:35:02.965+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:35:02.986+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:35:02.986+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:35:03.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.241 seconds
[2024-09-14T23:35:33.629+0000] {processor.py:186} INFO - Started process (PID=1671) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:35:33.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:35:33.633+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:35:33.632+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:35:33.798+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:35:33.819+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:35:33.819+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:35:33.840+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:35:33.840+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:35:33.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-09-14T23:36:04.581+0000] {processor.py:186} INFO - Started process (PID=1683) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:36:04.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:36:04.584+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:36:04.584+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:36:04.755+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:36:04.776+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:36:04.776+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:36:04.796+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:36:04.796+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:36:04.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-14T23:36:34.925+0000] {processor.py:186} INFO - Started process (PID=1696) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:36:34.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:36:34.928+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:36:34.928+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:36:35.103+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:36:35.124+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:36:35.124+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:36:35.146+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:36:35.146+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:36:35.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-14T23:37:05.395+0000] {processor.py:186} INFO - Started process (PID=1708) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:37:05.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:37:05.398+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:37:05.398+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:37:05.571+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:37:05.593+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:37:05.593+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:37:05.614+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:37:05.614+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:37:05.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-09-14T23:37:36.142+0000] {processor.py:186} INFO - Started process (PID=1720) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:37:36.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:37:36.146+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:37:36.145+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:37:36.319+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:37:36.341+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:37:36.341+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:37:36.361+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:37:36.361+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:37:36.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-09-14T23:38:06.865+0000] {processor.py:186} INFO - Started process (PID=1732) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:38:06.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:38:06.868+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:38:06.868+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:38:07.041+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:38:07.062+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:38:07.062+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:38:07.082+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:38:07.082+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:38:07.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-09-14T23:38:37.635+0000] {processor.py:186} INFO - Started process (PID=1744) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:38:37.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:38:37.638+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:38:37.638+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:38:37.811+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:38:37.832+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:38:37.832+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:38:37.854+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:38:37.854+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:38:37.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-09-14T23:39:08.511+0000] {processor.py:186} INFO - Started process (PID=1756) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:39:08.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:39:08.514+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:39:08.514+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:39:08.682+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:39:08.703+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:39:08.703+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:39:08.724+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:39:08.723+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:39:08.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-14T23:39:39.430+0000] {processor.py:186} INFO - Started process (PID=1769) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:39:39.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:39:39.433+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:39:39.433+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:39:39.602+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:39:39.622+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:39:39.622+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:39:39.643+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:39:39.643+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:39:39.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.236 seconds
[2024-09-14T23:40:10.235+0000] {processor.py:186} INFO - Started process (PID=1781) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:40:10.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:40:10.238+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:40:10.238+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:40:10.410+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:40:10.431+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:40:10.431+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:40:10.451+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:40:10.451+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:40:10.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.238 seconds
[2024-09-14T23:40:41.100+0000] {processor.py:186} INFO - Started process (PID=1793) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:40:41.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:40:41.104+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:40:41.103+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:40:41.276+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:40:41.298+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:40:41.298+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:40:41.319+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:40:41.319+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:40:41.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-14T23:41:11.631+0000] {processor.py:186} INFO - Started process (PID=1806) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:41:11.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:41:11.634+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:41:11.634+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:41:11.805+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:41:11.825+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:41:11.825+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:41:11.846+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:41:11.846+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:41:11.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-14T23:41:42.495+0000] {processor.py:186} INFO - Started process (PID=1816) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:41:42.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:41:42.499+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:41:42.498+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:41:42.670+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:41:42.691+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:41:42.691+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:41:42.712+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:41:42.712+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:41:42.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-14T23:42:13.654+0000] {processor.py:186} INFO - Started process (PID=1828) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:42:13.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:42:13.659+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:42:13.659+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:42:13.844+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:42:13.866+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:42:13.866+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:42:13.890+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:42:13.890+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:42:13.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-09-14T23:42:43.986+0000] {processor.py:186} INFO - Started process (PID=1840) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:42:43.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:42:43.989+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:42:43.989+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:42:44.158+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:42:44.179+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:42:44.179+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:42:44.200+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:42:44.200+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:42:44.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.238 seconds
[2024-09-14T23:43:14.362+0000] {processor.py:186} INFO - Started process (PID=1852) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:43:14.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:43:14.366+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:43:14.365+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:43:14.544+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:43:14.564+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:43:14.564+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:43:14.584+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:43:14.584+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:43:14.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-14T23:43:44.712+0000] {processor.py:186} INFO - Started process (PID=1864) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:43:44.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:43:44.716+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:43:44.715+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:43:44.886+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:43:44.906+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:43:44.906+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:43:44.927+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:43:44.926+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:43:44.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.236 seconds
[2024-09-14T23:44:15.123+0000] {processor.py:186} INFO - Started process (PID=1876) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:44:15.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:44:15.126+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:44:15.126+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:44:15.294+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:44:15.315+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:44:15.315+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:44:15.336+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:44:15.336+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:44:15.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.238 seconds
[2024-09-14T23:44:46.287+0000] {processor.py:186} INFO - Started process (PID=1888) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:44:46.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:44:46.292+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:44:46.291+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:44:46.455+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:44:46.475+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:44:46.475+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:44:46.496+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:44:46.496+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:44:46.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.234 seconds
[2024-09-14T23:45:16.659+0000] {processor.py:186} INFO - Started process (PID=1900) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:45:16.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:45:16.662+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:45:16.662+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:45:16.826+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:45:16.847+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:45:16.847+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:45:16.867+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:45:16.867+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:45:16.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.239 seconds
[2024-09-14T23:45:47.016+0000] {processor.py:186} INFO - Started process (PID=1912) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:45:47.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:45:47.019+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:45:47.019+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:45:47.189+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:45:47.209+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:45:47.209+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:45:47.229+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:45:47.229+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:45:47.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-09-14T23:46:18.267+0000] {processor.py:186} INFO - Started process (PID=1924) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:46:18.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:46:18.270+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:46:18.269+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:46:18.442+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:46:18.462+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:46:18.462+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:46:18.482+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:46:18.482+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:46:18.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.238 seconds
[2024-09-14T23:46:48.629+0000] {processor.py:186} INFO - Started process (PID=1936) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:46:48.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:46:48.632+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:46:48.632+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:46:48.805+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:46:48.825+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:46:48.825+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:46:48.846+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:46:48.846+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:46:49.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.437 seconds
[2024-09-14T23:47:19.872+0000] {processor.py:186} INFO - Started process (PID=1948) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:47:19.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:47:19.875+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:47:19.875+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:47:20.047+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:47:20.068+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:47:20.067+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:47:20.089+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:47:20.089+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:47:20.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.307 seconds
[2024-09-14T23:47:50.964+0000] {processor.py:186} INFO - Started process (PID=1960) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:47:50.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:47:50.968+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:47:50.968+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:47:51.139+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:47:51.160+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:47:51.160+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:47:51.180+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:47:51.180+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:47:51.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.238 seconds
[2024-09-14T23:48:21.274+0000] {processor.py:186} INFO - Started process (PID=1972) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:48:21.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:48:21.277+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:48:21.277+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:48:21.456+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:48:21.477+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:48:21.477+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:48:21.498+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:48:21.498+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:48:21.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-14T23:56:16.099+0000] {processor.py:186} INFO - Started process (PID=1984) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:56:16.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:56:16.105+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:56:16.104+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:56:16.476+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:56:16.505+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:56:16.504+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:56:16.531+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:56:16.531+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:56:16.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.476 seconds
[2024-09-14T23:56:47.118+0000] {processor.py:186} INFO - Started process (PID=1997) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:56:47.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:56:47.121+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:56:47.120+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:56:47.334+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:56:47.354+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:56:47.354+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:56:47.376+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:56:47.376+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:56:47.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.284 seconds
[2024-09-14T23:57:17.472+0000] {processor.py:186} INFO - Started process (PID=2010) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:57:17.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:57:17.476+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:57:17.475+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:57:17.651+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:57:17.671+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:57:17.671+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:57:17.693+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:57:17.693+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:57:17.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-09-14T23:57:47.995+0000] {processor.py:186} INFO - Started process (PID=2021) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:57:47.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:57:47.998+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:57:47.998+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:57:48.185+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:57:48.208+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:57:48.207+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:57:48.236+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:57:48.235+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:57:48.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-09-14T23:58:18.449+0000] {processor.py:186} INFO - Started process (PID=2035) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:58:18.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:58:18.453+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:58:18.453+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:58:18.662+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:58:18.686+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:58:18.685+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:58:18.711+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:58:18.710+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:58:18.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.292 seconds
[2024-09-14T23:58:49.317+0000] {processor.py:186} INFO - Started process (PID=2046) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:58:49.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:58:49.320+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:58:49.320+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:58:49.512+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:58:49.534+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:58:49.534+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:58:49.559+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:58:49.558+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:58:49.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-09-14T23:59:19.939+0000] {processor.py:186} INFO - Started process (PID=2058) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:59:19.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:59:19.943+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:59:19.943+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:59:20.136+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:59:20.160+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:59:20.159+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:59:20.182+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:59:20.182+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:59:20.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-09-14T23:59:50.546+0000] {processor.py:186} INFO - Started process (PID=2070) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:59:50.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-14T23:59:50.549+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:59:50.549+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:59:50.766+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-14T23:59:50.787+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:59:50.787+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-14T23:59:50.809+0000] {logging_mixin.py:190} INFO - [2024-09-14T23:59:50.809+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-14 00:00:00+00:00, run_after=2024-09-15 00:00:00+00:00
[2024-09-14T23:59:50.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.293 seconds
