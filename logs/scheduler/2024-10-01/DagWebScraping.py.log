[2024-10-01T00:00:11.757+0000] {processor.py:186} INFO - Started process (PID=17138) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:11.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:00:11.760+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:00:11.760+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:11.953+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:00:11.949+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 60, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:00:11.954+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:11.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.226 seconds
[2024-10-01T00:00:26.380+0000] {processor.py:186} INFO - Started process (PID=17153) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:26.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:00:26.382+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:00:26.382+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:26.590+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:00:26.585+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 61, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:00:26.591+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:26.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-10-01T00:00:36.881+0000] {processor.py:186} INFO - Started process (PID=17159) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:36.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:00:36.884+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:00:36.884+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:37.083+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:00:37.078+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 61, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:00:37.084+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:37.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.235 seconds
[2024-10-01T00:00:58.336+0000] {processor.py:186} INFO - Started process (PID=17182) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:58.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:00:58.338+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:00:58.338+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:58.532+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:00:58.527+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 61, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:00:58.533+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:00:58.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-10-01T00:01:03.457+0000] {processor.py:186} INFO - Started process (PID=17183) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:01:03.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:01:03.460+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:01:03.459+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:01:03.659+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:01:03.655+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 61, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:01:03.660+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:01:03.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.232 seconds
[2024-10-01T00:01:33.786+0000] {processor.py:186} INFO - Started process (PID=17206) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:01:33.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:01:33.788+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:01:33.788+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:01:33.976+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:01:33.971+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 61, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:01:33.977+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:01:33.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-10-01T00:01:56.312+0000] {processor.py:186} INFO - Started process (PID=17221) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:01:56.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:01:56.315+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:01:56.315+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:01:56.510+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:01:56.506+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 60, in <module>
    Await_file_Transformed.poke()
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:01:56.511+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:01:56.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T00:02:04.945+0000] {processor.py:186} INFO - Started process (PID=17230) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:04.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:02:04.947+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:02:04.947+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:05.143+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:02:05.139+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 62, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:02:05.144+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:05.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.226 seconds
[2024-10-01T00:02:10.292+0000] {processor.py:186} INFO - Started process (PID=17231) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:10.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:02:10.294+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:02:10.294+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:10.501+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:02:10.496+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 62, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:02:10.502+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:10.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.238 seconds
[2024-10-01T00:02:13.075+0000] {processor.py:186} INFO - Started process (PID=17234) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:13.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:02:13.078+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:02:13.077+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:13.295+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:02:13.291+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 62, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:02:13.296+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:13.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-10-01T00:02:43.466+0000] {processor.py:186} INFO - Started process (PID=17257) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:43.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:02:43.478+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:02:43.477+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:44.049+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:02:43.960+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 62, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:02:44.067+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:02:44.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.692 seconds
[2024-10-01T00:03:14.339+0000] {processor.py:186} INFO - Started process (PID=17280) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:03:14.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:03:14.343+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:03:14.343+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:03:14.623+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:03:14.618+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 62, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:03:14.624+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:03:14.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.331 seconds
[2024-10-01T00:03:33.505+0000] {processor.py:186} INFO - Started process (PID=17301) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:03:33.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:03:33.507+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:03:33.507+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:03:33.704+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:03:33.699+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 62, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:03:33.705+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:03:33.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.312 seconds
[2024-10-01T00:03:43.868+0000] {processor.py:186} INFO - Started process (PID=17302) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:03:43.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:03:43.871+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:03:43.871+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:03:44.062+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:03:44.057+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 62, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:03:44.063+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:03:44.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T00:04:14.564+0000] {processor.py:186} INFO - Started process (PID=17325) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:04:14.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:04:14.567+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:04:14.566+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:04:14.754+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:04:14.749+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 62, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:04:14.755+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:04:14.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-10-01T00:04:27.406+0000] {processor.py:186} INFO - Started process (PID=17333) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:04:27.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:04:27.409+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:04:27.408+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:04:27.604+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:04:27.599+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 67, in <module>
    task_file_exists = PythonOperator(
                       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:04:27.605+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:04:27.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.228 seconds
[2024-10-01T00:04:58.555+0000] {processor.py:186} INFO - Started process (PID=17363) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:04:58.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:04:58.557+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:04:58.557+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:04:58.751+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:04:58.746+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 67, in <module>
    task_file_exists = PythonOperator(
                       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:04:58.752+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:04:58.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
[2024-10-01T00:05:18.801+0000] {processor.py:186} INFO - Started process (PID=17374) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:05:18.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:05:18.804+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:05:18.803+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:05:18.995+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:05:18.991+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 67, in <module>
    task_file_exists = PythonOperator(
                       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:05:18.996+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:05:19.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T00:05:44.458+0000] {processor.py:186} INFO - Started process (PID=17395) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:05:44.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:05:44.461+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:05:44.461+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:05:44.658+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:05:44.654+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 67, in <module>
    task_file_exists = PythonOperator(
                       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:05:44.659+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:05:44.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.230 seconds
[2024-10-01T00:05:46.685+0000] {processor.py:186} INFO - Started process (PID=17396) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:05:46.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:05:46.688+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:05:46.687+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:05:46.892+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:05:46.887+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 67, in <module>
    task_file_exists = PythonOperator(
                       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:05:46.893+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:05:46.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.232 seconds
[2024-10-01T00:06:08.491+0000] {processor.py:186} INFO - Started process (PID=17419) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:06:08.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:06:08.493+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:06:08.493+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:06:08.709+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:06:08.697+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 72, in <module>
    Create_Container_Raw >> Web_Extraction  >> Create_Container_Silver  >> Spark_Transformation >> Await_file_Transformed  >> task_file_exists
                                                                                                                              ^^^^^^^^^^^^^^^^
NameError: name 'task_file_exists' is not defined
[2024-10-01T00:06:08.718+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:06:08.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T00:06:39.138+0000] {processor.py:186} INFO - Started process (PID=17442) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:06:39.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:06:39.141+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:06:39.141+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:06:39.333+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:06:39.322+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 72, in <module>
    Create_Container_Raw >> Web_Extraction  >> Create_Container_Silver  >> Spark_Transformation >> Await_file_Transformed  >> task_file_exists
                                                                                                                              ^^^^^^^^^^^^^^^^
NameError: name 'task_file_exists' is not defined
[2024-10-01T00:06:39.342+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:06:39.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.232 seconds
[2024-10-01T00:06:51.711+0000] {processor.py:186} INFO - Started process (PID=17445) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:06:51.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:06:51.713+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:06:51.713+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:06:51.906+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:06:52.012+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:06:52.012+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T00:06:52.024+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:06:52.024+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T00:06:52.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.347 seconds
[2024-10-01T00:07:13.692+0000] {processor.py:186} INFO - Started process (PID=17466) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:13.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:07:13.694+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:13.694+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:13.893+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:13.905+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:13.904+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T00:07:13.920+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:13.920+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T00:07:13.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T00:07:17.824+0000] {processor.py:186} INFO - Started process (PID=17467) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:17.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:07:17.828+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:17.827+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:18.029+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:18.039+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:18.039+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T00:07:18.054+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:18.054+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T00:07:18.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T00:07:22.172+0000] {processor.py:186} INFO - Started process (PID=17468) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:22.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:07:22.174+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:22.174+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:22.373+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:22.369+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 65, in <module>
    task_file_exists = PythonOperator(
                       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:07:22.374+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:22.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.230 seconds
[2024-10-01T00:07:26.645+0000] {processor.py:186} INFO - Started process (PID=17472) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:26.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:07:26.654+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:26.653+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:26.885+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:26.880+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 65, in <module>
    task_file_exists = PythonOperator(
                       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:07:26.887+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:26.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.293 seconds
[2024-10-01T00:07:32.242+0000] {processor.py:186} INFO - Started process (PID=17485) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:32.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:07:32.245+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:32.245+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:32.448+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:32.444+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 65, in <module>
    task_file_exists = PythonOperator(
                       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T00:07:32.448+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:32.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.231 seconds
[2024-10-01T00:07:40.019+0000] {processor.py:186} INFO - Started process (PID=17493) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:40.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:07:40.021+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:40.021+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:40.226+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:40.247+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:40.247+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T00:07:40.263+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:40.263+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T00:07:40.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.279 seconds
[2024-10-01T00:07:55.230+0000] {processor.py:186} INFO - Started process (PID=17497) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:55.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:07:55.234+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:55.234+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:55.431+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:07:55.451+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:55.451+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T00:07:55.466+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:07:55.466+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T00:07:55.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.280 seconds
[2024-10-01T00:08:09.512+0000] {processor.py:186} INFO - Started process (PID=17517) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:08:09.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:08:09.514+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:08:09.514+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:08:09.736+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:08:09.733+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:08:09.737+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:08:09.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-10-01T00:08:39.823+0000] {processor.py:186} INFO - Started process (PID=17540) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:08:39.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:08:39.826+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:08:39.826+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:08:40.028+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:08:40.023+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:08:40.029+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:08:40.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.232 seconds
[2024-10-01T00:09:10.494+0000] {processor.py:186} INFO - Started process (PID=17563) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:09:10.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:09:10.498+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:09:10.497+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:09:10.711+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:09:10.703+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:09:10.713+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:09:10.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-10-01T00:09:41.223+0000] {processor.py:186} INFO - Started process (PID=17586) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:09:41.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:09:41.225+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:09:41.225+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:09:41.410+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:09:41.405+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:09:41.411+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:09:41.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-10-01T00:10:11.812+0000] {processor.py:186} INFO - Started process (PID=17609) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:10:11.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:10:11.814+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:10:11.814+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:10:12.004+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:10:12.000+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:10:12.005+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:10:12.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-10-01T00:10:42.350+0000] {processor.py:186} INFO - Started process (PID=17632) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:10:42.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:10:42.352+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:10:42.352+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:10:42.537+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:10:42.533+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:10:42.538+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:10:42.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-10-01T00:11:12.978+0000] {processor.py:186} INFO - Started process (PID=17655) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:11:12.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:11:12.981+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:11:12.980+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:11:13.168+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:11:13.165+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:11:13.170+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:11:13.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-10-01T00:11:43.402+0000] {processor.py:186} INFO - Started process (PID=17678) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:11:43.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:11:43.404+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:11:43.404+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:11:43.597+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:11:43.593+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:11:43.598+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:11:43.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.226 seconds
[2024-10-01T00:12:13.778+0000] {processor.py:186} INFO - Started process (PID=17701) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:12:13.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:12:13.781+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:12:13.780+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:12:13.966+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:12:13.962+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:12:13.967+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:12:13.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T00:12:44.057+0000] {processor.py:186} INFO - Started process (PID=17724) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:12:44.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:12:44.059+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:12:44.059+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:12:44.250+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:12:44.246+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:12:44.252+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:12:44.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.220 seconds
[2024-10-01T00:13:14.363+0000] {processor.py:186} INFO - Started process (PID=17747) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:13:14.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:13:14.366+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:13:14.365+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:13:14.553+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:13:14.549+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:13:14.555+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:13:14.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.220 seconds
[2024-10-01T00:13:44.703+0000] {processor.py:186} INFO - Started process (PID=17770) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:13:44.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:13:44.706+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:13:44.705+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:13:44.891+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:13:44.887+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:13:44.893+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:13:44.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-10-01T00:14:15.760+0000] {processor.py:186} INFO - Started process (PID=17793) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:14:15.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:14:15.763+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:14:15.763+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:14:15.957+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:14:15.952+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:14:15.958+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:14:15.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
[2024-10-01T00:14:46.439+0000] {processor.py:186} INFO - Started process (PID=17816) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:14:46.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:14:46.441+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:14:46.441+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:14:46.631+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:14:46.627+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:14:46.633+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:14:46.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-10-01T00:15:17.140+0000] {processor.py:186} INFO - Started process (PID=17839) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:15:17.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:15:17.143+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:15:17.143+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:15:17.331+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:15:17.327+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:15:17.332+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:15:17.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-10-01T00:15:47.645+0000] {processor.py:186} INFO - Started process (PID=17862) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:15:47.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:15:47.648+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:15:47.648+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:15:47.838+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:15:47.834+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:15:47.839+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:15:47.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.222 seconds
[2024-10-01T00:16:18.233+0000] {processor.py:186} INFO - Started process (PID=17885) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:16:18.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:16:18.235+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:16:18.235+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:16:18.424+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:16:18.421+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:16:18.426+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:16:18.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.220 seconds
[2024-10-01T00:16:48.891+0000] {processor.py:186} INFO - Started process (PID=17908) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:16:48.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:16:48.893+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:16:48.893+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:16:49.079+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:16:49.075+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:16:49.080+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:16:49.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-10-01T00:17:19.370+0000] {processor.py:186} INFO - Started process (PID=17931) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:17:19.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:17:19.372+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:17:19.372+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:17:19.578+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:17:19.575+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:17:19.580+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:17:19.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-10-01T00:17:50.184+0000] {processor.py:186} INFO - Started process (PID=17954) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:17:50.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:17:50.186+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:17:50.186+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:17:50.373+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:17:50.369+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:17:50.374+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:17:50.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T00:18:21.125+0000] {processor.py:186} INFO - Started process (PID=17977) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:18:21.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:18:21.129+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:18:21.128+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:18:21.333+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:18:21.329+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:18:21.334+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:18:21.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-10-01T00:18:51.469+0000] {processor.py:186} INFO - Started process (PID=18000) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:18:51.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:18:51.471+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:18:51.471+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:18:51.661+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:18:51.657+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:18:51.663+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:18:51.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-10-01T00:19:22.339+0000] {processor.py:186} INFO - Started process (PID=18023) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:19:22.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:19:22.343+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:19:22.342+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:19:22.531+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:19:22.528+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:19:22.533+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:19:22.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T00:19:52.922+0000] {processor.py:186} INFO - Started process (PID=18046) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:19:52.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:19:52.924+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:19:52.924+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:19:53.111+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:19:53.107+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:19:53.112+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:19:53.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T00:20:23.647+0000] {processor.py:186} INFO - Started process (PID=18069) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:20:23.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:20:23.650+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:20:23.650+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:20:23.832+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:20:23.828+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:20:23.834+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:20:23.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.214 seconds
[2024-10-01T00:20:54.371+0000] {processor.py:186} INFO - Started process (PID=18092) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:20:54.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:20:54.373+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:20:54.373+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:20:54.560+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:20:54.557+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:20:54.562+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:20:54.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-10-01T00:21:25.084+0000] {processor.py:186} INFO - Started process (PID=18115) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:21:25.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:21:25.087+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:21:25.087+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:21:25.273+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:21:25.269+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:21:25.275+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:21:25.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-10-01T00:21:55.408+0000] {processor.py:186} INFO - Started process (PID=18138) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:21:55.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:21:55.410+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:21:55.410+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:21:55.593+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:21:55.589+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:21:55.594+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:21:55.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-10-01T00:22:25.693+0000] {processor.py:186} INFO - Started process (PID=18161) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:22:25.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:22:25.709+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:22:25.708+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:22:25.899+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:22:25.896+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:22:25.900+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:22:25.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.232 seconds
[2024-10-01T00:22:56.148+0000] {processor.py:186} INFO - Started process (PID=18184) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:22:56.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:22:56.151+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:22:56.150+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:22:56.336+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:22:56.332+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:22:56.337+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:22:56.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-10-01T00:23:26.553+0000] {processor.py:186} INFO - Started process (PID=18207) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:23:26.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:23:26.556+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:23:26.555+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:23:26.744+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:23:26.740+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:23:26.745+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:23:26.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-10-01T00:23:57.326+0000] {processor.py:186} INFO - Started process (PID=18230) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:23:57.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:23:57.329+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:23:57.329+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:23:57.523+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:23:57.519+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:23:57.524+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:23:57.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.225 seconds
[2024-10-01T00:24:27.649+0000] {processor.py:186} INFO - Started process (PID=18253) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:24:27.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:24:27.651+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:24:27.651+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:24:27.840+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:24:27.836+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:24:27.842+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:24:27.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.220 seconds
[2024-10-01T00:24:57.927+0000] {processor.py:186} INFO - Started process (PID=18274) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:24:57.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:24:57.930+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:24:57.930+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:24:58.119+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:24:58.115+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:24:58.120+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:24:58.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-10-01T00:25:28.407+0000] {processor.py:186} INFO - Started process (PID=18297) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:25:28.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:25:28.410+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:25:28.409+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:25:28.597+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:25:28.593+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:25:28.599+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:25:28.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-10-01T00:25:58.904+0000] {processor.py:186} INFO - Started process (PID=18320) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:25:58.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:25:58.907+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:25:58.907+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:25:59.088+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:25:59.083+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:25:59.089+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:25:59.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.210 seconds
[2024-10-01T00:26:29.401+0000] {processor.py:186} INFO - Started process (PID=18343) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:26:29.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:26:29.403+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:26:29.403+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:26:29.591+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:26:29.587+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:26:29.592+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:26:29.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-10-01T00:26:59.975+0000] {processor.py:186} INFO - Started process (PID=18372) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:26:59.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:26:59.978+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:26:59.977+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:27:00.169+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:27:00.164+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:27:00.170+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:27:00.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.222 seconds
[2024-10-01T00:27:31.131+0000] {processor.py:186} INFO - Started process (PID=18395) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:27:31.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:27:31.133+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:27:31.133+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:27:31.319+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:27:31.314+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:27:31.320+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:27:31.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T00:28:01.853+0000] {processor.py:186} INFO - Started process (PID=18418) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:28:01.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:28:01.856+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:28:01.855+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:28:02.051+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:28:02.047+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:28:02.053+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:28:02.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.225 seconds
[2024-10-01T00:28:32.438+0000] {processor.py:186} INFO - Started process (PID=18441) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:28:32.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:28:32.440+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:28:32.440+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:28:32.629+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:28:32.624+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:28:32.630+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:28:32.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T00:29:03.006+0000] {processor.py:186} INFO - Started process (PID=18464) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:29:03.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:29:03.009+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:29:03.009+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:29:03.199+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:29:03.195+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:29:03.200+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:29:03.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-10-01T00:29:33.522+0000] {processor.py:186} INFO - Started process (PID=18487) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:29:33.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:29:33.524+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:29:33.524+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:29:33.709+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:29:33.706+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:29:33.710+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:29:33.730+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-10-01T00:30:04.029+0000] {processor.py:186} INFO - Started process (PID=18510) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:30:04.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:30:04.032+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:30:04.032+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:30:04.221+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:30:04.217+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:30:04.223+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:30:04.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.220 seconds
[2024-10-01T00:30:34.525+0000] {processor.py:186} INFO - Started process (PID=18533) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:30:34.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:30:34.527+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:30:34.527+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:30:34.716+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:30:34.712+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:30:34.717+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:30:34.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.220 seconds
[2024-10-01T00:31:05.048+0000] {processor.py:186} INFO - Started process (PID=18556) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:31:05.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:31:05.052+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:31:05.052+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:31:05.236+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:31:05.232+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:31:05.237+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:31:05.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T00:31:35.542+0000] {processor.py:186} INFO - Started process (PID=18579) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:31:35.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:31:35.545+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:31:35.544+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:31:35.730+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:31:35.726+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:31:35.731+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:31:35.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.214 seconds
[2024-10-01T00:32:06.051+0000] {processor.py:186} INFO - Started process (PID=18602) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:32:06.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:32:06.054+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:32:06.054+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:32:06.242+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:32:06.238+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:32:06.244+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:32:06.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-10-01T00:32:36.528+0000] {processor.py:186} INFO - Started process (PID=18625) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:32:36.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:32:36.531+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:32:36.531+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:32:36.715+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:32:36.711+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:32:36.716+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:32:36.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-10-01T00:33:07.176+0000] {processor.py:186} INFO - Started process (PID=18648) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:33:07.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:33:07.178+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:33:07.177+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:33:07.363+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:33:07.359+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:33:07.364+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:33:07.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-10-01T00:33:37.811+0000] {processor.py:186} INFO - Started process (PID=18671) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:33:37.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:33:37.813+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:33:37.813+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:33:38.007+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:33:38.003+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:33:38.008+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:33:38.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
[2024-10-01T00:34:09.004+0000] {processor.py:186} INFO - Started process (PID=18694) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:34:09.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:34:09.006+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:34:09.006+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:34:09.193+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:34:09.188+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:34:09.194+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:34:09.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T00:34:40.196+0000] {processor.py:186} INFO - Started process (PID=18717) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:34:40.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:34:40.200+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:34:40.199+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:34:40.388+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:34:40.383+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:34:40.389+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:34:40.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.220 seconds
[2024-10-01T00:35:10.973+0000] {processor.py:186} INFO - Started process (PID=18740) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:35:10.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:35:10.975+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:35:10.975+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:35:11.158+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:35:11.155+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:35:11.159+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:35:11.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.212 seconds
[2024-10-01T00:35:42.013+0000] {processor.py:186} INFO - Started process (PID=18763) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:35:42.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:35:42.015+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:35:42.015+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:35:42.214+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:35:42.210+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:35:42.216+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:35:42.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.230 seconds
[2024-10-01T00:36:12.491+0000] {processor.py:186} INFO - Started process (PID=18786) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:36:12.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:36:12.493+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:36:12.493+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:36:12.683+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:36:12.679+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:36:12.684+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:36:12.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.222 seconds
[2024-10-01T00:36:42.898+0000] {processor.py:186} INFO - Started process (PID=18809) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:36:42.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:36:42.901+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:36:42.900+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:36:43.084+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:36:43.080+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:36:43.085+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:36:43.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.212 seconds
[2024-10-01T00:37:13.271+0000] {processor.py:186} INFO - Started process (PID=18832) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:37:13.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:37:13.273+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:37:13.273+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:37:13.458+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:37:13.455+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:37:13.459+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:37:13.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.213 seconds
[2024-10-01T00:37:43.798+0000] {processor.py:186} INFO - Started process (PID=18855) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:37:43.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:37:43.800+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:37:43.800+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:37:43.993+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:37:43.989+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:37:43.994+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:37:44.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T00:38:14.319+0000] {processor.py:186} INFO - Started process (PID=18878) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:38:14.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:38:14.321+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:38:14.321+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:38:14.505+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:38:14.500+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:38:14.506+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:38:14.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.214 seconds
[2024-10-01T00:38:44.760+0000] {processor.py:186} INFO - Started process (PID=18901) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:38:44.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:38:44.763+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:38:44.762+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:38:44.956+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:38:44.952+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:38:44.957+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:38:44.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
[2024-10-01T00:39:15.035+0000] {processor.py:186} INFO - Started process (PID=18924) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:39:15.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:39:15.038+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:39:15.037+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:39:15.222+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:39:15.217+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:39:15.223+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:39:15.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-10-01T00:39:45.348+0000] {processor.py:186} INFO - Started process (PID=18947) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:39:45.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:39:45.351+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:39:45.350+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:39:45.545+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:39:45.540+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:39:45.546+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:39:45.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T00:40:15.666+0000] {processor.py:186} INFO - Started process (PID=18970) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:40:15.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:40:15.669+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:40:15.668+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:40:15.859+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:40:15.855+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:40:15.860+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:40:15.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.222 seconds
[2024-10-01T00:40:45.962+0000] {processor.py:186} INFO - Started process (PID=18993) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:40:45.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:40:45.964+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:40:45.964+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:40:46.154+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:40:46.150+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:40:46.155+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:40:46.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-10-01T00:41:16.223+0000] {processor.py:186} INFO - Started process (PID=19016) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:41:16.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:41:16.225+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:41:16.225+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:41:16.417+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:41:16.412+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:41:16.418+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:41:16.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-10-01T00:41:46.548+0000] {processor.py:186} INFO - Started process (PID=19039) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:41:46.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:41:46.550+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:41:46.550+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:41:46.735+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:41:46.731+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:41:46.736+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:41:46.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.212 seconds
[2024-10-01T00:42:16.926+0000] {processor.py:186} INFO - Started process (PID=19062) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:42:16.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:42:16.929+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:42:16.928+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:42:17.114+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:42:17.110+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:42:17.115+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:42:17.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T00:42:47.247+0000] {processor.py:186} INFO - Started process (PID=19085) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:42:47.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:42:47.249+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:42:47.249+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:42:47.433+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:42:47.429+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:42:47.434+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:42:47.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.212 seconds
[2024-10-01T00:43:18.458+0000] {processor.py:186} INFO - Started process (PID=19108) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:43:18.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:43:18.460+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:43:18.460+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:43:18.647+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:43:18.643+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:43:18.649+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:43:18.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T00:43:49.683+0000] {processor.py:186} INFO - Started process (PID=19131) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:43:49.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:43:49.686+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:43:49.686+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:43:49.874+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:43:49.870+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:43:49.875+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:43:49.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-10-01T00:44:20.071+0000] {processor.py:186} INFO - Started process (PID=19154) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:44:20.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:44:20.074+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:44:20.073+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:44:20.271+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:44:20.266+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:44:20.272+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:44:20.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.226 seconds
[2024-10-01T00:44:50.417+0000] {processor.py:186} INFO - Started process (PID=19177) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:44:50.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:44:50.419+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:44:50.419+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:44:50.608+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:44:50.603+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:44:50.610+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:44:50.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-10-01T00:45:20.730+0000] {processor.py:186} INFO - Started process (PID=19200) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:45:20.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:45:20.733+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:45:20.732+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:45:20.916+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:45:20.912+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:45:20.917+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:45:20.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.214 seconds
[2024-10-01T00:45:51.394+0000] {processor.py:186} INFO - Started process (PID=19223) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:45:51.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:45:51.396+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:45:51.396+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:45:51.583+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:45:51.579+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:45:51.584+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:45:51.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-10-01T00:46:21.719+0000] {processor.py:186} INFO - Started process (PID=19246) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:46:21.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:46:21.722+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:46:21.721+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:46:21.926+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:46:21.922+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:46:21.928+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:46:21.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-10-01T00:46:52.384+0000] {processor.py:186} INFO - Started process (PID=19269) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:46:52.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:46:52.387+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:46:52.387+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:46:52.591+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:46:52.587+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:46:52.592+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:46:52.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.239 seconds
[2024-10-01T00:47:23.189+0000] {processor.py:186} INFO - Started process (PID=19292) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:47:23.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:47:23.192+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:47:23.191+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:47:23.382+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:47:23.378+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:47:23.383+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:47:23.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.222 seconds
[2024-10-01T00:47:53.974+0000] {processor.py:186} INFO - Started process (PID=19315) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:47:53.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:47:53.977+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:47:53.977+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:47:54.161+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:47:54.157+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:47:54.163+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:47:54.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.214 seconds
[2024-10-01T00:48:24.323+0000] {processor.py:186} INFO - Started process (PID=19338) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:48:24.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:48:24.326+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:48:24.326+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:48:24.539+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:48:24.536+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:48:24.540+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:48:24.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-10-01T00:48:55.007+0000] {processor.py:186} INFO - Started process (PID=19361) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:48:55.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:48:55.010+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:48:55.009+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:48:55.197+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:48:55.192+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:48:55.199+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:48:55.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-10-01T00:49:25.318+0000] {processor.py:186} INFO - Started process (PID=19385) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:49:25.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:49:25.322+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:49:25.321+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:49:25.513+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:49:25.509+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:49:25.514+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:49:25.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.226 seconds
[2024-10-01T00:49:55.652+0000] {processor.py:186} INFO - Started process (PID=19408) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:49:55.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:49:55.654+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:49:55.654+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:49:55.840+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:49:55.836+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:49:55.841+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:49:55.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T00:50:25.947+0000] {processor.py:186} INFO - Started process (PID=19431) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:50:25.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:50:25.950+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:50:25.949+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:50:26.132+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:50:26.128+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:50:26.134+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:50:26.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.220 seconds
[2024-10-01T00:50:56.242+0000] {processor.py:186} INFO - Started process (PID=19455) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:50:56.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:50:56.245+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:50:56.244+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:50:56.433+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:50:56.429+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:50:56.434+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:50:56.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-10-01T00:51:26.555+0000] {processor.py:186} INFO - Started process (PID=19478) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:51:26.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:51:26.558+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:51:26.558+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:51:26.745+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:51:26.742+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:51:26.747+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:51:26.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-10-01T00:51:57.267+0000] {processor.py:186} INFO - Started process (PID=19501) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:51:57.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:51:57.270+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:51:57.270+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:51:57.458+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:51:57.454+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:51:57.459+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:51:57.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-10-01T00:52:27.791+0000] {processor.py:186} INFO - Started process (PID=19524) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:52:27.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T00:52:27.794+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:52:27.794+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:52:27.985+0000] {logging_mixin.py:190} INFO - [2024-10-01T00:52:27.981+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T00:52:27.986+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T00:52:28.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.222 seconds
[2024-10-01T17:54:21.094+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:54:21.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T17:54:21.099+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:54:21.099+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:54:21.622+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:54:21.619+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T17:54:21.623+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:54:21.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.559 seconds
[2024-10-01T17:54:43.319+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:54:43.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T17:54:43.322+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:54:43.322+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:54:43.687+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:54:43.681+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T17:54:43.689+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:54:43.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.401 seconds
[2024-10-01T17:55:14.020+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:55:14.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T17:55:14.023+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:55:14.023+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:55:14.328+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:55:14.324+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T17:55:14.329+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:55:14.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.333 seconds
[2024-10-01T17:55:44.719+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:55:44.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T17:55:44.721+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:55:44.721+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:55:44.896+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:55:44.891+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T17:55:44.897+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:55:44.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.337 seconds
[2024-10-01T17:56:15.078+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:56:15.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T17:56:15.082+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:56:15.081+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:56:15.286+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:56:15.282+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T17:56:15.287+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:56:15.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.236 seconds
[2024-10-01T17:56:45.707+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:56:45.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T17:56:45.710+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:56:45.710+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:56:45.896+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:56:45.892+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 70, in <module>
    print(Await_file_Transformed.poke())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: OperatorFileSensor.poke() missing 1 required positional argument: 'context'
[2024-10-01T17:56:45.897+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:56:45.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-10-01T17:57:09.121+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:57:09.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T17:57:09.127+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:57:09.126+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:57:09.351+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:57:09.509+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:57:09.509+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T17:57:09.523+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:57:09.523+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T17:57:09.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.448 seconds
[2024-10-01T17:57:39.610+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:57:39.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T17:57:39.616+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:57:39.615+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:57:39.845+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:57:39.869+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:57:39.869+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T17:57:39.887+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:57:39.886+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T17:57:39.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.315 seconds
[2024-10-01T17:58:10.228+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:58:10.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T17:58:10.232+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:58:10.231+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:58:10.435+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:58:10.459+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:58:10.459+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T17:58:10.474+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:58:10.474+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T17:58:10.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.277 seconds
[2024-10-01T17:59:41.072+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:59:41.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T17:59:41.086+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:59:41.084+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:59:41.655+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T17:59:41.687+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:59:41.686+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T17:59:41.721+0000] {logging_mixin.py:190} INFO - [2024-10-01T17:59:41.720+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T17:59:41.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.696 seconds
[2024-10-01T18:00:09.303+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:00:09.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:00:09.308+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:00:09.308+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:00:09.661+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:00:09.650+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 71, in <module>
    Create_Container_Raw >> Web_Extraction  >> Create_Container_Silver  >> Spark_Transformation >> Await_file_Transformed
                          ^^^^^^^^^^^^^^
NameError: name 'Web_Extraction' is not defined
[2024-10-01T18:00:09.668+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:00:09.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.390 seconds
[2024-10-01T18:00:36.420+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:00:36.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:00:36.426+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:00:36.426+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:00:36.732+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:00:36.920+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:00:36.919+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:00:36.931+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:00:36.930+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:00:36.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.552 seconds
[2024-10-01T18:01:07.148+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:01:07.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:01:07.151+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:01:07.151+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:01:07.508+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:01:07.525+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:01:07.525+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:01:07.538+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:01:07.538+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:01:07.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.420 seconds
[2024-10-01T18:01:37.873+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:01:37.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:01:37.877+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:01:37.877+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:01:38.184+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:01:38.200+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:01:38.200+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:01:38.213+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:01:38.213+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:01:38.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.434 seconds
[2024-10-01T18:02:08.393+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:02:08.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:02:08.397+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:02:08.396+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:02:08.693+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:02:08.709+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:02:08.708+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:02:08.720+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:02:08.720+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:02:08.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.351 seconds
[2024-10-01T18:02:39.060+0000] {processor.py:186} INFO - Started process (PID=186) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:02:39.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:02:39.065+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:02:39.064+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:02:39.419+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:02:39.516+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:02:39.516+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:02:39.527+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:02:39.527+0000] {dag.py:3252} INFO - Creating ORM DAG for SitesWebScraping
[2024-10-01T18:02:39.528+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:02:39.528+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:02:39.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.495 seconds
[2024-10-01T18:03:09.853+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:03:09.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:03:09.857+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:03:09.857+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:03:10.155+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:03:10.172+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:03:10.171+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:03:10.184+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:03:10.184+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:03:10.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.355 seconds
[2024-10-01T18:03:40.297+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:03:40.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:03:40.300+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:03:40.300+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:03:40.473+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:03:40.491+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:03:40.490+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:03:40.504+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:03:40.504+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:03:40.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.234 seconds
[2024-10-01T18:04:10.810+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:04:10.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:04:10.813+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:04:10.812+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:04:11.000+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:04:11.020+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:04:11.019+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:04:11.034+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:04:11.034+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:04:11.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-10-01T18:04:41.272+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:04:41.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:04:41.276+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:04:41.276+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:04:41.483+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:04:41.509+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:04:41.509+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:04:41.527+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:04:41.527+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:04:41.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.281 seconds
[2024-10-01T18:05:12.163+0000] {processor.py:186} INFO - Started process (PID=307) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:05:12.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:05:12.167+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:05:12.166+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:05:12.355+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:05:12.478+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:05:12.478+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:05:12.492+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:05:12.491+0000] {dag.py:3252} INFO - Creating ORM DAG for SitesWebScraping
[2024-10-01T18:05:12.493+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:05:12.493+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:05:12.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.360 seconds
[2024-10-01T18:05:19.642+0000] {processor.py:186} INFO - Started process (PID=322) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:05:19.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:05:19.647+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:05:19.646+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:05:19.848+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:05:19.857+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:05:19.857+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:05:19.871+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:05:19.871+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:05:19.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T18:05:50.824+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:05:50.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:05:50.828+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:05:50.827+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:05:51.017+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:05:51.035+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:05:51.035+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:05:51.049+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:05:51.049+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:05:51.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T18:06:21.648+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:06:21.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:06:21.652+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:06:21.651+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:06:21.831+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:06:21.849+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:06:21.849+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:06:21.863+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:06:21.863+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:06:21.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-10-01T18:06:52.832+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:06:52.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:06:52.836+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:06:52.835+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:06:53.034+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:06:53.052+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:06:53.052+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:06:53.067+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:06:53.066+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:06:53.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T18:07:23.625+0000] {processor.py:186} INFO - Started process (PID=415) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:07:23.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:07:23.633+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:07:23.633+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:07:23.836+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:07:23.946+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:07:23.946+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:07:23.959+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:07:23.958+0000] {dag.py:3252} INFO - Creating ORM DAG for SitesWebScraping
[2024-10-01T18:07:23.960+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:07:23.960+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:07:23.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.362 seconds
[2024-10-01T18:07:54.990+0000] {processor.py:186} INFO - Started process (PID=438) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:07:54.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:07:54.993+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:07:54.993+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:07:55.168+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:07:55.185+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:07:55.185+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:07:55.198+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:07:55.198+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:07:55.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.235 seconds
[2024-10-01T18:08:25.316+0000] {processor.py:186} INFO - Started process (PID=461) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:08:25.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:08:25.321+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:08:25.320+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:08:25.503+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:08:25.522+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:08:25.522+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:08:25.536+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:08:25.535+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:08:25.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-10-01T18:08:55.617+0000] {processor.py:186} INFO - Started process (PID=484) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:08:55.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:08:55.620+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:08:55.620+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:08:55.804+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:08:55.823+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:08:55.822+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:08:55.838+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:08:55.838+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:08:55.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-10-01T18:09:25.947+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:09:25.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:09:25.952+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:09:25.952+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:09:26.133+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:09:26.155+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:09:26.154+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:09:26.169+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:09:26.169+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:09:26.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-10-01T18:09:57.055+0000] {processor.py:186} INFO - Started process (PID=531) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:09:57.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:09:57.058+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:09:57.058+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:09:57.293+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:09:57.287+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:09:57.298+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:09:57.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.276 seconds
[2024-10-01T18:10:53.684+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:10:53.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:10:53.688+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:10:53.687+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:10:54.036+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:10:54.030+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:10:54.040+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:10:54.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.383 seconds
[2024-10-01T18:11:24.170+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:11:24.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:11:24.173+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:11:24.172+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:11:24.501+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:11:24.495+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:11:24.506+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:11:24.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.359 seconds
[2024-10-01T18:11:55.039+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:11:55.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:11:55.042+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:11:55.041+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:11:55.236+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:11:55.229+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:11:55.240+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:11:55.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.227 seconds
[2024-10-01T18:12:25.917+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:12:25.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:12:25.919+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:12:25.919+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:12:26.104+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:12:26.098+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:12:26.109+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:12:26.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-10-01T18:12:56.199+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:12:56.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:12:56.203+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:12:56.202+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:12:56.428+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:12:56.422+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:12:56.433+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:12:56.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T18:13:26.788+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:13:26.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:13:26.791+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:13:26.791+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:13:26.985+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:13:26.978+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:13:26.989+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:13:27.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.227 seconds
[2024-10-01T18:13:57.133+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:13:57.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:13:57.136+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:13:57.136+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:13:57.326+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:13:57.319+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:13:57.330+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:13:57.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.222 seconds
[2024-10-01T18:14:27.805+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:14:27.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:14:27.807+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:14:27.807+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:14:27.995+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:14:27.988+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:14:27.999+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:14:28.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.220 seconds
[2024-10-01T18:14:58.484+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:14:58.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:14:58.486+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:14:58.486+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:14:58.681+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:14:58.675+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:14:58.686+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:14:58.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.226 seconds
[2024-10-01T18:15:04.828+0000] {processor.py:186} INFO - Started process (PID=246) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:15:04.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:15:04.830+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:15:04.830+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:15:05.047+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:15:05.041+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:15:05.051+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:15:05.086+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:15:05.086+0000] {taskinstance.py:3312} ERROR - {'DAG Id': 'SitesWebScraping', 'Task Id': 'Await_file_Transformed', 'Run Id': 'manual__2024-10-01T18:07:39.256787+00:00', 'Hostname': '8fb190c86b0d', 'External Executor Id': 'ede7da7f-6631-4035-83d1-35abba28d417'}
[2024-10-01T18:15:05.098+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:15:05.098+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=SitesWebScraping, task_id=Await_file_Transformed, run_id=manual__2024-10-01T18:07:39.256787+00:00, execution_date=20241001T180739, start_date=20241001T180741, end_date=20241001T181505
[2024-10-01T18:15:05.114+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:15:05.113+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: SitesWebScraping.Await_file_Transformed manual__2024-10-01T18:07:39.256787+00:00 [failed]> in state failed
[2024-10-01T18:15:05.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.296 seconds
[2024-10-01T18:16:21.968+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:16:21.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:16:21.974+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:16:21.974+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:16:22.480+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:16:22.474+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 73, in <module>
    Create_Container_Raw >> Await_file_Transformed
                          ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Await_file_Transformed' is not defined. Did you mean: 'Sesor_file_Transformed'?
[2024-10-01T18:16:22.485+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:16:22.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.549 seconds
[2024-10-01T18:16:44.896+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:16:44.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:16:44.900+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:16:44.899+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:16:45.237+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:16:45.434+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:16:45.434+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:16:45.446+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:16:45.446+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:16:45.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.582 seconds
[2024-10-01T18:17:15.795+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:17:15.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:17:15.798+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:17:15.798+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:17:16.099+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:17:16.115+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:17:16.115+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:17:16.127+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:17:16.127+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:17:16.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.359 seconds
[2024-10-01T18:17:46.244+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:17:46.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:17:46.248+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:17:46.247+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:17:46.557+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:17:46.572+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:17:46.572+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:17:46.584+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:17:46.584+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:17:46.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.365 seconds
[2024-10-01T18:18:16.875+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:18:16.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:18:16.879+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:18:16.878+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:18:17.177+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:18:17.192+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:18:17.192+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:18:17.204+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:18:17.204+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:18:17.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.361 seconds
[2024-10-01T18:18:47.535+0000] {processor.py:186} INFO - Started process (PID=161) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:18:47.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:18:47.539+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:18:47.539+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:18:47.843+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:18:47.860+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:18:47.860+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:18:47.872+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:18:47.872+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:18:47.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.361 seconds
[2024-10-01T18:19:18.110+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:19:18.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:19:18.113+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:19:18.112+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:19:18.423+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:19:18.439+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:19:18.439+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:19:18.450+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:19:18.450+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:19:18.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.366 seconds
[2024-10-01T18:19:49.184+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:19:49.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:19:49.314+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:19:49.313+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:19:49.482+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:19:49.497+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:19:49.497+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:19:49.508+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:19:49.508+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:19:49.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.353 seconds
[2024-10-01T18:20:20.261+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:20:20.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:20:20.265+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:20:20.265+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:20:20.448+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:20:20.468+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:20:20.468+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:20:20.483+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:20:20.483+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:20:20.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T18:20:43.835+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:20:43.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:20:43.839+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:20:43.839+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:20:43.851+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:20:43.850+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 61
    end_task = DummyOperator(
IndentationError: unexpected indent
[2024-10-01T18:20:43.851+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:20:43.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.044 seconds
[2024-10-01T18:20:53.058+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:20:53.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:20:53.062+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:20:53.061+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:20:53.253+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:20:53.360+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:20:53.359+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:20:53.371+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:20:53.371+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:20:53.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.348 seconds
[2024-10-01T18:21:01.329+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:21:01.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:21:01.333+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:21:01.332+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:21:01.535+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:21:01.546+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:21:01.545+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:21:01.561+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:21:01.560+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:21:01.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T18:21:31.658+0000] {processor.py:186} INFO - Started process (PID=298) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:21:31.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:21:31.662+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:21:31.662+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:21:31.845+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:21:31.953+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:21:31.952+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:21:31.965+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:21:31.964+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:21:31.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.334 seconds
[2024-10-01T18:22:02.853+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:22:02.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:22:02.857+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:22:02.856+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:22:03.060+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:22:03.081+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:22:03.081+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:22:03.097+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:22:03.096+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:22:03.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-10-01T18:22:33.267+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:22:33.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:22:33.271+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:22:33.271+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:22:33.477+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:22:33.501+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:22:33.501+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:22:33.519+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:22:33.519+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:22:33.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.283 seconds
[2024-10-01T18:23:04.330+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:23:04.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:23:04.333+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:23:04.333+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:23:04.528+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:23:04.548+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:23:04.547+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:23:04.563+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:23:04.562+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:23:04.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T18:23:35.403+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:23:35.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:23:35.407+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:23:35.406+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:23:35.589+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:23:35.611+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:23:35.611+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:23:35.625+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:23:35.625+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:23:35.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-10-01T18:24:06.613+0000] {processor.py:186} INFO - Started process (PID=414) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:24:06.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:24:06.617+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:24:06.616+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:24:06.798+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:24:06.818+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:24:06.818+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:24:06.831+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:24:06.831+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:24:06.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-10-01T18:24:36.970+0000] {processor.py:186} INFO - Started process (PID=437) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:24:36.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:24:36.974+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:24:36.973+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:24:37.153+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:24:37.173+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:24:37.173+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:24:37.187+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:24:37.186+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:24:37.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-10-01T18:25:08.147+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:08.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:25:08.151+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:08.150+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:08.348+0000] {logging_mixin.py:190} WARNING - /opt/airflow/operators/OperatorFileSensor.py:12 SyntaxWarning: invalid escape sequence '\d'
[2024-10-01T18:25:08.350+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:08.369+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:08.369+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:25:08.383+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:08.383+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:25:08.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T18:25:39.190+0000] {processor.py:186} INFO - Started process (PID=483) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:39.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:25:39.194+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:39.193+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:39.412+0000] {logging_mixin.py:190} WARNING - /opt/airflow/operators/OperatorFileSensor.py:13 SyntaxWarning: invalid escape sequence '\d'
[2024-10-01T18:25:39.414+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:39.441+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:39.441+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:25:39.460+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:39.460+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:25:39.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.303 seconds
[2024-10-01T18:25:48.924+0000] {processor.py:186} INFO - Started process (PID=486) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:48.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:25:48.928+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:48.928+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:48.946+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:48.944+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 59
    self.fs_conn_id='fs_default',
    ^^^^^^^^^^^^^^^^
SyntaxError: expression cannot contain assignment, perhaps you meant "=="?
[2024-10-01T18:25:48.946+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:48.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.048 seconds
[2024-10-01T18:25:54.098+0000] {processor.py:186} INFO - Started process (PID=493) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:54.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:25:54.102+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:54.102+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:54.316+0000] {logging_mixin.py:190} WARNING - /opt/airflow/operators/OperatorFileSensor.py:12 SyntaxWarning: invalid escape sequence '\d'
[2024-10-01T18:25:54.318+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:25:54.338+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:54.337+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:25:54.351+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:25:54.351+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:25:54.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.289 seconds
[2024-10-01T18:26:24.620+0000] {processor.py:186} INFO - Started process (PID=516) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:26:24.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:26:24.624+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:26:24.623+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:26:24.806+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:26:24.827+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:26:24.827+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:26:24.841+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:26:24.841+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:26:24.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-10-01T18:26:55.331+0000] {processor.py:186} INFO - Started process (PID=539) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:26:55.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:26:55.336+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:26:55.335+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:26:55.518+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:26:55.537+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:26:55.537+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:26:55.552+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:26:55.552+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:26:55.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-10-01T18:27:26.236+0000] {processor.py:186} INFO - Started process (PID=562) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:27:26.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:27:26.240+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:27:26.239+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:27:26.424+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:27:26.444+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:27:26.444+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:27:26.458+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:27:26.458+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:27:26.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-10-01T18:27:56.896+0000] {processor.py:186} INFO - Started process (PID=585) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:27:56.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:27:56.900+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:27:56.900+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:27:57.109+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:27:57.128+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:27:57.128+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:27:57.142+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:27:57.142+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:27:57.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.277 seconds
[2024-10-01T18:28:27.274+0000] {processor.py:186} INFO - Started process (PID=608) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:28:27.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:28:27.277+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:28:27.277+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:28:27.457+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:28:27.477+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:28:27.477+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:28:27.492+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:28:27.492+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:28:27.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-10-01T18:28:57.571+0000] {processor.py:186} INFO - Started process (PID=631) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:28:57.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:28:57.575+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:28:57.575+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:28:57.767+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:28:57.787+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:28:57.787+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:28:57.800+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:28:57.800+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:28:57.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T18:29:27.940+0000] {processor.py:186} INFO - Started process (PID=654) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:29:27.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:29:27.944+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:29:27.944+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:29:28.127+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:29:28.148+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:29:28.148+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:29:28.162+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:29:28.162+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:29:28.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-10-01T18:29:58.620+0000] {processor.py:186} INFO - Started process (PID=677) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:29:58.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:29:58.624+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:29:58.624+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:29:58.817+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:29:58.837+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:29:58.837+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:29:58.854+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:29:58.854+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:29:58.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T18:30:29.231+0000] {processor.py:186} INFO - Started process (PID=700) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:30:29.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:30:29.235+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:30:29.235+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:30:29.428+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:30:29.448+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:30:29.448+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:30:29.462+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:30:29.462+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:30:29.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T18:30:59.879+0000] {processor.py:186} INFO - Started process (PID=723) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:30:59.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:30:59.882+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:30:59.882+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:31:00.080+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:31:00.100+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:31:00.100+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:31:00.115+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:31:00.115+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:31:00.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T18:31:30.956+0000] {processor.py:186} INFO - Started process (PID=746) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:31:30.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:31:30.959+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:31:30.959+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:31:31.133+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:31:31.153+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:31:31.153+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:31:31.166+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:31:31.166+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:31:31.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-10-01T18:32:01.373+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:32:01.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:32:01.376+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:32:01.376+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:32:01.575+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:32:01.595+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:32:01.595+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:32:01.609+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:32:01.609+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:32:01.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T18:32:32.379+0000] {processor.py:186} INFO - Started process (PID=792) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:32:32.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:32:32.384+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:32:32.384+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:32:32.603+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:32:32.643+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:32:32.643+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:32:32.659+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:32:32.659+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:32:32.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.310 seconds
[2024-10-01T18:33:02.914+0000] {processor.py:186} INFO - Started process (PID=815) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:33:02.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:33:02.918+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:33:02.918+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:33:03.106+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:33:03.127+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:33:03.127+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:33:03.142+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:33:03.142+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:33:03.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T18:33:33.853+0000] {processor.py:186} INFO - Started process (PID=838) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:33:33.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:33:33.856+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:33:33.856+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:33:34.037+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:33:34.057+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:33:34.057+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:33:34.071+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:33:34.071+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:33:34.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-10-01T18:34:04.300+0000] {processor.py:186} INFO - Started process (PID=861) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:34:04.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:34:04.303+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:34:04.303+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:34:04.483+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:34:04.503+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:34:04.502+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:34:04.517+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:34:04.517+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:34:04.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-10-01T18:34:34.778+0000] {processor.py:186} INFO - Started process (PID=885) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:34:34.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:34:34.781+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:34:34.781+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:34:34.975+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:34:34.994+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:34:34.994+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:34:35.007+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:34:35.007+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:34:35.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T18:35:05.503+0000] {processor.py:186} INFO - Started process (PID=908) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:35:05.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:35:05.506+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:35:05.506+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:35:05.696+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:35:05.715+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:35:05.715+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:35:05.728+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:35:05.728+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:35:05.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T18:35:36.250+0000] {processor.py:186} INFO - Started process (PID=931) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:35:36.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:35:36.254+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:35:36.253+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:35:36.464+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:35:36.490+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:35:36.489+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:35:36.507+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:35:36.507+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:35:36.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.290 seconds
[2024-10-01T18:36:06.643+0000] {processor.py:186} INFO - Started process (PID=954) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:36:06.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:36:06.648+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:36:06.647+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:36:06.852+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:36:06.875+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:36:06.874+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:36:06.891+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:36:06.891+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:36:06.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.287 seconds
[2024-10-01T18:36:37.577+0000] {processor.py:186} INFO - Started process (PID=977) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:36:37.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:36:37.585+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:36:37.584+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:36:37.796+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:36:37.816+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:36:37.816+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:36:37.830+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:36:37.830+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:36:37.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.282 seconds
[2024-10-01T18:37:07.922+0000] {processor.py:186} INFO - Started process (PID=1000) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:37:07.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:37:07.925+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:37:07.925+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:37:08.106+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:37:08.126+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:37:08.126+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:37:08.140+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:37:08.140+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:37:08.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-10-01T18:37:38.295+0000] {processor.py:186} INFO - Started process (PID=1023) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:37:38.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:37:38.299+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:37:38.299+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:37:38.486+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:37:38.505+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:37:38.505+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:37:38.519+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:37:38.518+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:37:38.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-10-01T18:38:08.794+0000] {processor.py:186} INFO - Started process (PID=1045) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:38:08.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:38:08.798+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:38:08.798+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:38:08.994+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:38:09.016+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:38:09.015+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:38:09.032+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:38:09.032+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:38:09.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T18:38:39.423+0000] {processor.py:186} INFO - Started process (PID=1068) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:38:39.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:38:39.427+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:38:39.427+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:38:39.608+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:38:39.628+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:38:39.628+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:38:39.641+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:38:39.641+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:38:39.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-10-01T18:39:10.453+0000] {processor.py:186} INFO - Started process (PID=1091) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:39:10.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:39:10.456+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:39:10.456+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:39:10.640+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:39:10.659+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:39:10.659+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:39:10.673+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:39:10.673+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:39:10.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T18:39:41.111+0000] {processor.py:186} INFO - Started process (PID=1114) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:39:41.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:39:41.115+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:39:41.114+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:39:41.309+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:39:41.328+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:39:41.328+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:39:41.341+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:39:41.341+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:39:41.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T18:40:11.873+0000] {processor.py:186} INFO - Started process (PID=1137) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:40:11.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:40:11.876+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:40:11.876+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:40:12.066+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:40:12.085+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:40:12.084+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:40:12.099+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:40:12.099+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:40:12.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T18:40:42.424+0000] {processor.py:186} INFO - Started process (PID=1161) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:40:42.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:40:42.428+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:40:42.428+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:40:42.605+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:40:42.624+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:40:42.624+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:40:42.638+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:40:42.638+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:40:42.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-10-01T18:41:13.258+0000] {processor.py:186} INFO - Started process (PID=1184) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:13.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:41:13.263+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:41:13.261+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:13.466+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:13.487+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:41:13.487+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:41:13.502+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:41:13.502+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:41:13.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.272 seconds
[2024-10-01T18:41:41.803+0000] {processor.py:186} INFO - Started process (PID=1207) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:41.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:41:41.806+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:41:41.806+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:42.024+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:41:42.018+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 79, in <module>
    Create_Container_Raw >> Sesor_file_Transformed >> end_task
                            ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Sesor_file_Transformed' is not defined. Did you mean: 'Senor_file_Transformed'?
[2024-10-01T18:41:42.027+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:42.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-10-01T18:41:43.870+0000] {processor.py:186} INFO - Started process (PID=1208) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:43.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:41:43.874+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:41:43.873+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:44.072+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:41:44.067+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 79, in <module>
    Create_Container_Raw >> Sesor_file_Transformed >> end_task
                            ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'Sesor_file_Transformed' is not defined. Did you mean: 'Sensor_file_Transformed'?
[2024-10-01T18:41:44.075+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:44.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.231 seconds
[2024-10-01T18:41:50.023+0000] {processor.py:186} INFO - Started process (PID=1223) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:50.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:41:50.026+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:41:50.026+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:50.212+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:41:50.231+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:41:50.231+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:41:50.244+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:41:50.244+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:41:50.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T18:42:20.365+0000] {processor.py:186} INFO - Started process (PID=1246) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:42:20.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:42:20.370+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:42:20.370+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:42:20.552+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:42:20.571+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:42:20.571+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:42:20.585+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:42:20.584+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:42:20.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-10-01T18:42:51.351+0000] {processor.py:186} INFO - Started process (PID=1269) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:42:51.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:42:51.356+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:42:51.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:42:51.536+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:42:51.554+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:42:51.554+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:42:51.568+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:42:51.568+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:42:51.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-10-01T18:43:21.748+0000] {processor.py:186} INFO - Started process (PID=1292) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:43:21.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:43:21.752+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:43:21.751+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:43:21.930+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:43:21.948+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:43:21.948+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:43:21.962+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:43:21.962+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:43:21.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-10-01T18:43:47.542+0000] {processor.py:186} INFO - Started process (PID=1309) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:43:47.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:43:47.546+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:43:47.546+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:43:47.731+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:43:47.833+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:43:47.832+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:43:47.844+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:43:47.844+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:43:47.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.332 seconds
[2024-10-01T18:44:17.922+0000] {processor.py:186} INFO - Started process (PID=1339) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:44:17.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:44:17.926+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:44:17.925+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:44:18.102+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:44:18.121+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:44:18.121+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:44:18.134+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:44:18.134+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:44:18.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.236 seconds
[2024-10-01T18:44:49.048+0000] {processor.py:186} INFO - Started process (PID=1362) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:44:49.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:44:49.052+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:44:49.052+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:44:49.248+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:44:49.270+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:44:49.270+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:44:49.286+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:44:49.286+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:44:49.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-10-01T18:45:19.548+0000] {processor.py:186} INFO - Started process (PID=1385) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:45:19.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:45:19.551+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:45:19.551+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:45:19.762+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:45:19.782+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:45:19.782+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:45:19.800+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:45:19.800+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:45:19.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.280 seconds
[2024-10-01T18:45:50.095+0000] {processor.py:186} INFO - Started process (PID=1408) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:45:50.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:45:50.099+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:45:50.099+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:45:50.301+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:45:50.322+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:45:50.322+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:45:50.341+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:45:50.341+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:45:50.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T18:46:21.029+0000] {processor.py:186} INFO - Started process (PID=1431) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:46:21.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:46:21.033+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:46:21.032+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:46:21.251+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:46:21.282+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:46:21.281+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:46:21.303+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:46:21.302+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:46:21.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.313 seconds
[2024-10-01T18:46:51.777+0000] {processor.py:186} INFO - Started process (PID=1455) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:46:51.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:46:51.805+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:46:51.805+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:46:52.005+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:46:52.031+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:46:52.031+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:46:52.047+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:46:52.047+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:46:52.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.308 seconds
[2024-10-01T18:47:09.912+0000] {processor.py:186} INFO - Started process (PID=1467) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:09.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:47:09.915+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:09.915+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:10.101+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:10.121+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:10.121+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:47:10.135+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:10.135+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:47:10.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T18:47:13.055+0000] {processor.py:186} INFO - Started process (PID=1468) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:13.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:47:13.059+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:13.059+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:13.247+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:13.266+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:13.265+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T18:47:13.279+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:13.278+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T18:47:13.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T18:47:31.599+0000] {processor.py:186} INFO - Started process (PID=1491) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:31.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:47:31.603+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:31.603+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:31.811+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:31.805+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branch = BranchPythonOperator(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:47:31.812+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:31.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-10-01T18:47:45.056+0000] {processor.py:186} INFO - Started process (PID=1492) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:45.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:47:45.060+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:45.059+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:45.259+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:45.254+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:47:45.260+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:45.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.229 seconds
[2024-10-01T18:47:57.855+0000] {processor.py:186} INFO - Started process (PID=1515) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:57.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:47:57.859+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:57.859+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:58.050+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:47:58.044+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:47:58.051+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:47:58.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.226 seconds
[2024-10-01T18:48:28.153+0000] {processor.py:186} INFO - Started process (PID=1538) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:48:28.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:48:28.157+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:48:28.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:48:28.338+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:48:28.333+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:48:28.338+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:48:28.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.211 seconds
[2024-10-01T18:48:59.350+0000] {processor.py:186} INFO - Started process (PID=1561) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:48:59.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:48:59.353+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:48:59.353+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:48:59.532+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:48:59.528+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:48:59.533+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:48:59.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.208 seconds
[2024-10-01T18:49:30.118+0000] {processor.py:186} INFO - Started process (PID=1584) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:49:30.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:49:30.121+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:49:30.121+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:49:30.311+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:49:30.307+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:49:30.311+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:49:30.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T18:49:32.287+0000] {processor.py:186} INFO - Started process (PID=1585) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:49:32.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:49:32.291+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:49:32.290+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:49:32.492+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:49:32.487+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:49:32.493+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:49:32.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.234 seconds
[2024-10-01T18:49:49.972+0000] {processor.py:186} INFO - Started process (PID=1586) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:49:49.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:49:49.975+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:49:49.975+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:49:50.168+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:49:50.164+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:49:50.169+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:49:50.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
[2024-10-01T18:50:21.133+0000] {processor.py:186} INFO - Started process (PID=1609) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:21.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:50:21.135+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:50:21.135+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:21.320+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:50:21.316+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:50:21.321+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:21.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T18:50:40.701+0000] {processor.py:186} INFO - Started process (PID=1632) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:40.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:50:40.704+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:50:40.703+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:40.929+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:50:40.908+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:50:40.930+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:40.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T18:50:53.209+0000] {processor.py:186} INFO - Started process (PID=1636) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:53.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:50:53.212+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:50:53.212+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:53.405+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:50:53.399+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:50:53.405+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:53.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T18:50:56.751+0000] {processor.py:186} INFO - Started process (PID=1651) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:56.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:50:56.754+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:50:56.753+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:56.950+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:50:56.946+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:50:56.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:50:56.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T18:51:27.041+0000] {processor.py:186} INFO - Started process (PID=1675) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:51:27.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:51:27.044+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:51:27.043+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:51:27.224+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:51:27.220+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:51:27.225+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:51:27.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.209 seconds
[2024-10-01T18:51:57.751+0000] {processor.py:186} INFO - Started process (PID=1695) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:51:57.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:51:57.754+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:51:57.754+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:51:57.946+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:51:57.942+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:51:57.947+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:51:57.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-10-01T18:52:28.424+0000] {processor.py:186} INFO - Started process (PID=1718) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:52:28.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:52:28.427+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:52:28.427+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:52:28.616+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:52:28.611+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:52:28.617+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:52:28.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-10-01T18:52:59.118+0000] {processor.py:186} INFO - Started process (PID=1741) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:52:59.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:52:59.120+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:52:59.120+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:52:59.309+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:52:59.304+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:52:59.310+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:52:59.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T18:53:29.970+0000] {processor.py:186} INFO - Started process (PID=1764) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:53:29.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:53:29.972+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:53:29.972+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:53:30.167+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:53:30.161+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:53:30.168+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:53:30.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T18:54:00.370+0000] {processor.py:186} INFO - Started process (PID=1789) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:54:00.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:54:00.373+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:54:00.372+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:54:00.569+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:54:00.565+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:54:00.570+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:54:00.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.226 seconds
[2024-10-01T18:54:30.655+0000] {processor.py:186} INFO - Started process (PID=1813) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:54:30.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:54:30.657+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:54:30.657+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:54:30.848+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:54:30.844+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:54:30.849+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:54:30.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-10-01T18:55:00.972+0000] {processor.py:186} INFO - Started process (PID=1836) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:55:00.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:55:00.975+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:55:00.974+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:55:01.173+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:55:01.168+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:55:01.174+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:55:01.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.227 seconds
[2024-10-01T18:55:31.271+0000] {processor.py:186} INFO - Started process (PID=1860) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:55:31.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:55:31.274+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:55:31.273+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:55:31.461+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:55:31.456+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:55:31.462+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:55:31.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-10-01T18:56:01.571+0000] {processor.py:186} INFO - Started process (PID=1879) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:56:01.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:56:01.574+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:56:01.573+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:56:01.766+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:56:01.761+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:56:01.767+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:56:01.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-10-01T18:56:31.841+0000] {processor.py:186} INFO - Started process (PID=1902) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:56:31.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:56:31.843+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:56:31.843+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:56:32.040+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:56:32.036+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T18:56:32.041+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:56:32.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.225 seconds
[2024-10-01T18:56:37.342+0000] {processor.py:186} INFO - Started process (PID=1908) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:56:37.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:56:37.346+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:56:37.345+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:56:37.538+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:56:37.531+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 11, in <module>
    from airflow.operators.python_operator import EmailOperator
ImportError: cannot import name 'EmailOperator' from 'airflow.operators.python_operator' (unknown location)
[2024-10-01T18:56:37.541+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:56:37.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.226 seconds
[2024-10-01T18:57:08.000+0000] {processor.py:186} INFO - Started process (PID=1931) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:57:08.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:57:08.003+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:57:08.003+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:57:08.210+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:57:08.200+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 11, in <module>
    from airflow.operators.python_operator import EmailOperator
ImportError: cannot import name 'EmailOperator' from 'airflow.operators.python_operator' (unknown location)
[2024-10-01T18:57:08.214+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:57:08.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-10-01T18:57:20.782+0000] {processor.py:186} INFO - Started process (PID=1934) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:57:20.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:57:20.785+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:57:20.785+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:57:20.801+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:57:20.800+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 69
    Task_failed =
                 ^
SyntaxError: invalid syntax
[2024-10-01T18:57:20.802+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:57:20.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.048 seconds
[2024-10-01T18:57:51.496+0000] {processor.py:186} INFO - Started process (PID=1957) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:57:51.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:57:51.499+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:57:51.499+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:57:51.515+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:57:51.514+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 69
    Task_failed =
                 ^
SyntaxError: invalid syntax
[2024-10-01T18:57:51.515+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:57:51.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.046 seconds
[2024-10-01T18:58:22.007+0000] {processor.py:186} INFO - Started process (PID=1980) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:58:22.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:58:22.010+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:58:22.009+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:58:22.021+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:58:22.020+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 69
    Task_failed =
                 ^
SyntaxError: invalid syntax
[2024-10-01T18:58:22.022+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:58:22.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.042 seconds
[2024-10-01T18:58:52.623+0000] {processor.py:186} INFO - Started process (PID=2003) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:58:52.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:58:52.625+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:58:52.625+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:58:52.641+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:58:52.640+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 69
    Task_failed =
                 ^
SyntaxError: invalid syntax
[2024-10-01T18:58:52.642+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:58:52.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.048 seconds
[2024-10-01T18:59:22.255+0000] {processor.py:186} INFO - Started process (PID=2026) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:59:22.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:59:22.259+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:59:22.259+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:59:22.460+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:59:22.453+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 11, in <module>
    from airflow.operators.python_operator import EmailOperator
ImportError: cannot import name 'EmailOperator' from 'airflow.operators.python_operator' (unknown location)
[2024-10-01T18:59:22.463+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:59:22.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-10-01T18:59:36.267+0000] {processor.py:186} INFO - Started process (PID=2042) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:59:36.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T18:59:36.269+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:59:36.269+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:59:36.465+0000] {logging_mixin.py:190} INFO - [2024-10-01T18:59:36.459+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 11, in <module>
    from airflow.operators.python_operator import EmailOperator
ImportError: cannot import name 'EmailOperator' from 'airflow.operators.python_operator' (unknown location)
[2024-10-01T18:59:36.469+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T18:59:36.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.229 seconds
[2024-10-01T19:00:04.540+0000] {processor.py:186} INFO - Started process (PID=2059) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:00:04.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:00:04.542+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:00:04.542+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:00:04.738+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:00:04.731+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 11, in <module>
    from airflow.operators.python_operator import EmailOperator
ImportError: cannot import name 'EmailOperator' from 'airflow.operators.python_operator' (unknown location)
[2024-10-01T19:00:04.741+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:00:04.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.227 seconds
[2024-10-01T19:00:34.081+0000] {processor.py:186} INFO - Started process (PID=2079) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:00:34.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:00:34.083+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:00:34.083+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:00:34.312+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:00:34.306+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 11, in <module>
    from airflow.operators.python_operator import EmailOperator
ImportError: cannot import name 'EmailOperator' from 'airflow.operators.python_operator' (unknown location)
[2024-10-01T19:00:34.315+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:00:34.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T19:00:58.598+0000] {processor.py:186} INFO - Started process (PID=2103) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:00:58.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:00:58.601+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:00:58.601+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:00:58.798+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:00:58.792+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 64, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:00:58.799+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:00:58.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.228 seconds
[2024-10-01T19:01:25.946+0000] {processor.py:186} INFO - Started process (PID=2126) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:01:25.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:01:25.949+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:01:25.948+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:01:26.138+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:01:26.134+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 64, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:01:26.139+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:01:26.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-10-01T19:01:56.559+0000] {processor.py:186} INFO - Started process (PID=2149) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:01:56.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:01:56.561+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:01:56.561+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:01:56.751+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:01:56.746+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 64, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:01:56.752+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:01:56.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-10-01T19:02:23.940+0000] {processor.py:186} INFO - Started process (PID=2166) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:02:23.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:02:23.943+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:02:23.942+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:02:24.139+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:02:24.135+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 64, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:02:24.140+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:02:24.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.229 seconds
[2024-10-01T19:02:30.089+0000] {processor.py:186} INFO - Started process (PID=2173) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:02:30.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:02:30.093+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:02:30.092+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:02:30.295+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:02:30.291+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 64, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:02:30.296+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:02:30.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.232 seconds
[2024-10-01T19:03:00.513+0000] {processor.py:186} INFO - Started process (PID=2196) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:03:00.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:03:00.516+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:03:00.516+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:03:00.715+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:03:00.710+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 64, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:03:00.716+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:03:00.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.228 seconds
[2024-10-01T19:03:31.592+0000] {processor.py:186} INFO - Started process (PID=2219) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:03:31.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:03:31.595+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:03:31.595+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:03:31.780+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:03:31.776+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 64, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:03:31.781+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:03:31.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.212 seconds
[2024-10-01T19:04:02.006+0000] {processor.py:186} INFO - Started process (PID=2242) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:04:02.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:04:02.008+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:04:02.008+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:04:02.186+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:04:02.181+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 64, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:04:02.187+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:04:02.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.205 seconds
[2024-10-01T19:04:32.610+0000] {processor.py:186} INFO - Started process (PID=2265) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:04:32.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:04:32.612+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:04:32.612+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:04:32.805+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:04:32.799+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 64, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:04:32.806+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:04:32.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
[2024-10-01T19:05:03.234+0000] {processor.py:186} INFO - Started process (PID=2288) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:05:03.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:05:03.236+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:05:03.236+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:05:03.431+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:05:03.426+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 64, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:05:03.432+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:05:03.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.225 seconds
[2024-10-01T19:05:28.673+0000] {processor.py:186} INFO - Started process (PID=2311) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:05:28.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:05:28.676+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:05:28.675+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:05:28.870+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:05:28.865+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:05:28.871+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:05:28.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T19:05:46.928+0000] {processor.py:186} INFO - Started process (PID=2326) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:05:46.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:05:46.931+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:05:46.931+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:05:47.125+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:05:47.120+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:05:47.126+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:05:47.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.221 seconds
[2024-10-01T19:06:17.645+0000] {processor.py:186} INFO - Started process (PID=2349) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:06:17.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:06:17.648+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:06:17.647+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:06:17.837+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:06:17.832+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 63, in <module>
    Branching  = BranchPythonOperator(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-01T19:06:17.838+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:06:17.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-10-01T19:06:36.706+0000] {processor.py:186} INFO - Started process (PID=2358) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:06:36.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:06:36.709+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:06:36.708+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:06:36.902+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:06:37.010+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:06:37.009+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:06:37.022+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:06:37.021+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:06:37.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.354 seconds
[2024-10-01T19:07:07.677+0000] {processor.py:186} INFO - Started process (PID=2382) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:07.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:07:07.680+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:07.679+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:07.864+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:07.885+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:07.884+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:07:07.898+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:07.898+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:07:07.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-10-01T19:07:38.075+0000] {processor.py:186} INFO - Started process (PID=2405) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:38.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:07:38.078+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:38.078+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:38.266+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:38.287+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:38.287+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:07:38.300+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:38.300+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:07:38.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-10-01T19:07:42.338+0000] {processor.py:186} INFO - Started process (PID=2409) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:42.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:07:42.340+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:42.340+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:42.354+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:42.353+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 83
    Create_Container_Raw >> File_Sensor >> Branching >> [Task_failed,process_file_task]
IndentationError: unexpected indent
[2024-10-01T19:07:42.355+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:42.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.046 seconds
[2024-10-01T19:07:46.122+0000] {processor.py:186} INFO - Started process (PID=2421) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:46.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:07:46.124+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:46.124+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:46.145+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:46.144+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 83
    Create_Container_Raw >> File_Sensor >> Branching >> [Task_failed,process_file_task]
IndentationError: unexpected indent
[2024-10-01T19:07:46.146+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:46.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.052 seconds
[2024-10-01T19:07:49.295+0000] {processor.py:186} INFO - Started process (PID=2422) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:49.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:07:49.297+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:49.297+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:49.313+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:07:49.312+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 83
    Create_Container_Raw >> File_Sensor >> Branching >> [Task_Submission_With_Error,process_file_task]
IndentationError: unexpected indent
[2024-10-01T19:07:49.314+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:07:49.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.046 seconds
[2024-10-01T19:08:19.399+0000] {processor.py:186} INFO - Started process (PID=2445) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:08:19.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:08:19.402+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:08:19.401+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:08:19.416+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:08:19.415+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 83
    Create_Container_Raw >> File_Sensor >> Branching >> [Task_Submission_With_Error,process_file_task]
IndentationError: unexpected indent
[2024-10-01T19:08:19.417+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:08:19.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.046 seconds
[2024-10-01T19:08:35.321+0000] {processor.py:186} INFO - Started process (PID=2454) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:08:35.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:08:35.323+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:08:35.323+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:08:35.523+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:08:35.627+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:08:35.627+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:08:35.638+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:08:35.638+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:08:35.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.353 seconds
[2024-10-01T19:09:06.055+0000] {processor.py:186} INFO - Started process (PID=2477) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:09:06.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:09:06.057+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:09:06.057+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:09:06.278+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:09:06.299+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:09:06.298+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:09:06.313+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:09:06.313+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:09:06.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.284 seconds
[2024-10-01T19:09:36.814+0000] {processor.py:186} INFO - Started process (PID=2500) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:09:36.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:09:36.816+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:09:36.816+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:09:37.001+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:09:37.022+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:09:37.022+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:09:37.037+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:09:37.036+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:09:37.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-10-01T19:10:07.571+0000] {processor.py:186} INFO - Started process (PID=2523) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:10:07.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:10:07.574+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:10:07.573+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:10:07.756+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:10:07.776+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:10:07.776+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:10:07.789+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:10:07.788+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:10:07.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-10-01T19:10:37.979+0000] {processor.py:186} INFO - Started process (PID=2546) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:10:37.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:10:37.981+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:10:37.981+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:10:38.168+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:10:38.190+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:10:38.190+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:10:38.204+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:10:38.204+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:10:38.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T19:11:08.512+0000] {processor.py:186} INFO - Started process (PID=2569) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:11:08.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:11:08.515+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:11:08.514+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:11:08.702+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:11:08.722+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:11:08.722+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:11:08.735+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:11:08.735+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:11:08.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-10-01T19:11:38.831+0000] {processor.py:186} INFO - Started process (PID=2592) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:11:38.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:11:38.834+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:11:38.834+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:11:39.020+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:11:39.043+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:11:39.043+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:11:39.058+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:11:39.058+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:11:39.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.347 seconds
[2024-10-01T19:11:57.152+0000] {processor.py:186} INFO - Started process (PID=2613) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:11:57.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:11:57.155+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:11:57.154+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:11:57.392+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:11:57.500+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:11:57.500+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:11:57.512+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:11:57.511+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:11:57.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.473 seconds
[2024-10-01T19:12:28.457+0000] {processor.py:186} INFO - Started process (PID=2636) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:28.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:12:28.459+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:28.459+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:28.643+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:28.666+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:28.666+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:12:28.679+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:28.679+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:12:28.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-10-01T19:12:43.077+0000] {processor.py:186} INFO - Started process (PID=2639) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:43.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:12:43.079+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:43.079+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:43.278+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:43.422+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:43.422+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:12:43.435+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:43.435+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:12:43.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.406 seconds
[2024-10-01T19:12:50.358+0000] {processor.py:186} INFO - Started process (PID=2654) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:50.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:12:50.360+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:50.360+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:50.553+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:50.563+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:50.563+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:12:50.576+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:50.576+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:12:50.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-10-01T19:12:57.633+0000] {processor.py:186} INFO - Started process (PID=2661) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:57.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:12:57.636+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:57.635+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:57.827+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:12:57.837+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:57.837+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:12:57.850+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:12:57.850+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:12:57.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-10-01T19:13:18.087+0000] {processor.py:186} INFO - Started process (PID=2671) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:13:18.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:13:18.090+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:13:18.089+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:13:18.299+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:13:18.443+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:13:18.443+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:13:18.456+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:13:18.455+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:13:18.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.405 seconds
[2024-10-01T19:13:48.786+0000] {processor.py:186} INFO - Started process (PID=2694) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:13:48.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:13:48.789+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:13:48.788+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:13:48.979+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:13:49.098+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:13:49.098+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:13:49.110+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:13:49.110+0000] {dag.py:3252} INFO - Creating ORM DAG for SitesWebScraping
[2024-10-01T19:13:49.111+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:13:49.111+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:13:49.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.357 seconds
[2024-10-01T19:13:50.159+0000] {processor.py:186} INFO - Started process (PID=2697) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:13:50.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:13:50.161+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:13:50.161+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:13:50.358+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:13:50.369+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:13:50.369+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:13:50.387+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:13:50.387+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:13:50.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T19:14:20.508+0000] {processor.py:186} INFO - Started process (PID=2721) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:14:20.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:14:20.510+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:14:20.510+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:14:20.704+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:14:20.726+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:14:20.726+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:14:20.742+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:14:20.741+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:14:20.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.335 seconds
[2024-10-01T19:14:50.895+0000] {processor.py:186} INFO - Started process (PID=2745) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:14:50.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:14:50.897+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:14:50.897+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:14:51.077+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:14:51.099+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:14:51.099+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:14:51.112+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:14:51.112+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:14:51.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-10-01T19:15:21.680+0000] {processor.py:186} INFO - Started process (PID=2766) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:15:21.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:15:21.683+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:15:21.682+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:15:21.874+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:15:21.896+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:15:21.895+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:15:21.912+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:15:21.912+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:15:21.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T19:15:52.382+0000] {processor.py:186} INFO - Started process (PID=2789) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:15:52.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:15:52.385+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:15:52.384+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:15:52.579+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:15:52.601+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:15:52.601+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:15:52.616+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:15:52.616+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:15:52.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T19:16:23.380+0000] {processor.py:186} INFO - Started process (PID=2816) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:16:23.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:16:23.384+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:16:23.383+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:16:23.611+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:16:23.639+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:16:23.638+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:16:23.657+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:16:23.656+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:16:23.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.317 seconds
[2024-10-01T19:16:53.917+0000] {processor.py:186} INFO - Started process (PID=2842) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:16:53.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:16:53.919+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:16:53.919+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:16:54.166+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:16:54.193+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:16:54.193+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:16:54.212+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:16:54.212+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:16:54.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.338 seconds
[2024-10-01T19:17:24.449+0000] {processor.py:186} INFO - Started process (PID=2863) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:17:24.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:17:24.451+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:17:24.451+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:17:24.656+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:17:24.681+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:17:24.680+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:17:24.696+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:17:24.695+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:17:24.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.277 seconds
[2024-10-01T19:17:55.087+0000] {processor.py:186} INFO - Started process (PID=2886) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:17:55.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:17:55.089+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:17:55.089+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:17:55.278+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:17:55.300+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:17:55.300+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:17:55.316+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:17:55.316+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:17:55.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T19:18:25.894+0000] {processor.py:186} INFO - Started process (PID=2909) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:18:25.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:18:25.897+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:18:25.896+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:18:26.080+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:18:26.102+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:18:26.102+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:18:26.117+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:18:26.116+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:18:26.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-10-01T19:18:56.547+0000] {processor.py:186} INFO - Started process (PID=2932) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:18:56.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:18:56.550+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:18:56.549+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:18:56.829+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:18:56.853+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:18:56.852+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:18:56.869+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:18:56.869+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:18:56.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.354 seconds
[2024-10-01T19:19:23.917+0000] {processor.py:186} INFO - Started process (PID=2953) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:19:23.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:19:23.920+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:19:23.920+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:19:24.113+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:19:24.219+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:19:24.219+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:19:24.232+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:19:24.231+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:19:24.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.343 seconds
[2024-10-01T19:19:46.097+0000] {processor.py:186} INFO - Started process (PID=2970) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:19:46.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:19:46.100+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:19:46.099+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:19:46.315+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:19:46.326+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:19:46.326+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:19:46.343+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:19:46.343+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:19:46.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.276 seconds
[2024-10-01T19:20:16.857+0000] {processor.py:186} INFO - Started process (PID=2997) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:20:16.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:20:16.860+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:20:16.860+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:20:17.056+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:20:17.080+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:20:17.079+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:20:17.094+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:20:17.094+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:20:17.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-10-01T19:20:47.193+0000] {processor.py:186} INFO - Started process (PID=3020) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:20:47.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:20:47.196+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:20:47.195+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:20:47.391+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:20:47.413+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:20:47.413+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:20:47.427+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:20:47.427+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:20:47.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T19:21:18.018+0000] {processor.py:186} INFO - Started process (PID=3041) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:21:18.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:21:18.021+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:21:18.021+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:21:18.214+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:21:18.238+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:21:18.238+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:21:18.253+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:21:18.253+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:21:18.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-10-01T19:21:48.376+0000] {processor.py:186} INFO - Started process (PID=3064) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:21:48.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:21:48.379+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:21:48.378+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:21:48.626+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:21:48.653+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:21:48.653+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:21:48.677+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:21:48.677+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:21:48.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.346 seconds
[2024-10-01T19:22:19.583+0000] {processor.py:186} INFO - Started process (PID=3086) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:22:19.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:22:19.588+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:22:19.588+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:22:20.479+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:22:20.511+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:22:20.511+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:22:20.535+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:22:20.534+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:22:20.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.993 seconds
[2024-10-01T19:22:50.695+0000] {processor.py:186} INFO - Started process (PID=3109) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:22:50.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:22:50.731+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:22:50.720+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:22:51.306+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:22:51.351+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:22:51.351+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:22:51.377+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:22:51.377+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:22:51.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.731 seconds
[2024-10-01T19:23:21.965+0000] {processor.py:186} INFO - Started process (PID=3132) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:23:21.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:23:21.968+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:23:21.968+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:23:22.151+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:23:22.174+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:23:22.174+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:23:22.189+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:23:22.189+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:23:22.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T19:23:52.631+0000] {processor.py:186} INFO - Started process (PID=3155) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:23:52.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:23:52.633+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:23:52.633+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:23:52.818+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:23:52.840+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:23:52.840+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:23:52.854+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:23:52.854+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:23:52.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-10-01T19:24:23.745+0000] {processor.py:186} INFO - Started process (PID=3178) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:24:23.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:24:23.747+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:24:23.747+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:24:23.935+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:24:23.957+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:24:23.957+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:24:23.972+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:24:23.971+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:24:23.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-10-01T19:24:54.240+0000] {processor.py:186} INFO - Started process (PID=3201) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:24:54.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:24:54.243+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:24:54.243+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:24:54.431+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:24:54.453+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:24:54.452+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:24:54.466+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:24:54.466+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:24:54.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-10-01T19:25:24.529+0000] {processor.py:186} INFO - Started process (PID=3224) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:25:24.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:25:24.532+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:25:24.532+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:25:24.726+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:25:24.749+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:25:24.749+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:25:24.764+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:25:24.763+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:25:24.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T19:25:55.671+0000] {processor.py:186} INFO - Started process (PID=3247) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:25:55.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:25:55.674+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:25:55.673+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:25:55.865+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:25:55.887+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:25:55.887+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:25:55.901+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:25:55.901+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:25:55.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T19:26:26.261+0000] {processor.py:186} INFO - Started process (PID=3270) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:26:26.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:26:26.264+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:26:26.263+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:26:26.496+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:26:26.520+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:26:26.519+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:26:26.536+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:26:26.536+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:26:26.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.303 seconds
[2024-10-01T19:26:57.179+0000] {processor.py:186} INFO - Started process (PID=3293) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:26:57.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:26:57.182+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:26:57.181+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:26:57.380+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:26:57.403+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:26:57.403+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:26:57.416+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:26:57.416+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:26:57.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T19:27:27.895+0000] {processor.py:186} INFO - Started process (PID=3322) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:27:27.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:27:27.898+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:27:27.897+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:27:28.085+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:27:28.107+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:27:28.107+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:27:28.122+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:27:28.122+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:27:28.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T19:27:58.614+0000] {processor.py:186} INFO - Started process (PID=3345) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:27:58.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:27:58.616+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:27:58.616+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:27:58.801+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:27:58.824+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:27:58.823+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:27:58.837+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:27:58.837+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:27:58.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-10-01T19:28:29.738+0000] {processor.py:186} INFO - Started process (PID=3368) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:28:29.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:28:29.740+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:28:29.740+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:28:29.924+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:28:29.949+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:28:29.949+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:28:29.963+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:28:29.963+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:28:29.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T19:29:00.936+0000] {processor.py:186} INFO - Started process (PID=3391) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:29:00.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:29:00.938+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:29:00.938+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:29:01.128+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:29:01.150+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:29:01.150+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:29:01.164+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:29:01.164+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:29:01.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T19:29:32.142+0000] {processor.py:186} INFO - Started process (PID=3414) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:29:32.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:29:32.144+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:29:32.144+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:29:32.329+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:29:32.353+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:29:32.352+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:29:32.366+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:29:32.366+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:29:32.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T19:30:02.519+0000] {processor.py:186} INFO - Started process (PID=3437) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:30:02.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:30:02.522+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:30:02.521+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:30:02.706+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:30:02.729+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:30:02.729+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:30:02.743+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:30:02.742+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:30:02.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-10-01T19:30:32.828+0000] {processor.py:186} INFO - Started process (PID=3460) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:30:32.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:30:32.830+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:30:32.830+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:30:33.014+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:30:33.040+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:30:33.040+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:30:33.054+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:30:33.054+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:30:33.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T19:31:03.247+0000] {processor.py:186} INFO - Started process (PID=3483) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:31:03.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:31:03.249+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:31:03.249+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:31:03.440+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:31:03.465+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:31:03.465+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:31:03.480+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:31:03.479+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:31:03.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T19:31:33.861+0000] {processor.py:186} INFO - Started process (PID=3506) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:31:33.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:31:33.864+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:31:33.863+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:31:34.060+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:31:34.083+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:31:34.082+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:31:34.096+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:31:34.095+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:31:34.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T19:32:04.829+0000] {processor.py:186} INFO - Started process (PID=3529) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:32:04.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:32:04.832+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:32:04.832+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:32:05.040+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:32:05.062+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:32:05.062+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:32:05.076+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:32:05.075+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:32:05.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T19:32:35.336+0000] {processor.py:186} INFO - Started process (PID=3555) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:32:35.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:32:35.338+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:32:35.338+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:32:35.523+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:32:35.545+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:32:35.544+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:32:35.558+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:32:35.557+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:32:35.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-10-01T19:33:06.544+0000] {processor.py:186} INFO - Started process (PID=3578) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:33:06.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:33:06.546+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:33:06.546+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:33:06.743+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:33:06.766+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:33:06.766+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:33:06.780+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:33:06.780+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:33:06.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T19:33:37.004+0000] {processor.py:186} INFO - Started process (PID=3603) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:33:37.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:33:37.006+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:33:37.006+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:33:37.230+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:33:37.254+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:33:37.253+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:33:37.272+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:33:37.272+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:33:37.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.299 seconds
[2024-10-01T19:33:47.491+0000] {processor.py:186} INFO - Started process (PID=3614) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:33:47.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:33:47.493+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:33:47.493+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:33:47.695+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:33:47.813+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:33:47.813+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:33:47.825+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:33:47.825+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:33:47.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.366 seconds
[2024-10-01T19:34:18.147+0000] {processor.py:186} INFO - Started process (PID=3637) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:34:18.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:34:18.150+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:34:18.149+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:34:18.340+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:34:18.364+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:34:18.363+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:34:18.378+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:34:18.378+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:34:18.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T19:34:48.715+0000] {processor.py:186} INFO - Started process (PID=3660) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:34:48.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:34:48.717+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:34:48.717+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:34:48.905+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:34:48.927+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:34:48.927+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:34:48.940+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:34:48.940+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:34:48.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-10-01T19:35:09.578+0000] {processor.py:186} INFO - Started process (PID=3675) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:35:09.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:35:09.581+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:35:09.580+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:35:09.776+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:35:09.883+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:35:09.882+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:35:09.894+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:35:09.894+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:35:09.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.344 seconds
[2024-10-01T19:35:40.161+0000] {processor.py:186} INFO - Started process (PID=3698) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:35:40.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:35:40.164+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:35:40.163+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:35:40.356+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:35:40.378+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:35:40.378+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:35:40.391+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:35:40.391+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:35:40.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T19:36:10.995+0000] {processor.py:186} INFO - Started process (PID=3721) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:36:10.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:36:10.998+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:36:10.998+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:36:11.183+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:36:11.204+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:36:11.203+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:36:11.217+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:36:11.217+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:36:11.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T19:36:41.335+0000] {processor.py:186} INFO - Started process (PID=3745) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:36:41.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:36:41.337+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:36:41.337+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:36:41.532+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:36:41.555+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:36:41.555+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:36:41.570+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:36:41.569+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:36:41.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T19:37:12.495+0000] {processor.py:186} INFO - Started process (PID=3769) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:37:12.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:37:12.498+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:37:12.498+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:37:12.679+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:37:12.701+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:37:12.700+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:37:12.714+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:37:12.714+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:37:12.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-10-01T19:37:42.836+0000] {processor.py:186} INFO - Started process (PID=3792) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:37:42.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:37:42.839+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:37:42.839+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:37:43.021+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:37:43.042+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:37:43.042+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:37:43.055+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:37:43.054+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:37:43.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-10-01T19:38:13.439+0000] {processor.py:186} INFO - Started process (PID=3815) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:38:13.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:38:13.442+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:38:13.441+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:38:13.628+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:38:13.649+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:38:13.649+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:38:13.664+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:38:13.664+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:38:13.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T19:38:44.615+0000] {processor.py:186} INFO - Started process (PID=3838) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:38:44.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:38:44.617+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:38:44.617+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:38:44.819+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:38:44.856+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:38:44.856+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:38:44.873+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:38:44.872+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:38:44.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.290 seconds
[2024-10-01T19:39:15.258+0000] {processor.py:186} INFO - Started process (PID=3861) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:39:15.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:39:15.262+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:39:15.261+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:39:15.524+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:39:15.551+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:39:15.550+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:39:15.573+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:39:15.573+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:39:15.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.347 seconds
[2024-10-01T19:39:45.935+0000] {processor.py:186} INFO - Started process (PID=3884) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:39:45.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:39:45.938+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:39:45.937+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:39:46.141+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:39:46.167+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:39:46.166+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:39:46.183+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:39:46.182+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:39:46.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.288 seconds
[2024-10-01T19:40:16.424+0000] {processor.py:186} INFO - Started process (PID=3907) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:40:16.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:40:16.426+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:40:16.426+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:40:16.621+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:40:16.644+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:40:16.643+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:40:16.659+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:40:16.658+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:40:16.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-10-01T19:40:46.987+0000] {processor.py:186} INFO - Started process (PID=3930) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:40:46.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:40:46.990+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:40:46.990+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:40:47.182+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:40:47.205+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:40:47.205+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:40:47.221+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:40:47.220+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:40:47.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T19:41:17.495+0000] {processor.py:186} INFO - Started process (PID=3953) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:41:17.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:41:17.498+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:41:17.497+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:41:17.692+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:41:17.716+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:41:17.716+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:41:17.731+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:41:17.731+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:41:17.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T19:41:48.320+0000] {processor.py:186} INFO - Started process (PID=3976) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:41:48.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:41:48.323+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:41:48.322+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:41:48.514+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:41:48.539+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:41:48.538+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:41:48.554+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:41:48.554+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:41:48.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T19:42:18.938+0000] {processor.py:186} INFO - Started process (PID=3999) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:42:18.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:42:18.941+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:42:18.940+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:42:19.137+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:42:19.161+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:42:19.160+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:42:19.175+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:42:19.174+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:42:19.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-10-01T19:42:49.734+0000] {processor.py:186} INFO - Started process (PID=4022) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:42:49.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:42:49.737+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:42:49.736+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:42:49.926+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:42:49.948+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:42:49.948+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:42:49.964+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:42:49.963+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:42:49.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T19:43:20.510+0000] {processor.py:186} INFO - Started process (PID=4045) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:43:20.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:43:20.513+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:43:20.512+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:43:20.710+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:43:20.826+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:43:20.825+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:43:20.838+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:43:20.838+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:43:20.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.361 seconds
[2024-10-01T19:43:50.999+0000] {processor.py:186} INFO - Started process (PID=4071) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:43:50.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:43:51.001+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:43:51.001+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:43:51.185+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:43:51.206+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:43:51.206+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:43:51.220+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:43:51.219+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:43:51.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-10-01T19:44:21.338+0000] {processor.py:186} INFO - Started process (PID=4094) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:44:21.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:44:21.340+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:44:21.340+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:44:21.520+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:44:21.542+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:44:21.541+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:44:21.555+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:44:21.554+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:44:21.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-10-01T19:44:49.287+0000] {processor.py:186} INFO - Started process (PID=4113) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:44:49.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:44:49.289+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:44:49.289+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:44:49.486+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:44:49.595+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:44:49.594+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:44:49.606+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:44:49.606+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:44:49.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.357 seconds
[2024-10-01T19:45:20.095+0000] {processor.py:186} INFO - Started process (PID=4136) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:45:20.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:45:20.098+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:45:20.097+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:45:20.283+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:45:20.304+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:45:20.304+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:45:20.320+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:45:20.319+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:45:20.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-10-01T19:45:50.657+0000] {processor.py:186} INFO - Started process (PID=4159) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:45:50.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:45:50.660+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:45:50.660+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:45:50.903+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:45:50.931+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:45:50.931+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:45:50.948+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:45:50.948+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:45:50.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.323 seconds
[2024-10-01T19:46:21.200+0000] {processor.py:186} INFO - Started process (PID=4182) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:46:21.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:46:21.204+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:46:21.203+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:46:21.430+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:46:21.452+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:46:21.452+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:46:21.466+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:46:21.466+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:46:21.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.299 seconds
[2024-10-01T19:46:29.947+0000] {processor.py:186} INFO - Started process (PID=4195) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:46:29.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:46:29.950+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:46:29.950+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:46:30.161+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:46:30.184+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:46:30.184+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:46:30.198+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:46:30.197+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:46:30.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.281 seconds
[2024-10-01T19:46:34.365+0000] {processor.py:186} INFO - Started process (PID=4198) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:46:34.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:46:34.369+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:46:34.368+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:46:34.667+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:46:34.714+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:46:34.714+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:46:34.738+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:46:34.738+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:46:35.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.686 seconds
[2024-10-01T19:47:05.223+0000] {processor.py:186} INFO - Started process (PID=4221) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:47:05.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:47:05.226+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:47:05.225+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:47:05.629+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:47:06.430+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:47:06.430+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:47:06.462+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:47:06.461+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:47:06.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 1.573 seconds
[2024-10-01T19:47:36.854+0000] {processor.py:186} INFO - Started process (PID=4244) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:47:36.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:47:36.856+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:47:36.856+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:47:37.072+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:47:37.096+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:47:37.096+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:47:37.111+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:47:37.111+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:47:37.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.286 seconds
[2024-10-01T19:48:07.509+0000] {processor.py:186} INFO - Started process (PID=4267) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:48:07.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:48:07.513+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:48:07.511+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:48:07.884+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:48:07.913+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:48:07.913+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:48:07.933+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:48:07.933+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:48:07.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.454 seconds
[2024-10-01T19:48:38.353+0000] {processor.py:186} INFO - Started process (PID=4290) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:48:38.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:48:38.356+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:48:38.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:48:38.551+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:48:38.574+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:48:38.574+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:48:38.588+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:48:38.587+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:48:38.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T19:49:08.688+0000] {processor.py:186} INFO - Started process (PID=4313) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:49:08.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:49:08.690+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:49:08.690+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:49:08.874+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:49:08.896+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:49:08.896+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:49:08.910+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:49:08.910+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:49:08.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-10-01T19:49:25.617+0000] {processor.py:186} INFO - Started process (PID=4323) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:49:25.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:49:25.619+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:49:25.619+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:49:25.820+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:49:25.844+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:49:25.844+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:49:25.858+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:49:25.858+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:49:25.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.275 seconds
[2024-10-01T19:49:56.484+0000] {processor.py:186} INFO - Started process (PID=4346) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:49:56.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:49:56.486+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:49:56.486+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:49:56.672+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:49:56.693+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:49:56.693+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:49:56.706+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:49:56.706+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:49:56.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.344 seconds
[2024-10-01T19:50:27.194+0000] {processor.py:186} INFO - Started process (PID=4369) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:50:27.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:50:27.197+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:50:27.196+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:50:27.386+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:50:27.408+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:50:27.408+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:50:27.422+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:50:27.422+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:50:27.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.284 seconds
[2024-10-01T19:50:58.510+0000] {processor.py:186} INFO - Started process (PID=4392) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:50:58.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:50:58.513+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:50:58.512+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:50:58.702+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:50:58.724+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:50:58.724+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:50:58.738+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:50:58.738+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:50:58.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-10-01T19:51:29.123+0000] {processor.py:186} INFO - Started process (PID=4421) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:51:29.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:51:29.125+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:51:29.125+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:51:29.317+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:51:29.339+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:51:29.339+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:51:29.353+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:51:29.353+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:51:29.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T19:51:59.598+0000] {processor.py:186} INFO - Started process (PID=4444) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:51:59.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:51:59.600+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:51:59.600+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:51:59.826+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:51:59.855+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:51:59.855+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:51:59.872+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:51:59.872+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:51:59.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.307 seconds
[2024-10-01T19:52:29.981+0000] {processor.py:186} INFO - Started process (PID=4467) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:52:29.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:52:29.983+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:52:29.983+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:52:30.173+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:52:30.195+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:52:30.194+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:52:30.211+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:52:30.210+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:52:30.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T19:53:00.699+0000] {processor.py:186} INFO - Started process (PID=4490) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:53:00.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:53:00.701+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:53:00.701+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:53:00.893+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:53:00.916+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:53:00.916+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:53:00.932+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:53:00.931+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:53:00.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T19:53:31.315+0000] {processor.py:186} INFO - Started process (PID=4513) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:53:31.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:53:31.318+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:53:31.318+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:53:31.508+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:53:31.530+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:53:31.530+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:53:31.544+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:53:31.544+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:53:31.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T19:54:01.740+0000] {processor.py:186} INFO - Started process (PID=4536) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:54:01.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:54:01.743+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:54:01.743+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:54:01.936+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:54:01.960+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:54:01.960+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:54:01.974+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:54:01.974+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:54:01.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T19:54:32.224+0000] {processor.py:186} INFO - Started process (PID=4559) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:54:32.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:54:32.226+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:54:32.226+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:54:32.445+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:54:32.468+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:54:32.467+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:54:32.482+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:54:32.482+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:54:32.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.287 seconds
[2024-10-01T19:55:03.000+0000] {processor.py:186} INFO - Started process (PID=4582) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:55:03.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:55:03.002+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:55:03.002+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:55:03.195+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:55:03.224+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:55:03.223+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:55:03.246+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:55:03.245+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:55:03.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.277 seconds
[2024-10-01T19:55:33.669+0000] {processor.py:186} INFO - Started process (PID=4605) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:55:33.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:55:33.672+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:55:33.671+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:55:33.866+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:55:33.893+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:55:33.893+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:55:33.919+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:55:33.919+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:55:33.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.310 seconds
[2024-10-01T19:56:04.421+0000] {processor.py:186} INFO - Started process (PID=4628) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:56:04.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:56:04.424+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:56:04.423+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:56:04.611+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:56:04.633+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:56:04.633+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:56:04.647+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:56:04.647+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:56:04.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T19:56:35.215+0000] {processor.py:186} INFO - Started process (PID=4651) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:56:35.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:56:35.218+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:56:35.218+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:56:35.433+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:56:35.454+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:56:35.454+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:56:35.469+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:56:35.469+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:56:35.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.281 seconds
[2024-10-01T19:57:05.985+0000] {processor.py:186} INFO - Started process (PID=4674) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:57:05.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:57:05.988+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:57:05.988+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:57:06.214+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:57:06.238+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:57:06.238+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:57:06.258+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:57:06.258+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:57:06.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.318 seconds
[2024-10-01T19:57:36.950+0000] {processor.py:186} INFO - Started process (PID=4697) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:57:36.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:57:36.953+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:57:36.952+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:57:37.143+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:57:37.166+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:57:37.165+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:57:37.181+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:57:37.181+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:57:37.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T19:58:07.484+0000] {processor.py:186} INFO - Started process (PID=4720) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:58:07.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:58:07.487+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:58:07.486+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:58:07.686+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:58:07.710+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:58:07.710+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:58:07.725+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:58:07.725+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:58:07.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-10-01T19:58:37.900+0000] {processor.py:186} INFO - Started process (PID=4743) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:58:37.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:58:37.902+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:58:37.902+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:58:38.091+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:58:38.114+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:58:38.114+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:58:38.128+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:58:38.128+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:58:38.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T19:59:08.358+0000] {processor.py:186} INFO - Started process (PID=4766) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:59:08.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:59:08.361+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:59:08.361+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:59:08.579+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:59:08.602+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:59:08.601+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:59:08.618+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:59:08.618+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:59:08.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.289 seconds
[2024-10-01T19:59:38.833+0000] {processor.py:186} INFO - Started process (PID=4789) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:59:38.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T19:59:38.837+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:59:38.836+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:59:39.037+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T19:59:39.059+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:59:39.058+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T19:59:39.074+0000] {logging_mixin.py:190} INFO - [2024-10-01T19:59:39.073+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T19:59:39.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-10-01T20:00:09.342+0000] {processor.py:186} INFO - Started process (PID=4812) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:00:09.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:00:09.345+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:00:09.344+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:00:09.533+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:00:09.556+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:00:09.555+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:00:09.570+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:00:09.569+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:00:09.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T20:00:40.011+0000] {processor.py:186} INFO - Started process (PID=4835) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:00:40.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:00:40.014+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:00:40.014+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:00:40.202+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:00:40.224+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:00:40.224+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:00:40.239+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:00:40.238+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:00:40.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T20:01:10.507+0000] {processor.py:186} INFO - Started process (PID=4858) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:01:10.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:01:10.510+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:01:10.509+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:01:10.710+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:01:10.733+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:01:10.732+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:01:10.746+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:01:10.746+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:01:10.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-10-01T20:01:40.906+0000] {processor.py:186} INFO - Started process (PID=4881) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:01:40.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:01:40.908+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:01:40.908+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:01:41.109+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:01:41.132+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:01:41.132+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:01:41.148+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:01:41.148+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:01:41.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-10-01T20:02:11.517+0000] {processor.py:186} INFO - Started process (PID=4904) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:02:11.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:02:11.520+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:02:11.520+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:02:11.714+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:02:11.736+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:02:11.736+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:02:11.751+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:02:11.751+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:02:11.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T20:02:41.884+0000] {processor.py:186} INFO - Started process (PID=4927) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:02:41.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:02:41.887+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:02:41.887+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:02:42.084+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:02:42.108+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:02:42.108+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:02:42.126+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:02:42.126+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:02:42.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T20:02:53.515+0000] {processor.py:186} INFO - Started process (PID=4933) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:02:53.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:02:53.517+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:02:53.517+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:02:53.720+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:02:53.711+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 36, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^
NameError: name 'OperatorSiteB' is not defined
[2024-10-01T20:02:53.727+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:02:53.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.238 seconds
[2024-10-01T20:03:11.623+0000] {processor.py:186} INFO - Started process (PID=4951) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:03:11.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:03:11.626+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:03:11.626+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:03:11.838+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:03:11.825+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:03:11.847+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:03:11.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-10-01T20:03:31.363+0000] {processor.py:186} INFO - Started process (PID=4965) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:03:31.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:03:31.366+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:03:31.365+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:03:31.567+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:03:31.554+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:03:31.576+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:03:31.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-10-01T20:04:01.683+0000] {processor.py:186} INFO - Started process (PID=4988) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:04:01.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:04:01.685+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:04:01.685+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:04:01.878+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:04:01.866+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:04:01.887+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:04:01.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.231 seconds
[2024-10-01T20:04:32.275+0000] {processor.py:186} INFO - Started process (PID=5011) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:04:32.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:04:32.278+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:04:32.277+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:04:32.472+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:04:32.460+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:04:32.481+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:04:32.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.233 seconds
[2024-10-01T20:05:02.676+0000] {processor.py:186} INFO - Started process (PID=5034) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:05:02.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:05:02.679+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:05:02.678+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:05:02.903+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:05:02.889+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase,ABC):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:05:02.911+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:05:02.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T20:05:33.316+0000] {processor.py:186} INFO - Started process (PID=5057) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:05:33.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:05:33.318+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:05:33.318+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:05:33.515+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:05:33.502+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase,ABC):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:05:33.523+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:05:33.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.234 seconds
[2024-10-01T20:06:03.847+0000] {processor.py:186} INFO - Started process (PID=5080) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:06:03.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:06:03.850+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:06:03.849+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:06:04.054+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:06:04.038+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:06:04.063+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:06:04.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-10-01T20:06:34.292+0000] {processor.py:186} INFO - Started process (PID=5103) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:06:34.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:06:34.296+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:06:34.295+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:06:34.500+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:06:34.487+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:06:34.509+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:06:34.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-10-01T20:07:04.891+0000] {processor.py:186} INFO - Started process (PID=5126) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:07:04.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:07:04.894+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:07:04.893+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:07:05.086+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:07:05.074+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:07:05.095+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:07:05.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.232 seconds
[2024-10-01T20:07:35.363+0000] {processor.py:186} INFO - Started process (PID=5149) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:07:35.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:07:35.365+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:07:35.365+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:07:35.575+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:07:35.563+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:07:35.584+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:07:35.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-10-01T20:08:05.833+0000] {processor.py:186} INFO - Started process (PID=5172) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:08:05.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:08:05.836+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:08:05.835+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:08:06.022+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:08:06.010+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:08:06.030+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:08:06.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T20:08:36.306+0000] {processor.py:186} INFO - Started process (PID=5195) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:08:36.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:08:36.308+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:08:36.308+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:08:36.513+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:08:36.499+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:08:36.521+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:08:36.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-10-01T20:09:06.660+0000] {processor.py:186} INFO - Started process (PID=5216) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:09:06.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:09:06.663+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:09:06.662+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:09:06.852+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:09:06.839+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:09:06.860+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:09:06.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.230 seconds
[2024-10-01T20:09:37.300+0000] {processor.py:186} INFO - Started process (PID=5239) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:09:37.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:09:37.302+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:09:37.302+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:09:37.503+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:09:37.499+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
ImportError: cannot import name 'OperatorSiteB' from 'operators.OperatorSiteB' (/opt/airflow/operators/OperatorSiteB.py). Did you mean: 'OperatorSpark'?
[2024-10-01T20:09:37.505+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:09:37.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.231 seconds
[2024-10-01T20:10:08.048+0000] {processor.py:186} INFO - Started process (PID=5262) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:10:08.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:10:08.051+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:10:08.050+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:10:08.269+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:10:08.255+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 16, in <module>
    class OperatorSiteB(OperatorSiteBase):
                        ^^^^^^^^^^^^^^^^
NameError: name 'OperatorSiteBase' is not defined
[2024-10-01T20:10:08.278+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:10:08.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T20:10:38.586+0000] {processor.py:186} INFO - Started process (PID=5285) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:10:38.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:10:38.589+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:10:38.588+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:10:38.815+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:10:38.811+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
TypeError: Can't instantiate abstract class OperatorSiteB without an implementation for abstract methods '_ProcessamentoBeautifulSoup', '_Urls'
[2024-10-01T20:10:38.816+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:10:38.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T20:11:09.291+0000] {processor.py:186} INFO - Started process (PID=5308) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:11:09.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:11:09.293+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:11:09.293+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:11:09.495+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:11:09.492+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
TypeError: Can't instantiate abstract class OperatorSiteB without an implementation for abstract methods '_ProcessamentoBeautifulSoup', '_Urls'
[2024-10-01T20:11:09.497+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:11:09.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.235 seconds
[2024-10-01T20:11:40.095+0000] {processor.py:186} INFO - Started process (PID=5332) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:11:40.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:11:40.099+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:11:40.098+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:11:40.291+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:11:40.286+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 30
    @abstractmethod
    ^
IndentationError: expected an indented block after function definition on line 27
[2024-10-01T20:11:40.292+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:11:40.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
[2024-10-01T20:12:10.797+0000] {processor.py:186} INFO - Started process (PID=5355) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:12:10.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:12:10.800+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:12:10.799+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:12:10.984+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:12:10.981+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 7, in <module>
    from operators.OperatorSiteB import OperatorSiteB
  File "/opt/airflow/operators/OperatorSiteB.py", line 30
    @abstractmethod
    ^
IndentationError: expected an indented block after function definition on line 27
[2024-10-01T20:12:10.986+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:12:11.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-10-01T20:12:41.574+0000] {processor.py:186} INFO - Started process (PID=5378) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:12:41.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:12:41.578+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:12:41.577+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:12:41.797+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:12:41.789+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 20, in __init__
    super().__init__('Create_Container_Raw', **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 448, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2024-10-01T20:12:41.798+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:12:41.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T20:12:53.488+0000] {processor.py:186} INFO - Started process (PID=5390) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:12:53.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:12:53.490+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:12:53.490+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:12:53.698+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:12:53.692+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 20, in __init__
    super().__init__('Create_Container_Raw', **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 448, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2024-10-01T20:12:53.700+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:12:53.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.241 seconds
[2024-10-01T20:13:24.211+0000] {processor.py:186} INFO - Started process (PID=5413) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:13:24.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:13:24.214+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:13:24.213+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:13:24.411+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:13:24.404+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 20, in __init__
    super().__init__('Create_Container_Raw', **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 448, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2024-10-01T20:13:24.413+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:13:24.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.229 seconds
[2024-10-01T20:13:54.534+0000] {processor.py:186} INFO - Started process (PID=5437) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:13:54.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:13:54.536+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:13:54.536+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:13:54.736+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:13:54.728+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 20, in __init__
    super().__init__('Create_Container_Raw', **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 448, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2024-10-01T20:13:54.737+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:13:54.755+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.229 seconds
[2024-10-01T20:14:24.848+0000] {processor.py:186} INFO - Started process (PID=5459) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:14:24.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:14:24.851+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:14:24.850+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:14:25.043+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:14:25.037+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 20, in __init__
    super().__init__('Create_Container_Raw', **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 448, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2024-10-01T20:14:25.045+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:14:25.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-10-01T20:14:55.352+0000] {processor.py:186} INFO - Started process (PID=5482) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:14:55.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:14:55.354+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:14:55.354+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:14:55.549+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:14:55.542+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 20, in __init__
    super().__init__('Create_Container_Raw', **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 448, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2024-10-01T20:14:55.550+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:14:55.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
[2024-10-01T20:15:26.015+0000] {processor.py:186} INFO - Started process (PID=5505) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:15:26.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:15:26.017+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:15:26.017+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:15:26.240+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:15:26.233+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 20, in __init__
    super().__init__('Create_Container_Raw', **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 448, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2024-10-01T20:15:26.241+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:15:26.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T20:15:56.805+0000] {processor.py:186} INFO - Started process (PID=5528) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:15:56.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:15:56.807+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:15:56.807+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:15:57.007+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:15:56.999+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 20, in __init__
    super().__init__('Create_Container_Raw', **kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 448, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2024-10-01T20:15:57.008+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:15:57.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.232 seconds
[2024-10-01T20:16:27.511+0000] {processor.py:186} INFO - Started process (PID=5551) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:16:27.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:16:27.514+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:16:27.514+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:16:27.742+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:16:27.735+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:16:27.744+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:16:27.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T20:16:57.853+0000] {processor.py:186} INFO - Started process (PID=5575) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:16:57.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:16:57.856+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:16:57.855+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:16:58.061+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:16:58.055+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:16:58.063+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:16:58.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-10-01T20:17:28.423+0000] {processor.py:186} INFO - Started process (PID=5597) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:17:28.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:17:28.426+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:17:28.426+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:17:28.716+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:17:28.679+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:17:28.724+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:17:28.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.330 seconds
[2024-10-01T20:17:59.256+0000] {processor.py:186} INFO - Started process (PID=5620) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:17:59.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:17:59.258+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:17:59.258+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:17:59.458+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:17:59.448+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:17:59.460+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:17:59.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.230 seconds
[2024-10-01T20:18:30.030+0000] {processor.py:186} INFO - Started process (PID=5643) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:18:30.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:18:30.033+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:18:30.032+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:18:30.240+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:18:30.230+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:18:30.242+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:18:30.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-10-01T20:19:01.034+0000] {processor.py:186} INFO - Started process (PID=5672) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:19:01.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:19:01.037+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:19:01.036+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:19:01.241+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:19:01.232+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:19:01.243+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:19:01.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.235 seconds
[2024-10-01T20:19:31.776+0000] {processor.py:186} INFO - Started process (PID=5695) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:19:31.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:19:31.779+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:19:31.779+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:19:31.978+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:19:31.966+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:19:31.980+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:19:31.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.230 seconds
[2024-10-01T20:20:02.096+0000] {processor.py:186} INFO - Started process (PID=5719) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:20:02.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:20:02.098+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:20:02.098+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:20:02.297+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:20:02.288+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:20:02.298+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:20:02.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.325 seconds
[2024-10-01T20:20:32.502+0000] {processor.py:186} INFO - Started process (PID=5743) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:20:32.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:20:32.504+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:20:32.504+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:20:32.696+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:20:32.686+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:20:32.697+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:20:32.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.316 seconds
[2024-10-01T20:21:03.746+0000] {processor.py:186} INFO - Started process (PID=5767) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:21:03.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:21:03.748+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:21:03.748+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:21:03.943+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:21:03.932+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:21:03.945+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:21:03.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
[2024-10-01T20:21:34.053+0000] {processor.py:186} INFO - Started process (PID=5790) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:21:34.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:21:34.055+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:21:34.055+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:21:34.254+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:21:34.245+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:21:34.256+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:21:34.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.356 seconds
[2024-10-01T20:22:05.352+0000] {processor.py:186} INFO - Started process (PID=5813) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:22:05.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:22:05.355+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:22:05.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:22:05.574+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:22:05.564+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:22:05.575+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:22:05.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-10-01T20:22:35.653+0000] {processor.py:186} INFO - Started process (PID=5836) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:22:35.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:22:35.655+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:22:35.655+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:22:35.849+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:22:35.841+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:22:35.851+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:22:35.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.299 seconds
[2024-10-01T20:23:06.904+0000] {processor.py:186} INFO - Started process (PID=5859) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:06.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:23:06.906+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:23:06.906+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:07.102+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:23:07.093+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:23:07.104+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:07.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.226 seconds
[2024-10-01T20:23:17.449+0000] {processor.py:186} INFO - Started process (PID=5862) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:17.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:23:17.452+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:23:17.451+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:17.654+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:23:17.645+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 37, in <module>
    Web_Extraction = OperatorSiteB(
                     ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteB.py", line 22, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorSiteBase.py", line 19, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2024-10-01T20:23:17.656+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:17.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.309 seconds
[2024-10-01T20:23:22.957+0000] {processor.py:186} INFO - Started process (PID=5863) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:22.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:23:22.960+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:23:22.959+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:23.159+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:23.289+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:23:23.288+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:23:23.300+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:23:23.300+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:23:23.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.378 seconds
[2024-10-01T20:23:53.805+0000] {processor.py:186} INFO - Started process (PID=5886) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:53.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:23:53.810+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:23:53.808+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:54.053+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:23:54.078+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:23:54.078+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:23:54.097+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:23:54.096+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:23:54.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.451 seconds
[2024-10-01T20:24:24.451+0000] {processor.py:186} INFO - Started process (PID=5908) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:24:24.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:24:24.454+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:24:24.453+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:24:24.654+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:24:24.676+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:24:24.676+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:24:24.691+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:24:24.691+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:24:24.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-10-01T20:24:55.136+0000] {processor.py:186} INFO - Started process (PID=5931) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:24:55.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:24:55.140+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:24:55.139+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:24:55.351+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:24:55.387+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:24:55.387+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:24:55.401+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:24:55.401+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:24:55.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.297 seconds
[2024-10-01T20:25:25.752+0000] {processor.py:186} INFO - Started process (PID=5954) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:25:25.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:25:25.755+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:25:25.754+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:25:25.947+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:25:25.969+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:25:25.969+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:25:25.983+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:25:25.983+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:25:26.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T20:25:56.258+0000] {processor.py:186} INFO - Started process (PID=5977) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:25:56.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:25:56.260+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:25:56.260+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:25:56.454+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:25:56.475+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:25:56.475+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:25:56.488+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:25:56.488+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:25:56.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T20:26:26.604+0000] {processor.py:186} INFO - Started process (PID=6000) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:26:26.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:26:26.606+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:26:26.606+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:26:26.799+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:26:26.820+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:26:26.820+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:26:26.836+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:26:26.836+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:26:26.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T20:26:57.066+0000] {processor.py:186} INFO - Started process (PID=6023) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:26:57.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:26:57.069+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:26:57.069+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:26:57.280+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:26:57.302+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:26:57.302+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:26:57.317+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:26:57.316+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:26:57.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.289 seconds
[2024-10-01T20:27:27.520+0000] {processor.py:186} INFO - Started process (PID=6046) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:27:27.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:27:27.522+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:27:27.522+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:27:27.716+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:27:27.738+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:27:27.737+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:27:27.752+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:27:27.751+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:27:27.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T20:27:57.950+0000] {processor.py:186} INFO - Started process (PID=6069) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:27:57.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:27:57.953+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:27:57.952+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:27:58.189+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:27:58.226+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:27:58.225+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:27:58.241+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:27:58.241+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:27:58.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.317 seconds
[2024-10-01T20:28:28.502+0000] {processor.py:186} INFO - Started process (PID=6092) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:28:28.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:28:28.505+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:28:28.504+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:28:28.700+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:28:28.723+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:28:28.723+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:28:28.736+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:28:28.736+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:28:28.755+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T20:28:59.027+0000] {processor.py:186} INFO - Started process (PID=6115) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:28:59.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:28:59.029+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:28:59.029+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:28:59.228+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:28:59.249+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:28:59.249+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:28:59.263+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:28:59.263+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:28:59.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T20:29:03.131+0000] {processor.py:186} INFO - Started process (PID=6123) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:29:03.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:29:03.133+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:29:03.133+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:29:03.348+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:29:03.338+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 85, in <module>
    Create_Container_Raw >> Web_Extraction >> Create_Container_Silver >> Spark_Transformation >> File_Sensor >> Branching >> [Task_Submission_With_Error,process_file_task]
                            ^^^^^^^^^^^^^^
NameError: name 'Web_Extraction' is not defined. Did you mean: 'Web_Extraction_siteB'?
[2024-10-01T20:29:03.355+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:29:03.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T20:29:05.411+0000] {processor.py:186} INFO - Started process (PID=6127) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:29:05.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:29:05.413+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:29:05.413+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:29:05.628+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:29:05.618+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 85, in <module>
    Create_Container_Raw >> Web_Extraction >> Create_Container_Silver >> Spark_Transformation >> File_Sensor >> Branching >> [Task_Submission_With_Error,process_file_task]
                            ^^^^^^^^^^^^^^
NameError: name 'Web_Extraction' is not defined. Did you mean: 'Web_Extraction_siteB'?
[2024-10-01T20:29:05.636+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:29:05.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T20:29:35.727+0000] {processor.py:186} INFO - Started process (PID=6151) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:29:35.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:29:35.729+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:29:35.729+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:29:35.929+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:29:35.918+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 85, in <module>
    Create_Container_Raw >> Web_Extraction >> Create_Container_Silver >> Spark_Transformation >> File_Sensor >> Branching >> [Task_Submission_With_Error,process_file_task]
                            ^^^^^^^^^^^^^^
NameError: name 'Web_Extraction' is not defined. Did you mean: 'Web_Extraction_siteB'?
[2024-10-01T20:29:35.937+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:29:35.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.236 seconds
[2024-10-01T20:30:06.074+0000] {processor.py:186} INFO - Started process (PID=6175) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:30:06.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:30:06.077+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:30:06.076+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:30:06.306+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:30:06.296+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 85, in <module>
    Create_Container_Raw >> Web_Extraction >> Create_Container_Silver >> Spark_Transformation >> File_Sensor >> Branching >> [Task_Submission_With_Error,process_file_task]
                            ^^^^^^^^^^^^^^
NameError: name 'Web_Extraction' is not defined. Did you mean: 'Web_Extraction_siteB'?
[2024-10-01T20:30:06.314+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:30:06.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-10-01T20:30:37.317+0000] {processor.py:186} INFO - Started process (PID=6198) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:30:37.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:30:37.320+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:30:37.319+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:30:37.524+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:30:37.514+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 85, in <module>
    Create_Container_Raw >> Web_Extraction >> Create_Container_Silver >> Spark_Transformation >> File_Sensor >> Branching >> [Task_Submission_With_Error,process_file_task]
                            ^^^^^^^^^^^^^^
NameError: name 'Web_Extraction' is not defined. Did you mean: 'Web_Extraction_siteB'?
[2024-10-01T20:30:37.532+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:30:37.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-10-01T20:30:40.915+0000] {processor.py:186} INFO - Started process (PID=6207) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:30:40.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:30:40.918+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:30:40.917+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:30:41.124+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:30:41.240+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:30:41.240+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:30:41.253+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:30:41.253+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:30:41.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.377 seconds
[2024-10-01T20:31:11.571+0000] {processor.py:186} INFO - Started process (PID=6227) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:31:11.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:31:11.574+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:31:11.573+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:31:11.814+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:31:11.837+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:31:11.837+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:31:11.853+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:31:11.853+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:31:11.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.351 seconds
[2024-10-01T20:31:42.433+0000] {processor.py:186} INFO - Started process (PID=6250) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:31:42.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:31:42.435+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:31:42.435+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:31:42.644+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:31:42.668+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:31:42.668+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:31:42.682+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:31:42.682+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:31:42.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.280 seconds
[2024-10-01T20:32:12.753+0000] {processor.py:186} INFO - Started process (PID=6275) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:32:12.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:32:12.755+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:32:12.755+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:32:12.982+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:32:13.015+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:32:13.014+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:32:13.032+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:32:13.032+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:32:13.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.316 seconds
[2024-10-01T20:32:43.155+0000] {processor.py:186} INFO - Started process (PID=6299) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:32:43.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:32:43.157+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:32:43.157+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:32:43.354+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:32:43.376+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:32:43.376+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:32:43.389+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:32:43.389+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:32:43.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T20:33:14.308+0000] {processor.py:186} INFO - Started process (PID=6322) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:33:14.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:33:14.311+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:33:14.310+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:33:14.508+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:33:14.531+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:33:14.531+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:33:14.544+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:33:14.544+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:33:14.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T20:33:44.857+0000] {processor.py:186} INFO - Started process (PID=6345) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:33:44.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:33:44.860+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:33:44.859+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:33:45.049+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:33:45.070+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:33:45.070+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:33:45.084+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:33:45.084+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:33:45.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-10-01T20:34:15.513+0000] {processor.py:186} INFO - Started process (PID=6368) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:34:15.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:34:15.515+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:34:15.515+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:34:15.705+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:34:15.727+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:34:15.726+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:34:15.740+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:34:15.739+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:34:15.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T20:34:46.174+0000] {processor.py:186} INFO - Started process (PID=6391) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:34:46.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:34:46.176+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:34:46.176+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:34:46.367+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:34:46.389+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:34:46.388+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:34:46.402+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:34:46.402+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:34:46.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T20:35:16.859+0000] {processor.py:186} INFO - Started process (PID=6414) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:35:16.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:35:16.861+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:35:16.861+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:35:17.053+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:35:17.075+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:35:17.075+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:35:17.089+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:35:17.089+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:35:17.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T20:35:47.635+0000] {processor.py:186} INFO - Started process (PID=6437) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:35:47.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:35:47.638+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:35:47.637+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:35:47.833+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:35:47.855+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:35:47.855+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:35:47.869+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:35:47.869+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:35:47.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T20:36:18.576+0000] {processor.py:186} INFO - Started process (PID=6460) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:36:18.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:36:18.579+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:36:18.578+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:36:18.771+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:36:18.793+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:36:18.792+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:36:18.807+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:36:18.807+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:36:18.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T20:36:48.920+0000] {processor.py:186} INFO - Started process (PID=6483) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:36:48.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:36:48.923+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:36:48.922+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:36:49.119+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:36:49.143+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:36:49.143+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:36:49.157+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:36:49.157+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:36:49.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T20:37:20.020+0000] {processor.py:186} INFO - Started process (PID=6506) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:37:20.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:37:20.022+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:37:20.022+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:37:20.224+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:37:20.247+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:37:20.247+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:37:20.261+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:37:20.260+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:37:20.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-10-01T20:37:50.959+0000] {processor.py:186} INFO - Started process (PID=6529) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:37:50.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:37:50.962+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:37:50.961+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:37:51.152+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:37:51.174+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:37:51.174+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:37:51.187+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:37:51.187+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:37:51.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T20:38:21.871+0000] {processor.py:186} INFO - Started process (PID=6552) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:38:21.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:38:21.873+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:38:21.873+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:38:22.106+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:38:22.129+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:38:22.129+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:38:22.143+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:38:22.143+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:38:22.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.309 seconds
[2024-10-01T20:38:52.575+0000] {processor.py:186} INFO - Started process (PID=6575) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:38:52.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:38:52.577+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:38:52.577+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:38:52.770+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:38:52.792+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:38:52.792+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:38:52.806+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:38:52.806+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:38:52.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T20:39:23.408+0000] {processor.py:186} INFO - Started process (PID=6598) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:39:23.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:39:23.410+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:39:23.410+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:39:23.615+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:39:23.638+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:39:23.638+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:39:23.652+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:39:23.651+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:39:23.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T20:39:54.170+0000] {processor.py:186} INFO - Started process (PID=6621) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:39:54.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:39:54.173+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:39:54.172+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:39:54.371+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:39:54.393+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:39:54.393+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:39:54.407+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:39:54.407+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:39:54.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T20:40:24.882+0000] {processor.py:186} INFO - Started process (PID=6644) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:40:24.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:40:24.885+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:40:24.884+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:40:25.075+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:40:25.096+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:40:25.096+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:40:25.110+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:40:25.109+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:40:25.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-10-01T20:40:55.645+0000] {processor.py:186} INFO - Started process (PID=6667) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:40:55.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:40:55.647+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:40:55.647+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:40:55.843+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:40:55.864+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:40:55.864+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:40:55.879+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:40:55.878+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:40:55.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T20:41:26.597+0000] {processor.py:186} INFO - Started process (PID=6690) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:41:26.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:41:26.599+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:41:26.599+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:41:26.786+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:41:26.808+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:41:26.807+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:41:26.821+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:41:26.820+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:41:26.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.322 seconds
[2024-10-01T20:41:57.825+0000] {processor.py:186} INFO - Started process (PID=6713) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:41:57.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:41:57.829+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:41:57.829+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:41:58.026+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:41:58.048+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:41:58.048+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:41:58.062+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:41:58.062+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:41:58.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T20:42:28.537+0000] {processor.py:186} INFO - Started process (PID=6736) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:42:28.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:42:28.540+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:42:28.539+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:42:28.735+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:42:28.756+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:42:28.756+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:42:28.770+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:42:28.770+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:42:28.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T20:42:58.881+0000] {processor.py:186} INFO - Started process (PID=6760) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:42:58.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:42:58.884+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:42:58.884+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:42:59.088+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:42:59.111+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:42:59.111+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:42:59.125+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:42:59.125+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:42:59.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.338 seconds
[2024-10-01T20:43:29.515+0000] {processor.py:186} INFO - Started process (PID=6782) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:43:29.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:43:29.518+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:43:29.517+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:43:29.713+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:43:29.735+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:43:29.735+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:43:29.750+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:43:29.750+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:43:29.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T20:44:00.348+0000] {processor.py:186} INFO - Started process (PID=6805) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:44:00.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:44:00.351+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:44:00.351+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:44:00.547+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:44:00.570+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:44:00.570+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:44:00.584+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:44:00.583+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:44:00.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T20:44:30.697+0000] {processor.py:186} INFO - Started process (PID=6829) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:44:30.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:44:30.699+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:44:30.699+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:44:30.903+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:44:30.925+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:44:30.925+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:44:30.940+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:44:30.939+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:44:30.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.279 seconds
[2024-10-01T20:45:01.442+0000] {processor.py:186} INFO - Started process (PID=6851) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:45:01.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:45:01.444+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:45:01.444+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:45:01.638+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:45:01.660+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:45:01.659+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:45:01.673+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:45:01.672+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:45:01.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-10-01T20:45:31.799+0000] {processor.py:186} INFO - Started process (PID=6875) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:45:31.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:45:31.802+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:45:31.802+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:45:32.004+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:45:32.027+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:45:32.027+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:45:32.040+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:45:32.040+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:45:32.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-10-01T20:46:02.425+0000] {processor.py:186} INFO - Started process (PID=6897) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:46:02.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:46:02.428+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:46:02.428+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:46:02.644+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:46:02.669+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:46:02.669+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:46:02.689+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:46:02.689+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:46:02.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.294 seconds
[2024-10-01T20:46:33.189+0000] {processor.py:186} INFO - Started process (PID=6926) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:46:33.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:46:33.192+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:46:33.191+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:46:33.386+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:46:33.409+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:46:33.409+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:46:33.422+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:46:33.422+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:46:33.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T20:47:03.842+0000] {processor.py:186} INFO - Started process (PID=6950) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:47:03.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:47:03.845+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:47:03.844+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:47:04.051+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:47:04.073+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:47:04.073+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:47:04.087+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:47:04.086+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:47:04.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.284 seconds
[2024-10-01T20:47:34.523+0000] {processor.py:186} INFO - Started process (PID=6973) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:47:34.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:47:34.525+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:47:34.525+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:47:34.714+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:47:34.735+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:47:34.734+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:47:34.748+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:47:34.747+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:47:34.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T20:48:04.912+0000] {processor.py:186} INFO - Started process (PID=6997) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:48:04.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:48:04.915+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:48:04.914+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:48:05.101+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:48:05.124+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:48:05.123+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:48:05.138+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:48:05.138+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:48:05.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T20:48:36.056+0000] {processor.py:186} INFO - Started process (PID=7020) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:48:36.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:48:36.058+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:48:36.058+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:48:36.252+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:48:36.274+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:48:36.274+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:48:36.289+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:48:36.288+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:48:36.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T20:49:06.392+0000] {processor.py:186} INFO - Started process (PID=7043) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:49:06.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:49:06.394+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:49:06.394+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:49:06.600+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:49:06.625+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:49:06.625+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:49:06.639+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:49:06.638+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:49:06.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.280 seconds
[2024-10-01T20:49:37.087+0000] {processor.py:186} INFO - Started process (PID=7066) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:49:37.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:49:37.089+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:49:37.089+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:49:37.286+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:49:37.310+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:49:37.309+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:49:37.324+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:49:37.324+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:49:37.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-10-01T20:50:07.847+0000] {processor.py:186} INFO - Started process (PID=7089) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:50:07.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:50:07.849+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:50:07.849+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:50:08.040+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:50:08.062+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:50:08.061+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:50:08.075+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:50:08.075+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:50:08.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-10-01T20:50:38.659+0000] {processor.py:186} INFO - Started process (PID=7112) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:50:38.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:50:38.661+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:50:38.661+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:50:38.852+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:50:38.874+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:50:38.873+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:50:38.888+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:50:38.888+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:50:38.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T20:51:09.616+0000] {processor.py:186} INFO - Started process (PID=7135) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:51:09.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:51:09.619+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:51:09.618+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:51:09.817+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:51:09.839+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:51:09.839+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:51:09.853+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:51:09.853+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:51:09.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-10-01T20:51:39.963+0000] {processor.py:186} INFO - Started process (PID=7158) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:51:39.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:51:39.966+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:51:39.965+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:51:40.156+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:51:40.178+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:51:40.178+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:51:40.192+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:51:40.191+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:51:40.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T20:52:10.833+0000] {processor.py:186} INFO - Started process (PID=7182) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:52:10.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:52:10.835+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:52:10.835+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:52:11.070+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:52:11.093+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:52:11.093+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:52:11.107+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:52:11.107+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:52:11.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.307 seconds
[2024-10-01T20:52:41.192+0000] {processor.py:186} INFO - Started process (PID=7206) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:52:41.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:52:41.195+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:52:41.195+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:52:41.392+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:52:41.414+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:52:41.414+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:52:41.428+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:52:41.428+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:52:41.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-10-01T20:53:11.835+0000] {processor.py:186} INFO - Started process (PID=7228) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:53:11.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:53:11.837+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:53:11.837+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:53:12.032+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:53:12.054+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:53:12.054+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:53:12.069+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:53:12.068+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:53:12.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T20:53:43.017+0000] {processor.py:186} INFO - Started process (PID=7252) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:53:43.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:53:43.019+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:53:43.019+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:53:43.211+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:53:43.234+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:53:43.233+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:53:43.247+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:53:43.247+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:53:43.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T20:54:13.380+0000] {processor.py:186} INFO - Started process (PID=7275) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:54:13.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:54:13.382+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:54:13.382+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:54:13.568+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:54:13.590+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:54:13.590+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:54:13.604+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:54:13.603+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:54:13.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T20:54:43.926+0000] {processor.py:186} INFO - Started process (PID=7298) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:54:43.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:54:43.928+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:54:43.928+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:54:44.123+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:54:44.145+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:54:44.145+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:54:44.158+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:54:44.158+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:54:44.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T20:55:15.129+0000] {processor.py:186} INFO - Started process (PID=7321) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:55:15.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:55:15.131+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:55:15.131+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:55:15.319+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:55:15.342+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:55:15.341+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:55:15.355+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:55:15.355+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:55:15.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T20:55:46.285+0000] {processor.py:186} INFO - Started process (PID=7344) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:55:46.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:55:46.287+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:55:46.287+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:55:46.479+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:55:46.501+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:55:46.500+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:55:46.515+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:55:46.515+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:55:46.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T20:56:16.662+0000] {processor.py:186} INFO - Started process (PID=7367) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:56:16.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:56:16.665+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:56:16.665+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:56:16.855+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:56:16.878+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:56:16.878+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:56:16.892+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:56:16.891+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:56:16.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T20:56:47.952+0000] {processor.py:186} INFO - Started process (PID=7390) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:56:47.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:56:47.954+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:56:47.954+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:56:48.147+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:56:48.170+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:56:48.170+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:56:48.184+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:56:48.183+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:56:48.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T20:57:19.250+0000] {processor.py:186} INFO - Started process (PID=7413) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:57:19.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:57:19.252+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:57:19.252+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:57:19.441+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:57:19.462+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:57:19.462+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:57:19.476+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:57:19.476+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:57:19.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T20:57:49.573+0000] {processor.py:186} INFO - Started process (PID=7436) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:57:49.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:57:49.576+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:57:49.576+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:57:49.783+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:57:49.807+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:57:49.806+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:57:49.821+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:57:49.821+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:57:49.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.275 seconds
[2024-10-01T20:58:20.873+0000] {processor.py:186} INFO - Started process (PID=7459) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:58:20.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:58:20.875+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:58:20.875+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:58:21.076+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:58:21.099+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:58:21.099+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:58:21.116+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:58:21.115+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:58:21.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-10-01T20:58:51.857+0000] {processor.py:186} INFO - Started process (PID=7482) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:58:51.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:58:51.860+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:58:51.860+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:58:52.059+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:58:52.082+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:58:52.082+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:58:52.096+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:58:52.095+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:58:52.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-10-01T20:59:23.082+0000] {processor.py:186} INFO - Started process (PID=7505) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:59:23.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:59:23.085+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:59:23.084+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:59:23.278+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:59:23.300+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:59:23.300+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:59:23.314+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:59:23.314+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:59:23.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T20:59:54.200+0000] {processor.py:186} INFO - Started process (PID=7528) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:59:54.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T20:59:54.202+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:59:54.202+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:59:54.394+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T20:59:54.418+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:59:54.417+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T20:59:54.432+0000] {logging_mixin.py:190} INFO - [2024-10-01T20:59:54.432+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T20:59:54.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T21:00:24.579+0000] {processor.py:186} INFO - Started process (PID=7551) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:00:24.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:00:24.581+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:00:24.581+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:00:24.776+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:00:24.798+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:00:24.798+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:00:24.813+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:00:24.812+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:00:24.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T21:00:55.766+0000] {processor.py:186} INFO - Started process (PID=7574) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:00:55.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:00:55.768+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:00:55.768+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:00:55.965+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:00:55.989+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:00:55.988+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:00:56.003+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:00:56.003+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:00:56.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T21:01:26.941+0000] {processor.py:186} INFO - Started process (PID=7597) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:01:26.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:01:26.943+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:01:26.943+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:01:27.130+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:01:27.151+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:01:27.151+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:01:27.164+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:01:27.164+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:01:27.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T21:01:57.426+0000] {processor.py:186} INFO - Started process (PID=7620) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:01:57.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:01:57.429+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:01:57.428+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:01:57.613+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:01:57.634+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:01:57.634+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:01:57.646+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:01:57.646+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:01:57.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-10-01T21:02:28.292+0000] {processor.py:186} INFO - Started process (PID=7644) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:02:28.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:02:28.294+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:02:28.294+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:02:28.484+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:02:28.506+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:02:28.505+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:02:28.519+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:02:28.519+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:02:28.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-10-01T21:02:59.241+0000] {processor.py:186} INFO - Started process (PID=7667) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:02:59.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:02:59.244+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:02:59.244+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:02:59.452+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:02:59.476+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:02:59.476+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:02:59.492+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:02:59.492+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:02:59.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.281 seconds
[2024-10-01T21:03:29.602+0000] {processor.py:186} INFO - Started process (PID=7690) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:03:29.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:03:29.604+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:03:29.604+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:03:29.803+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:03:29.826+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:03:29.826+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:03:29.840+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:03:29.840+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:03:29.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-10-01T21:04:00.161+0000] {processor.py:186} INFO - Started process (PID=7713) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:04:00.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:04:00.163+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:04:00.163+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:04:00.357+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:04:00.379+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:04:00.379+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:04:00.393+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:04:00.392+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:04:00.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T21:04:30.611+0000] {processor.py:186} INFO - Started process (PID=7736) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:04:30.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:04:30.614+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:04:30.613+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:04:30.803+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:04:30.825+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:04:30.825+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:04:30.839+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:04:30.839+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:04:30.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T21:05:01.440+0000] {processor.py:186} INFO - Started process (PID=7759) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:05:01.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:05:01.443+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:05:01.443+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:05:01.643+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:05:01.665+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:05:01.664+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:05:01.682+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:05:01.681+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:05:01.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-10-01T21:05:32.253+0000] {processor.py:186} INFO - Started process (PID=7782) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:05:32.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:05:32.255+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:05:32.255+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:05:32.450+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:05:32.474+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:05:32.473+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:05:32.489+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:05:32.489+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:05:32.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T21:06:03.096+0000] {processor.py:186} INFO - Started process (PID=7805) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:06:03.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:06:03.098+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:06:03.098+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:06:03.297+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:06:03.319+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:06:03.319+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:06:03.333+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:06:03.333+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:06:03.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-10-01T21:06:34.015+0000] {processor.py:186} INFO - Started process (PID=7828) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:06:34.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:06:34.018+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:06:34.017+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:06:34.212+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:06:34.235+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:06:34.234+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:06:34.249+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:06:34.248+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:06:34.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T21:07:05.347+0000] {processor.py:186} INFO - Started process (PID=7857) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:07:05.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:07:05.349+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:07:05.349+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:07:05.541+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:07:05.563+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:07:05.563+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:07:05.576+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:07:05.576+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:07:05.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T21:07:36.101+0000] {processor.py:186} INFO - Started process (PID=7880) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:07:36.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:07:36.103+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:07:36.103+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:07:36.296+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:07:36.319+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:07:36.318+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:07:36.334+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:07:36.334+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:07:36.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T21:08:07.004+0000] {processor.py:186} INFO - Started process (PID=7903) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:08:07.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:08:07.006+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:08:07.006+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:08:07.219+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:08:07.252+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:08:07.251+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:08:07.265+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:08:07.265+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:08:07.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.290 seconds
[2024-10-01T21:08:38.288+0000] {processor.py:186} INFO - Started process (PID=7926) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:08:38.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:08:38.290+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:08:38.290+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:08:38.524+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:08:38.546+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:08:38.546+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:08:38.560+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:08:38.560+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:08:38.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.299 seconds
[2024-10-01T21:09:09.076+0000] {processor.py:186} INFO - Started process (PID=7949) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:09:09.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:09:09.079+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:09:09.079+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:09:09.279+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:09:09.301+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:09:09.300+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:09:09.314+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:09:09.314+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:09:09.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T21:09:40.057+0000] {processor.py:186} INFO - Started process (PID=7972) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:09:40.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:09:40.059+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:09:40.059+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:09:40.250+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:09:40.272+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:09:40.271+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:09:40.285+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:09:40.285+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:09:40.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-10-01T21:10:10.871+0000] {processor.py:186} INFO - Started process (PID=7996) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:10:10.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:10:10.874+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:10:10.873+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:10:11.069+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:10:11.091+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:10:11.091+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:10:11.106+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:10:11.106+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:10:11.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T21:10:41.593+0000] {processor.py:186} INFO - Started process (PID=8019) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:10:41.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:10:41.596+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:10:41.596+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:10:41.785+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:10:41.807+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:10:41.807+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:10:41.821+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:10:41.820+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:10:41.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-10-01T21:11:12.581+0000] {processor.py:186} INFO - Started process (PID=8042) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:11:12.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:11:12.583+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:11:12.583+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:11:12.794+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:11:12.823+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:11:12.823+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:11:12.847+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:11:12.847+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:11:12.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.312 seconds
[2024-10-01T21:11:43.151+0000] {processor.py:186} INFO - Started process (PID=8065) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:11:43.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:11:43.154+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:11:43.153+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:11:43.348+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:11:43.370+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:11:43.369+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:11:43.383+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:11:43.383+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:11:43.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T21:12:14.380+0000] {processor.py:186} INFO - Started process (PID=8088) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:12:14.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:12:14.382+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:12:14.382+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:12:14.570+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:12:14.592+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:12:14.592+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:12:14.605+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:12:14.605+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:12:14.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T21:12:45.096+0000] {processor.py:186} INFO - Started process (PID=8111) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:12:45.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:12:45.099+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:12:45.098+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:12:45.292+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:12:45.313+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:12:45.313+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:12:45.328+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:12:45.327+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:12:45.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T21:13:15.392+0000] {processor.py:186} INFO - Started process (PID=8135) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:13:15.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:13:15.395+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:13:15.394+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:13:15.587+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:13:15.611+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:13:15.610+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:13:15.625+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:13:15.625+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:13:15.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T21:13:45.952+0000] {processor.py:186} INFO - Started process (PID=8158) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:13:45.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:13:45.954+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:13:45.954+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:13:46.152+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:13:46.174+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:13:46.174+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:13:46.190+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:13:46.189+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:13:46.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.292 seconds
[2024-10-01T21:14:17.100+0000] {processor.py:186} INFO - Started process (PID=8181) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:14:17.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:14:17.103+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:14:17.102+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:14:17.300+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:14:17.321+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:14:17.321+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:14:17.335+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:14:17.335+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:14:17.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T21:14:47.778+0000] {processor.py:186} INFO - Started process (PID=8204) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:14:47.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:14:47.780+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:14:47.780+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:14:47.968+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:14:47.989+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:14:47.989+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:14:48.005+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:14:48.005+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:14:48.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T21:15:18.345+0000] {processor.py:186} INFO - Started process (PID=8227) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:15:18.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:15:18.347+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:15:18.347+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:15:18.536+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:15:18.557+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:15:18.557+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:15:18.571+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:15:18.571+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:15:18.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T21:15:49.514+0000] {processor.py:186} INFO - Started process (PID=8250) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:15:49.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:15:49.517+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:15:49.517+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:15:49.730+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:15:49.753+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:15:49.752+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:15:49.767+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:15:49.767+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:15:49.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.280 seconds
[2024-10-01T21:16:20.734+0000] {processor.py:186} INFO - Started process (PID=8273) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:16:20.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:16:20.736+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:16:20.736+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:16:20.954+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:16:20.978+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:16:20.978+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:16:20.994+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:16:20.993+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:16:21.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.291 seconds
[2024-10-01T21:16:51.450+0000] {processor.py:186} INFO - Started process (PID=8296) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:16:51.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:16:51.453+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:16:51.452+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:16:51.652+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:16:51.677+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:16:51.676+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:16:51.691+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:16:51.691+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:16:51.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-10-01T21:17:22.284+0000] {processor.py:186} INFO - Started process (PID=8320) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:17:22.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:17:22.287+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:17:22.286+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:17:22.529+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:17:22.552+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:17:22.551+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:17:22.567+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:17:22.567+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:17:22.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.310 seconds
[2024-10-01T21:17:53.581+0000] {processor.py:186} INFO - Started process (PID=8345) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:17:53.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:17:53.584+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:17:53.583+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:17:53.785+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:17:53.808+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:17:53.808+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:17:53.822+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:17:53.822+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:17:53.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-10-01T21:18:24.426+0000] {processor.py:186} INFO - Started process (PID=8368) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:18:24.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:18:24.429+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:18:24.428+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:18:24.628+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:18:24.650+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:18:24.649+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:18:24.663+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:18:24.662+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:18:24.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T21:18:54.727+0000] {processor.py:186} INFO - Started process (PID=8391) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:18:54.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:18:54.729+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:18:54.729+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:18:54.940+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:18:54.963+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:18:54.962+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:18:54.977+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:18:54.976+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:18:54.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.279 seconds
[2024-10-01T21:19:25.347+0000] {processor.py:186} INFO - Started process (PID=8414) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:19:25.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:19:25.349+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:19:25.349+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:19:25.551+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:19:25.602+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:19:25.601+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:19:25.628+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:19:25.627+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:19:25.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.313 seconds
[2024-10-01T21:19:56.190+0000] {processor.py:186} INFO - Started process (PID=8437) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:19:56.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:19:56.195+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:19:56.194+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:19:56.417+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:19:56.442+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:19:56.441+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:19:56.456+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:19:56.456+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:19:56.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.296 seconds
[2024-10-01T21:20:26.956+0000] {processor.py:186} INFO - Started process (PID=8460) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:20:26.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:20:26.959+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:20:26.958+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:20:27.156+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:20:27.178+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:20:27.178+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:20:27.191+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:20:27.191+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:20:27.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T21:20:57.782+0000] {processor.py:186} INFO - Started process (PID=8483) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:20:57.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:20:57.785+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:20:57.784+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:20:57.983+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:20:58.005+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:20:58.005+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:20:58.019+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:20:58.018+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:20:58.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T21:21:28.273+0000] {processor.py:186} INFO - Started process (PID=8506) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:21:28.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:21:28.275+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:21:28.275+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:21:28.502+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:21:28.523+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:21:28.523+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:21:28.538+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:21:28.537+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:21:28.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.303 seconds
[2024-10-01T21:21:59.082+0000] {processor.py:186} INFO - Started process (PID=8530) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:21:59.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:21:59.084+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:21:59.084+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:21:59.284+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:21:59.305+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:21:59.305+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:21:59.319+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:21:59.319+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:21:59.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-10-01T21:22:29.709+0000] {processor.py:186} INFO - Started process (PID=8553) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:22:29.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:22:29.712+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:22:29.711+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:22:29.956+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:22:29.980+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:22:29.979+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:22:29.995+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:22:29.995+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:22:30.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.325 seconds
[2024-10-01T21:23:00.584+0000] {processor.py:186} INFO - Started process (PID=8576) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:23:00.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:23:00.587+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:23:00.586+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:23:00.795+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:23:00.818+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:23:00.818+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:23:00.832+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:23:00.832+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:23:00.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.276 seconds
[2024-10-01T21:23:31.289+0000] {processor.py:186} INFO - Started process (PID=8599) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:23:31.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:23:31.292+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:23:31.291+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:23:31.497+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:23:31.520+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:23:31.519+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:23:31.534+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:23:31.534+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:23:31.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-10-01T21:24:01.976+0000] {processor.py:186} INFO - Started process (PID=8622) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:24:01.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:24:01.978+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:24:01.978+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:24:02.183+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:24:02.205+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:24:02.205+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:24:02.219+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:24:02.218+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:24:02.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-10-01T21:24:32.512+0000] {processor.py:186} INFO - Started process (PID=8645) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:24:32.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:24:32.516+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:24:32.516+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:24:32.841+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:24:32.880+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:24:32.880+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:24:32.898+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:24:32.898+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:24:32.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.427 seconds
[2024-10-01T21:25:03.311+0000] {processor.py:186} INFO - Started process (PID=8668) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:25:03.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:25:03.316+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:25:03.316+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:25:03.515+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:25:03.538+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:25:03.538+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:25:03.553+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:25:03.553+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:25:03.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-10-01T21:25:34.050+0000] {processor.py:186} INFO - Started process (PID=8691) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:25:34.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:25:34.053+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:25:34.053+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:25:34.249+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:25:34.271+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:25:34.270+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:25:34.284+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:25:34.284+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:25:34.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T21:26:04.848+0000] {processor.py:186} INFO - Started process (PID=8714) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:26:04.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:26:04.851+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:26:04.850+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:26:05.045+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:26:05.067+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:26:05.066+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:26:05.080+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:26:05.079+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:26:05.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-10-01T21:26:35.636+0000] {processor.py:186} INFO - Started process (PID=8737) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:26:35.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:26:35.639+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:26:35.638+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:26:35.834+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:26:35.854+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:26:35.854+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:26:35.867+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:26:35.867+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:26:35.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T21:27:06.894+0000] {processor.py:186} INFO - Started process (PID=8768) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:27:06.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:27:06.897+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:27:06.897+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:27:07.095+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:27:07.118+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:27:07.117+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:27:07.132+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:27:07.132+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:27:07.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T21:27:37.675+0000] {processor.py:186} INFO - Started process (PID=8791) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:27:37.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:27:37.677+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:27:37.677+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:27:37.873+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:27:37.896+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:27:37.896+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:27:37.910+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:27:37.910+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:27:37.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T21:28:08.525+0000] {processor.py:186} INFO - Started process (PID=8814) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:28:08.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:28:08.528+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:28:08.527+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:28:08.728+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:28:08.750+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:28:08.750+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:28:08.763+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:28:08.763+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:28:08.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-10-01T21:28:39.385+0000] {processor.py:186} INFO - Started process (PID=8838) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:28:39.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:28:39.388+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:28:39.387+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:28:39.587+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:28:39.609+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:28:39.609+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:28:39.623+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:28:39.623+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:28:39.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-10-01T21:29:10.186+0000] {processor.py:186} INFO - Started process (PID=8861) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:29:10.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:29:10.189+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:29:10.188+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:29:10.391+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:29:10.414+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:29:10.414+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:29:10.429+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:29:10.429+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:29:10.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T21:29:41.038+0000] {processor.py:186} INFO - Started process (PID=8884) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:29:41.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:29:41.042+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:29:41.041+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:29:41.237+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:29:41.259+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:29:41.259+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:29:41.274+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:29:41.274+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:29:41.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T21:30:12.151+0000] {processor.py:186} INFO - Started process (PID=8907) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:30:12.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:30:12.154+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:30:12.154+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:30:12.351+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:30:12.384+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:30:12.384+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:30:12.398+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:30:12.398+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:30:12.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.277 seconds
[2024-10-01T21:30:43.339+0000] {processor.py:186} INFO - Started process (PID=8930) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:30:43.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:30:43.341+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:30:43.341+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:30:43.531+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:30:43.554+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:30:43.553+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:30:43.567+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:30:43.567+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:30:43.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-10-01T21:31:13.667+0000] {processor.py:186} INFO - Started process (PID=8953) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:31:13.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:31:13.669+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:31:13.669+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:31:13.875+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:31:13.898+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:31:13.898+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:31:13.913+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:31:13.913+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:31:13.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.280 seconds
[2024-10-01T21:31:44.165+0000] {processor.py:186} INFO - Started process (PID=8976) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:31:44.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:31:44.167+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:31:44.167+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:31:44.410+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:31:44.434+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:31:44.434+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:31:44.451+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:31:44.451+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:31:44.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.322 seconds
[2024-10-01T21:32:15.334+0000] {processor.py:186} INFO - Started process (PID=8999) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:32:15.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:32:15.336+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:32:15.336+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:32:15.541+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:32:15.567+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:32:15.566+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:32:15.580+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:32:15.580+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:32:15.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T21:32:46.600+0000] {processor.py:186} INFO - Started process (PID=9022) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:32:46.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:32:46.602+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:32:46.602+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:32:46.788+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:32:46.809+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:32:46.809+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:32:46.822+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:32:46.822+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:32:46.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-10-01T21:33:16.941+0000] {processor.py:186} INFO - Started process (PID=9045) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:33:16.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:33:16.943+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:33:16.943+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:33:17.143+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:33:17.165+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:33:17.165+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:33:17.179+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:33:17.178+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:33:17.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.279 seconds
[2024-10-01T21:33:47.768+0000] {processor.py:186} INFO - Started process (PID=9068) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:33:47.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:33:47.771+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:33:47.770+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:33:47.958+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:33:47.979+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:33:47.979+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:33:47.992+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:33:47.992+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:33:48.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T21:34:19.059+0000] {processor.py:186} INFO - Started process (PID=9091) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:34:19.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:34:19.061+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:34:19.061+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:34:19.252+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:34:19.274+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:34:19.274+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:34:19.288+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:34:19.288+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:34:19.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T21:34:50.230+0000] {processor.py:186} INFO - Started process (PID=9114) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:34:50.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:34:50.233+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:34:50.232+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:34:50.456+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:34:50.479+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:34:50.479+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:34:50.493+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:34:50.493+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:34:50.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.293 seconds
[2024-10-01T21:35:21.265+0000] {processor.py:186} INFO - Started process (PID=9137) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:35:21.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:35:21.268+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:35:21.267+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:35:21.491+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:35:21.514+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:35:21.514+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:35:21.528+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:35:21.528+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:35:21.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.291 seconds
[2024-10-01T21:35:52.150+0000] {processor.py:186} INFO - Started process (PID=9160) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:35:52.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:35:52.152+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:35:52.152+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:35:52.351+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:35:52.373+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:35:52.372+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:35:52.386+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:35:52.386+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:35:52.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-10-01T21:36:23.349+0000] {processor.py:186} INFO - Started process (PID=9183) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:36:23.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:36:23.352+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:36:23.351+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:36:23.546+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:36:23.583+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:36:23.583+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:36:23.605+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:36:23.605+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:36:23.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.286 seconds
[2024-10-01T21:36:53.850+0000] {processor.py:186} INFO - Started process (PID=9207) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:36:53.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:36:53.852+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:36:53.852+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:36:54.042+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:36:54.064+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:36:54.064+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:36:54.078+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:36:54.078+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:36:54.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T21:37:25.152+0000] {processor.py:186} INFO - Started process (PID=9230) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:37:25.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:37:25.154+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:37:25.154+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:37:25.338+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:37:25.361+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:37:25.360+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:37:25.375+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:37:25.375+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:37:25.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-10-01T21:37:55.930+0000] {processor.py:186} INFO - Started process (PID=9253) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:37:55.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:37:55.932+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:37:55.932+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:37:56.126+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:37:56.148+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:37:56.148+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:37:56.162+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:37:56.162+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:37:56.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T21:38:26.551+0000] {processor.py:186} INFO - Started process (PID=9276) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:38:26.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:38:26.553+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:38:26.553+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:38:26.754+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:38:26.776+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:38:26.776+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:38:26.790+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:38:26.789+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:38:26.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-10-01T21:38:57.696+0000] {processor.py:186} INFO - Started process (PID=9299) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:38:57.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:38:57.699+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:38:57.698+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:38:57.890+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:38:57.913+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:38:57.913+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:38:57.928+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:38:57.927+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:38:57.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T21:39:28.121+0000] {processor.py:186} INFO - Started process (PID=9322) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:39:28.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:39:28.124+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:39:28.123+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:39:28.343+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:39:28.367+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:39:28.366+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:39:28.380+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:39:28.380+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:39:28.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.286 seconds
[2024-10-01T21:39:59.417+0000] {processor.py:186} INFO - Started process (PID=9345) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:39:59.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:39:59.419+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:39:59.419+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:39:59.613+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:39:59.635+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:39:59.635+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:39:59.649+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:39:59.649+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:39:59.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T21:40:30.415+0000] {processor.py:186} INFO - Started process (PID=9368) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:40:30.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:40:30.418+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:40:30.417+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:40:30.613+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:40:30.636+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:40:30.636+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:40:30.649+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:40:30.649+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:40:30.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T21:41:01.153+0000] {processor.py:186} INFO - Started process (PID=9391) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:41:01.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:41:01.155+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:41:01.155+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:41:01.346+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:41:01.368+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:41:01.368+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:41:01.381+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:41:01.381+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:41:01.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-10-01T21:41:31.899+0000] {processor.py:186} INFO - Started process (PID=9414) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:41:31.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:41:31.902+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:41:31.902+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:41:32.100+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:41:32.123+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:41:32.123+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:41:32.137+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:41:32.137+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:41:32.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-10-01T21:42:02.838+0000] {processor.py:186} INFO - Started process (PID=9437) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:42:02.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:42:02.840+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:42:02.840+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:42:03.029+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:42:03.050+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:42:03.050+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:42:03.063+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:42:03.063+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:42:03.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T21:42:33.987+0000] {processor.py:186} INFO - Started process (PID=9460) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:42:33.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:42:33.989+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:42:33.989+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:42:34.178+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:42:34.199+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:42:34.199+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:42:34.212+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:42:34.212+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:42:34.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T21:43:04.326+0000] {processor.py:186} INFO - Started process (PID=9483) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:43:04.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:43:04.328+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:43:04.328+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:43:04.517+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:43:04.539+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:43:04.538+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:43:04.552+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:43:04.551+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:43:04.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T21:43:35.318+0000] {processor.py:186} INFO - Started process (PID=9506) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:43:35.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:43:35.320+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:43:35.320+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:43:35.508+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:43:35.530+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:43:35.530+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:43:35.543+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:43:35.543+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:43:35.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-10-01T21:44:06.213+0000] {processor.py:186} INFO - Started process (PID=9529) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:44:06.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:44:06.215+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:44:06.215+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:44:06.402+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:44:06.423+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:44:06.423+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:44:06.437+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:44:06.437+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:44:06.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T21:44:36.900+0000] {processor.py:186} INFO - Started process (PID=9552) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:44:36.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:44:36.902+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:44:36.901+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:44:37.100+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:44:37.125+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:44:37.125+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:44:37.141+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:44:37.141+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:44:37.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T21:45:07.908+0000] {processor.py:186} INFO - Started process (PID=9581) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:45:07.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:45:07.910+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:45:07.910+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:45:08.097+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:45:08.118+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:45:08.118+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:45:08.132+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:45:08.132+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:45:08.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-10-01T21:45:38.781+0000] {processor.py:186} INFO - Started process (PID=9604) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:45:38.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:45:38.784+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:45:38.783+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:45:38.976+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:45:38.997+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:45:38.997+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:45:39.010+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:45:39.010+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:45:39.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T21:46:09.351+0000] {processor.py:186} INFO - Started process (PID=9627) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:46:09.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:46:09.353+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:46:09.353+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:46:09.599+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:46:09.621+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:46:09.621+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:46:09.636+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:46:09.636+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:46:09.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.315 seconds
[2024-10-01T21:46:40.534+0000] {processor.py:186} INFO - Started process (PID=9650) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:46:40.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:46:40.536+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:46:40.536+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:46:40.731+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:46:40.755+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:46:40.754+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:46:40.768+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:46:40.767+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:46:40.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T21:47:11.780+0000] {processor.py:186} INFO - Started process (PID=9673) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:47:11.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:47:11.782+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:47:11.782+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:47:11.978+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:47:11.999+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:47:11.999+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:47:12.012+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:47:12.012+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:47:12.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T21:47:42.215+0000] {processor.py:186} INFO - Started process (PID=9696) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:47:42.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:47:42.217+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:47:42.217+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:47:42.411+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:47:42.446+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:47:42.446+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:47:42.460+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:47:42.459+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:47:42.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T21:48:12.656+0000] {processor.py:186} INFO - Started process (PID=9719) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:48:12.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:48:12.659+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:48:12.658+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:48:12.853+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:48:12.875+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:48:12.874+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:48:12.888+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:48:12.888+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:48:12.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T21:48:43.214+0000] {processor.py:186} INFO - Started process (PID=9742) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:48:43.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:48:43.216+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:48:43.216+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:48:43.415+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:48:43.437+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:48:43.437+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:48:43.451+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:48:43.451+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:48:43.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T21:49:13.617+0000] {processor.py:186} INFO - Started process (PID=9765) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:49:13.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:49:13.619+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:49:13.619+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:49:13.806+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:49:13.829+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:49:13.828+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:49:13.842+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:49:13.842+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:49:13.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-10-01T21:49:43.972+0000] {processor.py:186} INFO - Started process (PID=9788) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:49:43.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:49:43.974+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:49:43.974+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:49:44.166+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:49:44.188+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:49:44.188+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:49:44.201+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:49:44.201+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:49:44.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T21:50:14.296+0000] {processor.py:186} INFO - Started process (PID=9811) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:50:14.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:50:14.299+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:50:14.298+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:50:14.486+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:50:14.507+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:50:14.507+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:50:14.520+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:50:14.519+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:50:14.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-10-01T21:50:45.561+0000] {processor.py:186} INFO - Started process (PID=9834) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:50:45.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:50:45.564+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:50:45.563+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:50:45.757+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:50:45.778+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:50:45.778+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:50:45.792+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:50:45.791+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:50:45.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T21:51:16.629+0000] {processor.py:186} INFO - Started process (PID=9857) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:51:16.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:51:16.631+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:51:16.631+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:51:16.827+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:51:16.850+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:51:16.849+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:51:16.864+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:51:16.863+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:51:16.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T21:51:47.114+0000] {processor.py:186} INFO - Started process (PID=9880) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:51:47.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:51:47.116+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:51:47.116+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:51:47.314+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:51:47.337+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:51:47.337+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:51:47.350+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:51:47.350+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:51:47.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T21:52:18.081+0000] {processor.py:186} INFO - Started process (PID=9903) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:52:18.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:52:18.084+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:52:18.083+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:52:18.288+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:52:18.311+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:52:18.311+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:52:18.325+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:52:18.325+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:52:18.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-10-01T21:52:48.437+0000] {processor.py:186} INFO - Started process (PID=9927) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:52:48.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:52:48.440+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:52:48.440+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:52:48.633+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:52:48.655+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:52:48.655+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:52:48.670+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:52:48.669+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:52:48.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T21:53:19.343+0000] {processor.py:186} INFO - Started process (PID=9949) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:53:19.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:53:19.346+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:53:19.345+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:53:19.545+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:53:19.571+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:53:19.570+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:53:19.585+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:53:19.585+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:53:19.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-10-01T21:53:50.285+0000] {processor.py:186} INFO - Started process (PID=9972) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:53:50.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:53:50.288+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:53:50.287+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:53:50.483+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:53:50.505+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:53:50.505+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:53:50.520+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:53:50.520+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:53:50.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-10-01T21:54:20.619+0000] {processor.py:186} INFO - Started process (PID=9996) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:54:20.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:54:20.621+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:54:20.621+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:54:20.828+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:54:20.849+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:54:20.849+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:54:20.862+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:54:20.862+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:54:20.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-10-01T21:54:50.953+0000] {processor.py:186} INFO - Started process (PID=10020) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:54:50.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:54:50.955+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:54:50.955+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:54:51.142+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:54:51.163+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:54:51.163+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:54:51.176+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:54:51.176+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:54:51.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-10-01T21:55:21.258+0000] {processor.py:186} INFO - Started process (PID=10043) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:55:21.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:55:21.260+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:55:21.260+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:55:21.446+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:55:21.468+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:55:21.468+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:55:21.481+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:55:21.481+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:55:21.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-10-01T21:55:52.347+0000] {processor.py:186} INFO - Started process (PID=10066) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:55:52.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:55:52.350+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:55:52.349+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:55:52.534+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:55:52.555+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:55:52.555+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:55:52.569+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:55:52.569+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:55:52.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-10-01T21:56:23.447+0000] {processor.py:186} INFO - Started process (PID=10089) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:56:23.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:56:23.449+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:56:23.449+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:56:23.645+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:56:23.669+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:56:23.668+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:56:23.684+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:56:23.684+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:56:23.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-10-01T21:56:54.230+0000] {processor.py:186} INFO - Started process (PID=10112) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:56:54.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:56:54.233+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:56:54.232+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:56:54.431+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:56:54.454+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:56:54.453+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:56:54.469+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:56:54.468+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:56:54.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-10-01T21:57:25.155+0000] {processor.py:186} INFO - Started process (PID=10135) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:57:25.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:57:25.157+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:57:25.157+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:57:25.365+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:57:25.387+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:57:25.387+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:57:25.401+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:57:25.401+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:57:25.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T21:57:55.883+0000] {processor.py:186} INFO - Started process (PID=10158) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:57:55.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:57:55.886+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:57:55.885+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:57:56.092+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:57:56.114+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:57:56.113+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:57:56.128+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:57:56.127+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:57:56.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-10-01T21:58:26.218+0000] {processor.py:186} INFO - Started process (PID=10181) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:58:26.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:58:26.221+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:58:26.220+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:58:26.420+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:58:26.442+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:58:26.441+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:58:26.456+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:58:26.456+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:58:26.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-10-01T21:58:56.722+0000] {processor.py:186} INFO - Started process (PID=10205) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:58:56.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:58:56.724+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:58:56.724+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:58:56.919+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:58:56.942+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:58:56.941+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:58:56.955+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:58:56.955+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:58:57.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.408 seconds
[2024-10-01T21:59:27.316+0000] {processor.py:186} INFO - Started process (PID=10231) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:59:27.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:59:27.318+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:59:27.318+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:59:27.513+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:59:27.535+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:59:27.534+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:59:27.548+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:59:27.547+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:59:27.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-10-01T21:59:58.400+0000] {processor.py:186} INFO - Started process (PID=10254) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:59:58.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T21:59:58.403+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:59:58.402+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:59:58.603+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T21:59:58.624+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:59:58.624+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T21:59:58.638+0000] {logging_mixin.py:190} INFO - [2024-10-01T21:59:58.638+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T21:59:58.661+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-10-01T23:35:26.013+0000] {processor.py:186} INFO - Started process (PID=10271) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:35:26.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:35:26.016+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:35:26.015+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:35:26.744+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:35:26.798+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:35:26.798+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:35:26.841+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:35:26.841+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:35:26.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.886 seconds
[2024-10-01T23:35:56.980+0000] {processor.py:186} INFO - Started process (PID=10296) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:35:56.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:35:56.982+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:35:56.982+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:35:57.170+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:35:57.193+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:35:57.193+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:35:57.207+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:35:57.207+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:35:57.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T23:36:27.530+0000] {processor.py:186} INFO - Started process (PID=10317) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:36:27.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:36:27.533+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:36:27.532+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:36:27.730+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:36:27.755+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:36:27.755+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:36:27.769+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:36:27.769+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:36:27.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-10-01T23:36:58.030+0000] {processor.py:186} INFO - Started process (PID=10340) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:36:58.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:36:58.032+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:36:58.032+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:36:58.228+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:36:58.253+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:36:58.252+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:36:58.266+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:36:58.266+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:36:58.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-10-01T23:37:28.482+0000] {processor.py:186} INFO - Started process (PID=10366) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:37:28.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:37:28.485+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:37:28.485+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:37:28.682+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:37:28.704+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:37:28.703+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:37:28.717+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:37:28.717+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:37:28.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T23:37:59.076+0000] {processor.py:186} INFO - Started process (PID=10386) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:37:59.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:37:59.079+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:37:59.078+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:37:59.273+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:37:59.297+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:37:59.297+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:37:59.312+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:37:59.312+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:37:59.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-10-01T23:38:29.445+0000] {processor.py:186} INFO - Started process (PID=10412) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:38:29.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:38:29.447+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:38:29.447+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:38:29.653+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:38:29.678+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:38:29.678+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:38:29.692+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:38:29.692+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:38:29.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.279 seconds
[2024-10-01T23:39:00.659+0000] {processor.py:186} INFO - Started process (PID=10435) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:39:00.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:39:00.661+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:39:00.661+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:39:00.852+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:39:00.873+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:39:00.873+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:39:00.888+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:39:00.888+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:39:00.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-10-01T23:39:31.076+0000] {processor.py:186} INFO - Started process (PID=10458) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:39:31.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:39:31.078+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:39:31.078+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:39:31.276+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:39:31.297+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:39:31.297+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:39:31.311+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:39:31.311+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:39:31.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T23:40:01.468+0000] {processor.py:186} INFO - Started process (PID=10481) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:40:01.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:40:01.470+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:40:01.470+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:40:01.661+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:40:01.683+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:40:01.682+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:40:01.696+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:40:01.696+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:40:01.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-10-01T23:40:31.820+0000] {processor.py:186} INFO - Started process (PID=10506) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:40:31.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:40:31.822+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:40:31.822+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:40:32.015+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:40:32.037+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:40:32.037+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:40:32.052+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:40:32.052+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:40:32.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T23:41:02.293+0000] {processor.py:186} INFO - Started process (PID=10527) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:41:02.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:41:02.296+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:41:02.296+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:41:02.491+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:41:02.513+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:41:02.513+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:41:02.526+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:41:02.526+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:41:02.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T23:41:32.673+0000] {processor.py:186} INFO - Started process (PID=10552) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:41:32.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:41:32.676+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:41:32.676+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:41:32.869+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:41:32.893+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:41:32.893+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:41:32.907+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:41:32.906+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:41:32.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-10-01T23:42:02.970+0000] {processor.py:186} INFO - Started process (PID=10576) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:42:02.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:42:02.972+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:42:02.972+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:42:03.163+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:42:03.186+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:42:03.186+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:42:03.201+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:42:03.200+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:42:03.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-10-01T23:42:33.288+0000] {processor.py:186} INFO - Started process (PID=10600) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:42:33.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:42:33.291+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:42:33.290+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:42:33.480+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:42:33.502+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:42:33.502+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:42:33.516+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:42:33.516+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:42:33.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-10-01T23:43:03.807+0000] {processor.py:186} INFO - Started process (PID=10619) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:43:03.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:43:03.810+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:43:03.810+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:43:04.008+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:43:04.031+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:43:04.031+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:43:04.046+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:43:04.045+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:43:04.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-10-01T23:43:34.340+0000] {processor.py:186} INFO - Started process (PID=10642) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:43:34.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:43:34.342+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:43:34.342+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:43:34.554+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:43:34.578+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:43:34.578+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:43:34.593+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:43:34.593+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:43:34.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.284 seconds
[2024-10-01T23:44:04.920+0000] {processor.py:186} INFO - Started process (PID=10665) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:44:04.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:44:04.923+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:44:04.923+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:44:05.160+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:44:05.188+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:44:05.188+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:44:05.204+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:44:05.203+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:44:05.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.315 seconds
[2024-10-01T23:44:35.650+0000] {processor.py:186} INFO - Started process (PID=10688) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:44:35.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:44:35.653+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:44:35.653+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:44:35.854+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:44:35.876+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:44:35.875+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:44:35.889+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:44:35.889+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:44:35.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-10-01T23:45:06.377+0000] {processor.py:186} INFO - Started process (PID=10711) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:45:06.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:45:06.380+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:45:06.380+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:45:06.574+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:45:06.596+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:45:06.596+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:45:06.611+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:45:06.610+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:45:06.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-10-01T23:45:37.120+0000] {processor.py:186} INFO - Started process (PID=10734) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:45:37.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:45:37.123+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:45:37.122+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:45:37.323+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:45:37.346+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:45:37.346+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:45:37.359+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:45:37.359+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:45:37.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-10-01T23:46:07.827+0000] {processor.py:186} INFO - Started process (PID=10757) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:46:07.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:46:07.829+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:46:07.829+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:46:08.061+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:46:08.085+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:46:08.084+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:46:08.099+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:46:08.098+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:46:08.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.302 seconds
[2024-10-01T23:46:38.368+0000] {processor.py:186} INFO - Started process (PID=10780) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:46:38.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:46:38.370+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:46:38.370+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:46:38.575+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:46:38.598+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:46:38.598+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:46:38.612+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:46:38.612+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:46:38.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.272 seconds
[2024-10-01T23:47:08.980+0000] {processor.py:186} INFO - Started process (PID=10809) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:47:08.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:47:08.982+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:47:08.982+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:47:09.233+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:47:09.262+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:47:09.261+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:47:09.279+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:47:09.278+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:47:09.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.337 seconds
[2024-10-01T23:47:39.404+0000] {processor.py:186} INFO - Started process (PID=10834) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:47:39.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:47:39.408+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:47:39.408+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:47:39.647+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:47:39.674+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:47:39.674+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:47:39.691+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:47:39.690+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:47:39.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.317 seconds
[2024-10-01T23:48:10.655+0000] {processor.py:186} INFO - Started process (PID=10858) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:48:10.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:48:10.658+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:48:10.657+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:48:10.859+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:48:10.884+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:48:10.884+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:48:10.899+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:48:10.898+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:48:10.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T23:48:41.470+0000] {processor.py:186} INFO - Started process (PID=10881) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:48:41.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:48:41.472+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:48:41.472+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:48:41.689+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:48:41.711+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:48:41.711+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:48:41.726+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:48:41.726+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:48:41.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.287 seconds
[2024-10-01T23:49:12.114+0000] {processor.py:186} INFO - Started process (PID=10904) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:49:12.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:49:12.117+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:49:12.117+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:49:12.327+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:49:12.351+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:49:12.351+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:49:12.369+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:49:12.368+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:49:12.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.287 seconds
[2024-10-01T23:49:42.635+0000] {processor.py:186} INFO - Started process (PID=10927) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:49:42.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:49:42.638+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:49:42.638+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:49:42.840+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:49:42.862+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:49:42.862+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:49:42.879+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:49:42.879+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:49:42.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.346 seconds
[2024-10-01T23:50:13.135+0000] {processor.py:186} INFO - Started process (PID=10952) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:50:13.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:50:13.138+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:50:13.138+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:50:13.334+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:50:13.357+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:50:13.357+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:50:13.371+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:50:13.370+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:50:13.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-10-01T23:50:43.636+0000] {processor.py:186} INFO - Started process (PID=10973) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:50:43.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:50:43.638+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:50:43.638+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:50:43.840+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:50:43.865+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:50:43.865+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:50:43.879+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:50:43.879+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:50:43.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-10-01T23:51:14.066+0000] {processor.py:186} INFO - Started process (PID=10997) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:51:14.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:51:14.068+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:51:14.068+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:51:14.270+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:51:14.293+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:51:14.293+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:51:14.308+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:51:14.308+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:51:14.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-10-01T23:51:44.486+0000] {processor.py:186} INFO - Started process (PID=11022) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:51:44.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:51:44.489+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:51:44.488+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:51:44.692+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:51:44.714+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:51:44.714+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:51:44.732+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:51:44.731+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:51:44.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-10-01T23:52:14.909+0000] {processor.py:186} INFO - Started process (PID=11047) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:52:14.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:52:14.911+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:52:14.911+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:52:15.107+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:52:15.131+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:52:15.130+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:52:15.145+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:52:15.145+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:52:15.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-10-01T23:52:45.432+0000] {processor.py:186} INFO - Started process (PID=11070) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:52:45.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:52:45.434+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:52:45.434+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:52:45.638+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:52:45.664+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:52:45.663+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:52:45.679+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:52:45.678+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:52:45.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.350 seconds
[2024-10-01T23:53:15.926+0000] {processor.py:186} INFO - Started process (PID=11093) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:53:15.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:53:15.929+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:53:15.928+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:53:16.127+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:53:16.149+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:53:16.149+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:53:16.163+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:53:16.162+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:53:16.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.361 seconds
[2024-10-01T23:53:46.344+0000] {processor.py:186} INFO - Started process (PID=11111) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:53:46.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:53:46.348+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:53:46.346+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:53:46.544+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:53:46.567+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:53:46.567+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:53:46.583+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:53:46.582+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:53:46.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-10-01T23:54:17.182+0000] {processor.py:186} INFO - Started process (PID=11134) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:54:17.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:54:17.185+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:54:17.184+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:54:17.384+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:54:17.407+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:54:17.407+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:54:17.426+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:54:17.426+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:54:17.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-10-01T23:54:47.513+0000] {processor.py:186} INFO - Started process (PID=11158) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:54:47.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:54:47.516+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:54:47.516+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:54:47.714+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:54:47.737+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:54:47.737+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:54:47.750+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:54:47.750+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:54:47.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.313 seconds
[2024-10-01T23:55:17.896+0000] {processor.py:186} INFO - Started process (PID=11182) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:55:17.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:55:17.899+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:55:17.898+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:55:18.132+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:55:18.160+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:55:18.159+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:55:18.177+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:55:18.176+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:55:18.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.313 seconds
[2024-10-01T23:55:48.540+0000] {processor.py:186} INFO - Started process (PID=11207) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:55:48.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:55:48.542+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:55:48.542+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:55:48.759+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:55:48.788+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:55:48.787+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:55:48.802+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:55:48.802+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:55:48.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.295 seconds
[2024-10-01T23:56:18.983+0000] {processor.py:186} INFO - Started process (PID=11230) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:56:18.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:56:18.986+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:56:18.986+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:56:19.217+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:56:19.242+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:56:19.242+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:56:19.257+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:56:19.257+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:56:19.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.307 seconds
[2024-10-01T23:56:50.197+0000] {processor.py:186} INFO - Started process (PID=11253) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:56:50.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:56:50.200+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:56:50.199+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:56:50.391+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:56:50.412+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:56:50.412+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:56:50.426+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:56:50.426+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:56:50.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T23:57:21.140+0000] {processor.py:186} INFO - Started process (PID=11276) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:57:21.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:57:21.143+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:57:21.143+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:57:21.383+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:57:21.407+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:57:21.407+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:57:21.421+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:57:21.421+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:57:21.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.314 seconds
[2024-10-01T23:57:51.562+0000] {processor.py:186} INFO - Started process (PID=11300) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:57:51.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:57:51.565+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:57:51.565+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:57:51.763+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:57:51.789+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:57:51.789+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:57:51.803+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:57:51.803+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:57:51.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-10-01T23:58:22.224+0000] {processor.py:186} INFO - Started process (PID=11322) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:58:22.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:58:22.227+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:58:22.227+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:58:22.477+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:58:22.507+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:58:22.507+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:58:22.525+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:58:22.524+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:58:22.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.336 seconds
[2024-10-01T23:58:52.920+0000] {processor.py:186} INFO - Started process (PID=11345) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:58:52.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:58:52.923+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:58:52.923+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:58:53.116+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:58:53.138+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:58:53.137+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:58:53.152+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:58:53.152+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:58:53.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-10-01T23:59:23.608+0000] {processor.py:186} INFO - Started process (PID=11368) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:59:23.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:59:23.613+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:59:23.612+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:59:23.835+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:59:23.858+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:59:23.858+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:59:23.878+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:59:23.878+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:59:23.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.303 seconds
[2024-10-01T23:59:54.250+0000] {processor.py:186} INFO - Started process (PID=11392) to work on /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:59:54.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-10-01T23:59:54.256+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:59:54.256+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:59:54.466+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-10-01T23:59:54.488+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:59:54.488+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-01T23:59:54.502+0000] {logging_mixin.py:190} INFO - [2024-10-01T23:59:54.502+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to None, run_after=None
[2024-10-01T23:59:54.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.296 seconds
