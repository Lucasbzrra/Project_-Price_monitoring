[2024-09-10T15:52:19.917+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:52:19.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:52:19.924+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:52:19.924+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:52:20.450+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:52:20.591+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:52:20.590+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:52:20.613+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:52:20.613+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:52:20.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.727 seconds
[2024-09-10T15:52:50.853+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:52:50.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:52:50.858+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:52:50.858+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:52:51.173+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:52:51.194+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:52:51.193+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:52:51.216+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:52:51.216+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:52:51.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.390 seconds
[2024-09-10T15:53:21.292+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:53:21.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:53:21.295+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:53:21.295+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:53:21.469+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:53:21.490+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:53:21.490+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:53:21.513+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:53:21.513+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:53:21.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-10T15:53:51.625+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:53:51.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:53:51.629+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:53:51.628+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:53:51.805+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:53:51.827+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:53:51.826+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:53:51.850+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:53:51.850+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:53:51.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T15:54:22.000+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:54:22.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:54:22.003+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:54:22.003+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:54:22.181+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:54:22.204+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:54:22.203+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:54:22.229+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:54:22.228+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:54:22.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T15:54:52.358+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:54:52.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:54:52.361+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:54:52.361+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:54:52.536+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:54:52.558+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:54:52.557+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:54:52.579+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:54:52.579+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:54:52.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T15:55:22.657+0000] {processor.py:186} INFO - Started process (PID=157) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:55:22.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:55:22.661+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:55:22.660+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:55:22.857+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:55:22.878+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:55:22.878+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:55:22.899+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:55:22.899+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:55:22.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-10T15:55:52.987+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:55:52.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:55:52.991+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:55:52.991+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:55:53.178+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:55:53.199+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:55:53.198+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:55:53.221+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:55:53.220+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:55:53.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-09-10T15:56:23.522+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:56:23.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:56:23.525+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:56:23.525+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:56:23.718+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:56:23.741+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:56:23.741+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:56:23.764+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:56:23.764+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:56:23.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-09-10T15:56:53.980+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:56:53.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:56:53.983+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:56:53.983+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:56:54.259+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:56:54.286+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:56:54.285+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:56:54.310+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:56:54.310+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:56:54.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.355 seconds
[2024-09-10T15:57:25.405+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:57:25.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:57:25.409+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:57:25.408+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:57:25.621+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:57:25.642+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:57:25.641+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:57:25.666+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:57:25.666+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:57:25.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.287 seconds
[2024-09-10T15:57:55.874+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:57:55.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:57:55.878+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:57:55.877+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:57:56.069+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:57:56.097+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:57:56.096+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:57:56.122+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:57:56.122+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:57:56.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.278 seconds
[2024-09-10T15:58:26.237+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:58:26.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:58:26.240+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:58:26.240+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:58:26.419+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:58:26.439+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:58:26.439+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:58:26.461+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:58:26.461+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:58:26.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T15:58:56.537+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:58:56.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:58:56.540+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:58:56.539+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:58:56.742+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:58:56.762+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:58:56.762+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:58:56.784+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:58:56.784+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:58:56.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-09-10T15:59:27.325+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:59:27.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:59:27.329+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:59:27.328+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:59:27.511+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:59:27.534+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:59:27.533+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:59:27.558+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:59:27.557+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:59:27.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-10T15:59:57.615+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:59:57.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T15:59:57.619+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:59:57.618+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:59:57.786+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T15:59:57.809+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:59:57.809+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T15:59:57.838+0000] {logging_mixin.py:190} INFO - [2024-09-10T15:59:57.838+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T15:59:57.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T16:00:28.153+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:00:28.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:00:28.156+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:00:28.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:00:28.331+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:00:28.352+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:00:28.352+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:00:28.374+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:00:28.374+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:00:28.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-10T16:00:58.554+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:00:58.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:00:58.562+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:00:58.561+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:00:59.021+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:00:59.064+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:00:59.064+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:00:59.112+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:00:59.112+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:00:59.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.663 seconds
[2024-09-10T16:01:29.339+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:01:29.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:01:29.344+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:01:29.344+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:01:29.549+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:01:29.573+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:01:29.572+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:01:29.598+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:01:29.597+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:01:29.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.285 seconds
[2024-09-10T16:01:59.739+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:01:59.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:01:59.744+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:01:59.744+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:01:59.924+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:01:59.946+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:01:59.945+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:01:59.969+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:01:59.969+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:01:59.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-10T16:02:30.920+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:02:30.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:02:30.924+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:02:30.924+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:02:31.090+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:02:31.114+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:02:31.114+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:02:31.135+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:02:31.135+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:02:31.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T16:03:01.848+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:03:01.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:03:01.851+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:03:01.850+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:03:02.045+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:03:02.066+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:03:02.065+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:03:02.088+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:03:02.087+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:03:02.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-09-10T16:03:32.196+0000] {processor.py:186} INFO - Started process (PID=373) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:03:32.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:03:32.199+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:03:32.199+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:03:32.367+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:03:32.390+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:03:32.389+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:03:32.411+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:03:32.411+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:03:32.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.238 seconds
[2024-09-10T16:04:59.070+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:04:59.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:04:59.077+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:04:59.076+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:04:59.601+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:04:59.625+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:04:59.625+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:04:59.649+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:04:59.649+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:04:59.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.611 seconds
[2024-09-10T16:05:29.932+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:05:29.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:05:29.937+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:05:29.937+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:05:30.229+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:05:30.247+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:05:30.247+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:05:30.267+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:05:30.267+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:05:30.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.359 seconds
[2024-09-10T16:06:00.621+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:06:00.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:06:00.625+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:06:00.625+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:06:00.796+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:06:00.817+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:06:00.816+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:06:00.838+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:06:00.838+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:06:00.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-10T16:06:31.021+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:06:31.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:06:31.025+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:06:31.024+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:06:31.192+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:06:31.212+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:06:31.212+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:06:31.237+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:06:31.236+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:06:31.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.241 seconds
[2024-09-10T16:07:01.421+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:07:01.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:07:01.424+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:07:01.424+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:07:01.601+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:07:01.623+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:07:01.622+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:07:01.645+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:07:01.644+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:07:01.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T16:07:31.867+0000] {processor.py:186} INFO - Started process (PID=134) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:07:31.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:07:31.871+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:07:31.871+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:07:32.063+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:07:32.092+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:07:32.092+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:07:32.128+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:07:32.127+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:07:32.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.286 seconds
[2024-09-10T16:08:02.288+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:08:02.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:08:02.291+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:08:02.291+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:08:02.465+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:08:02.488+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:08:02.487+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:08:02.510+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:08:02.510+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-09 00:00:00+00:00, run_after=2024-09-10 00:00:00+00:00
[2024-09-10T16:08:02.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-09-10T16:08:33.354+0000] {processor.py:186} INFO - Started process (PID=161) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:08:33.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:08:33.357+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:08:33.357+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:08:33.526+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:08:33.547+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:08:33.547+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:08:33.575+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:08:33.574+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:08:33.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-10T16:12:47.408+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:12:47.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:12:47.415+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:12:47.415+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:12:47.837+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:12:47.865+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:12:47.864+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:12:47.899+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:12:47.898+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:12:47.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.525 seconds
[2024-09-10T16:13:18.412+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:13:18.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:13:18.418+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:13:18.418+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:13:18.765+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:13:18.786+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:13:18.785+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:13:18.808+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:13:18.808+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:13:18.827+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.420 seconds
[2024-09-10T16:13:48.988+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:13:48.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:13:48.992+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:13:48.992+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:13:49.176+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:13:49.198+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:13:49.197+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:13:49.221+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:13:49.220+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:13:49.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-10T16:14:19.345+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:14:19.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:14:19.349+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:14:19.349+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:14:19.558+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:14:19.578+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:14:19.578+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:14:19.602+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:14:19.602+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:14:19.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.306 seconds
[2024-09-10T16:14:49.735+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:14:49.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:14:49.738+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:14:49.738+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:14:49.913+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:14:49.937+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:14:49.936+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:14:49.959+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:14:49.959+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:14:49.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T16:15:20.191+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:15:20.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:15:20.195+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:15:20.195+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:15:20.423+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:15:20.450+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:15:20.449+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:15:20.479+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:15:20.479+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:15:20.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.324 seconds
[2024-09-10T16:15:50.624+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:15:50.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:15:50.627+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:15:50.627+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:15:50.791+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:15:50.812+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:15:50.812+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:15:50.833+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:15:50.833+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-09 00:00:00+00:00, run_after=2024-09-10 00:00:00+00:00
[2024-09-10T16:15:50.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-10T16:16:43.738+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:16:43.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:16:43.742+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:16:43.741+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:16:44.094+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:16:44.117+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:16:44.116+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:16:44.143+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:16:44.143+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:16:44.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.435 seconds
[2024-09-10T16:17:14.229+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:17:14.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:17:14.243+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:17:14.242+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:17:14.608+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:17:14.627+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:17:14.626+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:17:14.649+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:17:14.649+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:17:14.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.449 seconds
[2024-09-10T16:17:44.860+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:17:44.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:17:44.864+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:17:44.863+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:17:45.037+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:17:45.058+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:17:45.058+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:17:45.081+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:17:45.081+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:17:45.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-10T16:19:22.364+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:19:22.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:19:22.372+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:19:22.372+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:19:22.760+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:19:22.783+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:19:22.782+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:19:22.806+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:19:22.806+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:19:22.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.470 seconds
[2024-09-10T16:19:53.033+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:19:53.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:19:53.037+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:19:53.036+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:19:53.340+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:19:53.360+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:19:53.359+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:19:53.381+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:19:53.381+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:19:53.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.374 seconds
[2024-09-10T16:20:23.727+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:20:23.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:20:23.733+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:20:23.733+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:20:23.992+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:20:24.027+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:20:24.026+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:20:24.052+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:20:24.052+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:20:24.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.369 seconds
[2024-09-10T16:20:54.353+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:20:54.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:20:54.355+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:20:54.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:20:54.522+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:20:54.543+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:20:54.542+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:20:54.566+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:20:54.566+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:20:54.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-09-10T16:21:24.692+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:21:24.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:21:24.696+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:21:24.696+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:21:24.868+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:21:24.892+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:21:24.891+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:21:24.914+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:21:24.914+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:21:24.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T16:21:54.980+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:21:54.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:21:54.984+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:21:54.984+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:21:55.155+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:21:55.178+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:21:55.177+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:21:55.199+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:21:55.199+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:21:55.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-09-10T16:22:25.358+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:22:25.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:22:25.361+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:22:25.361+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:22:25.529+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:22:25.551+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:22:25.550+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:22:25.575+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:22:25.575+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:22:25.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T16:22:55.695+0000] {processor.py:186} INFO - Started process (PID=153) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:22:55.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:22:55.699+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:22:55.698+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:22:55.872+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:22:55.894+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:22:55.893+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:22:55.915+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:22:55.915+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:22:55.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T16:23:26.066+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:23:26.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:23:26.070+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:23:26.069+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:23:26.245+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:23:26.267+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:23:26.266+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:23:26.289+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:23:26.289+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:23:26.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-10T16:23:56.611+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:23:56.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:23:56.615+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:23:56.615+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:23:56.784+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:23:56.805+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:23:56.804+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:23:56.829+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:23:56.828+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:23:56.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-09-10T16:24:26.941+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:24:26.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:24:26.944+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:24:26.944+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:24:27.120+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:24:27.141+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:24:27.141+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:24:27.163+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:24:27.163+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:24:27.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-10T16:24:57.378+0000] {processor.py:186} INFO - Started process (PID=211) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:24:57.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:24:57.381+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:24:57.381+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:24:57.556+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:24:57.578+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:24:57.578+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:24:57.600+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:24:57.599+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:24:57.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T16:25:27.723+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:25:27.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:25:27.726+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:25:27.726+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:25:27.901+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:25:27.923+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:25:27.923+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:25:27.946+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:25:27.946+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:25:27.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-10T16:25:58.086+0000] {processor.py:186} INFO - Started process (PID=238) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:25:58.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:25:58.089+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:25:58.089+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:25:58.287+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:25:58.316+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:25:58.315+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:25:58.343+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:25:58.343+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:25:58.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.286 seconds
[2024-09-10T16:26:28.495+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:26:28.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:26:28.499+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:26:28.499+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:26:28.683+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:26:28.705+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:26:28.705+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:26:28.728+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:26:28.728+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:26:28.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T16:27:45.986+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:27:45.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:27:45.990+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:27:45.990+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:27:46.362+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:27:46.384+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:27:46.384+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:27:46.407+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:27:46.407+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:27:46.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.447 seconds
[2024-09-10T16:28:16.763+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:28:16.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:28:16.768+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:28:16.768+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:28:17.098+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:28:17.116+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:28:17.116+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:28:17.138+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:28:17.137+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:28:17.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.398 seconds
[2024-09-10T16:28:47.858+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:28:47.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:28:47.862+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:28:47.861+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:28:48.033+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:28:48.054+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:28:48.054+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:28:48.076+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:28:48.076+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:28:48.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T16:29:18.770+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:29:18.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:29:18.783+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:29:18.782+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:29:19.035+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:29:19.065+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:29:19.064+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:29:19.102+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:29:19.102+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-09 00:00:00+00:00, run_after=2024-09-10 00:00:00+00:00
[2024-09-10T16:29:19.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.375 seconds
[2024-09-10T16:29:49.218+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:29:49.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:29:49.222+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:29:49.221+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:29:49.438+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:29:49.557+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:29:49.557+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:29:49.589+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:29:49.588+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:29:49.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.473 seconds
[2024-09-10T16:30:20.554+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:30:20.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T16:30:20.557+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:30:20.556+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:30:20.732+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T16:30:20.755+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:30:20.754+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T16:30:20.779+0000] {logging_mixin.py:190} INFO - [2024-09-10T16:30:20.779+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T16:30:20.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T17:12:03.691+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:12:03.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:12:03.694+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:12:03.694+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:12:04.229+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:12:04.278+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:12:04.276+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:12:04.310+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:12:04.310+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:12:04.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.657 seconds
[2024-09-10T17:12:34.678+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:12:34.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:12:34.687+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:12:34.687+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:12:35.014+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:12:35.037+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:12:35.037+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:12:35.063+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:12:35.062+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:12:35.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.416 seconds
[2024-09-10T17:13:05.292+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:13:05.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:13:05.295+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:13:05.295+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:13:05.509+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:13:05.541+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:13:05.540+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:13:05.581+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:13:05.581+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:13:05.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.325 seconds
[2024-09-10T17:13:36.370+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:13:36.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:13:36.373+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:13:36.373+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:13:36.539+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:13:36.560+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:13:36.560+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:13:36.585+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:13:36.585+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:13:36.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.239 seconds
[2024-09-10T17:14:06.688+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:14:06.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:14:06.691+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:14:06.691+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:14:06.884+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:14:06.907+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:14:06.907+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:14:06.931+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:14:06.930+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:14:06.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-10T17:22:41.546+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:22:41.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:22:41.550+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:22:41.549+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:22:41.902+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:22:41.932+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:22:41.932+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:22:41.970+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:22:41.970+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:22:41.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.459 seconds
[2024-09-10T17:23:12.124+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:23:12.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:23:12.129+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:23:12.129+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:23:12.473+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:23:12.494+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:23:12.494+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:23:12.516+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:23:12.515+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:23:12.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.418 seconds
[2024-09-10T17:23:42.698+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:23:42.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:23:42.701+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:23:42.701+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:23:42.886+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:23:42.909+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:23:42.909+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:23:42.935+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:23:42.935+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:23:42.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-10T17:24:13.785+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:24:13.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:24:13.788+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:24:13.788+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:24:13.963+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:24:13.986+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:24:13.985+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:24:14.012+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:24:14.012+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:24:14.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T17:24:44.117+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:24:44.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:24:44.121+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:24:44.121+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:24:44.292+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:24:44.316+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:24:44.315+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:24:44.339+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:24:44.339+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:24:44.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T17:25:14.496+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:25:14.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:25:14.500+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:25:14.500+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:25:14.680+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:25:14.702+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:25:14.702+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:25:14.724+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:25:14.724+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:25:14.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-10T17:25:45.421+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:25:45.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:25:45.424+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:25:45.424+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:25:45.601+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:25:45.623+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:25:45.623+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:25:45.647+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:25:45.647+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:25:45.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-10T17:26:15.762+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:26:15.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:26:15.766+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:26:15.766+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:26:15.938+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:26:15.959+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:26:15.958+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:26:15.983+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:26:15.983+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:26:16.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-10T17:30:58.290+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:30:58.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:30:58.296+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:30:58.296+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:30:58.850+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:30:58.886+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:30:58.884+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:30:58.948+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:30:58.948+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:30:59.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.769 seconds
[2024-09-10T17:31:29.388+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:31:29.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:31:29.396+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:31:29.396+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:31:29.908+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:31:29.938+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:31:29.938+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:31:29.968+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:31:29.967+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-09 00:00:00+00:00, run_after=2024-09-10 00:00:00+00:00
[2024-09-10T17:31:29.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.608 seconds
[2024-09-10T17:32:00.117+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:32:00.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:32:00.121+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:32:00.121+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:32:00.347+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:32:00.371+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:32:00.370+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:32:00.396+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:32:00.396+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:32:00.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.309 seconds
[2024-09-10T17:32:30.488+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:32:30.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:32:30.491+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:32:30.491+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:32:30.658+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:32:30.681+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:32:30.681+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:32:30.703+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:32:30.703+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:32:30.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.238 seconds
[2024-09-10T17:33:01.546+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:33:01.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:33:01.550+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:33:01.549+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:33:01.739+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:33:01.763+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:33:01.762+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:33:01.786+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:33:01.785+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:33:01.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-09-10T17:33:31.967+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:33:31.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:33:31.972+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:33:31.971+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:33:32.156+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:33:32.179+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:33:32.178+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:33:32.200+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:33:32.200+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-09 00:00:00+00:00, run_after=2024-09-10 00:00:00+00:00
[2024-09-10T17:33:32.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T17:34:02.269+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:34:02.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:34:02.272+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:34:02.272+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:34:02.448+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:34:02.470+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:34:02.469+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:34:02.491+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:34:02.491+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-09 00:00:00+00:00, run_after=2024-09-10 00:00:00+00:00
[2024-09-10T17:34:02.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T17:34:33.061+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:34:33.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:34:33.064+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:34:33.064+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:34:33.273+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:34:33.297+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:34:33.297+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:34:33.324+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:34:33.323+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:34:33.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.290 seconds
[2024-09-10T17:35:03.431+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:35:03.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:35:03.436+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:35:03.435+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:35:03.629+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:35:03.651+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:35:03.651+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:35:03.675+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:35:03.675+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:35:03.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.350 seconds
[2024-09-10T17:35:33.848+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:35:33.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:35:33.852+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:35:33.852+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:35:34.031+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:35:34.054+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:35:34.053+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:35:34.079+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:35:34.079+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:35:34.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-10T17:36:04.144+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:36:04.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:36:04.149+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:36:04.148+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:36:04.333+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:36:04.355+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:36:04.354+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:36:04.377+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:36:04.377+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:36:04.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-09-10T17:36:34.489+0000] {processor.py:186} INFO - Started process (PID=218) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:36:34.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:36:34.492+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:36:34.492+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:36:34.664+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:36:34.693+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:36:34.693+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:36:34.724+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:36:34.724+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:36:34.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-10T17:37:04.821+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:37:04.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:37:04.824+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:37:04.824+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:37:04.990+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:37:05.011+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:37:05.010+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:37:05.032+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:37:05.031+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:37:05.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-09-10T17:38:45.790+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:38:45.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:38:45.795+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:38:45.795+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:38:46.213+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:38:46.239+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:38:46.238+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:38:46.263+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:38:46.263+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:38:46.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.506 seconds
[2024-09-10T17:39:16.676+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:39:16.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:39:16.682+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:39:16.681+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:39:17.013+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:39:17.034+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:39:17.033+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:39:17.055+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:39:17.055+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:39:17.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.407 seconds
[2024-09-10T17:39:47.214+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:39:47.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:39:47.218+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:39:47.218+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:39:47.393+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:39:47.415+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:39:47.414+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:39:47.437+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:39:47.436+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:39:47.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T17:41:49.217+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:41:49.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:41:49.220+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:41:49.220+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:41:49.630+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:41:49.652+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:41:49.651+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:41:49.676+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:41:49.675+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:41:49.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.488 seconds
[2024-09-10T17:42:19.910+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:42:19.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:42:19.916+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:42:19.916+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:42:20.227+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:42:20.249+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:42:20.248+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:42:20.269+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:42:20.268+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:42:20.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.482 seconds
[2024-09-10T17:42:50.532+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:42:50.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:42:50.536+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:42:50.535+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:42:50.836+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:42:50.856+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:42:50.856+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:42:50.877+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:42:50.877+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:42:50.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.369 seconds
[2024-09-10T17:43:21.606+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:43:21.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:43:21.610+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:43:21.610+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:43:21.979+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:43:22.001+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:43:22.001+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:43:22.027+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:43:22.027+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:43:22.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.450 seconds
[2024-09-10T17:43:52.194+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:43:52.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:43:52.197+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:43:52.196+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:43:52.521+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:43:52.542+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:43:52.541+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:43:52.566+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:43:52.566+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:43:52.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.398 seconds
[2024-09-10T17:44:22.734+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:44:22.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:44:22.738+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:44:22.737+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:44:23.057+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:44:23.079+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:44:23.078+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:44:23.101+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:44:23.101+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:44:23.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.391 seconds
[2024-09-10T17:44:53.376+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:44:53.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:44:53.379+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:44:53.379+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:44:53.732+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:44:53.752+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:44:53.751+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:44:53.775+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:44:53.775+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:44:53.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.426 seconds
[2024-09-10T17:45:24.018+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:45:24.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:45:24.171+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:45:24.170+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:45:24.414+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:45:24.451+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:45:24.450+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:45:24.495+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:45:24.495+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:45:24.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.528 seconds
[2024-09-10T17:45:54.894+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:45:54.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:45:54.897+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:45:54.897+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:45:55.123+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:45:55.155+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:45:55.154+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:45:55.190+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:45:55.190+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:45:55.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.329 seconds
[2024-09-10T17:46:26.090+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:46:26.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:46:26.094+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:46:26.093+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:46:26.295+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:46:26.323+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:46:26.322+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:46:26.355+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:46:26.355+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:46:26.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.289 seconds
[2024-09-10T17:46:56.469+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:46:56.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:46:56.472+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:46:56.472+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:46:56.652+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:46:56.675+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:46:56.675+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:46:56.696+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:46:56.696+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:46:56.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T17:47:26.854+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:47:26.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:47:26.857+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:47:26.857+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:47:27.028+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:47:27.050+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:47:27.050+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:47:27.072+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:47:27.072+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:47:27.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-09-10T17:47:57.160+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:47:57.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:47:57.164+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:47:57.163+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:47:57.354+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:47:57.375+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:47:57.375+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:47:57.399+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:47:57.398+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:47:57.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-09-10T17:50:51.854+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:50:51.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:50:51.858+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:50:51.857+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:50:52.252+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:50:52.274+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:50:52.274+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:50:52.310+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:50:52.309+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:50:52.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.490 seconds
[2024-09-10T17:51:22.758+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:51:22.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:51:22.766+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:51:22.766+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:51:23.103+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:51:23.123+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:51:23.123+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:51:23.148+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:51:23.148+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:51:23.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.417 seconds
[2024-09-10T17:51:53.699+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:51:53.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:51:53.703+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:51:53.703+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:51:53.896+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:51:53.918+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:51:53.917+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:51:53.942+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:51:53.942+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:51:53.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-09-10T17:52:24.047+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:52:24.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:52:24.050+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:52:24.050+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:52:24.380+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:52:24.405+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:52:24.405+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:52:24.436+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:52:24.436+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:52:24.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.417 seconds
[2024-09-10T17:52:55.310+0000] {processor.py:186} INFO - Started process (PID=122) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:52:55.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:52:55.314+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:52:55.314+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:52:55.516+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:52:55.543+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:52:55.543+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:52:55.569+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:52:55.569+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:52:55.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.301 seconds
[2024-09-10T17:53:25.848+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:53:25.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:53:25.852+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:53:25.851+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:53:26.027+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:53:26.049+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:53:26.049+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:53:26.075+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:53:26.075+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:53:26.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-09-10T17:53:56.139+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:53:56.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:53:56.143+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:53:56.142+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:53:56.316+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:53:56.339+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:53:56.338+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:53:56.362+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:53:56.362+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:53:56.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-10T17:54:26.529+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:54:26.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:54:26.533+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:54:26.532+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:54:26.706+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:54:26.726+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:54:26.726+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:54:26.748+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:54:26.747+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:54:26.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T17:54:56.896+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:54:56.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:54:56.899+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:54:56.899+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:54:57.079+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:54:57.103+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:54:57.102+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:54:57.126+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:54:57.126+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:54:57.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-10T17:57:00.925+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:57:00.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:57:00.928+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:57:00.928+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:57:01.307+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:57:01.326+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:57:01.326+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:57:01.355+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:57:01.354+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:57:01.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.456 seconds
[2024-09-10T17:57:31.809+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:57:31.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:57:31.817+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:57:31.817+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:57:32.157+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:57:32.177+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:57:32.177+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:57:32.202+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:57:32.202+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:57:32.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.418 seconds
[2024-09-10T17:58:02.792+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:58:02.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:58:02.798+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:58:02.795+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:58:02.999+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:58:03.037+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:58:03.036+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:58:03.059+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:58:03.059+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:58:03.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.290 seconds
[2024-09-10T17:58:33.210+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:58:33.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:58:33.214+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:58:33.214+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:58:33.470+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:58:33.503+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:58:33.502+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:58:33.537+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:58:33.536+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:58:33.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.353 seconds
[2024-09-10T17:59:03.752+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:59:03.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:59:03.765+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:59:03.764+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:59:04.080+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:59:04.258+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:59:04.257+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:59:04.322+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:59:04.322+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:59:04.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.632 seconds
[2024-09-10T17:59:34.413+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:59:34.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T17:59:34.416+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:59:34.416+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:59:34.697+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T17:59:34.727+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:59:34.727+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T17:59:34.757+0000] {logging_mixin.py:190} INFO - [2024-09-10T17:59:34.757+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T17:59:34.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.384 seconds
[2024-09-10T18:00:05.055+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:00:05.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:00:05.060+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:00:05.059+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:00:05.255+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:00:05.280+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:00:05.279+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:00:05.303+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:00:05.303+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:00:05.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-09-10T18:00:35.900+0000] {processor.py:186} INFO - Started process (PID=161) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:00:35.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:00:35.903+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:00:35.903+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:00:36.077+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:00:36.105+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:00:36.105+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:00:36.130+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:00:36.130+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:00:36.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-10T18:01:06.274+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:01:06.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:01:06.277+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:01:06.277+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:01:06.448+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:01:06.476+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:01:06.475+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:01:06.504+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:01:06.504+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:01:06.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-10T18:01:36.588+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:01:36.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:01:36.591+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:01:36.591+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:01:36.778+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:01:36.810+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:01:36.809+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:01:36.834+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:01:36.833+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-09 00:00:00+00:00, run_after=2024-09-10 00:00:00+00:00
[2024-09-10T18:01:36.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.276 seconds
[2024-09-10T18:02:06.990+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:02:06.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:02:06.995+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:02:06.993+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:02:07.212+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:02:07.239+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:02:07.239+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:02:07.269+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:02:07.269+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:02:07.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.317 seconds
[2024-09-10T18:02:37.468+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:02:37.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:02:37.471+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:02:37.471+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:02:37.675+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:02:37.704+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:02:37.704+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:02:37.732+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:02:37.732+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:02:37.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.294 seconds
[2024-09-10T18:03:08.138+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:03:08.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:03:08.141+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:03:08.141+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:03:08.632+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:03:08.675+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:03:08.674+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:03:08.723+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:03:08.723+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:03:08.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.637 seconds
[2024-09-10T18:03:38.889+0000] {processor.py:186} INFO - Started process (PID=239) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:03:38.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:03:38.892+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:03:38.892+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:03:39.090+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:03:39.116+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:03:39.115+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:03:39.144+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:03:39.143+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:03:39.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.283 seconds
[2024-09-10T18:04:09.258+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:04:09.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:04:09.262+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:04:09.262+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:04:09.449+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:04:09.474+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:04:09.473+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:04:09.498+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:04:09.498+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:04:09.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-09-10T18:04:39.616+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:04:39.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:04:39.620+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:04:39.619+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:04:39.814+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:04:39.838+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:04:39.838+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:04:39.861+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:04:39.861+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:04:39.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-09-10T18:05:09.924+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:05:09.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:05:09.927+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:05:09.927+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:05:10.114+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:05:10.137+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:05:10.137+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:05:10.161+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:05:10.161+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:05:10.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-09-10T18:05:40.385+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:05:40.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:05:40.388+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:05:40.388+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:05:40.568+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:05:40.591+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:05:40.590+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:05:40.614+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:05:40.614+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:05:40.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-09-10T18:06:10.789+0000] {processor.py:186} INFO - Started process (PID=304) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:06:10.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:06:10.793+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:06:10.793+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:06:10.966+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:06:10.988+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:06:10.987+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:06:11.010+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:06:11.010+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:06:11.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T18:06:41.326+0000] {processor.py:186} INFO - Started process (PID=317) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:06:41.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:06:41.330+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:06:41.329+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:06:41.501+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:06:41.523+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:06:41.522+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:06:41.547+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:06:41.546+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:06:41.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-10T18:07:11.948+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:07:11.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:07:11.952+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:07:11.952+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:07:12.125+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:07:12.149+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:07:12.149+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:07:12.172+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:07:12.172+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:07:12.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-09-10T18:07:42.253+0000] {processor.py:186} INFO - Started process (PID=343) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:07:42.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:07:42.257+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:07:42.256+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:07:42.426+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:07:42.447+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:07:42.447+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:07:42.469+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:07:42.469+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:07:42.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.241 seconds
[2024-09-10T18:08:12.754+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:08:12.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:08:12.757+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:08:12.757+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:08:12.926+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:08:12.946+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:08:12.946+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:08:12.968+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:08:12.968+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:08:12.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-09-10T18:08:43.122+0000] {processor.py:186} INFO - Started process (PID=369) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:08:43.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:08:43.125+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:08:43.125+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:08:43.300+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:08:43.321+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:08:43.320+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:08:43.343+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:08:43.343+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:08:43.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T18:09:13.528+0000] {processor.py:186} INFO - Started process (PID=382) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:09:13.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:09:13.532+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:09:13.532+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:09:13.704+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:09:13.727+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:09:13.726+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:09:13.750+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:09:13.750+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:09:13.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-10T18:09:43.987+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:09:43.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:09:43.991+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:09:43.990+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:09:44.168+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:09:44.190+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:09:44.189+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:09:44.212+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:09:44.212+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:09:44.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-09-10T18:10:14.406+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:10:14.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:10:14.409+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:10:14.409+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:10:14.590+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:10:14.614+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:10:14.614+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:10:14.638+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:10:14.638+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:10:14.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-10T18:10:44.790+0000] {processor.py:186} INFO - Started process (PID=421) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:10:44.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:10:44.793+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:10:44.793+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:10:44.964+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:10:44.986+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:10:44.985+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:10:45.010+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:10:45.009+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:10:45.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-10T18:11:15.110+0000] {processor.py:186} INFO - Started process (PID=434) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:11:15.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:11:15.115+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:11:15.114+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:11:15.302+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:11:15.333+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:11:15.333+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:11:15.357+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:11:15.357+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:11:15.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-09-10T18:11:45.556+0000] {processor.py:186} INFO - Started process (PID=447) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:11:45.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:11:45.559+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:11:45.559+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:11:45.751+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:11:45.773+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:11:45.773+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:11:45.799+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:11:45.799+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:11:45.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.273 seconds
[2024-09-10T18:12:16.264+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:12:16.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:12:16.267+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:12:16.267+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:12:16.453+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:12:16.475+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:12:16.474+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:12:16.502+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:12:16.501+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:12:16.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-10T18:12:46.735+0000] {processor.py:186} INFO - Started process (PID=473) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:12:46.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:12:46.738+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:12:46.738+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:12:46.946+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:12:46.968+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:12:46.968+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:12:46.990+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:12:46.990+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:12:47.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.280 seconds
[2024-09-10T18:13:17.202+0000] {processor.py:186} INFO - Started process (PID=486) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:13:17.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:13:17.205+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:13:17.205+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:13:17.397+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:13:17.422+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:13:17.421+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:13:17.448+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:13:17.448+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:13:17.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-09-10T18:13:47.883+0000] {processor.py:186} INFO - Started process (PID=499) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:13:47.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:13:47.888+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:13:47.888+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:13:48.078+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:13:48.101+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:13:48.100+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:13:48.124+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:13:48.123+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:13:48.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.272 seconds
[2024-09-10T18:14:18.363+0000] {processor.py:186} INFO - Started process (PID=513) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:14:18.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:14:18.367+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:14:18.366+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:14:18.555+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:14:18.579+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:14:18.578+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:14:18.601+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:14:18.601+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:14:18.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.387 seconds
[2024-09-10T18:14:48.797+0000] {processor.py:186} INFO - Started process (PID=526) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:14:48.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:14:48.800+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:14:48.800+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:14:48.980+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:14:49.002+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:14:49.002+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:14:49.029+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:14:49.029+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:14:49.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.294 seconds
[2024-09-10T18:15:19.190+0000] {processor.py:186} INFO - Started process (PID=540) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:15:19.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:15:19.193+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:15:19.193+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:15:19.381+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:15:19.405+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:15:19.405+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:15:19.431+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:15:19.430+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:15:19.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-09-10T18:15:49.568+0000] {processor.py:186} INFO - Started process (PID=553) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:15:49.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:15:49.572+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:15:49.571+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:15:49.760+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:15:49.786+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:15:49.785+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:15:49.811+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:15:49.811+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:15:49.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-09-10T18:16:19.994+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:16:19.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:16:19.998+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:16:19.998+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:16:20.183+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:16:20.205+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:16:20.205+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:16:20.228+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:16:20.228+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:16:20.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-10T18:16:50.312+0000] {processor.py:186} INFO - Started process (PID=578) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:16:50.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:16:50.317+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:16:50.317+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:16:50.503+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:16:50.528+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:16:50.528+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:16:50.555+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:16:50.555+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:16:50.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.270 seconds
[2024-09-10T18:17:20.752+0000] {processor.py:186} INFO - Started process (PID=592) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:17:20.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:17:20.755+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:17:20.755+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:17:20.947+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:17:20.969+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:17:20.969+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:17:20.993+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:17:20.992+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:17:21.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-09-10T18:17:51.122+0000] {processor.py:186} INFO - Started process (PID=606) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:17:51.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:17:51.126+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:17:51.126+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:17:51.312+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:17:51.336+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:17:51.336+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:17:51.363+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:17:51.363+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:17:51.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.267 seconds
[2024-09-10T18:18:21.465+0000] {processor.py:186} INFO - Started process (PID=619) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:18:21.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:18:21.469+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:18:21.469+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:18:21.648+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:18:21.672+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:18:21.672+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:18:21.696+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:18:21.696+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:18:21.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-10T18:18:51.788+0000] {processor.py:186} INFO - Started process (PID=630) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:18:51.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:18:51.792+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:18:51.792+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:18:51.968+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:18:51.990+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:18:51.990+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:18:52.023+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:18:52.023+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:18:52.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-09-10T18:19:22.135+0000] {processor.py:186} INFO - Started process (PID=643) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:19:22.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:19:22.138+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:19:22.138+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:19:22.308+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:19:22.329+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:19:22.329+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:19:22.351+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:19:22.351+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:19:22.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-09-10T18:19:52.603+0000] {processor.py:186} INFO - Started process (PID=656) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:19:52.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:19:52.608+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:19:52.607+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:19:52.774+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:19:52.796+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:19:52.795+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:19:52.817+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:19:52.817+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:19:52.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.239 seconds
[2024-09-10T18:20:23.033+0000] {processor.py:186} INFO - Started process (PID=669) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:20:23.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:20:23.037+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:20:23.036+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:20:23.207+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:20:23.229+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:20:23.228+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:20:23.251+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:20:23.251+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:20:23.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-09-10T18:20:53.413+0000] {processor.py:186} INFO - Started process (PID=682) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:20:53.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:20:53.421+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:20:53.421+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:20:53.659+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:20:53.692+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:20:53.692+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:20:53.723+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:20:53.722+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:20:53.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.344 seconds
[2024-09-10T18:21:23.911+0000] {processor.py:186} INFO - Started process (PID=696) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:21:23.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:21:23.914+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:21:23.914+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:21:24.101+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:21:24.124+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:21:24.123+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:21:24.146+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:21:24.146+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:21:24.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T18:21:54.314+0000] {processor.py:186} INFO - Started process (PID=710) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:21:54.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:21:54.319+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:21:54.319+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:21:54.503+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:21:54.525+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:21:54.524+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:21:54.547+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:21:54.547+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:21:54.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-10T18:22:24.633+0000] {processor.py:186} INFO - Started process (PID=725) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:22:24.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:22:24.637+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:22:24.636+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:22:24.808+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:22:24.829+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:22:24.828+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:22:24.850+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:22:24.849+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:22:24.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.241 seconds
[2024-09-10T18:22:54.941+0000] {processor.py:186} INFO - Started process (PID=738) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:22:54.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:22:54.947+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:22:54.947+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:22:55.112+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:22:55.133+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:22:55.132+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:22:55.155+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:22:55.155+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:22:55.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.238 seconds
[2024-09-10T18:23:25.247+0000] {processor.py:186} INFO - Started process (PID=748) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:23:25.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:23:25.251+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:23:25.250+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:23:25.442+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:23:25.468+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:23:25.467+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:23:25.493+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:23:25.493+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:23:25.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-09-10T18:23:55.752+0000] {processor.py:186} INFO - Started process (PID=761) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:23:55.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:23:55.756+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:23:55.755+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:23:55.941+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:23:55.965+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:23:55.965+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:23:55.988+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:23:55.988+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:23:56.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T18:24:26.103+0000] {processor.py:186} INFO - Started process (PID=774) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:24:26.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:24:26.109+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:24:26.108+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:24:26.293+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:24:26.317+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:24:26.317+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:24:26.343+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:24:26.343+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:24:26.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-10T18:24:56.587+0000] {processor.py:186} INFO - Started process (PID=787) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:24:56.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:24:56.592+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:24:56.592+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:24:56.775+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:24:56.799+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:24:56.798+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:24:56.822+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:24:56.822+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:24:56.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-09-10T18:25:27.016+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:25:27.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:25:27.019+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:25:27.019+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:25:27.209+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:25:27.232+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:25:27.232+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:25:27.255+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:25:27.255+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:25:27.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-09-10T18:25:57.366+0000] {processor.py:186} INFO - Started process (PID=813) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:25:57.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:25:57.371+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:25:57.371+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:25:57.555+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:25:57.581+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:25:57.581+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:25:57.608+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:25:57.607+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:25:57.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-10T18:26:27.839+0000] {processor.py:186} INFO - Started process (PID=826) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:26:27.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:26:27.842+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:26:27.842+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:26:28.024+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:26:28.048+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:26:28.047+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:26:28.073+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:26:28.073+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:26:28.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-10T18:26:58.238+0000] {processor.py:186} INFO - Started process (PID=839) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:26:58.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:26:58.241+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:26:58.241+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:26:58.426+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:26:58.457+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:26:58.456+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:26:58.483+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:26:58.483+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:26:58.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.276 seconds
[2024-09-10T18:27:28.735+0000] {processor.py:186} INFO - Started process (PID=852) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:27:28.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:27:28.739+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:27:28.739+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:27:28.923+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:27:28.945+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:27:28.944+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:27:28.970+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:27:28.970+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:27:28.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T18:27:59.130+0000] {processor.py:186} INFO - Started process (PID=865) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:27:59.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:27:59.134+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:27:59.133+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:27:59.312+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:27:59.336+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:27:59.335+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:27:59.359+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:27:59.359+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:27:59.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-10T18:28:29.486+0000] {processor.py:186} INFO - Started process (PID=878) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:28:29.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:28:29.489+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:28:29.489+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:28:29.670+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:28:29.693+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:28:29.693+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:28:29.718+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:28:29.718+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:28:29.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-10T18:28:59.914+0000] {processor.py:186} INFO - Started process (PID=891) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:28:59.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:28:59.918+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:28:59.918+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:29:00.102+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:29:00.126+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:29:00.126+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:29:00.151+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:29:00.151+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:29:00.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-09-10T18:29:30.262+0000] {processor.py:186} INFO - Started process (PID=904) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:29:30.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:29:30.266+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:29:30.266+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:29:30.447+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:29:30.471+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:29:30.470+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:29:30.498+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:29:30.498+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:29:30.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-09-10T18:30:00.698+0000] {processor.py:186} INFO - Started process (PID=917) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:30:00.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:30:00.701+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:30:00.701+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:30:00.882+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:30:00.905+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:30:00.904+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:30:00.929+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:30:00.929+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:30:00.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T18:30:31.055+0000] {processor.py:186} INFO - Started process (PID=930) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:30:31.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:30:31.059+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:30:31.059+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:30:31.245+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:30:31.267+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:30:31.267+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:30:31.290+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:30:31.290+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:30:31.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T18:31:01.551+0000] {processor.py:186} INFO - Started process (PID=943) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:31:01.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:31:01.554+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:31:01.554+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:31:01.723+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:31:01.744+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:31:01.743+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:31:01.766+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:31:01.766+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:31:01.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-09-10T18:31:32.452+0000] {processor.py:186} INFO - Started process (PID=954) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:31:32.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:31:32.456+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:31:32.455+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:31:32.627+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:31:32.651+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:31:32.650+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:31:32.673+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:31:32.673+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:31:32.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-10T18:32:02.749+0000] {processor.py:186} INFO - Started process (PID=967) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:32:02.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:32:02.753+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:32:02.753+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:32:02.938+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:32:02.961+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:32:02.961+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:32:02.984+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:32:02.984+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:32:03.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-09-10T18:32:33.153+0000] {processor.py:186} INFO - Started process (PID=980) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:32:33.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:32:33.156+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:32:33.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:32:33.336+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:32:33.360+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:32:33.360+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:32:33.384+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:32:33.383+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:32:33.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-10T18:33:03.569+0000] {processor.py:186} INFO - Started process (PID=993) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:33:03.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:33:03.572+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:33:03.572+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:33:03.794+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:33:03.828+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:33:03.828+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:33:03.851+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:33:03.851+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:33:03.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.311 seconds
[2024-09-10T18:33:34.065+0000] {processor.py:186} INFO - Started process (PID=1006) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:33:34.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:33:34.070+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:33:34.069+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:33:34.259+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:33:34.285+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:33:34.284+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:33:34.310+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:33:34.309+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:33:34.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-09-10T18:34:04.455+0000] {processor.py:186} INFO - Started process (PID=1020) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:34:04.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:34:04.459+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:34:04.459+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:34:04.640+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:34:04.664+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:34:04.663+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:34:04.690+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:34:04.690+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:34:04.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T18:34:34.835+0000] {processor.py:186} INFO - Started process (PID=1034) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:34:34.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:34:34.838+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:34:34.838+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:34:35.021+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:34:35.051+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:34:35.050+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:34:35.082+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:34:35.081+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:34:35.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.278 seconds
[2024-09-10T18:35:05.150+0000] {processor.py:186} INFO - Started process (PID=1048) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:35:05.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:35:05.154+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:35:05.154+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:35:05.333+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:35:05.355+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:35:05.355+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:35:05.377+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:35:05.377+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:35:05.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T18:35:35.452+0000] {processor.py:186} INFO - Started process (PID=1061) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:35:35.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:35:35.456+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:35:35.456+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:35:35.629+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:35:35.651+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:35:35.650+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:35:35.672+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:35:35.672+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:35:35.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T18:36:06.129+0000] {processor.py:186} INFO - Started process (PID=1071) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:36:06.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:36:06.132+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:36:06.132+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:36:06.309+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:36:06.331+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:36:06.331+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:36:06.353+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:36:06.353+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:36:06.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T18:36:36.552+0000] {processor.py:186} INFO - Started process (PID=1084) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:36:36.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:36:36.555+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:36:36.554+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:36:36.730+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:36:36.752+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:36:36.752+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:36:36.778+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:36:36.777+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:36:36.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T18:37:06.983+0000] {processor.py:186} INFO - Started process (PID=1098) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:37:06.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:37:06.986+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:37:06.986+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:37:07.160+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:37:07.182+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:37:07.182+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:37:07.207+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:37:07.207+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:37:07.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T18:37:37.349+0000] {processor.py:186} INFO - Started process (PID=1112) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:37:37.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:37:37.353+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:37:37.353+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:37:37.533+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:37:37.557+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:37:37.556+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:37:37.587+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:37:37.586+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:37:37.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-09-10T18:38:08.427+0000] {processor.py:186} INFO - Started process (PID=1131) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:38:08.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:38:08.431+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:38:08.431+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:38:08.612+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:38:08.634+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:38:08.634+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:38:08.659+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:38:08.658+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:38:08.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T18:38:38.733+0000] {processor.py:186} INFO - Started process (PID=1145) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:38:38.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:38:38.736+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:38:38.736+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:38:38.908+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:38:38.930+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:38:38.929+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:38:38.951+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:38:38.951+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:38:38.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-09-10T18:39:09.102+0000] {processor.py:186} INFO - Started process (PID=1158) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:39:09.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:39:09.106+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:39:09.106+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:39:09.277+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:39:09.300+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:39:09.300+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:39:09.326+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:39:09.325+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:39:09.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T18:39:39.388+0000] {processor.py:186} INFO - Started process (PID=1171) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:39:39.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:39:39.392+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:39:39.391+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:39:39.568+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:39:39.591+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:39:39.591+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:39:39.614+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:39:39.613+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:39:39.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T18:40:10.317+0000] {processor.py:186} INFO - Started process (PID=1184) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:40:10.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:40:10.322+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:40:10.321+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:40:10.495+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:40:10.518+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:40:10.517+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:40:10.540+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:40:10.539+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:40:10.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-10T18:40:41.302+0000] {processor.py:186} INFO - Started process (PID=1197) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:40:41.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:40:41.305+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:40:41.305+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:40:41.484+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:40:41.506+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:40:41.506+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:40:41.528+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:40:41.528+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:40:41.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-10T18:41:11.624+0000] {processor.py:186} INFO - Started process (PID=1210) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:41:11.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:41:11.627+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:41:11.627+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:41:11.796+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:41:11.818+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:41:11.817+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:41:11.838+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:41:11.838+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:41:11.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.237 seconds
[2024-09-10T18:41:42.167+0000] {processor.py:186} INFO - Started process (PID=1223) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:41:42.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:41:42.170+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:41:42.170+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:41:42.341+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:41:42.363+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:41:42.363+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:41:42.386+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:41:42.386+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:41:42.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T18:43:13.680+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:43:13.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:43:13.684+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:43:13.684+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:43:14.100+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:43:14.127+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:43:14.127+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:43:14.155+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:43:14.155+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:43:14.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.512 seconds
[2024-09-10T18:43:28.437+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:43:28.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:43:28.446+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:43:28.445+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:43:29.047+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:43:29.305+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:43:29.304+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:43:29.330+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:43:29.330+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:43:29.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.937 seconds
[2024-09-10T18:43:59.783+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:43:59.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:43:59.785+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:43:59.785+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:43:59.946+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:43:59.966+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:43:59.966+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:43:59.986+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:43:59.986+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:44:00.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.357 seconds
[2024-09-10T18:44:30.257+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:44:30.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:44:30.260+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:44:30.260+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:44:30.449+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:44:30.470+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:44:30.469+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:44:30.492+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:44:30.492+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:44:30.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-10T18:45:28.471+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:45:28.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:45:28.475+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:45:28.474+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:45:28.827+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:45:28.849+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:45:28.848+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:45:28.873+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:45:28.873+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:45:28.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.429 seconds
[2024-09-10T18:45:59.161+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:45:59.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:45:59.164+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:45:59.164+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:45:59.470+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:45:59.489+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:45:59.489+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:45:59.509+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:45:59.509+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:45:59.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.375 seconds
[2024-09-10T18:46:29.720+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:46:29.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:46:29.724+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:46:29.723+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:46:29.900+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:46:29.922+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:46:29.921+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:46:29.943+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:46:29.943+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:46:29.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-10T18:47:00.089+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:47:00.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:47:00.093+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:47:00.092+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:47:00.405+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:47:00.426+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:47:00.426+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:47:00.449+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:47:00.449+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:47:00.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.383 seconds
[2024-09-10T18:47:30.525+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:47:30.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:47:30.529+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:47:30.529+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:47:30.706+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:47:30.728+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:47:30.728+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:47:30.750+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:47:30.750+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:47:30.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-09-10T18:48:00.829+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:48:00.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:48:00.832+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:48:00.832+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:48:01.026+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:48:01.047+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:48:01.046+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:48:01.068+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:48:01.067+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:48:01.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-10T18:48:31.251+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:48:31.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:48:31.254+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:48:31.253+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:48:31.454+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:48:31.488+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:48:31.488+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:48:31.514+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:48:31.514+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:48:31.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.290 seconds
[2024-09-10T18:49:01.695+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:49:01.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:49:01.699+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:49:01.698+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:49:01.873+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:49:01.894+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:49:01.894+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:49:01.915+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:49:01.915+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:49:01.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-10T18:49:32.040+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:49:32.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:49:32.043+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:49:32.042+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:49:32.227+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:49:32.249+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:49:32.248+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:49:32.273+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:49:32.273+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:49:32.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-09-10T18:55:51.755+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:55:51.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:55:51.758+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:55:51.758+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:55:52.131+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:55:52.152+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:55:52.152+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:55:52.175+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:55:52.175+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:55:52.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.447 seconds
[2024-09-10T18:56:22.248+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:56:22.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:56:22.254+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:56:22.253+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:56:22.563+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:56:22.582+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:56:22.582+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:56:22.603+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:56:22.602+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:56:22.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.378 seconds
[2024-09-10T18:56:53.358+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:56:53.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:56:53.361+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:56:53.361+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:56:53.685+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:56:53.705+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:56:53.705+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:56:53.729+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:56:53.728+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:56:53.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.420 seconds
[2024-09-10T18:57:24.035+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:57:24.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:57:24.038+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:57:24.038+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:57:24.339+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:57:24.358+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:57:24.358+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:57:24.379+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:57:24.379+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:57:24.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.370 seconds
[2024-09-10T18:57:54.475+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:57:54.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:57:54.478+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:57:54.477+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:57:54.792+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:57:54.811+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:57:54.810+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:57:54.831+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:57:54.831+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:57:54.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.380 seconds
[2024-09-10T18:58:25.097+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:58:25.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:58:25.100+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:58:25.100+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:58:25.414+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:58:25.434+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:58:25.434+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:58:25.454+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:58:25.454+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:58:25.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.382 seconds
[2024-09-10T18:58:55.815+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:58:55.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T18:58:55.819+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:58:55.819+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:58:56.121+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T18:58:56.140+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:58:56.139+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T18:58:56.160+0000] {logging_mixin.py:190} INFO - [2024-09-10T18:58:56.160+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T18:58:56.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.370 seconds
[2024-09-10T19:00:20.690+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:00:20.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:00:20.695+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:00:20.694+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:00:21.052+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:00:21.083+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:00:21.083+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:00:21.113+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:00:21.113+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:00:21.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.452 seconds
[2024-09-10T19:00:51.349+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:00:51.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:00:51.354+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:00:51.354+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:00:51.696+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:00:51.721+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:00:51.721+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:00:51.746+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:00:51.746+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:00:51.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.433 seconds
[2024-09-10T19:03:29.519+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:03:29.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:03:29.523+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:03:29.523+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:03:29.875+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:03:29.896+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:03:29.896+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:03:29.920+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:03:29.920+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:03:29.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.429 seconds
[2024-09-10T19:03:51.685+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:03:51.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:03:51.691+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:03:51.691+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:03:52.068+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:03:52.103+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:03:52.102+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:03:52.132+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:03:52.132+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:03:52.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.484 seconds
[2024-09-10T19:04:22.288+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:04:22.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:04:22.294+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:04:22.293+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:04:22.601+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:04:22.622+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:04:22.622+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:04:22.643+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:04:22.643+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:04:22.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.382 seconds
[2024-09-10T19:04:52.804+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:04:52.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:04:52.807+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:04:52.807+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:04:52.992+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:04:53.012+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:04:53.012+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:04:53.033+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:04:53.033+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:04:53.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-09-10T19:05:23.160+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:05:23.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:05:23.164+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:05:23.164+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:05:23.348+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:05:23.370+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:05:23.369+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:05:23.393+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:05:23.392+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:05:23.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-09-10T19:05:53.556+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:05:53.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:05:53.560+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:05:53.559+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:05:53.749+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:05:53.772+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:05:53.772+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:05:53.794+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:05:53.794+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:05:53.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-10T19:06:23.899+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:06:23.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:06:23.903+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:06:23.902+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:06:24.082+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:06:24.105+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:06:24.105+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:06:24.127+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:06:24.127+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:06:24.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-10T19:06:54.346+0000] {processor.py:186} INFO - Started process (PID=142) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:06:54.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:06:54.350+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:06:54.349+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:06:54.543+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:06:54.567+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:06:54.567+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:06:54.593+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:06:54.592+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:06:54.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.279 seconds
[2024-09-10T19:07:24.727+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:07:24.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:07:24.730+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:07:24.730+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:07:24.908+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:07:24.931+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:07:24.931+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:07:24.954+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:07:24.954+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:07:24.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T19:07:55.302+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:07:55.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:07:55.314+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:07:55.314+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:07:55.502+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:07:55.524+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:07:55.524+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:07:55.550+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:07:55.550+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:07:55.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.276 seconds
[2024-09-10T19:08:25.656+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:08:25.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:08:25.660+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:08:25.660+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:08:25.840+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:08:25.862+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:08:25.862+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:08:25.885+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:08:25.885+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:08:25.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T19:08:56.202+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:08:56.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:08:56.205+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:08:56.204+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:08:56.393+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:08:56.415+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:08:56.415+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:08:56.438+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:08:56.438+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:08:56.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.262 seconds
[2024-09-10T19:09:26.586+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:09:26.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:09:26.589+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:09:26.589+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:09:26.773+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:09:26.795+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:09:26.795+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:09:26.819+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:09:26.818+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:09:26.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T19:09:56.970+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:09:56.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:09:56.974+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:09:56.974+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:09:57.149+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:09:57.171+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:09:57.171+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:09:57.195+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:09:57.195+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:09:57.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-09-10T19:10:27.300+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:10:27.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:10:27.304+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:10:27.303+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:10:27.522+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:10:27.544+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:10:27.544+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:10:27.568+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:10:27.568+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:10:27.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.295 seconds
[2024-09-10T19:10:57.765+0000] {processor.py:186} INFO - Started process (PID=247) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:10:57.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:10:57.768+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:10:57.768+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:10:57.969+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:10:57.993+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:10:57.993+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:10:58.018+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:10:58.017+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:10:58.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.278 seconds
[2024-09-10T19:11:28.093+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:11:28.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:11:28.096+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:11:28.096+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:11:28.283+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:11:28.308+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:11:28.307+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:11:28.332+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:11:28.332+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:11:28.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-10T19:11:58.531+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:11:58.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:11:58.534+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:11:58.534+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:11:58.722+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:11:58.745+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:11:58.745+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:11:58.768+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:11:58.768+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:11:58.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-10T19:12:29.277+0000] {processor.py:186} INFO - Started process (PID=286) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:12:29.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:12:29.281+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:12:29.281+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:12:29.467+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:12:29.487+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:12:29.487+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:12:29.509+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:12:29.509+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:12:29.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-10T19:12:59.875+0000] {processor.py:186} INFO - Started process (PID=299) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:12:59.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:12:59.878+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:12:59.878+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:13:00.076+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:13:00.096+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:13:00.096+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:13:00.121+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:13:00.121+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:13:00.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.277 seconds
[2024-09-10T19:13:30.291+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:13:30.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:13:30.295+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:13:30.294+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:13:30.492+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:13:30.515+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:13:30.515+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:13:30.540+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:13:30.540+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:13:30.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.276 seconds
[2024-09-10T19:14:00.676+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:14:00.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:14:00.683+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:14:00.683+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:14:00.881+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:14:00.905+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:14:00.904+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:14:00.928+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:14:00.928+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:14:00.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.278 seconds
[2024-09-10T19:14:31.758+0000] {processor.py:186} INFO - Started process (PID=339) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:14:31.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:14:31.763+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:14:31.762+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:14:31.939+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:14:31.962+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:14:31.962+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:14:31.985+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:14:31.985+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:14:32.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T19:15:02.106+0000] {processor.py:186} INFO - Started process (PID=352) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:15:02.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:15:02.110+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:15:02.110+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:15:02.314+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:15:02.336+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:15:02.336+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:15:02.364+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:15:02.363+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:15:02.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.287 seconds
[2024-09-10T19:15:32.445+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:15:32.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:15:32.448+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:15:32.448+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:15:32.644+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:15:32.665+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:15:32.665+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:15:32.688+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:15:32.688+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:15:32.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-09-10T19:16:02.861+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:16:02.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:16:02.865+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:16:02.864+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:16:03.035+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:16:03.055+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:16:03.055+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:16:03.077+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:16:03.077+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:16:03.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T19:16:33.164+0000] {processor.py:186} INFO - Started process (PID=394) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:16:33.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:16:33.167+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:16:33.167+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:16:33.344+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:16:33.365+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:16:33.365+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:16:33.387+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:16:33.387+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:16:33.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-10T19:17:03.524+0000] {processor.py:186} INFO - Started process (PID=407) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:17:03.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:17:03.527+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:17:03.527+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:17:03.695+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:17:03.716+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:17:03.716+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:17:03.738+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:17:03.738+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:17:03.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-09-10T19:20:49.365+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:20:49.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:20:49.369+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:20:49.368+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:20:49.771+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:20:49.795+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:20:49.794+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:20:49.821+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:20:49.821+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:20:49.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.490 seconds
[2024-09-10T19:21:20.366+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:21:20.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:21:20.371+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:21:20.371+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:21:20.681+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:21:20.700+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:21:20.700+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:21:20.721+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:21:20.721+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:21:20.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.398 seconds
[2024-09-10T19:21:50.980+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:21:50.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:21:50.984+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:21:50.983+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:21:51.178+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:21:51.199+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:21:51.199+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:21:51.220+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:21:51.220+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:21:51.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-09-10T19:22:21.453+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:22:21.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:22:21.456+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:22:21.456+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:22:21.632+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:22:21.652+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:22:21.652+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:22:21.675+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:22:21.675+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:22:21.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-10T19:22:51.881+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:22:51.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:22:51.884+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:22:51.884+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:22:52.061+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:22:52.083+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:22:52.082+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:22:52.105+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:22:52.105+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:22:52.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T19:23:22.302+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:23:22.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:23:22.305+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:23:22.305+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:23:22.475+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:23:22.496+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:23:22.496+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:23:22.517+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:23:22.517+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:23:22.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-09-10T19:23:52.754+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:23:52.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:23:52.757+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:23:52.757+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:23:52.933+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:23:52.954+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:23:52.954+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:23:52.976+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:23:52.976+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:23:52.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-10T19:24:23.179+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:24:23.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:24:23.182+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:24:23.182+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:24:23.354+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:24:23.375+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:24:23.375+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:24:23.397+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:24:23.396+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:24:23.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.242 seconds
[2024-09-10T19:24:53.546+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:24:53.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:24:53.549+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:24:53.549+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:24:53.721+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:24:53.741+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:24:53.741+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:24:53.769+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:24:53.769+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:24:53.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T19:25:23.939+0000] {processor.py:186} INFO - Started process (PID=189) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:25:23.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:25:23.942+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:25:23.942+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:25:24.116+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:25:24.137+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:25:24.137+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:25:24.159+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:25:24.159+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:25:24.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-10T19:25:54.229+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:25:54.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:25:54.232+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:25:54.232+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:25:54.410+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:25:54.434+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:25:54.433+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:25:54.456+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:25:54.456+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:25:54.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-09-10T19:26:25.269+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:26:25.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:26:25.273+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:26:25.273+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:26:25.453+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:26:25.474+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:26:25.473+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:26:25.496+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:26:25.496+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:26:25.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-10T19:26:55.629+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:26:55.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:26:55.632+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:26:55.631+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:26:55.808+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:26:55.829+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:26:55.829+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:26:55.851+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:26:55.851+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:26:55.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T19:27:26.037+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:27:26.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:27:26.040+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:27:26.040+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:27:26.217+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:27:26.267+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:27:26.267+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:27:26.295+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:27:26.295+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:27:26.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.283 seconds
[2024-09-10T19:27:56.626+0000] {processor.py:186} INFO - Started process (PID=254) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:27:56.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:27:56.629+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:27:56.629+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:27:56.811+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:27:56.831+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:27:56.831+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:27:56.853+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:27:56.853+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:27:56.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-10T19:28:27.091+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:28:27.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:28:27.095+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:28:27.095+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:28:27.271+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:28:27.293+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:28:27.293+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:28:27.315+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:28:27.315+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:28:27.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-09-10T19:29:58.637+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:29:58.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:29:58.641+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:29:58.640+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:29:59.026+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:29:59.046+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:29:59.046+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:29:59.069+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:29:59.068+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:29:59.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.456 seconds
[2024-09-10T19:30:29.487+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:30:29.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:30:29.493+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:30:29.492+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:30:29.808+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:30:29.827+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:30:29.827+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:30:29.846+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:30:29.846+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:30:29.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.512 seconds
[2024-09-10T19:31:00.765+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:31:00.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:31:00.768+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:31:00.768+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:31:01.125+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:31:01.159+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:31:01.158+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:31:01.182+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:31:01.181+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:31:01.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.445 seconds
[2024-09-10T19:33:11.187+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:33:11.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:33:11.191+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:33:11.190+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:33:11.597+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:33:11.816+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:33:11.816+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:33:11.839+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:33:11.839+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:33:12.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 1.437 seconds
[2024-09-10T19:33:43.304+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:33:43.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:33:43.311+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:33:43.310+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:33:43.692+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:33:43.712+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:33:43.712+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:33:43.732+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:33:43.732+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:33:43.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.563 seconds
[2024-09-10T19:34:13.909+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:34:13.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:34:13.912+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:34:13.912+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:34:14.193+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:34:14.211+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:34:14.210+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:34:14.229+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:34:14.229+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:34:14.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.351 seconds
[2024-09-10T19:34:44.325+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:34:44.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:34:44.327+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:34:44.327+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:34:44.618+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:34:44.637+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:34:44.637+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:34:44.657+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:34:44.657+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:34:44.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.354 seconds
[2024-09-10T19:35:15.631+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:35:15.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:35:15.634+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:35:15.634+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:35:15.918+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:35:15.936+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:35:15.936+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:35:15.956+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:35:15.955+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:35:15.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.348 seconds
[2024-09-10T19:35:46.349+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:35:46.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:35:46.352+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:35:46.352+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:35:46.637+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:35:46.656+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:35:46.656+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:35:46.675+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:35:46.675+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:35:46.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.348 seconds
[2024-09-10T19:39:40.350+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:39:40.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:39:40.353+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:39:40.353+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:39:40.740+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:39:41.017+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:39:41.017+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:39:41.039+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:39:41.039+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:39:41.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.715 seconds
[2024-09-10T19:40:11.660+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:40:11.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:40:11.666+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:40:11.666+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:40:11.986+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:40:12.006+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:40:12.005+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:40:12.026+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:40:12.025+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:40:12.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.391 seconds
[2024-09-10T19:40:42.178+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:40:42.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:40:42.182+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:40:42.182+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:40:42.484+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:40:42.503+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:40:42.503+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:40:42.522+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:40:42.522+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:40:42.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.368 seconds
[2024-09-10T19:41:13.324+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:41:13.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:41:13.327+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:41:13.327+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:41:13.638+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:41:13.658+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:41:13.658+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:41:13.679+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:41:13.679+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:41:13.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.378 seconds
[2024-09-10T19:41:43.824+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:41:43.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:41:43.827+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:41:43.827+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:41:44.129+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:41:44.148+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:41:44.148+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:41:44.168+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:41:44.168+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:41:44.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.367 seconds
[2024-09-10T19:42:14.543+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:42:14.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:42:14.546+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:42:14.546+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:42:14.871+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:42:14.891+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:42:14.891+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:42:14.912+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:42:14.912+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:42:14.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.396 seconds
[2024-09-10T19:42:45.108+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:42:45.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:42:45.111+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:42:45.111+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:42:45.415+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:42:45.435+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:42:45.434+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:42:45.455+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:42:45.455+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:42:45.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.372 seconds
[2024-09-10T19:43:15.539+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:43:15.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:43:15.675+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:43:15.674+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:43:15.842+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:43:15.862+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:43:15.862+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:43:15.883+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:43:15.883+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:43:15.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.368 seconds
[2024-09-10T19:44:58.257+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:44:58.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:44:58.260+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:44:58.259+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:44:58.632+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:44:58.653+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:44:58.653+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:44:58.675+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:44:58.675+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:44:58.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.444 seconds
[2024-09-10T19:45:29.269+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:45:29.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:45:29.274+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:45:29.274+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:45:29.571+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:45:29.590+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:45:29.590+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:45:29.610+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:45:29.610+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:45:29.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.364 seconds
[2024-09-10T19:45:59.880+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:45:59.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:45:59.883+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:45:59.883+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:46:00.176+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:46:00.195+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:46:00.195+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:46:00.215+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:46:00.215+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:46:00.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.361 seconds
[2024-09-10T19:46:30.536+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:46:30.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:46:30.539+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:46:30.539+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:46:30.862+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:46:30.882+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:46:30.882+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:46:30.904+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:46:30.903+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:46:30.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.392 seconds
[2024-09-10T19:47:00.976+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:47:00.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:47:00.979+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:47:00.979+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:47:01.297+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:47:01.316+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:47:01.315+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:47:01.337+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:47:01.337+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:47:01.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.388 seconds
[2024-09-10T19:47:31.577+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:47:31.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:47:31.579+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:47:31.579+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:47:31.892+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:47:31.912+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:47:31.911+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:47:31.932+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:47:31.931+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:47:31.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.381 seconds
[2024-09-10T19:48:02.208+0000] {processor.py:186} INFO - Started process (PID=161) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:48:02.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:48:02.212+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:48:02.212+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:48:02.578+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:48:02.601+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:48:02.600+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:48:02.625+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:48:02.625+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:48:02.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.443 seconds
[2024-09-10T19:48:32.781+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:48:32.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:48:32.920+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:48:32.920+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:48:33.128+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:48:33.148+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:48:33.148+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:48:33.169+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:48:33.169+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:48:33.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.414 seconds
[2024-09-10T19:49:03.354+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:49:03.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:49:03.357+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:49:03.357+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:49:03.524+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:49:03.544+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:49:03.543+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:49:03.565+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:49:03.565+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:49:03.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-09-10T19:49:11.073+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:49:11.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:49:11.077+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:49:11.077+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:49:11.262+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:49:11.283+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:49:11.283+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:49:11.306+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:49:11.305+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:49:11.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T19:54:45.835+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:54:45.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:54:45.840+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:54:45.839+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:54:46.217+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:54:46.435+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:54:46.435+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:54:46.463+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:54:46.463+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:54:46.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.661 seconds
[2024-09-10T19:55:16.642+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:55:16.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:55:16.647+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:55:16.647+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:55:16.994+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:55:17.017+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:55:17.017+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:55:17.040+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:55:17.040+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:55:17.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.424 seconds
[2024-09-10T19:55:47.413+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:55:47.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:55:47.416+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:55:47.416+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:55:47.710+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:55:47.751+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:55:47.751+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:55:47.783+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:55:47.782+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:55:47.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.404 seconds
[2024-09-10T19:56:17.870+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:56:17.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:56:17.873+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:56:17.873+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:56:18.086+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:56:18.111+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:56:18.111+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:56:18.137+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:56:18.137+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:56:18.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.301 seconds
[2024-09-10T19:56:48.689+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:56:48.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:56:48.696+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:56:48.695+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:56:48.994+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:56:49.030+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:56:49.029+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:56:49.117+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:56:49.115+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:56:49.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.469 seconds
[2024-09-10T19:57:19.656+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:57:19.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:57:19.662+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:57:19.661+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:57:19.855+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:57:19.882+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:57:19.882+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:57:19.906+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:57:19.906+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:57:19.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.277 seconds
[2024-09-10T19:57:50.073+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:57:50.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:57:50.076+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:57:50.076+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:57:50.257+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:57:50.279+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:57:50.279+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:57:50.302+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:57:50.301+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:57:50.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-10T19:58:20.423+0000] {processor.py:186} INFO - Started process (PID=161) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:58:20.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:58:20.426+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:58:20.426+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:58:20.611+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:58:20.633+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:58:20.633+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:58:20.655+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:58:20.655+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-09 00:00:00+00:00, run_after=2024-09-10 00:00:00+00:00
[2024-09-10T19:58:20.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-10T19:58:50.816+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:58:50.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:58:50.820+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:58:50.819+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:58:51.017+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:58:51.043+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:58:51.042+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:58:51.075+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:58:51.075+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:58:51.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.289 seconds
[2024-09-10T19:59:21.172+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:59:21.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:59:21.175+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:59:21.175+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:59:21.364+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:59:21.390+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:59:21.390+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:59:21.459+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:59:21.459+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:59:21.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.332 seconds
[2024-09-10T19:59:51.553+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:59:51.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T19:59:51.556+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:59:51.556+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:59:51.741+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T19:59:51.764+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:59:51.764+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T19:59:51.789+0000] {logging_mixin.py:190} INFO - [2024-09-10T19:59:51.788+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T19:59:51.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-09-10T20:00:22.059+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:00:22.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:00:22.063+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:00:22.062+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:00:22.243+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:00:22.266+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:00:22.266+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:00:22.289+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:00:22.288+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:00:22.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-10T20:00:52.429+0000] {processor.py:186} INFO - Started process (PID=234) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:00:52.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:00:52.433+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:00:52.432+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:00:52.611+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:00:52.635+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:00:52.634+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:00:52.659+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:00:52.659+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:00:52.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.259 seconds
[2024-09-10T20:01:22.929+0000] {processor.py:186} INFO - Started process (PID=247) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:01:22.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:01:22.933+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:01:22.932+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:01:23.111+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:01:23.132+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:01:23.132+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:01:23.159+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:01:23.158+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:01:23.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.260 seconds
[2024-09-10T20:01:53.361+0000] {processor.py:186} INFO - Started process (PID=259) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:01:53.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:01:53.365+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:01:53.365+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:01:53.536+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:01:53.558+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:01:53.558+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:01:53.581+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:01:53.581+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:01:53.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T20:02:23.904+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:02:23.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:02:23.909+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:02:23.909+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:02:24.080+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:02:24.102+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:02:24.102+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:02:24.124+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:02:24.123+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:02:24.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-10T20:02:54.382+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:02:54.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:02:54.386+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:02:54.385+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:02:54.560+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:02:54.582+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:02:54.582+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:02:54.604+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:02:54.603+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:02:54.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-10T20:03:24.761+0000] {processor.py:186} INFO - Started process (PID=299) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:03:24.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:03:24.764+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:03:24.764+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:03:24.953+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:03:24.977+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:03:24.977+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:03:25.000+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:03:24.999+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:03:25.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.278 seconds
[2024-09-10T20:03:55.101+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:03:55.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:03:55.105+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:03:55.105+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:03:55.276+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:03:55.299+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:03:55.299+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:03:55.321+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:03:55.321+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:03:55.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T20:04:26.290+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:04:26.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:04:26.293+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:04:26.293+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:04:26.464+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:04:26.486+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:04:26.485+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:04:26.510+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:04:26.509+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:04:26.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-10T20:04:56.679+0000] {processor.py:186} INFO - Started process (PID=337) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:04:56.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:04:56.682+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:04:56.681+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:04:56.912+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:04:56.956+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:04:56.956+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:04:56.999+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:04:56.999+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:04:57.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.353 seconds
[2024-09-10T20:05:27.753+0000] {processor.py:186} INFO - Started process (PID=350) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:05:27.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:05:27.756+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:05:27.756+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:05:27.932+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:05:27.960+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:05:27.960+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:05:28.013+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:05:28.012+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:05:28.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.284 seconds
[2024-09-10T20:05:58.122+0000] {processor.py:186} INFO - Started process (PID=363) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:05:58.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:05:58.125+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:05:58.125+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:05:58.303+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:05:58.325+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:05:58.325+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:05:58.348+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:05:58.348+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:05:58.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-09-10T20:06:28.635+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:06:28.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:06:28.639+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:06:28.638+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:06:28.914+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:06:28.939+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:06:28.939+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:06:28.964+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:06:28.964+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:06:28.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.362 seconds
[2024-09-10T20:06:59.945+0000] {processor.py:186} INFO - Started process (PID=389) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:06:59.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:06:59.950+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:06:59.949+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:07:00.127+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:07:00.149+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:07:00.149+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:07:00.173+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:07:00.173+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:07:00.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T20:07:31.057+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:07:31.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:07:31.061+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:07:31.060+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:07:31.235+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:07:31.257+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:07:31.257+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:07:31.280+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:07:31.279+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:07:31.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T20:08:01.406+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:08:01.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:08:01.409+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:08:01.409+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:08:01.584+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:08:01.606+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:08:01.605+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:08:01.627+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:08:01.627+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:08:01.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-10T20:08:31.909+0000] {processor.py:186} INFO - Started process (PID=429) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:08:31.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:08:31.914+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:08:31.914+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:08:32.356+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:08:32.382+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:08:32.382+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:08:32.406+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:08:32.405+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:08:32.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.522 seconds
[2024-09-10T20:09:03.237+0000] {processor.py:186} INFO - Started process (PID=442) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:09:03.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:09:03.241+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:09:03.241+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:09:03.424+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:09:03.449+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:09:03.449+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:09:03.473+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:09:03.473+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:09:03.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.269 seconds
[2024-09-10T20:09:34.406+0000] {processor.py:186} INFO - Started process (PID=455) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:09:34.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:09:34.409+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:09:34.409+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:09:34.585+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:09:34.607+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:09:34.607+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:09:34.632+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:09:34.631+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:09:34.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-09-10T20:10:05.066+0000] {processor.py:186} INFO - Started process (PID=469) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:10:05.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:10:05.069+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:10:05.069+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:10:05.241+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:10:05.265+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:10:05.264+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:10:05.287+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:10:05.287+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:10:05.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T20:10:35.576+0000] {processor.py:186} INFO - Started process (PID=482) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:10:35.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:10:35.580+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:10:35.580+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:10:35.757+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:10:35.779+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:10:35.778+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:10:35.800+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:10:35.800+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:10:35.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-10T20:11:06.070+0000] {processor.py:186} INFO - Started process (PID=495) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:11:06.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:11:06.075+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:11:06.074+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:11:06.248+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:11:06.270+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:11:06.270+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:11:06.292+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:11:06.292+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:11:06.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-10T20:11:36.446+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:11:36.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:11:36.449+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:11:36.449+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:11:36.624+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:11:36.647+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:11:36.646+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:11:36.669+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:11:36.669+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:11:36.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-10T20:12:07.751+0000] {processor.py:186} INFO - Started process (PID=521) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:12:07.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:12:07.754+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:12:07.753+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:12:07.926+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:12:07.948+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:12:07.948+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:12:07.972+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:12:07.972+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:12:07.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T20:12:38.296+0000] {processor.py:186} INFO - Started process (PID=534) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:12:38.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:12:38.299+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:12:38.299+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:12:38.474+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:12:38.497+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:12:38.497+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:12:38.520+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:12:38.520+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:12:38.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T20:13:08.717+0000] {processor.py:186} INFO - Started process (PID=547) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:13:08.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:13:08.721+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:13:08.721+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:13:08.892+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:13:08.915+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:13:08.915+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:13:08.937+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:13:08.937+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:13:08.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T20:13:39.233+0000] {processor.py:186} INFO - Started process (PID=560) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:13:39.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:13:39.236+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:13:39.236+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:13:39.424+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:13:39.463+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:13:39.462+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:13:39.494+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:13:39.494+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:13:39.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.296 seconds
[2024-09-10T20:14:09.762+0000] {processor.py:186} INFO - Started process (PID=573) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:14:09.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:14:09.765+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:14:09.764+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:14:09.942+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:14:09.964+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:14:09.963+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:14:09.986+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:14:09.986+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:14:10.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-10T20:14:40.256+0000] {processor.py:186} INFO - Started process (PID=586) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:14:40.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:14:40.259+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:14:40.259+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:14:40.433+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:14:40.454+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:14:40.454+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:14:40.476+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:14:40.476+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:14:40.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-10T20:15:10.659+0000] {processor.py:186} INFO - Started process (PID=599) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:15:10.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:15:10.662+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:15:10.662+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:15:10.834+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:15:10.856+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:15:10.856+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:15:10.879+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:15:10.878+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:15:10.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T20:15:41.791+0000] {processor.py:186} INFO - Started process (PID=612) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:15:41.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:15:41.794+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:15:41.794+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:15:41.970+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:15:41.993+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:15:41.993+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:15:42.016+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:15:42.016+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:15:42.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T20:16:12.192+0000] {processor.py:186} INFO - Started process (PID=625) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:16:12.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:16:12.196+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:16:12.196+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:16:12.379+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:16:12.402+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:16:12.401+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:16:12.429+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:16:12.428+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:16:12.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.317 seconds
[2024-09-10T20:16:43.414+0000] {processor.py:186} INFO - Started process (PID=638) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:16:43.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:16:43.419+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:16:43.419+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:16:43.600+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:16:43.622+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:16:43.622+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:16:43.646+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:16:43.645+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:16:43.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.263 seconds
[2024-09-10T20:17:14.562+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:17:14.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:17:14.566+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:17:14.566+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:17:14.741+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:17:14.762+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:17:14.762+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:17:14.787+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:17:14.787+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:17:14.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.252 seconds
[2024-09-10T20:17:45.062+0000] {processor.py:186} INFO - Started process (PID=664) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:17:45.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:17:45.066+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:17:45.065+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:17:45.245+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:17:45.267+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:17:45.267+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:17:45.291+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:17:45.290+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:17:45.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.256 seconds
[2024-09-10T20:18:16.164+0000] {processor.py:186} INFO - Started process (PID=677) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:18:16.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:18:16.167+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:18:16.167+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:18:16.342+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:18:16.365+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:18:16.365+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:18:16.388+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:18:16.388+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:18:16.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-10T20:18:46.459+0000] {processor.py:186} INFO - Started process (PID=690) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:18:46.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:18:46.462+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:18:46.462+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:18:46.639+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:18:46.662+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:18:46.662+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:18:46.684+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:18:46.684+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:18:46.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.251 seconds
[2024-09-10T20:19:16.935+0000] {processor.py:186} INFO - Started process (PID=703) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:19:16.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:19:16.939+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:19:16.938+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:19:17.111+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:19:17.133+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:19:17.133+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:19:17.155+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:19:17.155+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:19:17.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-10T20:19:47.952+0000] {processor.py:186} INFO - Started process (PID=716) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:19:47.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:19:47.956+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:19:47.956+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:19:48.133+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:19:48.154+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:19:48.154+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:19:48.177+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:19:48.177+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:19:48.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.250 seconds
[2024-09-10T20:20:19.188+0000] {processor.py:186} INFO - Started process (PID=729) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:20:19.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:20:19.192+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:20:19.191+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:20:19.362+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:20:19.384+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:20:19.384+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:20:19.407+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:20:19.407+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:20:19.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.243 seconds
[2024-09-10T20:20:49.516+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:20:49.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:20:49.521+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:20:49.520+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:20:49.710+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:20:49.736+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:20:49.735+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:20:49.762+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:20:49.761+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:20:49.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.271 seconds
[2024-09-10T20:21:20.757+0000] {processor.py:186} INFO - Started process (PID=755) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:21:20.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:21:20.760+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:21:20.760+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:21:20.959+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:21:20.983+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:21:20.983+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:21:21.005+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:21:21.005+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:21:21.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.274 seconds
[2024-09-10T20:21:51.081+0000] {processor.py:186} INFO - Started process (PID=774) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:21:51.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:21:51.084+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:21:51.084+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:21:51.269+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:21:51.292+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:21:51.292+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:21:51.314+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:21:51.314+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:21:51.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.265 seconds
[2024-09-10T20:22:22.203+0000] {processor.py:186} INFO - Started process (PID=788) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:22:22.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:22:22.206+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:22:22.205+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:22:22.382+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:22:22.405+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:22:22.405+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:22:22.438+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:22:22.437+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:22:22.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.268 seconds
[2024-09-10T20:22:53.469+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:22:53.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:22:53.472+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:22:53.472+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:22:53.642+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:22:53.664+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:22:53.664+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:22:53.685+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:22:53.685+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:22:53.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.290 seconds
[2024-09-10T20:23:23.799+0000] {processor.py:186} INFO - Started process (PID=814) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:23:23.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:23:23.804+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:23:23.804+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:23:23.997+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:23:24.024+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:23:24.024+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:23:24.053+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:23:24.053+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:23:24.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.285 seconds
[2024-09-10T20:23:55.062+0000] {processor.py:186} INFO - Started process (PID=827) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:23:55.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:23:55.065+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:23:55.065+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:23:55.236+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:23:55.259+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:23:55.259+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:23:55.281+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:23:55.281+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:23:55.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T20:24:26.225+0000] {processor.py:186} INFO - Started process (PID=840) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:24:26.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:24:26.229+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:24:26.228+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:24:26.409+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:24:26.433+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:24:26.433+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:24:26.455+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:24:26.455+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:24:26.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-09-10T20:24:56.554+0000] {processor.py:186} INFO - Started process (PID=853) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:24:56.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:24:56.558+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:24:56.558+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:24:56.734+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:24:56.755+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:24:56.755+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:24:56.778+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:24:56.777+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:24:56.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.247 seconds
[2024-09-10T20:25:26.868+0000] {processor.py:186} INFO - Started process (PID=866) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:25:26.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:25:26.872+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:25:26.872+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:25:27.060+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:25:27.082+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:25:27.082+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:25:27.104+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:25:27.104+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:25:27.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-10T20:25:57.171+0000] {processor.py:186} INFO - Started process (PID=879) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:25:57.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:25:57.174+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:25:57.174+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:25:57.347+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:25:57.368+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:25:57.368+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:25:57.390+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:25:57.390+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:25:57.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.254 seconds
[2024-09-10T20:26:27.460+0000] {processor.py:186} INFO - Started process (PID=892) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:26:27.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:26:27.463+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:26:27.463+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:26:27.633+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:26:27.657+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:26:27.656+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:26:27.678+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:26:27.678+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:26:27.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T20:26:57.850+0000] {processor.py:186} INFO - Started process (PID=905) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:26:57.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:26:57.853+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:26:57.853+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:26:58.024+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:26:58.045+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:26:58.045+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:26:58.067+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:26:58.066+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:26:58.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.241 seconds
[2024-09-10T20:27:28.885+0000] {processor.py:186} INFO - Started process (PID=918) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:27:28.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:27:28.889+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:27:28.889+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:27:29.075+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:27:29.098+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:27:29.098+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:27:29.122+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:27:29.121+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:27:29.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.264 seconds
[2024-09-10T20:27:59.237+0000] {processor.py:186} INFO - Started process (PID=931) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:27:59.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:27:59.242+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:27:59.241+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:27:59.465+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:27:59.490+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:27:59.489+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:27:59.517+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:27:59.516+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:27:59.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.307 seconds
[2024-09-10T20:28:29.638+0000] {processor.py:186} INFO - Started process (PID=944) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:28:29.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:28:29.641+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:28:29.640+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:28:29.812+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:28:29.834+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:28:29.834+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:28:29.856+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:28:29.856+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:28:29.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.245 seconds
[2024-09-10T20:28:59.948+0000] {processor.py:186} INFO - Started process (PID=957) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:28:59.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:28:59.952+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:28:59.952+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:29:00.136+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:29:00.160+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:29:00.160+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:29:00.186+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:29:00.186+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:29:00.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.266 seconds
[2024-09-10T20:29:31.189+0000] {processor.py:186} INFO - Started process (PID=970) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:29:31.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:29:31.192+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:29:31.192+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:29:31.368+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:29:31.390+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:29:31.390+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:29:31.413+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:29:31.412+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:29:31.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.258 seconds
[2024-09-10T20:30:02.314+0000] {processor.py:186} INFO - Started process (PID=983) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:30:02.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:30:02.317+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:30:02.317+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:30:02.494+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:30:02.520+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:30:02.520+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:30:02.547+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:30:02.547+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:30:02.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.261 seconds
[2024-09-10T20:30:33.564+0000] {processor.py:186} INFO - Started process (PID=997) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:30:33.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:30:33.567+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:30:33.567+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:30:33.734+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:30:33.755+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:30:33.755+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:30:33.776+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:30:33.776+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:30:33.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.234 seconds
[2024-09-10T20:31:04.211+0000] {processor.py:186} INFO - Started process (PID=1010) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:31:04.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:31:04.214+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:31:04.214+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:31:04.382+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:31:04.404+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:31:04.404+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:31:04.426+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:31:04.425+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:31:04.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.240 seconds
[2024-09-10T20:31:35.468+0000] {processor.py:186} INFO - Started process (PID=1023) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:31:35.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:31:35.471+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:31:35.471+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:31:35.641+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:31:35.662+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:31:35.662+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:31:35.684+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:31:35.684+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:31:35.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.241 seconds
[2024-09-10T20:32:05.813+0000] {processor.py:186} INFO - Started process (PID=1036) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:32:05.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:32:05.816+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:32:05.816+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:32:05.991+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:32:06.015+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:32:06.015+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:32:06.037+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:32:06.036+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:32:06.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.248 seconds
[2024-09-10T20:32:36.316+0000] {processor.py:186} INFO - Started process (PID=1049) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:32:36.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:32:36.319+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:32:36.319+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:32:36.494+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:32:36.516+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:32:36.516+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:32:36.539+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:32:36.539+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:32:36.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-10T20:33:06.748+0000] {processor.py:186} INFO - Started process (PID=1062) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:33:06.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:33:06.752+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:33:06.752+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:33:06.926+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:33:06.948+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:33:06.948+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:33:06.970+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:33:06.970+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:33:06.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-10T20:33:37.242+0000] {processor.py:186} INFO - Started process (PID=1075) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:33:37.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:33:37.248+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:33:37.248+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:33:37.423+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:33:37.444+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:33:37.444+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:33:37.466+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:33:37.465+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:33:37.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.255 seconds
[2024-09-10T20:34:08.198+0000] {processor.py:186} INFO - Started process (PID=1087) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:34:08.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:34:08.202+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:34:08.201+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:34:08.370+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:34:08.392+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:34:08.392+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:34:08.414+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:34:08.414+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:34:08.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.241 seconds
[2024-09-10T20:34:38.751+0000] {processor.py:186} INFO - Started process (PID=1100) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:34:38.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:34:38.755+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:34:38.754+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:34:38.929+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:34:38.951+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:34:38.951+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:34:38.974+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:34:38.974+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:34:38.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.249 seconds
[2024-09-10T20:35:09.226+0000] {processor.py:186} INFO - Started process (PID=1113) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:35:09.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:35:09.230+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:35:09.229+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:35:09.405+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:35:09.428+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:35:09.427+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:35:09.450+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:35:09.450+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:35:09.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.257 seconds
[2024-09-10T20:35:40.038+0000] {processor.py:186} INFO - Started process (PID=1126) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:35:40.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T20:35:40.042+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:35:40.041+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:35:40.213+0000] {processor.py:925} INFO - DAG(s) 'SitesWebScraping' retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T20:35:40.235+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:35:40.235+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-10T20:35:40.257+0000] {logging_mixin.py:190} INFO - [2024-09-10T20:35:40.256+0000] {dag.py:4156} INFO - Setting next_dagrun for SitesWebScraping to 2024-09-10 00:00:00+00:00, run_after=2024-09-11 00:00:00+00:00
[2024-09-10T20:35:40.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.244 seconds
[2024-09-10T22:22:05.623+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:22:05.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:22:05.642+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:22:05.641+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:22:06.690+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:22:06.681+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:22:06.691+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:22:06.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 1.119 seconds
[2024-09-10T22:22:36.797+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:22:36.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:22:36.802+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:22:36.802+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:22:37.113+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:22:37.107+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:22:37.115+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:22:37.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.342 seconds
[2024-09-10T22:23:07.227+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:23:07.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:23:07.229+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:23:07.228+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:23:07.416+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:23:07.408+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:23:07.417+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:23:07.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.217 seconds
[2024-09-10T22:23:37.507+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:23:37.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:23:37.509+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:23:37.509+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:23:37.697+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:23:37.689+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:23:37.698+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:23:37.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-09-10T22:24:07.784+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:24:07.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:24:07.786+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:24:07.786+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:24:07.970+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:24:07.963+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:24:07.971+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:24:07.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.211 seconds
[2024-09-10T22:24:38.177+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:24:38.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:24:38.179+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:24:38.178+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:24:38.358+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:24:38.351+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:24:38.359+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:24:38.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.205 seconds
[2024-09-10T22:25:08.538+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:25:08.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:25:08.540+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:25:08.540+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:25:08.714+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:25:08.707+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:25:08.715+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:25:08.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.201 seconds
[2024-09-10T22:25:39.639+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:25:39.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:25:39.641+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:25:39.641+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:25:39.840+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:25:39.833+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:25:39.841+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:25:39.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.223 seconds
[2024-09-10T22:26:09.992+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:26:09.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:26:09.996+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:26:09.995+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:26:10.219+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:26:10.212+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:26:10.221+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:26:10.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.253 seconds
[2024-09-10T22:26:40.293+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:26:40.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:26:40.295+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:26:40.295+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:26:40.482+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:26:40.473+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:26:40.483+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:26:40.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
[2024-09-10T22:27:11.161+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:27:11.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:27:11.163+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:27:11.163+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:27:11.351+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:27:11.343+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:27:11.352+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:27:11.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.220 seconds
[2024-09-10T22:27:41.977+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:27:41.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:27:41.980+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:27:41.979+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:27:42.162+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:27:42.155+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:27:42.163+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:27:42.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.211 seconds
[2024-09-10T22:28:12.956+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:28:12.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:28:12.958+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:28:12.958+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:28:13.141+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:28:13.134+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:28:13.142+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:28:13.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.212 seconds
[2024-09-10T22:28:43.259+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:28:43.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:28:43.261+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:28:43.261+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:28:43.440+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:28:43.432+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:28:43.441+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:28:43.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.206 seconds
[2024-09-10T22:29:14.257+0000] {processor.py:186} INFO - Started process (PID=239) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:29:14.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:29:14.260+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:29:14.259+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:29:14.445+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:29:14.438+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:29:14.446+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:29:14.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.214 seconds
[2024-09-10T22:29:45.104+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:29:45.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:29:45.107+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:29:45.107+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:29:45.285+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:29:45.279+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:29:45.287+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:29:45.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.206 seconds
[2024-09-10T22:30:15.404+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:30:15.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:30:15.406+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:30:15.406+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:30:15.587+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:30:15.579+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:30:15.588+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:30:15.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.209 seconds
[2024-09-10T22:30:46.478+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:30:46.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:30:46.481+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:30:46.480+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:30:46.664+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:30:46.657+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:30:46.666+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:30:46.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.214 seconds
[2024-09-10T22:31:17.227+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:31:17.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:31:17.229+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:31:17.229+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:31:17.419+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:31:17.410+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:31:17.421+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:31:17.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-09-10T22:31:48.070+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:31:48.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:31:48.072+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:31:48.072+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:31:48.258+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:31:48.250+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:31:48.259+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:31:48.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.214 seconds
[2024-09-10T22:32:18.398+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:32:18.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:32:18.400+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:32:18.400+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:32:18.578+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:32:18.570+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:32:18.580+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:32:18.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.206 seconds
[2024-09-10T22:32:49.479+0000] {processor.py:186} INFO - Started process (PID=324) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:32:49.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:32:49.482+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:32:49.481+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:32:49.661+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:32:49.653+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:32:49.662+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:32:49.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.208 seconds
[2024-09-10T22:33:19.770+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:33:19.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:33:19.772+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:33:19.772+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:33:19.947+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:33:19.940+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:33:19.948+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:33:19.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.201 seconds
[2024-09-10T22:33:50.184+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:33:50.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:33:50.186+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:33:50.185+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:33:50.369+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:33:50.361+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:33:50.371+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:33:50.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.209 seconds
[2024-09-10T22:34:21.053+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:34:21.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:34:21.055+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:34:21.054+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:34:21.233+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:34:21.226+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:34:21.234+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:34:21.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.205 seconds
[2024-09-10T22:34:51.935+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:34:51.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:34:51.937+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:34:51.937+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:34:52.115+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:34:52.107+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:34:52.116+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:34:52.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.206 seconds
[2024-09-10T22:35:22.778+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:35:22.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:35:22.780+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:35:22.780+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:35:22.959+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:35:22.952+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:35:22.960+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:35:22.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.207 seconds
[2024-09-10T22:35:53.738+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:35:53.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:35:53.740+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:35:53.740+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:35:53.919+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:35:53.912+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:35:53.921+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:35:53.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.205 seconds
[2024-09-10T22:36:24.083+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:36:24.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:36:24.085+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:36:24.085+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:36:24.266+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:36:24.260+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:36:24.267+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:36:24.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.207 seconds
[2024-09-10T22:36:54.397+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:36:54.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:36:54.400+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:36:54.400+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:36:54.582+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:36:54.575+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:36:54.584+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:36:54.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.211 seconds
[2024-09-10T22:37:25.543+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:37:25.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:37:25.546+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:37:25.545+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:37:25.723+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:37:25.716+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:37:25.724+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:37:25.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.203 seconds
[2024-09-10T22:37:56.618+0000] {processor.py:186} INFO - Started process (PID=444) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:37:56.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:37:56.620+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:37:56.620+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:37:56.803+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:37:56.796+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:37:56.804+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:37:56.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.212 seconds
[2024-09-10T22:38:26.892+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:38:26.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:38:26.894+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:38:26.894+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:38:27.095+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:38:27.087+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:38:27.097+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:38:27.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.229 seconds
[2024-09-10T22:38:57.192+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:38:57.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:38:57.194+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:38:57.194+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:38:57.374+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:38:57.367+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:38:57.375+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:38:57.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.207 seconds
[2024-09-10T22:39:27.952+0000] {processor.py:186} INFO - Started process (PID=480) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:39:27.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:39:27.954+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:39:27.954+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:39:28.140+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:39:28.134+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:39:28.141+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:39:28.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-09-10T22:39:58.597+0000] {processor.py:186} INFO - Started process (PID=493) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:39:58.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:39:58.599+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:39:58.599+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:39:58.787+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:39:58.781+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:39:58.788+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:39:58.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-09-10T22:40:29.244+0000] {processor.py:186} INFO - Started process (PID=505) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:40:29.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:40:29.247+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:40:29.246+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:40:29.433+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:40:29.425+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:40:29.434+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:40:29.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-09-10T22:40:59.903+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:40:59.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:40:59.906+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:40:59.906+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:41:00.085+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:41:00.078+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:41:00.087+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:41:00.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.208 seconds
[2024-09-10T22:41:30.556+0000] {processor.py:186} INFO - Started process (PID=529) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:41:30.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:41:30.558+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:41:30.558+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:41:30.743+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:41:30.735+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:41:30.744+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:41:30.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-09-10T22:42:01.219+0000] {processor.py:186} INFO - Started process (PID=541) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:42:01.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:42:01.222+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:42:01.222+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:42:01.404+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:42:01.396+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:42:01.405+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:42:01.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.211 seconds
[2024-09-10T22:42:31.861+0000] {processor.py:186} INFO - Started process (PID=553) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:42:31.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:42:31.864+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:42:31.864+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:42:32.042+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:42:32.034+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:42:32.043+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:42:32.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.206 seconds
[2024-09-10T22:43:02.536+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:43:02.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:43:02.538+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:43:02.538+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:43:02.716+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:43:02.709+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:43:02.718+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:43:02.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.206 seconds
[2024-09-10T22:43:33.210+0000] {processor.py:186} INFO - Started process (PID=577) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:43:33.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:43:33.212+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:43:33.212+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:43:33.390+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:43:33.383+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:43:33.392+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:43:33.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.206 seconds
[2024-09-10T22:44:04.071+0000] {processor.py:186} INFO - Started process (PID=589) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:44:04.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:44:04.073+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:44:04.073+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:44:04.251+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:44:04.243+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:44:04.252+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:44:04.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.205 seconds
[2024-09-10T22:45:24.296+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:45:24.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:45:24.300+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:45:24.299+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:45:24.678+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:45:24.673+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:45:24.679+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:45:24.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.406 seconds
[2024-09-10T22:45:54.900+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:45:54.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:45:54.903+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:45:54.903+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:45:55.198+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:45:55.191+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:45:55.199+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:45:55.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.323 seconds
[2024-09-10T22:46:26.097+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:46:26.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:46:26.101+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:46:26.100+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:46:26.294+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:46:26.287+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:46:26.295+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:46:26.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.225 seconds
[2024-09-10T22:46:56.960+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:46:56.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:46:56.963+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:46:56.962+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:46:57.142+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:46:57.135+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:46:57.143+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:46:57.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.208 seconds
[2024-09-10T22:47:27.964+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:47:27.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:47:27.967+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:47:27.967+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:47:28.156+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:47:28.149+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:47:28.157+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:47:28.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.219 seconds
[2024-09-10T22:47:58.323+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:47:58.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:47:58.327+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:47:58.326+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:47:58.514+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:47:58.507+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:47:58.516+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:47:58.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-09-10T22:48:29.515+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:48:29.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:48:29.518+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:48:29.518+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:48:29.704+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:48:29.696+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:48:29.705+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:48:29.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-09-10T22:49:00.432+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:49:00.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:49:00.435+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:49:00.435+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:49:00.620+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:49:00.613+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:49:00.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:49:00.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.216 seconds
[2024-09-10T22:49:31.487+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:49:31.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:49:31.491+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:49:31.490+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:49:31.674+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:49:31.667+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:49:31.676+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:49:31.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.212 seconds
[2024-09-10T22:50:02.409+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:50:02.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:50:02.412+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:50:02.412+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:50:02.620+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:50:02.613+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:50:02.621+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:50:02.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.246 seconds
[2024-09-10T22:50:33.533+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:50:33.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:50:33.537+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:50:33.536+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:50:33.717+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:50:33.710+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:50:33.719+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:50:33.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.213 seconds
[2024-09-10T22:51:04.518+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:51:04.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:51:04.521+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:51:04.521+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:51:04.706+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:51:04.700+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:51:04.708+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:51:04.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.215 seconds
[2024-09-10T22:53:08.981+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:53:08.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:53:08.987+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:53:08.987+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:53:09.424+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:53:09.418+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:53:09.425+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:53:09.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.471 seconds
[2024-09-10T22:53:39.655+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:53:39.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:53:39.659+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:53:39.659+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:53:39.961+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:53:39.954+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:53:39.962+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:53:39.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.330 seconds
[2024-09-10T22:54:10.754+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:54:10.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:54:10.757+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:54:10.757+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:54:10.939+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:54:10.933+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:54:10.940+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:54:10.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.210 seconds
[2024-09-10T22:54:41.303+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:54:41.304+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:54:41.307+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:54:41.306+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:54:41.489+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:54:41.482+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:54:41.491+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:54:41.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.210 seconds
[2024-09-10T22:55:11.851+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:55:11.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:55:11.854+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:55:11.853+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:55:12.041+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:55:12.033+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:55:12.043+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:55:12.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.218 seconds
[2024-09-10T22:55:42.438+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:55:42.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/DagWebScraping.py for tasks to queue
[2024-09-10T22:55:42.442+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:55:42.441+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:55:42.636+0000] {logging_mixin.py:190} INFO - [2024-09-10T22:55:42.630+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/DagWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/DagWebScraping.py", line 15, in <module>
    createContainerTask = CreateContainerInDataLake(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/operators/OperatorCreateContainer.py", line 10, in __init__
    super().__init__(
TypeError: airflow.operators.bash.BashOperator.__init__() got multiple values for keyword argument 'task_id'
[2024-09-10T22:55:42.638+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/DagWebScraping.py
[2024-09-10T22:55:42.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/DagWebScraping.py took 0.224 seconds
