[2024-09-22T00:00:19.155+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:00:19.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:00:19.158+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:00:19.158+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:00:19.187+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:00:19.210+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:00:19.210+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:00:19.234+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:00:19.234+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T00:00:19.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T00:00:47.440+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:00:47.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:00:47.444+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:00:47.443+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:00:47.473+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:00:47.467+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:00:47.474+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:00:47.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.059 seconds
[2024-09-22T00:00:50.788+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:00:50.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:00:50.792+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:00:50.791+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:00:50.816+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:00:50.811+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:00:50.817+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:00:50.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.053 seconds
[2024-09-22T00:01:20.993+0000] {processor.py:186} INFO - Started process (PID=413) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:01:20.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:01:20.996+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:01:20.996+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:01:21.016+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:01:21.011+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:01:21.017+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:01:21.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.053 seconds
[2024-09-22T00:03:18.853+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:03:18.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:03:18.856+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:03:18.856+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:03:18.873+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:03:18.869+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:03:18.874+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:03:18.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T00:03:49.186+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:03:49.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:03:49.189+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:03:49.188+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:03:49.207+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:03:49.203+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:03:49.207+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:03:49.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T00:04:19.510+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:04:19.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:04:19.517+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:04:19.516+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:04:19.537+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:04:19.532+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:04:19.538+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:04:19.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.054 seconds
[2024-09-22T00:04:49.666+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:04:49.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:04:49.669+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:04:49.668+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:04:49.690+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:04:49.684+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:04:49.691+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:04:49.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.058 seconds
[2024-09-22T00:05:19.795+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:05:19.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:05:19.798+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:05:19.797+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:05:19.820+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:05:19.813+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:05:19.822+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:05:19.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.060 seconds
[2024-09-22T00:05:49.962+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:05:49.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:05:49.964+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:05:49.963+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:05:49.987+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:05:49.983+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:05:49.988+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:05:50.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.052 seconds
[2024-09-22T00:06:20.337+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:06:20.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:06:20.339+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:06:20.339+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:06:20.358+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:06:20.354+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:06:20.359+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:06:20.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T00:06:50.580+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:06:50.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:06:50.582+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:06:50.582+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:06:50.601+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:06:50.596+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:06:50.602+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:06:50.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T00:07:20.789+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:07:20.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:07:20.924+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:07:20.923+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:07:20.941+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:07:20.937+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:07:20.942+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:07:20.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.174 seconds
[2024-09-22T00:07:51.123+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:07:51.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:07:51.125+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:07:51.125+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:07:51.142+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:07:51.138+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:07:51.143+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:07:51.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T00:08:21.207+0000] {processor.py:186} INFO - Started process (PID=189) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:08:21.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:08:21.209+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:08:21.209+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:08:21.229+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:08:21.224+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:08:21.230+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:08:21.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T00:08:51.364+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:08:51.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:08:51.367+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:08:51.367+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:08:51.384+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:08:51.379+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:08:51.385+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:08:51.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T00:09:21.469+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:09:21.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:09:21.471+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:09:21.471+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:09:21.493+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:09:21.487+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:09:21.494+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:09:21.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.056 seconds
[2024-09-22T00:09:52.373+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:09:52.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:09:52.375+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:09:52.375+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:09:52.396+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:09:52.391+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:09:52.397+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:09:52.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.052 seconds
[2024-09-22T00:11:02.787+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:11:02.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:11:02.793+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:11:02.792+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:11:02.814+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:11:02.807+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:11:02.815+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:11:02.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.064 seconds
[2024-09-22T00:11:33.179+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:11:33.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:11:33.182+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:11:33.182+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:11:33.198+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:11:33.195+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:11:33.199+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:11:33.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T00:12:03.370+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:12:03.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:12:03.373+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:12:03.373+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:12:03.394+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:12:03.390+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:12:03.395+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:12:03.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.051 seconds
[2024-09-22T00:12:33.613+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:12:33.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:12:33.617+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:12:33.616+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:12:33.632+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:12:33.629+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:12:33.633+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:12:33.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T00:13:03.895+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:13:03.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:13:03.898+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:13:03.898+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:13:03.917+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:13:03.913+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:13:03.918+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:13:03.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T00:13:34.109+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:13:34.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:13:34.112+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:13:34.112+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:13:34.132+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:13:34.127+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:13:34.133+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:13:34.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.052 seconds
[2024-09-22T00:13:55.920+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:13:55.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:13:55.924+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:13:55.924+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:13:55.952+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:13:55.947+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 32, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:13:55.953+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:13:55.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.060 seconds
[2024-09-22T00:14:03.168+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:14:03.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:14:03.171+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:14:03.170+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:14:03.194+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:14:03.516+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:14:03.516+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:14:03.536+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:14:03.536+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T00:14:03.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.407 seconds
[2024-09-22T00:14:29.896+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:14:29.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:14:29.899+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:14:29.899+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:14:29.923+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:14:29.919+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:14:29.924+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:14:29.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.054 seconds
[2024-09-22T00:14:48.820+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:14:48.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:14:48.823+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:14:48.823+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:14:48.845+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:14:49.070+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:14:49.070+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:14:49.087+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:14:49.087+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:14:49.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.300 seconds
[2024-09-22T00:15:19.339+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:15:19.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:15:19.343+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:15:19.342+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:15:19.359+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:15:19.383+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:15:19.383+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:15:19.405+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:15:19.405+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:15:19.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T00:15:49.568+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:15:49.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:15:49.572+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:15:49.572+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:15:49.588+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:15:49.613+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:15:49.612+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:15:49.635+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:15:49.635+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:15:49.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T00:16:20.044+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:16:20.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:16:20.047+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:16:20.047+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:16:20.064+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:16:20.087+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:16:20.086+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:16:20.109+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:16:20.108+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:16:20.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T00:16:47.999+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:16:48.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:16:48.003+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:16:48.003+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:16:48.027+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:16:48.022+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:16:48.028+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:16:48.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.058 seconds
[2024-09-22T00:16:53.146+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:16:53.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:16:53.150+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:16:53.150+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:16:53.172+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:16:53.167+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:16:53.173+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:16:53.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.053 seconds
[2024-09-22T00:18:04.736+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:18:04.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:18:04.739+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:18:04.739+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:18:04.754+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:18:04.750+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:18:04.755+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:18:04.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T00:18:35.246+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:18:35.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:18:35.249+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:18:35.249+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:18:35.265+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:18:35.261+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:18:35.266+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:18:35.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T00:19:05.412+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:19:05.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:19:05.415+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:19:05.414+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:19:05.431+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:19:05.427+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:19:05.432+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:19:05.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.170 seconds
[2024-09-22T00:19:35.710+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:19:35.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:19:35.714+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:19:35.713+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:19:35.732+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:19:35.727+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:19:35.732+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:19:35.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T00:20:05.947+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:20:05.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:20:05.949+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:20:05.949+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:20:05.966+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:20:05.961+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:20:05.967+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:20:05.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T00:20:36.034+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:20:36.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:20:36.037+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:20:36.037+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:20:36.055+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:20:36.050+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T00:20:36.055+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:20:36.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T00:21:00.076+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:21:00.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:21:00.078+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:21:00.078+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:21:00.109+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:21:00.220+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:21:00.220+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:21:00.240+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:21:00.240+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:21:00.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.195 seconds
[2024-09-22T00:22:16.749+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:22:16.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:22:16.753+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:22:16.753+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:22:16.770+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:22:16.804+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:22:16.804+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:22:16.829+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:22:16.829+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:22:16.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.251 seconds
[2024-09-22T00:22:47.096+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:22:47.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:22:47.099+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:22:47.098+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:22:47.122+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:22:47.148+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:22:47.148+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:22:47.303+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:22:47.303+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:22:47.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.252 seconds
[2024-09-22T00:23:17.498+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:23:17.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:23:17.504+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:23:17.504+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:23:17.531+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:23:17.688+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:23:17.688+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:23:17.707+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:23:17.707+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-20 00:00:00+00:00, run_after=2024-09-20 00:00:00+00:00
[2024-09-22T00:23:17.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.242 seconds
[2024-09-22T00:23:47.806+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:23:47.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:23:47.809+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:23:47.809+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:23:47.831+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:23:47.855+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:23:47.854+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:23:47.877+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:23:47.876+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:23:47.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.097 seconds
[2024-09-22T00:24:18.037+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:24:18.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:24:18.040+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:24:18.040+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:24:18.062+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:24:18.085+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:24:18.085+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:24:18.108+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:24:18.108+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:24:18.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T00:24:48.477+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:24:48.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:24:48.480+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:24:48.479+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:24:48.506+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:24:48.535+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:24:48.535+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:24:48.558+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:24:48.558+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:24:48.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.123 seconds
[2024-09-22T00:25:18.730+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:25:18.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:25:18.733+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:25:18.733+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:25:18.756+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:25:18.779+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:25:18.779+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:25:18.800+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:25:18.800+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:25:19.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.312 seconds
[2024-09-22T00:25:49.236+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:25:49.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:25:49.240+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:25:49.239+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:25:49.274+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:25:49.303+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:25:49.302+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:25:49.327+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:25:49.327+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:25:49.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.127 seconds
[2024-09-22T00:27:44.970+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:27:44.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:27:44.975+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:27:44.975+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:27:45.022+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:27:45.111+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:27:45.110+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:27:45.202+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:27:45.202+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:27:45.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.285 seconds
[2024-09-22T00:28:15.554+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:28:15.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:28:15.560+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:28:15.559+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:28:15.581+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:28:15.612+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:28:15.611+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:28:15.635+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:28:15.635+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:28:15.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T00:28:46.051+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:28:46.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:28:46.054+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:28:46.054+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:28:46.073+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:28:46.097+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:28:46.097+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:28:46.120+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:28:46.120+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:28:46.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.099 seconds
[2024-09-22T00:29:16.675+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:29:16.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:29:16.679+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:29:16.679+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:29:16.697+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:29:16.722+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:29:16.722+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:29:16.747+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:29:16.747+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:29:16.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T00:29:47.497+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:29:47.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:29:47.500+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:29:47.500+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:29:47.517+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:29:47.541+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:29:47.540+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:29:47.563+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:29:47.563+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:29:47.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.097 seconds
[2024-09-22T00:30:17.964+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:30:17.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:30:17.968+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:30:17.967+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:30:17.986+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:30:18.010+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:30:18.010+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:30:18.033+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:30:18.033+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:30:18.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.237 seconds
[2024-09-22T00:30:48.279+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:30:48.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:30:48.282+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:30:48.282+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:30:48.299+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:30:48.323+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:30:48.322+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:30:48.464+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:30:48.464+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:30:48.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.210 seconds
[2024-09-22T00:31:18.665+0000] {processor.py:186} INFO - Started process (PID=157) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:31:18.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:31:18.668+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:31:18.668+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:31:18.686+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:31:18.838+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:31:18.838+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:31:18.858+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:31:18.857+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:31:18.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.219 seconds
[2024-09-22T00:31:49.276+0000] {processor.py:186} INFO - Started process (PID=170) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:31:49.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:31:49.432+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:31:49.431+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:31:49.445+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:31:49.464+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:31:49.464+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:31:49.485+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:31:49.484+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:31:49.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.234 seconds
[2024-09-22T00:32:19.945+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:32:19.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:32:19.949+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:32:19.949+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:32:19.971+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:32:19.994+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:32:19.994+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:32:20.015+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:32:20.015+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:32:20.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.099 seconds
[2024-09-22T00:32:51.085+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:32:51.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:32:51.088+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:32:51.088+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:32:51.108+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:32:51.132+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:32:51.132+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:32:51.153+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:32:51.153+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:32:51.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T00:43:01.312+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:43:01.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:43:01.319+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:43:01.318+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:43:01.412+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:43:01.504+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:43:01.503+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:43:01.550+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:43:01.550+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:43:01.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.322 seconds
[2024-09-22T00:43:31.751+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:43:31.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:43:31.756+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:43:31.755+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:43:31.787+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:43:31.837+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:43:31.837+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:43:31.862+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:43:31.861+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:43:32.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.261 seconds
[2024-09-22T00:44:02.398+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:44:02.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:44:02.409+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:44:02.407+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:44:02.444+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:44:02.496+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:44:02.495+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:44:02.523+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:44:02.523+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:44:02.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.163 seconds
[2024-09-22T00:44:32.925+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:44:32.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:44:32.929+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:44:32.928+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:44:32.948+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:44:32.976+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:44:32.975+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:44:32.999+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:44:32.999+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:44:33.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T00:45:03.775+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:45:03.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:45:03.779+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:45:03.779+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:45:03.797+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:45:03.821+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:45:03.820+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:45:03.841+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:45:03.841+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:45:03.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T00:45:34.074+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:45:34.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:45:34.079+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:45:34.079+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:45:34.114+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:45:34.153+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:45:34.153+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:45:34.205+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:45:34.204+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:45:34.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.382 seconds
[2024-09-22T00:46:04.568+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:46:04.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:46:04.572+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:46:04.571+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:46:04.591+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:46:04.616+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:46:04.616+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:46:04.778+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:46:04.778+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:46:04.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.236 seconds
[2024-09-22T00:46:06.105+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:46:06.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:46:06.108+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:46:06.107+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:46:06.132+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:46:06.450+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:46:06.450+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:46:06.467+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:46:06.467+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:46:06.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.390 seconds
[2024-09-22T00:46:32.002+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:46:32.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:46:32.005+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:46:32.005+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:46:32.033+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:46:32.044+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:46:32.043+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:46:32.206+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:46:32.206+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:46:32.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.241 seconds
[2024-09-22T00:47:03.062+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:47:03.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:47:03.065+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:47:03.065+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:47:03.202+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:47:03.224+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:47:03.224+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:47:03.243+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:47:03.243+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:47:03.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.204 seconds
[2024-09-22T00:47:33.961+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:47:33.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:47:33.965+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:47:33.965+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:47:33.982+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:47:34.008+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:47:34.008+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:47:34.032+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:47:34.032+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:47:34.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.099 seconds
[2024-09-22T00:48:04.444+0000] {processor.py:186} INFO - Started process (PID=189) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:48:04.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:48:04.448+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:48:04.447+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:48:04.469+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:48:04.498+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:48:04.498+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:48:04.523+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:48:04.523+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:48:04.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T00:48:34.774+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:48:34.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:48:34.779+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:48:34.779+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:48:34.800+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:48:34.829+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:48:34.829+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:48:34.855+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:48:34.854+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:48:34.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T00:49:05.125+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:49:05.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:49:05.129+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:49:05.128+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:49:05.148+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:49:05.177+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:49:05.176+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:49:05.201+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:49:05.201+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:49:05.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T00:49:35.333+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:49:35.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:49:35.337+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:49:35.337+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:49:35.355+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:49:35.378+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:49:35.378+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:49:35.399+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:49:35.399+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:49:35.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.091 seconds
[2024-09-22T00:50:05.557+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:50:05.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:50:05.561+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:50:05.561+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:50:05.580+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:50:05.607+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:50:05.606+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:50:05.629+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:50:05.629+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:50:05.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T00:50:36.534+0000] {processor.py:186} INFO - Started process (PID=254) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:50:36.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:50:36.537+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:50:36.537+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:50:36.554+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:50:36.577+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:50:36.576+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:50:36.598+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:50:36.598+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:50:36.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T00:51:06.975+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:51:06.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:51:06.979+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:51:06.979+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:51:06.995+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:51:07.017+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:51:07.017+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:51:07.038+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:51:07.038+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:51:07.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T00:51:37.214+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:51:37.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:51:37.218+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:51:37.217+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:51:37.235+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:51:37.263+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:51:37.263+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:51:37.287+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:51:37.287+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:51:37.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T00:52:08.376+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:52:08.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:52:08.382+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:52:08.381+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:52:08.401+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:52:08.432+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:52:08.428+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:52:08.455+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:52:08.455+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:52:08.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T00:52:38.566+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:52:38.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:52:38.570+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:52:38.570+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:52:38.588+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:52:38.613+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:52:38.613+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:52:38.634+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:52:38.634+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:52:38.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T00:53:08.792+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:53:08.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:53:08.796+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:53:08.796+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:53:08.818+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:53:08.857+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:53:08.857+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:53:08.882+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:53:08.882+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:53:08.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T00:53:39.052+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:53:39.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:53:39.055+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:53:39.055+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:53:39.073+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:53:39.096+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:53:39.096+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:53:39.117+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:53:39.117+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:53:39.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.091 seconds
[2024-09-22T00:54:09.207+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:54:09.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:54:09.210+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:54:09.210+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:54:09.230+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:54:09.258+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:54:09.258+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:54:09.285+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:54:09.284+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:54:09.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.176 seconds
[2024-09-22T00:54:39.613+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:54:39.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:54:39.617+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:54:39.617+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:54:39.633+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:54:39.657+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:54:39.656+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:54:39.677+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:54:39.677+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:54:39.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T00:55:10.602+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:55:10.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:55:10.609+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:55:10.609+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:55:10.627+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:55:10.657+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:55:10.657+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:55:10.683+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:55:10.682+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:55:10.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T00:55:41.349+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:55:41.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:55:41.356+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:55:41.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:55:41.371+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:55:41.400+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:55:41.400+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:55:41.429+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:55:41.429+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:55:41.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T00:56:11.581+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:56:11.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:56:11.589+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:56:11.588+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:56:11.612+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:56:11.645+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:56:11.644+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:56:11.678+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:56:11.678+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:56:11.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.135 seconds
[2024-09-22T00:56:41.810+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:56:41.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:56:41.813+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:56:41.813+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:56:41.832+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:56:41.855+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:56:41.855+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:56:41.877+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:56:41.877+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:56:41.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T00:57:12.255+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:57:12.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:57:12.261+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:57:12.261+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:57:12.283+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:57:12.310+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:57:12.309+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:57:12.334+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:57:12.333+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:57:12.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T00:57:42.587+0000] {processor.py:186} INFO - Started process (PID=437) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:57:42.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:57:42.593+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:57:42.592+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:57:42.615+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:57:42.641+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:57:42.641+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:57:42.670+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:57:42.670+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:57:42.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T00:58:12.995+0000] {processor.py:186} INFO - Started process (PID=450) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:58:12.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:58:12.999+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:58:12.998+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:58:13.018+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:58:13.041+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:58:13.041+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:58:13.062+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:58:13.062+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:58:13.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T00:58:43.430+0000] {processor.py:186} INFO - Started process (PID=463) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:58:43.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:58:43.434+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:58:43.434+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:58:43.462+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:58:43.493+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:58:43.492+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:58:43.520+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:58:43.520+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:58:43.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.127 seconds
[2024-09-22T00:59:13.762+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:59:13.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:59:13.766+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:59:13.765+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:59:13.785+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:59:13.819+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:59:13.819+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:59:13.850+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:59:13.850+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:59:13.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T00:59:44.281+0000] {processor.py:186} INFO - Started process (PID=489) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:59:44.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T00:59:44.286+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:59:44.286+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:59:44.302+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T00:59:44.331+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:59:44.331+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T00:59:44.353+0000] {logging_mixin.py:190} INFO - [2024-09-22T00:59:44.353+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T00:59:44.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T01:00:14.555+0000] {processor.py:186} INFO - Started process (PID=502) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:00:14.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:00:14.560+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:00:14.559+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:00:14.575+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:00:14.598+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:00:14.598+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:00:14.620+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:00:14.620+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T01:00:14.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T01:00:45.169+0000] {processor.py:186} INFO - Started process (PID=515) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:00:45.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:00:45.173+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:00:45.172+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:00:45.192+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:00:45.219+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:00:45.218+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:00:45.241+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:00:45.241+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T01:00:45.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.099 seconds
[2024-09-22T01:01:15.333+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:01:15.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:01:15.339+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:01:15.339+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:01:15.357+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:01:15.382+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:01:15.382+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:01:15.409+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:01:15.409+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T01:01:15.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T01:01:45.699+0000] {processor.py:186} INFO - Started process (PID=541) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:01:45.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:01:45.706+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:01:45.705+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:01:45.727+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:01:45.753+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:01:45.752+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:01:45.779+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:01:45.779+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T01:01:45.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T01:02:16.144+0000] {processor.py:186} INFO - Started process (PID=554) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:02:16.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:02:16.148+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:02:16.147+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:02:16.168+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:02:16.203+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:02:16.203+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:02:16.228+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:02:16.228+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T01:02:16.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.126 seconds
[2024-09-22T01:02:46.416+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:02:46.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:02:46.418+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:02:46.417+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:02:46.434+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:02:46.458+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:02:46.458+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:02:46.480+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:02:46.480+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T01:02:46.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T01:03:16.742+0000] {processor.py:186} INFO - Started process (PID=580) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:03:16.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:03:16.746+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:03:16.745+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:03:16.766+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:03:16.789+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:03:16.789+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:03:16.816+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:03:16.816+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T01:03:16.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T01:03:46.930+0000] {processor.py:186} INFO - Started process (PID=593) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:03:46.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:03:46.934+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:03:46.933+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:03:46.951+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:03:46.974+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:03:46.974+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:03:46.997+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:03:46.996+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T01:03:47.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T01:04:17.258+0000] {processor.py:186} INFO - Started process (PID=606) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:04:17.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:04:17.263+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:04:17.263+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:04:17.286+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:04:17.310+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:04:17.310+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:04:17.332+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:04:17.332+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T01:04:17.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T01:04:29.695+0000] {processor.py:186} INFO - Started process (PID=610) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:04:29.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:04:29.698+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:04:29.698+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:04:29.721+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:04:29.716+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 37, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:04:29.722+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:04:29.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.057 seconds
[2024-09-22T01:04:40.188+0000] {processor.py:186} INFO - Started process (PID=618) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:04:40.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:04:40.192+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:04:40.191+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:04:40.216+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:04:40.211+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:04:40.218+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:04:40.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.057 seconds
[2024-09-22T01:05:10.294+0000] {processor.py:186} INFO - Started process (PID=631) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:05:10.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:05:10.297+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:05:10.297+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:05:10.312+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:05:10.307+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:05:10.313+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:05:10.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T01:06:31.085+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:06:31.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:06:31.089+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:06:31.088+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:06:31.105+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:06:31.100+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:06:31.106+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:06:31.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.066 seconds
[2024-09-22T01:07:01.360+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:07:01.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:07:01.365+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:07:01.364+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:07:01.384+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:07:01.378+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:07:01.385+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:07:01.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.063 seconds
[2024-09-22T01:07:32.061+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:07:32.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:07:32.064+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:07:32.064+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:07:32.087+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:07:32.080+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:07:32.088+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:07:32.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.052 seconds
[2024-09-22T01:08:02.707+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:08:02.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:08:02.711+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:08:02.711+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:08:02.725+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:08:02.722+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:08:02.726+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:08:02.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T01:08:33.278+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:08:33.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:08:33.281+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:08:33.281+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:08:33.300+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:08:33.295+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:08:33.301+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:08:33.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T01:08:52.139+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:08:52.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:08:52.142+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:08:52.142+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:08:52.165+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:08:52.160+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://842f55c7b74e:7077'}
[2024-09-22T01:08:52.166+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:08:52.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.054 seconds
[2024-09-22T01:09:22.551+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:09:22.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:09:22.555+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:09:22.554+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:09:22.571+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:09:22.567+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://842f55c7b74e:7077'}
[2024-09-22T01:09:22.572+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:09:22.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T01:09:53.385+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:09:53.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:09:53.388+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:09:53.388+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:09:53.406+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:09:53.401+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://842f55c7b74e:7077'}
[2024-09-22T01:09:53.408+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:09:53.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.051 seconds
[2024-09-22T01:11:57.274+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:11:57.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:11:57.278+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:11:57.277+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:11:57.293+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:11:57.288+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://842f55c7b74e:7077'}
[2024-09-22T01:11:57.295+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:11:57.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.051 seconds
[2024-09-22T01:12:27.621+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:12:27.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:12:27.626+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:12:27.625+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:12:27.644+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:12:27.638+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://842f55c7b74e:7077'}
[2024-09-22T01:12:27.645+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:12:27.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T01:12:57.742+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:12:57.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:12:57.745+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:12:57.745+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:12:57.769+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:12:57.760+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://842f55c7b74e:7077'}
[2024-09-22T01:12:57.770+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:12:57.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.057 seconds
[2024-09-22T01:12:57.842+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:12:57.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:12:57.845+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:12:57.845+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:12:57.869+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:12:57.864+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://842f55c7b74e:7077'}
[2024-09-22T01:12:57.869+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:12:57.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.056 seconds
[2024-09-22T01:13:09.635+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:13:09.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:13:09.638+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:13:09.638+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:13:09.663+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:13:09.658+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:13:09.664+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:13:09.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.055 seconds
[2024-09-22T01:14:10.020+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:14:10.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:14:10.024+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:14:10.023+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:14:10.039+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:14:10.034+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:14:10.040+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:14:10.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.085 seconds
[2024-09-22T01:14:40.329+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:14:40.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:14:40.334+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:14:40.333+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:14:40.351+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:14:40.346+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:14:40.352+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:14:40.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T01:15:10.605+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:15:10.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:15:10.611+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:15:10.610+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:15:10.629+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:15:10.625+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:15:10.630+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:15:10.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T01:15:15.827+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:15:15.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:15:15.830+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:15:15.830+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:15:15.854+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:15:15.850+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:15:15.855+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:15:16.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.180 seconds
[2024-09-22T01:16:34.281+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:16:34.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:16:34.285+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:16:34.284+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:16:34.300+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:16:34.296+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:16:34.301+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:16:34.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T01:17:04.445+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:17:04.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:17:04.448+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:17:04.448+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:17:04.464+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:17:04.460+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:17:04.465+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:17:04.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T01:17:34.995+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:17:34.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:17:35.003+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:17:35.002+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:17:35.021+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:17:35.017+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:17:35.022+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:17:35.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.053 seconds
[2024-09-22T01:18:05.444+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:18:05.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:18:05.449+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:18:05.449+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:18:05.466+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:18:05.460+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:18:05.467+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:18:05.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.055 seconds
[2024-09-22T01:18:35.739+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:18:35.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:18:35.742+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:18:35.742+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:18:35.758+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:18:35.754+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:18:35.759+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:18:35.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.053 seconds
[2024-09-22T01:19:06.075+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:19:06.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:19:06.078+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:19:06.078+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:19:06.093+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:19:06.089+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 31, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'local'}
[2024-09-22T01:19:06.094+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:19:06.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T01:19:10.160+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:19:10.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:19:10.164+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:19:10.164+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:19:10.196+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:19:10.401+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:19:10.401+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:19:10.414+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:19:10.414+0000] {dag.py:3252} INFO - Creating ORM DAG for spark_example_dag
[2024-09-22T01:19:10.424+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:19:10.424+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:19:10.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.296 seconds
[2024-09-22T01:19:15.289+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:19:15.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:19:15.292+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:19:15.291+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:19:15.325+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:19:15.336+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:19:15.336+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:19:15.361+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:19:15.361+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:19:15.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T01:20:29.992+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:20:29.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:20:29.997+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:20:29.996+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:20:30.043+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:20:30.092+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:20:30.092+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:20:30.123+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:20:30.123+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:20:30.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.162 seconds
[2024-09-22T01:21:00.539+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:21:00.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:21:00.542+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:21:00.542+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:21:00.560+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:21:00.589+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:21:00.589+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:21:00.617+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:21:00.617+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:21:00.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T01:21:30.825+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:21:30.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:21:30.832+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:21:30.831+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:21:30.854+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:21:30.877+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:21:30.877+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:21:30.903+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:21:30.903+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:21:30.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.125 seconds
[2024-09-22T01:22:01.439+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:22:01.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:22:01.442+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:22:01.441+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:22:01.463+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:22:01.495+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:22:01.495+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:22:01.521+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:22:01.521+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:22:01.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T01:22:32.073+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:22:32.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:22:32.078+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:22:32.078+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:22:32.097+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:22:32.124+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:22:32.120+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:22:32.154+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:22:32.154+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:22:32.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.164 seconds
[2024-09-22T01:23:02.405+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:23:02.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:23:02.412+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:23:02.411+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:23:02.431+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:23:02.460+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:23:02.460+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:23:02.485+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:23:02.485+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:23:02.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.272 seconds
[2024-09-22T01:23:33.556+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:23:33.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:23:33.560+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:23:33.560+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:23:33.582+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:23:33.606+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:23:33.605+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:23:33.764+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:23:33.764+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:23:33.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.239 seconds
[2024-09-22T01:24:03.891+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:24:03.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:24:03.895+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:24:03.894+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:24:03.914+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:24:04.073+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:24:04.073+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:24:04.095+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:24:04.094+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:24:04.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.229 seconds
[2024-09-22T01:24:34.273+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:24:34.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:24:34.413+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:24:34.413+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:24:34.434+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:24:34.455+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:24:34.454+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:24:34.476+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:24:34.476+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:24:34.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.228 seconds
[2024-09-22T01:25:04.651+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:25:04.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:25:04.655+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:25:04.655+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:25:04.676+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:25:04.699+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:25:04.699+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:25:04.721+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:25:04.721+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:25:04.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T01:25:34.903+0000] {processor.py:186} INFO - Started process (PID=189) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:25:34.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:25:34.906+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:25:34.906+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:25:34.926+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:25:34.950+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:25:34.950+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:25:34.990+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:25:34.990+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:25:35.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T01:25:37.079+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:25:37.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:25:37.082+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:25:37.082+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:25:37.112+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:25:37.328+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:25:37.328+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:25:37.349+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:25:37.349+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:25:37.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.300 seconds
[2024-09-22T01:27:18.578+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:27:18.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:27:18.581+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:27:18.581+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:27:18.615+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:27:18.651+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:27:18.650+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:27:18.693+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:27:18.692+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:27:18.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.317 seconds
[2024-09-22T01:27:49.056+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:27:49.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:27:49.061+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:27:49.060+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:27:49.094+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:27:49.142+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:27:49.141+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:27:49.349+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:27:49.348+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:27:49.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.356 seconds
[2024-09-22T01:28:19.928+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:28:19.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:28:19.934+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:28:19.933+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:28:19.966+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:28:20.128+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:28:20.127+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:28:20.148+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:28:20.148+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:28:20.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.246 seconds
[2024-09-22T01:28:50.522+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:28:50.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:28:50.525+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:28:50.525+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:28:50.547+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:28:50.572+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:28:50.572+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:28:50.597+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:28:50.597+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:28:50.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T01:29:20.813+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:29:20.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:29:20.817+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:29:20.816+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:29:20.845+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:29:20.869+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:29:20.869+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:29:20.894+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:29:20.894+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:29:20.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T01:29:51.218+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:29:51.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:29:51.228+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:29:51.227+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:29:51.269+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:29:51.293+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:29:51.293+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:29:51.319+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:29:51.319+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:29:51.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.131 seconds
[2024-09-22T01:30:21.562+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:30:21.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:30:21.565+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:30:21.564+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:30:21.591+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:30:21.616+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:30:21.616+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:30:21.640+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:30:21.640+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:30:21.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T01:30:51.931+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:30:51.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:30:51.935+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:30:51.934+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:30:51.961+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:30:51.985+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:30:51.985+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:30:52.008+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:30:52.008+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:30:52.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T01:31:22.352+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:31:22.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:31:22.355+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:31:22.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:31:22.380+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:31:22.403+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:31:22.403+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:31:22.426+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:31:22.426+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:31:22.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T01:31:52.560+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:31:52.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:31:52.564+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:31:52.563+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:31:52.589+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:31:52.613+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:31:52.613+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:31:52.637+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:31:52.636+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:31:52.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T01:32:22.942+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:32:22.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:32:22.948+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:32:22.947+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:32:22.983+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:32:23.008+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:32:23.008+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:32:23.032+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:32:23.032+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:32:23.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.121 seconds
[2024-09-22T01:32:53.092+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:32:53.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:32:53.096+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:32:53.096+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:32:53.120+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:32:53.146+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:32:53.145+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:32:53.171+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:32:53.171+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:32:53.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T01:33:23.278+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:33:23.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:33:23.281+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:33:23.281+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:33:23.307+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:33:23.331+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:33:23.331+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:33:23.355+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:33:23.355+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:33:23.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T01:33:53.517+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:33:53.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:33:53.520+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:33:53.519+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:33:53.544+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:33:53.571+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:33:53.570+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:33:53.601+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:33:53.601+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:33:53.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T01:34:23.854+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:34:23.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:34:23.857+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:34:23.857+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:34:23.882+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:34:23.906+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:34:23.906+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:34:23.930+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:34:23.930+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:34:23.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T01:34:52.696+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:34:52.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:34:52.699+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:34:52.699+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:34:52.737+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:34:52.860+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:34:52.860+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:34:52.882+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:34:52.882+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:34:52.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.217 seconds
[2024-09-22T01:35:55.144+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:35:55.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:35:55.147+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:35:55.147+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:35:55.174+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:35:55.206+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:35:55.206+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:35:55.233+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:35:55.232+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:35:55.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.292 seconds
[2024-09-22T01:36:25.496+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:36:25.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:36:25.499+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:36:25.499+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:36:25.529+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:36:25.556+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:36:25.556+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:36:25.726+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:36:25.726+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:36:25.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.254 seconds
[2024-09-22T01:36:55.801+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:36:55.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:36:55.806+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:36:55.806+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:36:55.837+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:36:55.984+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:36:55.984+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:36:56.005+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:36:56.005+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:36:56.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.227 seconds
[2024-09-22T01:37:26.388+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:37:26.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:37:26.391+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:37:26.391+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:37:26.417+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:37:26.441+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:37:26.441+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:37:26.466+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:37:26.466+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:37:26.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T01:37:56.555+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:37:56.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:37:56.558+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:37:56.557+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:37:56.586+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:37:56.611+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:37:56.611+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:37:56.635+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:37:56.635+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:37:56.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T01:38:26.759+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:38:26.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:38:26.762+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:38:26.762+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:38:26.787+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:38:26.813+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:38:26.813+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:38:26.839+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:38:26.839+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:38:26.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T01:38:57.132+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:38:57.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:38:57.136+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:38:57.136+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:38:57.164+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:38:57.189+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:38:57.188+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:38:57.212+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:38:57.212+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:38:57.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T01:39:27.942+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:39:27.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:39:27.948+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:39:27.947+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:39:27.976+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:39:28.001+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:39:28.001+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:39:28.028+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:39:28.028+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:39:28.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T01:39:58.772+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:39:58.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:39:58.779+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:39:58.779+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:39:58.806+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:39:58.832+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:39:58.832+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:39:58.857+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:39:58.857+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:39:58.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T01:40:28.963+0000] {processor.py:186} INFO - Started process (PID=175) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:40:28.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:40:28.966+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:40:28.966+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:40:28.992+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:40:29.016+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:40:29.016+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:40:29.040+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:40:29.040+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:40:29.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T01:40:59.506+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:40:59.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:40:59.510+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:40:59.509+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:40:59.538+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:40:59.566+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:40:59.566+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:40:59.621+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:40:59.621+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:40:59.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.166 seconds
[2024-09-22T01:41:29.898+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:41:29.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:41:29.902+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:41:29.902+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:41:29.935+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:41:29.961+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:41:29.960+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:41:29.985+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:41:29.985+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:41:30.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T01:42:00.866+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:42:00.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:42:00.871+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:42:00.870+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:42:00.897+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:42:00.923+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:42:00.923+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:42:00.947+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:42:00.947+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:42:00.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T01:42:31.834+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:42:31.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:42:31.837+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:42:31.837+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:42:31.867+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:42:31.891+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:42:31.891+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:42:31.916+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:42:31.916+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:42:31.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T01:43:02.849+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:43:02.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:43:02.852+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:43:02.852+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:43:02.876+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:43:02.900+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:43:02.900+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:43:02.923+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:43:02.923+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:43:02.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T01:43:33.001+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:43:33.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:43:33.005+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:43:33.005+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:43:33.037+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:43:33.067+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:43:33.066+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:43:33.096+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:43:33.095+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:43:33.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.126 seconds
[2024-09-22T01:44:03.158+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:44:03.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:44:03.161+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:44:03.161+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:44:03.190+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:44:03.215+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:44:03.215+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:44:03.241+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:44:03.241+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:44:03.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T01:44:34.027+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:44:34.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:44:34.031+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:44:34.031+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:44:34.063+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:44:34.091+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:44:34.091+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:44:34.123+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:44:34.123+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:44:34.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.125 seconds
[2024-09-22T01:45:04.279+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:45:04.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:45:04.282+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:45:04.282+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:45:04.308+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:45:04.332+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:45:04.332+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:45:04.355+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:45:04.355+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:45:04.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T01:45:35.292+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:45:35.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:45:35.297+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:45:35.297+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:45:35.336+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:45:35.401+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:45:35.401+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:45:35.460+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:45:35.460+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:45:35.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.222 seconds
[2024-09-22T01:46:05.755+0000] {processor.py:186} INFO - Started process (PID=318) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:46:05.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:46:05.758+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:46:05.758+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:46:05.786+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:46:05.811+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:46:05.810+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:46:05.834+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:46:05.834+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:46:05.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T01:46:36.210+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:46:36.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:46:36.214+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:46:36.214+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:46:36.239+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:46:36.262+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:46:36.262+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:46:36.285+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:46:36.285+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:46:36.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T01:47:06.529+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:47:06.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:47:06.534+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:47:06.533+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:47:06.564+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:47:06.591+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:47:06.591+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:47:06.616+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:47:06.615+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:47:06.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T01:47:36.767+0000] {processor.py:186} INFO - Started process (PID=357) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:47:36.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:47:36.770+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:47:36.770+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:47:36.798+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:47:36.821+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:47:36.821+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:47:36.845+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:47:36.844+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:47:36.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T01:48:06.941+0000] {processor.py:186} INFO - Started process (PID=370) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:48:06.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:48:06.944+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:48:06.944+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:48:06.968+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:48:06.993+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:48:06.992+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:48:07.016+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:48:07.016+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:48:07.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T01:48:37.200+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:48:37.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:48:37.203+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:48:37.203+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:48:37.229+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:48:37.255+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:48:37.255+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:48:37.278+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:48:37.278+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:48:37.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T01:49:07.430+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:49:07.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T01:49:07.434+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:49:07.434+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:49:07.459+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T01:49:07.483+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:49:07.483+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T01:49:07.507+0000] {logging_mixin.py:190} INFO - [2024-09-22T01:49:07.507+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T01:49:07.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T12:24:04.363+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:24:04.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:24:04.371+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:24:04.370+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:24:04.401+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:24:04.441+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:24:04.441+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:24:04.479+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:24:04.479+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:24:04.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.309 seconds
[2024-09-22T12:24:34.863+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:24:34.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:24:34.869+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:24:34.869+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:24:34.901+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:24:34.936+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:24:34.935+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:24:35.135+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:24:35.135+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:24:35.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.311 seconds
[2024-09-22T12:25:05.370+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:25:05.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:25:05.390+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:25:05.389+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:25:05.446+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:25:05.970+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:25:05.969+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:25:06.041+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:25:06.040+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:25:06.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.764 seconds
[2024-09-22T12:25:36.632+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:25:36.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:25:36.638+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:25:36.637+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:25:36.669+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:25:36.697+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:25:36.697+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:25:36.720+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:25:36.720+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:25:36.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.122 seconds
[2024-09-22T12:26:07.150+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:26:07.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:26:07.153+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:26:07.153+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:26:07.179+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:26:07.202+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:26:07.202+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:26:07.225+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:26:07.225+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:26:07.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T12:26:37.462+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:26:37.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:26:37.465+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:26:37.465+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:26:37.498+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:26:37.527+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:26:37.527+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:26:37.557+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:26:37.556+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:26:37.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.126 seconds
[2024-09-22T12:27:07.752+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:27:07.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:27:07.756+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:27:07.755+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:27:07.793+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:27:07.820+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:27:07.819+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:27:07.844+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:27:07.844+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:27:07.866+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T12:27:38.193+0000] {processor.py:186} INFO - Started process (PID=142) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:27:38.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:27:38.198+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:27:38.197+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:27:38.230+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:27:38.257+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:27:38.256+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:27:38.282+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:27:38.282+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:27:38.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T12:28:08.497+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:28:08.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:28:08.500+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:28:08.500+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:28:08.534+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:28:08.558+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:28:08.558+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:28:08.584+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:28:08.584+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:28:08.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T12:28:38.699+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:28:38.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:28:38.702+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:28:38.702+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:28:38.729+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:28:38.752+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:28:38.752+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:28:38.777+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:28:38.777+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:28:38.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T12:29:08.885+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:29:08.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:29:08.888+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:29:08.888+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:29:08.914+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:29:08.937+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:29:08.937+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:29:08.963+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:29:08.962+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:29:08.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T12:29:39.886+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:29:39.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:29:39.890+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:29:39.890+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:29:39.919+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:29:39.943+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:29:39.943+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:29:39.967+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:29:39.967+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:29:39.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T12:30:10.159+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:30:10.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:30:10.162+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:30:10.162+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:30:10.187+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:30:10.211+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:30:10.211+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:30:10.237+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:30:10.236+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:30:10.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T12:30:40.408+0000] {processor.py:186} INFO - Started process (PID=222) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:30:40.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:30:40.411+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:30:40.410+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:30:40.433+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:30:40.455+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:30:40.455+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:30:40.477+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:30:40.477+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:30:40.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T12:31:10.560+0000] {processor.py:186} INFO - Started process (PID=234) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:31:10.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:31:10.564+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:31:10.563+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:31:10.593+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:31:10.620+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:31:10.620+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:31:10.649+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:31:10.648+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:31:10.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T12:31:40.720+0000] {processor.py:186} INFO - Started process (PID=247) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:31:40.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:31:40.724+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:31:40.723+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:31:40.751+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:31:40.776+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:31:40.776+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:31:40.801+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:31:40.801+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:31:40.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T12:32:10.939+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:32:10.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:32:10.943+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:32:10.943+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:32:10.970+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:32:10.995+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:32:10.995+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:32:11.019+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:32:11.018+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:32:11.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T12:32:41.101+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:32:41.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:32:41.104+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:32:41.104+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:32:41.137+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:32:41.161+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:32:41.161+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:32:41.183+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:32:41.183+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:32:41.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T12:33:11.387+0000] {processor.py:186} INFO - Started process (PID=286) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:33:11.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:33:11.391+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:33:11.390+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:33:11.415+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:33:11.438+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:33:11.438+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:33:11.462+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:33:11.462+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:33:11.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T12:33:41.721+0000] {processor.py:186} INFO - Started process (PID=299) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:33:41.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:33:41.724+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:33:41.723+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:33:41.751+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:33:41.774+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:33:41.774+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:33:41.798+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:33:41.797+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:33:41.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T12:34:11.981+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:34:11.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:34:11.984+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:34:11.984+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:34:12.010+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:34:12.036+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:34:12.036+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:34:12.062+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:34:12.062+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:34:12.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T12:34:42.444+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:34:42.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:34:42.447+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:34:42.447+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:34:42.472+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:34:42.494+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:34:42.494+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:34:42.517+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:34:42.517+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:34:42.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T12:35:12.896+0000] {processor.py:186} INFO - Started process (PID=339) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:35:12.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:35:12.900+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:35:12.899+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:35:12.924+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:35:12.947+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:35:12.947+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:35:12.973+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:35:12.972+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:35:12.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T12:35:43.151+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:35:43.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:35:43.154+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:35:43.154+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:35:43.179+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:35:43.202+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:35:43.202+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:35:43.225+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:35:43.225+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:35:43.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T12:36:13.540+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:36:13.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:36:13.544+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:36:13.544+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:36:13.570+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:36:13.599+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:36:13.598+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:36:13.625+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:36:13.624+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:36:13.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T12:36:44.502+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:36:44.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:36:44.505+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:36:44.505+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:36:44.531+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:36:44.554+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:36:44.554+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:36:44.576+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:36:44.576+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:36:44.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T12:37:15.514+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:37:15.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:37:15.518+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:37:15.517+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:37:15.543+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:37:15.567+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:37:15.567+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:37:15.590+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:37:15.590+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:37:15.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T12:37:45.693+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:37:45.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:37:45.696+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:37:45.696+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:37:45.723+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:37:45.749+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:37:45.748+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:37:45.773+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:37:45.772+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:37:45.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T12:38:15.899+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:38:15.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:38:15.902+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:38:15.902+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:38:15.927+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:38:15.950+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:38:15.950+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:38:15.974+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:38:15.973+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:38:15.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T12:38:46.851+0000] {processor.py:186} INFO - Started process (PID=430) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:38:46.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:38:46.855+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:38:46.855+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:38:46.881+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:38:46.904+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:38:46.904+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:38:46.927+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:38:46.927+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:38:46.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T12:39:17.122+0000] {processor.py:186} INFO - Started process (PID=443) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:39:17.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:39:17.125+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:39:17.125+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:39:17.150+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:39:17.174+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:39:17.174+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:39:17.197+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:39:17.197+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:39:17.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T12:39:47.446+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:39:47.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:39:47.449+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:39:47.448+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:39:47.472+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:39:47.496+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:39:47.495+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:39:47.518+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:39:47.518+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:39:47.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T12:39:50.663+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:39:50.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:39:50.666+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:39:50.665+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:39:50.698+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:39:50.836+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:39:50.836+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:39:50.857+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:39:50.856+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:39:50.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.220 seconds
[2024-09-22T12:40:01.027+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:40:01.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:40:01.030+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:40:01.030+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:40:01.062+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:40:01.073+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:40:01.073+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:40:01.098+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:40:01.097+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:40:01.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T12:40:09.597+0000] {processor.py:186} INFO - Started process (PID=471) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:40:09.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:40:09.601+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:40:09.600+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:40:09.633+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:40:09.643+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:40:09.642+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:40:09.665+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:40:09.665+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:40:09.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T12:41:08.884+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:41:08.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:41:08.888+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:41:08.888+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:41:08.918+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:41:08.960+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:41:08.959+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:41:08.990+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:41:08.990+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:41:09.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.352 seconds
[2024-09-22T12:41:39.622+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:41:39.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:41:39.625+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:41:39.625+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:41:39.651+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:41:39.676+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:41:39.676+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:41:39.819+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:41:39.819+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:41:39.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.227 seconds
[2024-09-22T12:42:10.109+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:42:10.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:42:10.114+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:42:10.114+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:42:10.137+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:42:10.282+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:42:10.282+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:42:10.304+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:42:10.304+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:42:10.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.222 seconds
[2024-09-22T12:42:40.500+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:42:40.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:42:40.503+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:42:40.503+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:42:40.526+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:42:40.549+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:42:40.549+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:42:40.572+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:42:40.571+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:42:40.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T12:43:10.762+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:43:10.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:43:10.765+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:43:10.765+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:43:10.792+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:43:10.815+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:43:10.815+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:43:10.838+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:43:10.838+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:43:10.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T12:43:40.943+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:43:40.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:43:40.945+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:43:40.945+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:43:40.972+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:43:40.995+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:43:40.995+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:43:41.018+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:43:41.018+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:43:41.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T12:44:11.294+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:11.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:44:11.297+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:11.297+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:11.324+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:11.347+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:11.346+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:44:11.371+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:11.371+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:44:11.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T12:44:40.060+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:40.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:44:40.064+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:40.063+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:40.095+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:40.206+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:40.205+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:44:40.226+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:40.226+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:44:40.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.195 seconds
[2024-09-22T12:44:42.113+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:42.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:44:42.116+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:42.116+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:42.148+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:42.159+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:42.159+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:44:42.184+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:42.184+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:44:42.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T12:44:47.033+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:47.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:44:47.036+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:47.036+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:47.052+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:44:47.050+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 45
    application='/opt/***/dags/my_spark_app.py',  # Caminho do seu script Spark
                                                                               ^
IndentationError: unindent does not match any outer indentation level
[2024-09-22T12:44:47.052+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:44:47.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T12:45:08.359+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:45:08.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:45:08.364+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:45:08.363+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:45:08.398+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:45:08.408+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:45:08.408+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:45:08.435+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:45:08.435+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:45:08.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T12:45:17.185+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:45:17.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:45:17.188+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:45:17.188+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:45:17.219+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:45:17.330+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:45:17.330+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:45:17.352+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:45:17.352+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:45:17.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.200 seconds
[2024-09-22T12:45:47.539+0000] {processor.py:186} INFO - Started process (PID=170) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:45:47.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:45:47.542+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:45:47.542+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:45:47.570+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:45:47.594+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:45:47.594+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:45:47.618+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:45:47.618+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:45:47.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T12:46:18.484+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:46:18.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:46:18.487+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:46:18.487+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:46:18.514+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:46:18.538+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:46:18.538+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:46:18.563+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:46:18.563+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:46:18.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T12:46:49.443+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:46:49.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:46:49.446+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:46:49.445+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:46:49.475+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:46:49.502+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:46:49.502+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:46:49.528+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:46:49.527+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:46:49.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T12:47:19.773+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:47:19.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:47:19.776+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:47:19.776+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:47:19.801+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:47:19.824+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:47:19.823+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:47:19.847+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:47:19.847+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:47:19.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T12:47:49.909+0000] {processor.py:186} INFO - Started process (PID=222) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:47:49.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:47:49.913+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:47:49.912+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:47:49.940+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:47:49.967+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:47:49.966+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:47:49.992+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:47:49.992+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:47:50.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T12:48:20.575+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:48:20.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:48:20.579+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:48:20.578+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:48:20.603+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:48:20.626+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:48:20.626+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:48:20.648+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:48:20.648+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T12:48:20.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T12:48:44.054+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:48:44.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:48:44.057+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:48:44.056+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:48:44.086+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:48:44.190+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:48:44.190+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:48:44.202+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:48:44.202+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:48:44.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.179 seconds
[2024-09-22T12:48:50.538+0000] {processor.py:186} INFO - Started process (PID=249) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:48:50.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:48:50.542+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:48:50.542+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:48:50.572+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:48:50.583+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:48:50.583+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:48:50.597+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:48:50.597+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:48:50.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T12:50:04.465+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:50:04.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:50:04.475+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:50:04.474+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:50:04.503+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:50:04.786+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:50:04.786+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:50:04.800+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:50:04.800+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:50:04.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.371 seconds
[2024-09-22T12:50:34.959+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:50:34.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:50:34.963+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:50:34.962+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:50:34.992+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:50:35.023+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:50:35.022+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:50:35.218+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:50:35.218+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:50:35.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.289 seconds
[2024-09-22T12:51:05.514+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:51:05.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:51:05.520+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:51:05.519+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:51:05.542+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:51:05.688+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:51:05.688+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:51:05.700+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:51:05.699+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:51:05.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.210 seconds
[2024-09-22T12:51:36.163+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:51:36.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:51:36.167+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:51:36.167+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:51:36.188+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:51:36.211+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:51:36.211+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:51:36.225+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:51:36.224+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:51:36.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T12:52:06.405+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:52:06.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:52:06.408+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:52:06.408+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:52:06.433+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:52:06.459+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:52:06.459+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:52:06.476+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:52:06.476+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:52:06.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T12:52:36.957+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:52:36.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:52:36.961+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:52:36.960+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:52:36.986+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:52:37.009+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:52:37.009+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:52:37.023+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:52:37.023+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:52:37.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.093 seconds
[2024-09-22T12:53:07.179+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:53:07.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:53:07.182+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:53:07.181+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:53:07.206+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:53:07.229+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:53:07.229+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:53:07.242+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:53:07.242+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:53:07.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T12:53:38.120+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:53:38.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:53:38.124+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:53:38.124+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:53:38.149+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:53:38.174+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:53:38.174+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:53:38.187+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:53:38.187+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:53:38.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.093 seconds
[2024-09-22T12:54:09.027+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:54:09.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:54:09.030+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:54:09.030+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:54:09.055+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:54:09.080+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:54:09.079+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:54:09.094+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:54:09.094+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:54:09.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T12:54:39.268+0000] {processor.py:186} INFO - Started process (PID=170) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:54:39.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:54:39.273+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:54:39.272+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:54:39.303+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:54:39.328+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:54:39.328+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:54:39.342+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:54:39.341+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:54:39.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T12:54:49.089+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:54:49.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:54:49.092+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:54:49.092+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:54:49.121+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:54:49.232+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:54:49.232+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:54:49.245+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:54:49.245+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:54:49.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.188 seconds
[2024-09-22T12:56:02.793+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:56:02.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:56:02.796+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:56:02.796+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:56:02.832+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:56:02.882+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:56:02.882+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:56:02.899+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:56:02.899+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:56:02.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.143 seconds
[2024-09-22T12:56:32.984+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:56:32.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:56:32.987+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:56:32.987+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:56:33.008+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:56:33.032+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:56:33.032+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:56:33.156+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:56:33.156+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:56:33.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.198 seconds
[2024-09-22T12:57:03.441+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:57:03.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:57:03.447+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:57:03.447+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:57:03.469+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:57:03.616+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:57:03.616+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:57:03.627+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:57:03.627+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:57:03.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.211 seconds
[2024-09-22T12:57:34.009+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:57:34.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:57:34.013+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:57:34.013+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:57:34.037+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:57:34.063+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:57:34.062+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:57:34.078+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:57:34.077+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:57:34.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T12:57:59.958+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:57:59.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:57:59.961+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:57:59.961+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:57:59.987+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:57:59.979+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 9, in <module>
    default_args=default_args,
                 ^^^^^^^^^^^^
NameError: name 'default_args' is not defined
[2024-09-22T12:57:59.992+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:00.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.060 seconds
[2024-09-22T12:58:06.328+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:06.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:58:06.332+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:58:06.332+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:06.354+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:58:06.347+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 10, in <module>
    default_args=default_args,
                 ^^^^^^^^^^^^
NameError: name 'default_args' is not defined
[2024-09-22T12:58:06.359+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:06.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.055 seconds
[2024-09-22T12:58:23.789+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:23.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:58:23.793+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:58:23.792+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:23.816+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:58:23.809+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 10, in <module>
    default_args=default_args,
                 ^^^^^^^^^^^^
NameError: name 'default_args' is not defined
[2024-09-22T12:58:23.822+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:23.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.059 seconds
[2024-09-22T12:58:38.274+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:38.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:58:38.278+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:58:38.278+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:38.313+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:38.427+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:58:38.427+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:58:38.439+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:58:38.439+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:58:38.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.197 seconds
[2024-09-22T12:58:56.894+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:56.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:58:56.897+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:58:56.896+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:56.925+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:58:56.935+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:58:56.935+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:58:56.950+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:58:56.950+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:58:56.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.085 seconds
[2024-09-22T12:59:58.793+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:59:58.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T12:59:58.800+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:59:58.799+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:59:58.827+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T12:59:58.860+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:59:58.859+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T12:59:58.875+0000] {logging_mixin.py:190} INFO - [2024-09-22T12:59:58.875+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T12:59:58.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T13:00:29.183+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:00:29.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:00:29.186+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:00:29.185+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:00:29.207+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:00:29.231+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:00:29.231+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:00:29.364+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:00:29.363+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:00:29.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.206 seconds
[2024-09-22T13:00:59.558+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:00:59.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:00:59.564+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:00:59.563+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:00:59.587+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:00:59.748+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:00:59.748+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:00:59.762+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:00:59.762+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:00:59.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.236 seconds
[2024-09-22T13:01:30.016+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:01:30.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:01:30.019+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:01:30.019+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:01:30.042+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:01:30.065+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:01:30.064+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:01:30.079+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:01:30.079+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:01:30.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.090 seconds
[2024-09-22T13:02:00.280+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:02:00.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:02:00.284+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:02:00.283+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:02:00.306+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:02:00.329+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:02:00.329+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:02:00.343+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:02:00.342+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:02:00.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.090 seconds
[2024-09-22T13:02:30.506+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:02:30.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:02:30.509+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:02:30.509+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:02:30.533+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:02:30.557+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:02:30.557+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:02:30.572+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:02:30.571+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:02:30.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.091 seconds
[2024-09-22T13:03:00.717+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:03:00.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:03:00.720+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:03:00.720+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:03:00.743+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:03:00.767+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:03:00.766+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:03:00.782+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:03:00.781+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:03:00.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.091 seconds
[2024-09-22T13:03:30.908+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:03:30.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:03:30.912+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:03:30.911+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:03:30.936+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:03:30.960+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:03:30.960+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:03:30.975+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:03:30.975+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:03:30.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.093 seconds
[2024-09-22T13:04:01.160+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:04:01.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:04:01.164+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:04:01.164+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:04:01.187+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:04:01.210+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:04:01.210+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:04:01.225+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:04:01.225+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:04:01.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.090 seconds
[2024-09-22T13:04:31.329+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:04:31.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:04:31.333+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:04:31.333+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:04:31.356+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:04:31.379+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:04:31.378+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:04:31.393+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:04:31.392+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:04:31.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T13:05:01.570+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:05:01.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:05:01.576+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:05:01.575+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:05:01.599+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:05:01.623+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:05:01.623+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:05:01.637+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:05:01.637+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:05:01.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T13:05:31.813+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:05:31.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:05:31.816+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:05:31.816+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:05:31.837+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:05:31.860+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:05:31.860+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:05:31.875+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:05:31.875+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:05:31.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.089 seconds
[2024-09-22T13:06:01.944+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:06:01.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:06:01.947+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:06:01.947+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:06:01.970+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:06:01.994+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:06:01.993+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:06:02.008+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:06:02.008+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:06:02.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.090 seconds
[2024-09-22T13:06:32.320+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:06:32.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:06:32.324+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:06:32.323+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:06:32.346+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:06:32.369+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:06:32.369+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:06:32.383+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:06:32.383+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:06:32.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T13:07:02.471+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:07:02.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:07:02.476+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:07:02.475+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:07:02.496+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:07:02.519+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:07:02.519+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:07:02.534+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:07:02.534+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:07:02.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.090 seconds
[2024-09-22T13:07:33.427+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:07:33.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:07:33.430+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:07:33.429+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:07:33.451+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:07:33.473+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:07:33.473+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:07:33.487+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:07:33.486+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:07:33.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T13:08:03.607+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:08:03.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:08:03.611+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:08:03.610+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:08:03.634+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:08:03.659+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:08:03.658+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:08:03.673+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:08:03.673+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:08:03.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.093 seconds
[2024-09-22T13:08:33.938+0000] {processor.py:186} INFO - Started process (PID=271) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:08:33.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:08:33.941+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:08:33.940+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:08:33.965+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:08:33.987+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:08:33.987+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:08:34.001+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:08:34.001+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:08:34.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T13:09:04.108+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:09:04.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:09:04.111+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:09:04.111+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:09:04.134+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:09:04.157+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:09:04.157+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:09:04.171+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:09:04.171+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:09:04.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.091 seconds
[2024-09-22T13:09:35.183+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:09:35.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:09:35.187+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:09:35.186+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:09:35.208+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:09:35.230+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:09:35.230+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:09:35.244+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:09:35.244+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:09:35.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T13:10:05.454+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:10:05.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:10:05.457+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:10:05.457+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:10:05.482+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:10:05.505+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:10:05.505+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:10:05.519+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:10:05.519+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:10:05.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.090 seconds
[2024-09-22T13:10:10.881+0000] {processor.py:186} INFO - Started process (PID=314) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:10:10.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:10:10.885+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:10:10.885+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:10:10.916+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:10:11.027+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:10:11.027+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:10:11.039+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:10:11.039+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:10:11.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.193 seconds
[2024-09-22T13:10:41.934+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:10:41.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:10:41.938+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:10:41.937+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:10:41.961+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:10:41.985+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:10:41.985+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:10:42.000+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:10:42.000+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:10:42.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T13:11:12.981+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:11:12.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:11:12.984+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:11:12.984+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:11:13.007+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:11:13.029+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:11:13.029+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:11:13.043+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:11:13.043+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:11:13.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T13:11:19.155+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:11:19.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:11:19.159+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:11:19.158+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:11:19.188+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:11:19.211+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:11:19.211+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:11:19.225+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:11:19.225+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:11:19.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.099 seconds
[2024-09-22T13:11:45.250+0000] {processor.py:186} INFO - Started process (PID=354) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:11:45.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:11:45.253+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:11:45.252+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:11:45.283+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:11:45.307+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:11:45.307+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:11:45.321+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:11:45.320+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:11:45.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T13:12:56.223+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:12:56.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:12:56.227+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:12:56.226+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:12:56.243+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:12:56.281+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:12:56.281+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:12:56.298+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:12:56.298+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:12:56.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T13:13:26.554+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:13:26.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:13:26.557+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:13:26.557+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:13:26.582+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:13:26.609+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:13:26.609+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:13:26.776+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:13:26.775+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:13:26.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.257 seconds
[2024-09-22T13:13:56.979+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:13:56.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:13:56.985+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:13:56.984+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:13:57.005+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:13:57.151+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:13:57.150+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:13:57.163+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:13:57.162+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:13:57.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.208 seconds
[2024-09-22T13:14:27.706+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:14:27.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:14:27.712+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:14:27.711+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:14:27.735+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:14:27.759+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:14:27.759+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:14:27.773+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:14:27.773+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:14:27.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.091 seconds
[2024-09-22T13:14:49.782+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:14:49.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:14:49.785+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:14:49.785+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:14:49.813+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:14:49.928+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:14:49.927+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:14:49.940+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:14:49.940+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:14:49.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.189 seconds
[2024-09-22T13:15:16.832+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:15:16.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:15:16.836+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:15:16.835+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:15:16.867+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:15:16.877+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:15:16.877+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:15:16.892+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:15:16.892+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:15:16.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.089 seconds
[2024-09-22T13:15:22.015+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:15:22.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:15:22.018+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:15:22.017+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:15:22.047+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:15:22.071+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:15:22.071+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:15:22.086+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:15:22.086+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:15:22.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T13:16:19.533+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:16:19.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:16:19.537+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:16:19.536+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:16:19.553+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:16:19.583+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:16:19.583+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:16:19.598+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:16:19.598+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:16:19.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T13:16:49.971+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:16:49.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:16:49.976+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:16:49.975+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:16:50.006+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:16:50.032+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:16:50.031+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:16:50.185+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:16:50.185+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:16:50.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.242 seconds
[2024-09-22T13:17:20.246+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:17:20.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:17:20.252+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:17:20.251+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:17:20.273+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:17:20.448+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:17:20.448+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:17:20.462+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:17:20.462+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:17:20.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.241 seconds
[2024-09-22T13:17:50.636+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:17:50.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:17:50.639+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:17:50.639+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:17:50.663+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:17:50.693+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:17:50.692+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:17:50.708+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:17:50.708+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:17:50.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T13:18:20.953+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:18:20.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:18:20.956+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:18:20.955+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:18:20.980+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:18:21.004+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:18:21.003+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:18:21.018+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:18:21.018+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:18:21.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.093 seconds
[2024-09-22T13:18:51.283+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:18:51.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:18:51.286+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:18:51.286+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:18:51.310+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:18:51.334+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:18:51.334+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:18:51.349+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:18:51.349+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:18:51.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T13:18:53.748+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:18:53.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:18:53.752+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:18:53.751+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:18:53.785+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:18:53.895+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:18:53.895+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:18:53.917+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:18:53.917+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:18:53.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.199 seconds
[2024-09-22T13:19:09.271+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:19:09.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:19:09.275+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:19:09.274+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:19:09.308+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:19:09.319+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:19:09.319+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:19:09.344+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:19:09.344+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:19:09.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T13:20:04.654+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:20:04.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:20:04.657+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:20:04.657+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:20:04.676+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:20:04.706+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:20:04.706+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:20:04.731+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:20:04.731+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:20:04.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.244 seconds
[2024-09-22T13:20:34.995+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:20:34.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:20:34.997+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:20:34.997+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:20:35.018+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:20:35.042+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:20:35.041+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:20:35.174+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:20:35.174+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:20:35.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.202 seconds
[2024-09-22T13:21:05.382+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:21:05.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:21:05.387+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:21:05.387+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:21:05.414+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:21:05.557+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:21:05.557+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:21:05.580+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:21:05.580+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:21:05.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.222 seconds
[2024-09-22T13:21:22.158+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:21:22.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:21:22.160+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:21:22.160+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:21:22.184+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:21:22.281+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:21:22.281+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:21:22.291+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:21:22.291+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:21:22.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.288 seconds
[2024-09-22T13:22:12.540+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:22:12.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:22:12.551+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:22:12.551+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:22:12.584+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:22:12.617+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:22:12.617+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:22:12.633+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:22:12.632+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:22:12.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.138 seconds
[2024-09-22T13:22:42.866+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:22:42.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:22:42.870+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:22:42.869+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:22:42.896+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:22:42.922+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:22:42.921+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:22:43.068+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:22:43.068+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:22:43.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.227 seconds
[2024-09-22T13:23:13.328+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:23:13.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:23:13.333+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:23:13.332+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:23:13.354+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:23:13.511+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:23:13.511+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:23:13.523+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:23:13.523+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:23:13.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.222 seconds
[2024-09-22T13:23:44.215+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:23:44.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:23:44.219+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:23:44.218+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:23:44.243+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:23:44.266+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:23:44.265+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:23:44.279+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:23:44.279+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:23:44.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T13:24:14.515+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:24:14.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:24:14.518+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:24:14.518+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:24:14.543+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:24:14.568+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:24:14.567+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:24:14.583+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:24:14.583+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:24:14.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T13:24:42.489+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:24:42.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:24:42.492+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:24:42.492+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:24:42.521+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:24:42.544+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:24:42.544+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:24:42.563+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:24:42.563+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:24:42.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T13:25:42.210+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:25:42.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:25:42.214+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:25:42.214+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:25:42.232+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:25:42.266+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:25:42.266+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:25:42.284+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:25:42.284+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:25:42.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T13:26:12.605+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:26:12.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:26:12.608+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:26:12.608+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:26:12.629+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:26:12.653+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:26:12.653+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:26:12.796+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:26:12.796+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:26:12.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.215 seconds
[2024-09-22T13:26:43.073+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:26:43.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:26:43.079+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:26:43.079+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:26:43.100+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:26:43.234+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:26:43.234+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:26:43.245+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:26:43.245+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:26:43.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.195 seconds
[2024-09-22T13:27:13.478+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:27:13.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:27:13.481+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:27:13.481+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:27:13.506+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:27:13.533+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:27:13.532+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:27:13.548+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:27:13.547+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:27:13.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T13:27:43.682+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:27:43.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:27:43.685+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:27:43.685+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:27:43.709+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:27:43.732+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:27:43.732+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:27:43.746+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:27:43.746+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:27:43.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T13:28:13.921+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:28:13.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:28:13.924+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:28:13.924+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:28:13.947+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:28:13.969+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:28:13.969+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:28:13.983+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:28:13.983+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:28:14.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T13:28:44.120+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:28:44.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:28:44.124+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:28:44.124+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:28:44.147+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:28:44.171+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:28:44.170+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:28:44.184+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:28:44.184+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:28:44.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T13:29:14.315+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:29:14.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:29:14.320+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:29:14.319+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:29:14.345+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:29:14.374+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:29:14.373+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:29:14.391+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:29:14.391+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:29:14.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T13:29:44.601+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:29:44.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:29:44.604+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:29:44.604+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:29:44.625+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:29:44.648+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:29:44.648+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:29:44.662+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:29:44.662+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:29:44.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.086 seconds
[2024-09-22T13:30:15.013+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:30:15.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:30:15.017+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:30:15.016+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:30:15.040+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:30:15.064+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:30:15.063+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:30:15.077+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:30:15.077+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:30:15.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.091 seconds
[2024-09-22T13:30:45.332+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:30:45.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:30:45.335+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:30:45.335+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:30:45.360+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:30:45.383+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:30:45.383+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:30:45.397+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:30:45.397+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:30:45.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T13:31:15.683+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:31:15.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:31:15.686+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:31:15.686+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:31:15.710+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:31:15.735+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:31:15.734+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:31:15.752+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:31:15.752+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:31:15.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T13:35:04.704+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:35:04.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:35:04.707+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:35:04.706+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:35:04.737+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:35:04.775+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:35:04.775+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:35:04.789+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:35:04.789+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:35:04.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T13:35:35.762+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:35:35.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:35:35.766+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:35:35.765+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:35:35.785+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:35:35.811+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:35:35.811+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:35:35.826+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:35:35.825+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:35:35.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.093 seconds
[2024-09-22T13:36:06.176+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:36:06.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:36:06.182+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:36:06.179+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:36:06.198+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:36:06.220+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:36:06.219+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:36:06.233+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:36:06.233+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:36:06.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.083 seconds
[2024-09-22T13:36:36.833+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:36:36.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:36:36.837+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:36:36.837+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:36:36.855+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:36:36.877+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:36:36.877+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:36:36.891+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:36:36.890+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:36:36.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.082 seconds
[2024-09-22T13:37:07.303+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:37:07.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:37:07.308+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:37:07.307+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:37:07.330+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:37:07.355+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:37:07.355+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:37:07.369+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:37:07.368+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:37:07.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T13:37:37.590+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:37:37.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:37:37.593+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:37:37.593+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:37:37.611+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:37:37.633+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:37:37.633+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:37:37.647+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:37:37.646+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:37:37.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.201 seconds
[2024-09-22T13:38:08.383+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:38:08.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:38:08.387+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:38:08.387+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:38:08.406+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:38:08.434+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:38:08.434+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:38:08.585+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:38:08.585+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:38:08.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.227 seconds
[2024-09-22T13:38:38.684+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:38:38.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:38:38.687+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:38:38.687+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:38:38.704+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:38:38.884+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:38:38.884+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:38:38.897+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:38:38.897+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:38:38.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.237 seconds
[2024-09-22T13:39:09.460+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:39:09.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:39:09.621+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:39:09.621+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:39:09.635+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:39:09.657+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:39:09.657+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:39:09.670+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:39:09.669+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:39:09.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.238 seconds
[2024-09-22T13:39:39.888+0000] {processor.py:186} INFO - Started process (PID=175) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:39:39.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:39:39.891+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:39:39.891+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:39:39.914+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:39:39.939+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:39:39.939+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:39:39.954+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:39:39.954+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:39:39.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.093 seconds
[2024-09-22T13:40:10.161+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:40:10.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:40:10.164+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:40:10.164+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:40:10.186+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:40:10.219+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:40:10.219+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:40:10.236+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:40:10.235+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:40:10.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T13:40:40.405+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:40:40.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:40:40.409+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:40:40.408+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:40:40.429+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:40:40.452+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:40:40.451+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:40:40.466+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:40:40.466+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:40:40.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.086 seconds
[2024-09-22T13:41:10.731+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:41:10.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:41:10.737+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:41:10.736+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:41:10.758+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:41:10.781+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:41:10.781+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:41:10.794+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:41:10.794+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:41:10.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T13:41:41.145+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:41:41.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:41:41.148+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:41:41.148+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:41:41.167+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:41:41.190+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:41:41.190+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:41:41.204+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:41:41.204+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:41:41.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T13:42:11.313+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:42:11.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:42:11.316+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:42:11.316+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:42:11.336+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:42:11.360+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:42:11.360+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:42:11.374+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:42:11.373+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:42:11.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T13:42:41.628+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:42:41.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:42:41.631+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:42:41.631+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:42:41.651+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:42:41.674+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:42:41.674+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:42:41.688+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:42:41.688+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:42:41.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.086 seconds
[2024-09-22T13:43:12.726+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:43:12.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:43:12.729+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:43:12.729+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:43:12.746+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:43:12.771+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:43:12.771+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:43:12.786+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:43:12.786+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:43:12.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.090 seconds
[2024-09-22T13:43:43.070+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:43:43.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:43:43.074+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:43:43.073+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:43:43.091+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:43:43.115+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:43:43.115+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:43:43.128+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:43:43.128+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:43:43.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.085 seconds
[2024-09-22T13:44:07.004+0000] {processor.py:186} INFO - Started process (PID=286) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:44:07.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:44:07.013+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:44:07.012+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:44:07.035+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:44:07.030+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:44:07.036+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:44:07.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.083 seconds
[2024-09-22T13:44:13.056+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:44:13.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:44:13.060+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:44:13.060+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:44:13.085+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:44:13.080+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:44:13.086+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:44:13.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.058 seconds
[2024-09-22T13:44:34.830+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:44:34.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:44:34.833+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:44:34.833+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:44:34.858+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:44:34.852+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:44:34.859+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:44:34.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.054 seconds
[2024-09-22T13:45:05.124+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:45:05.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:45:05.128+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:45:05.128+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:45:05.145+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:45:05.140+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:45:05.146+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:45:05.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T13:45:35.251+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:45:35.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:45:35.253+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:45:35.253+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:45:35.269+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:45:35.265+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:45:35.270+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:45:35.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T13:46:05.503+0000] {processor.py:186} INFO - Started process (PID=339) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:46:05.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:46:05.506+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:46:05.506+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:46:05.522+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:46:05.519+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:46:05.523+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:46:05.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T13:46:35.928+0000] {processor.py:186} INFO - Started process (PID=352) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:46:35.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:46:35.931+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:46:35.931+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:46:35.948+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:46:35.944+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:46:35.949+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:46:35.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T13:47:06.081+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:47:06.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:47:06.083+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:47:06.083+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:47:06.099+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:47:06.094+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:47:06.099+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:47:06.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T13:48:13.733+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:48:13.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:48:13.737+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:48:13.736+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:48:13.753+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:48:13.747+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:48:13.754+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:48:13.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.053 seconds
[2024-09-22T13:48:43.839+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:48:43.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:48:43.842+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:48:43.842+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:48:43.859+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:48:43.854+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:48:43.859+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:48:43.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T13:49:14.251+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:49:14.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:49:14.254+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:49:14.254+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:49:14.274+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:49:14.269+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:49:14.275+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:49:14.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.051 seconds
[2024-09-22T13:49:44.754+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:49:44.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:49:44.757+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:49:44.757+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:49:44.772+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:49:44.769+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 20, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: my_spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T13:49:44.773+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:49:44.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T13:50:05.617+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:50:05.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:50:05.620+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:50:05.619+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:50:05.642+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:50:05.954+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:50:05.953+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:50:05.964+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:50:05.964+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:50:06.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.389 seconds
[2024-09-22T13:50:13.958+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:50:13.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:50:13.962+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:50:13.962+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:50:13.985+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:50:13.996+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:50:13.996+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:50:14.010+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:50:14.010+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T13:50:14.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.079 seconds
[2024-09-22T13:51:53.139+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:51:53.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:51:53.142+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:51:53.141+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:51:53.173+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:51:53.497+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:51:53.494+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:51:53.524+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:51:53.524+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:51:53.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.418 seconds
[2024-09-22T13:52:23.837+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:52:23.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:52:23.842+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:52:23.842+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:52:23.888+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:52:23.921+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:52:23.921+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:52:24.092+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:52:24.092+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:52:24.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.288 seconds
[2024-09-22T13:52:54.709+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:52:54.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:52:54.714+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:52:54.714+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:52:54.739+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:52:54.879+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:52:54.878+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:52:54.898+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:52:54.898+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:52:54.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.221 seconds
[2024-09-22T13:53:03.573+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:53:03.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:53:03.692+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:53:03.691+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:53:03.722+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:53:03.741+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:53:03.741+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:53:03.762+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:53:03.761+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:53:03.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.218 seconds
[2024-09-22T13:54:04.679+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:54:04.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:54:04.687+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:54:04.686+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:54:04.710+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:54:04.745+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:54:04.745+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:54:04.778+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:54:04.778+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:54:04.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.294 seconds
[2024-09-22T13:54:35.350+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:54:35.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:54:35.353+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:54:35.353+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:54:35.379+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:54:35.403+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:54:35.403+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:54:35.561+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:54:35.560+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:54:35.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.235 seconds
[2024-09-22T13:55:05.924+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:55:05.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:55:05.929+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:55:05.929+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:55:05.957+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:55:06.108+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:55:06.108+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:55:06.128+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:55:06.128+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:55:06.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.228 seconds
[2024-09-22T13:55:36.884+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:55:36.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:55:36.888+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:55:36.888+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:55:36.915+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:55:36.939+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:55:36.938+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:55:36.961+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:55:36.961+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:55:36.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T13:56:07.129+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:56:07.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:56:07.133+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:56:07.132+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:56:07.160+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:56:07.185+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:56:07.184+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:56:07.211+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:56:07.211+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:56:07.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T13:56:37.686+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:56:37.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:56:37.690+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:56:37.690+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:56:37.719+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:56:37.743+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:56:37.743+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:56:37.771+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:56:37.770+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:56:37.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T13:57:08.158+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:57:08.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:57:08.161+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:57:08.161+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:57:08.186+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:57:08.209+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:57:08.208+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:57:08.231+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:57:08.231+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:57:08.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.099 seconds
[2024-09-22T13:57:38.434+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:57:38.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:57:38.437+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:57:38.437+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:57:38.468+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:57:38.492+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:57:38.492+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:57:38.517+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:57:38.517+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:57:38.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T13:59:36.678+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:59:36.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T13:59:36.682+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:59:36.681+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:59:36.719+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T13:59:36.757+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:59:36.757+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T13:59:36.783+0000] {logging_mixin.py:190} INFO - [2024-09-22T13:59:36.783+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T13:59:36.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.147 seconds
[2024-09-22T14:00:06.918+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:00:06.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:00:06.921+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:00:06.921+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:00:06.941+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:00:06.967+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:00:06.967+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:00:06.993+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:00:06.993+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:00:07.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T14:00:37.357+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:00:37.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:00:37.361+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:00:37.361+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:00:37.385+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:00:37.409+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:00:37.408+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:00:37.432+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:00:37.431+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:00:37.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T14:01:07.603+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:01:07.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:01:07.607+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:01:07.606+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:01:07.624+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:01:07.648+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:01:07.648+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:01:07.672+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:01:07.672+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:01:07.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T14:01:38.341+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:01:38.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:01:38.345+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:01:38.345+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:01:38.364+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:01:38.387+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:01:38.387+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:01:38.410+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:01:38.409+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:01:38.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T14:02:08.879+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:02:08.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:02:08.882+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:02:08.882+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:02:08.902+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:02:08.924+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:02:08.924+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:02:08.948+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:02:08.947+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:02:09.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.219 seconds
[2024-09-22T14:02:39.490+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:02:39.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:02:39.493+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:02:39.492+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:02:39.511+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:02:39.534+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:02:39.533+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:02:39.683+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:02:39.682+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:02:39.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.220 seconds
[2024-09-22T14:03:09.872+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:03:09.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:03:09.877+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:03:09.877+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:03:09.897+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:03:10.079+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:03:10.079+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:03:10.110+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:03:10.109+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:03:10.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.265 seconds
[2024-09-22T14:03:40.264+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:03:40.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:03:40.267+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:03:40.267+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:03:40.418+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:03:40.437+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:03:40.437+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:03:40.456+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:03:40.456+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:03:40.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.225 seconds
[2024-09-22T14:04:10.604+0000] {processor.py:186} INFO - Started process (PID=169) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:04:10.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:04:10.608+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:04:10.607+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:04:10.625+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:04:10.648+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:04:10.648+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:04:10.670+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:04:10.670+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:04:10.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T14:04:41.571+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:04:41.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:04:41.574+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:04:41.574+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:04:41.594+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:04:41.618+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:04:41.618+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:04:41.643+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:04:41.643+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:04:41.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T14:05:11.724+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:05:11.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:05:11.727+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:05:11.727+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:05:11.745+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:05:11.769+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:05:11.768+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:05:11.796+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:05:11.795+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:05:11.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T14:05:42.009+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:05:42.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:05:42.013+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:05:42.013+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:05:42.032+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:05:42.056+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:05:42.056+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:05:42.079+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:05:42.079+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:05:42.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T14:06:12.948+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:06:12.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:06:12.952+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:06:12.952+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:06:12.971+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:06:12.995+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:06:12.995+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:06:13.019+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:06:13.018+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:06:13.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T14:06:43.935+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:06:43.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:06:43.938+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:06:43.938+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:06:43.962+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:06:43.985+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:06:43.985+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:06:44.009+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:06:44.008+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:06:44.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T14:06:46.137+0000] {processor.py:186} INFO - Started process (PID=236) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:06:46.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:06:46.140+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:06:46.140+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:06:46.166+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:06:46.376+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:06:46.376+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:06:46.397+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:06:46.397+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:06:46.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.293 seconds
[2024-09-22T14:07:06.074+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:07:06.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:07:06.078+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:07:06.077+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:07:06.103+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:07:06.114+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:07:06.114+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:07:06.138+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:07:06.137+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:07:06.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T14:08:35.573+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:08:35.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:08:35.583+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:08:35.583+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:08:35.606+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:08:35.999+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:08:35.999+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:08:36.021+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:08:36.021+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:08:36.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.479 seconds
[2024-09-22T14:09:06.192+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:09:06.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:09:06.196+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:09:06.196+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:09:06.220+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:09:06.244+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:09:06.244+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:09:06.397+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:09:06.397+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:09:06.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.232 seconds
[2024-09-22T14:09:36.539+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:09:36.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:09:36.545+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:09:36.545+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:09:36.570+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:09:36.706+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:09:36.706+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:09:36.727+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:09:36.727+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:09:36.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.211 seconds
[2024-09-22T14:10:07.037+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:10:07.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:10:07.041+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:10:07.041+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:10:07.070+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:10:07.096+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:10:07.095+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:10:07.121+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:10:07.121+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:10:07.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T14:10:38.100+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:10:38.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:10:38.103+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:10:38.103+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:10:38.130+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:10:38.155+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:10:38.155+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:10:38.181+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:10:38.181+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:10:38.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T14:11:08.272+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:11:08.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:11:08.275+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:11:08.275+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:11:08.301+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:11:08.324+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:11:08.324+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:11:08.347+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:11:08.347+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:11:08.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T14:11:38.501+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:11:38.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:11:38.505+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:11:38.505+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:11:38.535+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:11:38.560+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:11:38.560+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:11:38.584+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:11:38.584+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:11:38.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T14:13:02.067+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:13:02.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:13:02.070+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:13:02.070+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:13:02.118+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:13:02.159+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:13:02.159+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:13:02.189+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:13:02.189+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:13:02.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.151 seconds
[2024-09-22T14:13:32.466+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:13:32.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:13:32.469+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:13:32.469+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:13:32.488+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:13:32.516+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:13:32.516+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:13:32.539+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:13:32.538+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:13:32.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.099 seconds
[2024-09-22T14:14:02.716+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:14:02.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:14:02.720+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:14:02.719+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:14:02.744+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:14:02.767+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:14:02.767+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:14:02.791+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:14:02.791+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:14:02.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T14:14:32.936+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:14:32.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:14:32.940+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:14:32.939+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:14:32.958+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:14:32.981+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:14:32.980+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:14:33.003+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:14:33.003+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:14:33.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T14:15:03.344+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:15:03.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:15:03.349+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:15:03.348+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:15:03.372+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:15:03.397+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:15:03.397+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:15:03.420+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:15:03.420+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:15:03.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T14:15:33.575+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:15:33.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:15:33.579+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:15:33.579+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:15:33.598+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:15:33.628+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:15:33.627+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:15:33.655+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:15:33.655+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:15:33.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.311 seconds
[2024-09-22T14:16:04.020+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:16:04.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:16:04.023+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:16:04.023+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:16:04.041+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:16:04.064+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:16:04.063+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:16:04.204+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:16:04.204+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:16:04.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.210 seconds
[2024-09-22T14:16:35.197+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:16:35.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:16:35.200+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:16:35.200+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:16:35.221+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:16:35.375+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:16:35.375+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:16:35.400+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:16:35.400+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:16:35.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.227 seconds
[2024-09-22T14:17:05.589+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:17:05.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:17:05.740+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:17:05.739+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:17:05.760+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:17:05.779+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:17:05.779+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:17:05.799+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:17:05.799+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:17:05.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.234 seconds
[2024-09-22T14:17:36.464+0000] {processor.py:186} INFO - Started process (PID=169) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:17:36.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:17:36.468+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:17:36.467+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:17:36.487+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:17:36.511+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:17:36.511+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:17:36.534+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:17:36.534+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:17:36.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T14:18:07.383+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:18:07.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:18:07.387+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:18:07.386+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:18:07.406+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:18:07.431+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:18:07.431+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:18:07.458+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:18:07.457+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:18:07.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T14:18:38.302+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:18:38.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:18:38.307+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:18:38.306+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:18:38.326+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:18:38.351+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:18:38.351+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:18:38.375+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:18:38.375+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:18:38.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T14:20:45.654+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:20:45.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:20:45.657+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:20:45.657+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:20:45.692+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:20:45.730+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:20:45.729+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:20:45.755+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:20:45.755+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:20:45.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.128 seconds
[2024-09-22T14:21:08.100+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:21:08.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:21:08.103+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:21:08.102+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:21:08.122+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:21:08.152+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:21:08.151+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:21:08.176+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:21:08.176+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:21:08.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.237 seconds
[2024-09-22T14:21:38.428+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:21:38.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:21:38.431+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:21:38.430+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:21:38.454+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:21:38.478+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:21:38.478+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:21:38.617+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:21:38.617+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:21:38.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.213 seconds
[2024-09-22T14:22:08.994+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:22:08.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:22:09.001+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:22:09.000+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:22:09.032+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:22:09.196+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:22:09.196+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:22:09.216+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:22:09.216+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:22:09.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.251 seconds
[2024-09-22T14:22:39.358+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:22:39.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:22:39.361+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:22:39.361+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:22:39.385+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:22:39.407+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:22:39.407+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:22:39.430+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:22:39.430+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:22:39.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.139 seconds
[2024-09-22T14:23:09.568+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:23:09.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:23:09.571+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:23:09.571+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:23:09.592+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:23:09.616+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:23:09.615+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:23:09.640+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:23:09.640+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:23:09.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T14:23:39.711+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:23:39.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:23:39.714+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:23:39.714+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:23:39.738+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:23:39.761+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:23:39.761+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:23:39.785+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:23:39.785+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:23:39.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T14:24:09.911+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:24:09.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:24:09.914+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:24:09.914+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:24:09.941+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:24:09.965+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:24:09.965+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:24:09.988+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:24:09.988+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:24:10.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T14:24:40.059+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:24:40.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:24:40.063+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:24:40.062+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:24:40.089+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:24:40.113+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:24:40.113+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:24:40.137+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:24:40.137+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:24:40.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T14:25:10.331+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:25:10.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:25:10.334+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:25:10.334+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:25:10.363+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:25:10.398+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:25:10.398+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:25:10.444+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:25:10.444+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:25:10.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.150 seconds
[2024-09-22T14:25:40.585+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:25:40.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:25:40.589+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:25:40.589+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:25:40.616+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:25:40.640+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:25:40.639+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:25:40.662+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:25:40.662+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:25:40.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T14:26:10.823+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:26:10.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:26:10.827+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:26:10.826+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:26:10.872+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:26:10.896+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:26:10.896+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:26:10.920+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:26:10.920+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:26:10.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.126 seconds
[2024-09-22T14:26:41.000+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:26:41.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:26:41.003+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:26:41.003+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:26:41.029+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:26:41.052+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:26:41.052+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:26:41.078+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:26:41.078+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:26:41.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T14:27:12.002+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:27:12.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:27:12.006+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:27:12.006+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:27:12.034+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:27:12.059+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:27:12.059+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:27:12.087+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:27:12.087+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:27:12.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T14:27:42.342+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:27:42.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:27:42.346+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:27:42.346+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:27:42.375+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:27:42.401+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:27:42.401+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:27:42.425+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:27:42.425+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:27:42.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T14:28:09.317+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:28:09.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:28:09.321+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:28:09.320+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:28:09.352+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:28:09.551+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:28:09.551+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:28:09.571+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:28:09.570+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:28:09.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.287 seconds
[2024-09-22T14:28:12.494+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:28:12.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:28:12.497+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:28:12.497+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:28:12.529+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:28:12.539+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:28:12.539+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:28:12.567+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:28:12.566+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:28:12.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T14:28:42.696+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:28:42.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:28:42.699+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:28:42.698+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:28:42.724+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:28:42.749+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:28:42.748+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:28:42.772+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:28:42.772+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:28:42.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T14:29:13.243+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:29:13.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:29:13.246+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:29:13.246+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:29:13.272+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:29:13.294+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:29:13.294+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:29:13.317+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:29:13.317+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:29:13.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T14:29:43.697+0000] {processor.py:186} INFO - Started process (PID=271) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:29:43.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:29:43.701+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:29:43.701+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:29:43.725+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:29:43.749+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:29:43.749+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:29:43.772+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:29:43.772+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:29:43.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T14:30:14.160+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:30:14.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:30:14.165+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:30:14.164+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:30:14.190+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:30:14.213+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:30:14.213+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:30:14.235+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:30:14.235+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:30:14.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T14:30:44.460+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:30:44.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:30:44.463+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:30:44.463+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:30:44.488+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:30:44.511+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:30:44.511+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:30:44.534+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:30:44.533+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:30:44.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T14:32:08.047+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:32:08.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:32:08.051+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:32:08.050+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:32:08.089+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:32:08.129+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:32:08.129+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:32:08.158+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:32:08.158+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:32:08.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.140 seconds
[2024-09-22T14:32:38.404+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:32:38.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:32:38.407+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:32:38.406+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:32:38.431+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:32:38.456+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:32:38.455+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:32:38.478+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:32:38.478+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:32:38.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T14:33:08.579+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:33:08.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:33:08.582+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:33:08.582+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:33:08.603+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:33:08.631+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:33:08.631+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:33:08.655+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:33:08.655+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:33:08.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T14:33:38.951+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:33:38.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:33:38.954+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:33:38.954+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:33:38.973+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:33:38.996+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:33:38.996+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:33:39.023+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:33:39.023+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:33:39.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T14:34:09.504+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:34:09.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:34:09.508+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:34:09.508+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:34:09.527+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:34:09.550+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:34:09.550+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:34:09.575+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:34:09.574+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:34:09.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T14:34:15.723+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:34:15.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:34:15.726+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:34:15.726+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:34:15.751+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:34:16.077+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:34:16.077+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:34:16.097+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:34:16.097+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:34:16.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.403 seconds
[2024-09-22T14:34:35.433+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:34:35.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:34:35.437+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:34:35.437+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:34:35.463+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:34:35.473+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:34:35.473+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:34:35.497+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:34:35.497+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:34:35.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.093 seconds
[2024-09-22T14:36:06.585+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:36:06.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:36:06.590+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:36:06.590+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:36:06.643+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:36:06.693+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:36:06.693+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:36:06.726+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:36:06.726+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:36:06.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.185 seconds
[2024-09-22T14:36:37.126+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:36:37.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:36:37.132+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:36:37.130+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:36:37.153+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:36:37.183+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:36:37.183+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:36:37.208+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:36:37.208+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:36:37.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T14:37:07.451+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:37:07.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:37:07.454+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:37:07.454+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:37:07.475+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:37:07.498+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:37:07.498+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:37:07.520+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:37:07.520+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:37:07.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T14:37:37.601+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:37:37.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:37:37.605+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:37:37.605+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:37:37.625+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:37:37.652+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:37:37.652+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:37:37.679+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:37:37.679+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:37:37.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T14:38:07.749+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:38:07.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:38:07.753+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:38:07.752+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:38:07.773+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:38:07.797+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:38:07.797+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:38:07.819+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:38:07.819+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:38:07.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T14:38:37.930+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:38:37.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:38:37.933+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:38:37.933+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:38:37.955+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:38:37.980+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:38:37.980+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:38:38.005+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:38:38.005+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:38:38.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.229 seconds
[2024-09-22T14:39:08.363+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:39:08.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:39:08.366+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:39:08.366+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:39:08.387+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:39:08.412+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:39:08.412+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:39:08.574+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:39:08.574+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:39:08.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.237 seconds
[2024-09-22T14:39:38.693+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:39:38.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:39:38.696+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:39:38.696+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:39:38.714+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:39:38.854+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:39:38.854+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:39:38.873+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:39:38.873+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:39:38.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.267 seconds
[2024-09-22T14:40:09.142+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:40:09.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:40:09.145+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:40:09.144+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:40:09.295+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:40:09.318+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:40:09.318+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:40:09.339+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:40:09.339+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:40:09.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.226 seconds
[2024-09-22T14:40:39.652+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:40:39.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:40:39.656+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:40:39.655+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:40:39.676+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:40:39.699+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:40:39.699+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:40:39.722+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:40:39.721+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:40:39.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T14:41:09.787+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:41:09.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:41:09.790+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:41:09.790+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:41:09.812+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:41:09.837+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:41:09.837+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:41:09.862+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:41:09.862+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:41:09.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T14:42:08.416+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:42:08.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:42:08.419+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:42:08.419+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:42:08.440+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:42:08.479+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:42:08.478+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:42:08.508+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:42:08.508+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:42:08.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.279 seconds
[2024-09-22T14:42:38.882+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:42:38.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:42:38.885+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:42:38.885+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:42:38.911+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:42:38.938+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:42:38.938+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:42:39.091+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:42:39.090+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:42:39.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.236 seconds
[2024-09-22T14:43:09.402+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:43:09.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:43:09.409+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:43:09.409+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:43:09.436+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:43:09.598+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:43:09.597+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:43:09.619+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:43:09.619+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:43:09.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.241 seconds
[2024-09-22T14:43:39.717+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:43:39.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:43:39.721+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:43:39.721+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:43:39.746+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:43:39.771+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:43:39.771+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:43:39.795+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:43:39.795+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:43:39.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T14:44:09.970+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:44:09.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:44:09.974+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:44:09.973+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:44:10.000+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:44:10.023+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:44:10.023+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:44:10.046+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:44:10.046+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:44:10.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T14:44:40.366+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:44:40.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:44:40.371+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:44:40.370+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:44:40.397+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:44:40.424+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:44:40.424+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:44:40.453+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:44:40.452+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:44:40.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T14:45:10.839+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:45:10.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:45:10.842+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:45:10.842+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:45:10.872+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:45:10.897+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:45:10.897+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:45:10.924+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:45:10.924+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:45:10.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T14:45:41.763+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:45:41.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:45:41.766+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:45:41.766+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:45:41.792+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:45:41.815+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:45:41.815+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:45:41.839+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:45:41.839+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:45:41.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T14:46:12.080+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:46:12.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:46:12.083+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:46:12.082+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:46:12.109+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:46:12.134+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:46:12.134+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:46:12.158+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:46:12.158+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:46:12.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T14:46:42.620+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:46:42.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:46:42.623+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:46:42.623+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:46:42.648+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:46:42.671+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:46:42.671+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:46:42.695+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:46:42.695+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:46:42.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T14:47:12.955+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:47:12.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:47:12.958+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:47:12.958+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:47:12.986+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:47:13.010+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:47:13.010+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:47:13.036+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:47:13.036+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:47:13.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T14:47:43.248+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:47:43.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:47:43.252+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:47:43.252+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:47:43.282+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:47:43.309+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:47:43.308+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:47:43.334+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:47:43.334+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:47:43.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T14:48:13.726+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:48:13.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:48:13.729+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:48:13.729+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:48:13.754+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:48:13.794+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:48:13.794+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:48:13.822+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:48:13.822+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:48:13.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.136 seconds
[2024-09-22T14:48:43.996+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:48:43.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:48:43.999+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:48:43.999+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:48:44.024+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:48:44.049+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:48:44.048+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:48:44.077+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:48:44.075+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:48:44.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T14:49:14.974+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:49:14.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:49:14.978+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:49:14.977+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:49:15.003+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:49:15.027+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:49:15.026+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T14:49:15.050+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:49:15.050+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T14:49:15.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T14:49:35.787+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:49:35.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:49:35.790+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:49:35.790+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:49:35.814+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:49:35.808+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:49:35.815+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:49:35.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.056 seconds
[2024-09-22T14:50:06.078+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:50:06.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:50:06.082+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:50:06.081+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:50:06.098+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:50:06.094+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:50:06.099+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:50:06.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T14:50:36.330+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:50:36.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:50:36.333+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:50:36.332+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:50:36.348+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:50:36.344+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:50:36.348+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:50:36.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T14:51:06.488+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:51:06.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:51:06.490+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:51:06.490+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:51:06.509+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:51:06.503+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:51:06.509+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:51:06.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T14:51:36.804+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:51:36.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:51:36.807+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:51:36.806+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:51:36.825+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:51:36.819+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:51:36.826+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:51:36.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T14:52:06.911+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:52:06.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:52:06.914+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:52:06.913+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:52:06.930+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:52:06.926+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:52:06.931+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:52:06.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T14:52:15.168+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:52:15.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:52:15.170+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:52:15.169+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:52:15.191+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:52:15.187+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:52:15.192+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:52:15.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T14:52:46.070+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:52:46.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:52:46.073+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:52:46.072+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:52:46.089+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:52:46.085+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:52:46.090+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:52:46.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.043 seconds
[2024-09-22T14:53:16.177+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:53:16.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:53:16.180+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:53:16.179+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:53:16.198+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:53:16.193+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:53:16.199+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:53:16.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T14:53:46.345+0000] {processor.py:186} INFO - Started process (PID=354) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:53:46.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:53:46.348+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:53:46.348+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:53:46.366+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:53:46.361+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:53:46.367+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:53:46.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T14:54:16.491+0000] {processor.py:186} INFO - Started process (PID=367) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:54:16.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:54:16.493+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:54:16.493+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:54:16.510+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:54:16.506+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:54:16.511+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:54:16.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T14:54:46.572+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:54:46.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:54:46.574+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:54:46.574+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:54:46.592+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:54:46.587+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:54:46.593+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:54:46.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T14:55:17.376+0000] {processor.py:186} INFO - Started process (PID=393) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:55:17.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:55:17.378+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:55:17.377+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:55:17.394+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:55:17.389+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:55:17.395+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:55:17.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T14:55:47.575+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:55:47.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:55:47.577+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:55:47.577+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:55:47.593+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:55:47.589+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:55:47.594+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:55:47.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T14:56:18.528+0000] {processor.py:186} INFO - Started process (PID=419) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:56:18.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:56:18.531+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:56:18.531+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:56:18.548+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:56:18.543+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:56:18.549+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:56:18.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T14:56:49.558+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:56:49.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:56:49.561+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:56:49.560+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:56:49.574+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:56:49.570+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:56:49.575+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:56:49.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.042 seconds
[2024-09-22T14:57:20.595+0000] {processor.py:186} INFO - Started process (PID=445) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:57:20.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:57:20.597+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:57:20.597+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:57:20.615+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:57:20.610+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:57:20.616+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:57:20.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T14:57:51.474+0000] {processor.py:186} INFO - Started process (PID=458) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:57:51.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:57:51.477+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:57:51.476+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:57:51.495+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:57:51.490+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:57:51.496+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:57:51.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T14:58:22.345+0000] {processor.py:186} INFO - Started process (PID=471) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:58:22.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:58:22.347+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:58:22.347+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:58:22.363+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:58:22.359+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:58:22.364+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:58:22.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T14:58:53.187+0000] {processor.py:186} INFO - Started process (PID=485) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:58:53.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:58:53.194+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:58:53.194+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:58:53.228+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:58:53.220+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:58:53.229+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:58:53.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.068 seconds
[2024-09-22T14:59:23.297+0000] {processor.py:186} INFO - Started process (PID=498) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:59:23.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:59:23.299+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:59:23.299+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:59:23.316+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:59:23.310+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:59:23.317+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:59:23.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T14:59:53.434+0000] {processor.py:186} INFO - Started process (PID=511) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:59:53.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T14:59:53.437+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:59:53.436+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:59:53.454+0000] {logging_mixin.py:190} INFO - [2024-09-22T14:59:53.449+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T14:59:53.455+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T14:59:53.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T15:00:23.561+0000] {processor.py:186} INFO - Started process (PID=524) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:00:23.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:00:23.563+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:00:23.563+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:00:23.580+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:00:23.575+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:00:23.580+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:00:23.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T15:00:53.953+0000] {processor.py:186} INFO - Started process (PID=537) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:00:53.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:00:53.955+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:00:53.955+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:00:53.971+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:00:53.967+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:00:53.972+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:00:53.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.043 seconds
[2024-09-22T15:01:24.027+0000] {processor.py:186} INFO - Started process (PID=550) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:01:24.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:01:24.029+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:01:24.029+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:01:24.047+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:01:24.042+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:01:24.047+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:01:24.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T15:01:54.453+0000] {processor.py:186} INFO - Started process (PID=563) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:01:54.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:01:54.455+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:01:54.455+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:01:54.471+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:01:54.467+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:01:54.472+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:01:54.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T15:03:32.437+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:03:32.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:03:32.441+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:03:32.440+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:03:32.457+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:03:32.453+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:03:32.458+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:03:32.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T15:04:02.561+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:04:02.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:04:02.564+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:04:02.564+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:04:02.579+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:04:02.575+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:04:02.580+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:04:02.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T15:04:32.837+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:04:32.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:04:32.841+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:04:32.840+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:04:32.860+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:04:32.855+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:04:32.861+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:04:32.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T15:05:43.207+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:05:43.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:05:43.211+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:05:43.211+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:05:43.227+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:05:43.222+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:05:43.228+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:05:43.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.051 seconds
[2024-09-22T15:06:13.836+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:06:13.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:06:13.839+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:06:13.839+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:06:13.856+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:06:13.852+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:06:13.857+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:06:13.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T15:06:43.980+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:06:43.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:06:43.985+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:06:43.984+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:06:44.000+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:06:43.996+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:06:44.001+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:06:44.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T15:07:14.536+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:07:14.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:07:14.540+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:07:14.540+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:07:14.553+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:07:14.549+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:07:14.554+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:07:14.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T15:09:56.051+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:09:56.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:09:56.054+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:09:56.054+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:09:56.074+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:09:56.070+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:09:56.076+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:09:56.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.053 seconds
[2024-09-22T15:10:26.259+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:10:26.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:10:26.262+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:10:26.262+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:10:26.279+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:10:26.274+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:10:26.279+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:10:26.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T15:10:56.603+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:10:56.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:10:56.609+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:10:56.609+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:10:56.625+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:10:56.621+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:10:56.626+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:10:56.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T15:11:27.043+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:11:27.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:11:27.047+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:11:27.047+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:11:27.064+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:11:27.060+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:11:27.065+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:11:27.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T15:12:45.308+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:12:45.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:12:45.311+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:12:45.311+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:12:45.327+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:12:45.324+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:12:45.328+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:12:45.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.059 seconds
[2024-09-22T15:13:15.493+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:13:15.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:13:15.496+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:13:15.496+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:13:15.515+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:13:15.510+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:13:15.517+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:13:15.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T15:13:45.811+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:13:45.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:13:45.814+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:13:45.814+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:13:45.833+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:13:45.829+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:13:45.834+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:13:45.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T15:14:16.019+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:14:16.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:14:16.022+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:14:16.022+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:14:16.036+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:14:16.032+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:14:16.036+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:14:16.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T15:14:46.760+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:14:46.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:14:46.764+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:14:46.763+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:14:46.780+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:14:46.776+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:14:46.781+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:14:46.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T15:15:17.795+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:15:17.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:15:17.798+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:15:17.798+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:15:17.816+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:15:17.812+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:15:17.817+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:15:17.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.052 seconds
[2024-09-22T15:15:48.164+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:15:48.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:15:48.168+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:15:48.167+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:15:48.186+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:15:48.181+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:15:48.187+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:15:48.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.056 seconds
[2024-09-22T15:16:18.693+0000] {processor.py:186} INFO - Started process (PID=164) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:16:18.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:16:18.697+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:16:18.696+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:16:18.713+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:16:18.709+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:16:18.715+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:16:18.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T15:16:49.104+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:16:49.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:16:49.264+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:16:49.264+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:16:49.278+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:16:49.274+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:16:49.278+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:16:49.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.200 seconds
[2024-09-22T15:17:19.341+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:17:19.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:17:19.345+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:17:19.345+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:17:19.362+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:17:19.357+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:17:19.363+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:17:19.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T15:17:49.515+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:17:49.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:17:49.519+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:17:49.519+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:17:49.545+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:17:49.537+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:17:49.546+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:17:49.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.059 seconds
[2024-09-22T15:18:19.913+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:18:19.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:18:19.917+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:18:19.917+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:18:19.933+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:18:19.929+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:18:19.934+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:18:19.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T15:18:50.894+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:18:50.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:18:50.897+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:18:50.897+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:18:50.914+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:18:50.910+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:18:50.915+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:18:50.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.057 seconds
[2024-09-22T15:19:20.998+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:19:20.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:19:21.001+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:19:21.001+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:19:21.019+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:19:21.015+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:19:21.020+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:19:21.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.053 seconds
[2024-09-22T15:19:51.432+0000] {processor.py:186} INFO - Started process (PID=262) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:19:51.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:19:51.436+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:19:51.436+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:19:51.453+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:19:51.449+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:19:51.454+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:19:51.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T15:20:22.351+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:20:22.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:20:22.355+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:20:22.354+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:20:22.371+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:20:22.367+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:20:22.372+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:20:22.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T15:20:52.459+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:20:52.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:20:52.466+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:20:52.465+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:20:52.490+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:20:52.485+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:20:52.493+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:20:52.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.070 seconds
[2024-09-22T15:21:22.959+0000] {processor.py:186} INFO - Started process (PID=302) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:21:22.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:21:22.963+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:21:22.962+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:21:22.978+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:21:22.974+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:21:22.979+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:21:22.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T15:21:53.863+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:21:53.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:21:53.866+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:21:53.866+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:21:53.882+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:21:53.877+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:21:53.883+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:21:53.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T15:21:58.124+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:21:58.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:21:58.128+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:21:58.128+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:21:58.153+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:21:58.148+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 13, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T15:21:58.154+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:21:58.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.059 seconds
[2024-09-22T15:22:02.276+0000] {processor.py:186} INFO - Started process (PID=322) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:22:02.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:22:02.279+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:22:02.279+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:22:02.307+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:22:02.529+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:22:02.529+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:22:02.542+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:22:02.542+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:22:02.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.302 seconds
[2024-09-22T15:22:32.652+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:22:32.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:22:32.656+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:22:32.656+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:22:32.676+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:22:32.739+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:22:32.729+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:22:32.762+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:22:32.761+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:22:32.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.135 seconds
[2024-09-22T15:26:05.463+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:26:05.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:26:05.469+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:26:05.469+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:26:05.528+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:26:05.571+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:26:05.571+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:26:05.589+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:26:05.589+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:26:05.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.171 seconds
[2024-09-22T15:26:35.691+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:26:35.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:26:35.694+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:26:35.694+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:26:35.711+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:26:35.737+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:26:35.737+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:26:35.752+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:26:35.751+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:26:35.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T15:27:06.193+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:27:06.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:27:06.196+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:27:06.196+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:27:06.214+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:27:06.236+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:27:06.236+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:27:06.249+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:27:06.249+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:27:06.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.081 seconds
[2024-09-22T15:27:36.451+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:27:36.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:27:36.457+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:27:36.457+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:27:36.483+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:27:36.517+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:27:36.516+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:27:36.533+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:27:36.532+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:27:36.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T15:28:56.000+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:28:56.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:28:56.004+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:28:56.003+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:28:56.115+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:28:56.156+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:28:56.156+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:28:56.172+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:28:56.172+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:28:56.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.204 seconds
[2024-09-22T15:29:27.200+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:29:27.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:29:27.203+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:29:27.203+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:29:27.221+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:29:27.248+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:29:27.248+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:29:27.262+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:29:27.261+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:29:27.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T15:29:57.572+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:29:57.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:29:57.579+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:29:57.576+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:29:57.598+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:29:57.625+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:29:57.624+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:29:57.640+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:29:57.640+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:29:57.661+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T15:30:27.746+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:30:27.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:30:27.750+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:30:27.749+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:30:27.766+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:30:27.790+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:30:27.790+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:30:27.804+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:30:27.804+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:30:27.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.086 seconds
[2024-09-22T15:30:57.913+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:30:57.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:30:57.917+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:30:57.917+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:30:57.935+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:30:57.961+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:30:57.961+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:30:57.979+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:30:57.978+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:30:58.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T15:31:28.324+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:31:28.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:31:28.327+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:31:28.327+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:31:28.367+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:31:28.443+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:31:28.442+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:31:28.469+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:31:28.469+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:31:28.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.341 seconds
[2024-09-22T15:31:58.840+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:31:58.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:31:58.843+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:31:58.843+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:31:58.861+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:31:58.889+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:31:58.889+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:31:59.050+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:31:59.049+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:31:59.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.239 seconds
[2024-09-22T15:34:09.773+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:34:09.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:34:09.777+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:34:09.777+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:34:09.817+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:34:09.860+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:34:09.860+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:34:09.876+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:34:09.876+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:34:09.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.135 seconds
[2024-09-22T15:34:40.929+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:34:40.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:34:40.932+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:34:40.932+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:34:40.950+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:34:40.976+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:34:40.976+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:34:40.990+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:34:40.989+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:34:41.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.085 seconds
[2024-09-22T15:35:11.547+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:35:11.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:35:11.552+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:35:11.550+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:35:11.569+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:35:11.591+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:35:11.591+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:35:11.605+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:35:11.605+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:35:11.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.085 seconds
[2024-09-22T15:35:41.985+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:35:41.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:35:41.989+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:35:41.989+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:35:42.008+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:35:42.032+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:35:42.031+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:35:42.046+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:35:42.046+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:35:42.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T15:36:12.179+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:36:12.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:36:12.182+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:36:12.182+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:36:12.200+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:36:12.225+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:36:12.225+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:36:12.240+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:36:12.240+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:36:12.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T15:36:42.685+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:36:42.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:36:42.689+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:36:42.689+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:36:42.708+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:36:42.731+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:36:42.731+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:36:42.745+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:36:42.745+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:36:42.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.208 seconds
[2024-09-22T15:37:13.151+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:37:13.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:37:13.154+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:37:13.154+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:37:13.171+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:37:13.193+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:37:13.193+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:37:13.334+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:37:13.333+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:37:13.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.209 seconds
[2024-09-22T15:37:43.587+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:37:43.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:37:43.590+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:37:43.590+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:37:43.661+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:37:43.813+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:37:43.813+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:37:43.826+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:37:43.826+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:37:43.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.263 seconds
[2024-09-22T15:38:14.073+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:38:14.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:38:14.214+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:38:14.214+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:38:14.231+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:38:14.249+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:38:14.249+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:38:14.261+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:38:14.261+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:38:14.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.210 seconds
[2024-09-22T15:38:44.622+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:38:44.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:38:44.626+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:38:44.625+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:38:44.643+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:38:44.667+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:38:44.667+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:38:44.681+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:38:44.681+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:38:44.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.084 seconds
[2024-09-22T15:39:14.894+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:39:14.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:39:14.898+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:39:14.898+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:39:14.919+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:39:14.948+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:39:14.948+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:39:14.962+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:39:14.961+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:39:14.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.094 seconds
[2024-09-22T15:39:45.143+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:39:45.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:39:45.147+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:39:45.146+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:39:45.163+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:39:45.187+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:39:45.186+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:39:45.201+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:39:45.201+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:39:45.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.086 seconds
[2024-09-22T15:40:15.336+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:40:15.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:40:15.340+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:40:15.340+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:40:15.357+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:40:15.380+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:40:15.380+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:40:15.393+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:40:15.393+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:40:15.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.083 seconds
[2024-09-22T15:40:45.630+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:40:45.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:40:45.634+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:40:45.633+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:40:45.651+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:40:45.673+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:40:45.673+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:40:45.687+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:40:45.686+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:40:45.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.086 seconds
[2024-09-22T15:41:15.871+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:41:15.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:41:15.874+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:41:15.874+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:41:15.896+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:41:15.922+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:41:15.921+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:41:15.936+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:41:15.936+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:41:15.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.093 seconds
[2024-09-22T15:41:46.276+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:41:46.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:41:46.279+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:41:46.279+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:41:46.298+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:41:46.321+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:41:46.321+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:41:46.334+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:41:46.334+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:41:46.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.086 seconds
[2024-09-22T15:42:16.675+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:42:16.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:42:16.678+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:42:16.678+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:42:16.698+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:42:16.725+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:42:16.725+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:42:16.740+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:42:16.740+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:42:16.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T15:42:47.015+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:42:47.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:42:47.019+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:42:47.018+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:42:47.037+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:42:47.064+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:42:47.063+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:42:47.078+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:42:47.078+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:42:47.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.091 seconds
[2024-09-22T15:43:17.504+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:43:17.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:43:17.508+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:43:17.508+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:43:17.527+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:43:17.551+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:43:17.551+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:43:17.565+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:43:17.564+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:43:17.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T15:43:47.891+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:43:47.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:43:47.895+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:43:47.895+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:43:47.912+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:43:47.936+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:43:47.936+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:43:47.950+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:43:47.950+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:43:47.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.089 seconds
[2024-09-22T15:44:18.172+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:44:18.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:44:18.175+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:44:18.175+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:44:18.193+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:44:18.217+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:44:18.216+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:44:18.231+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:44:18.231+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:44:18.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.085 seconds
[2024-09-22T15:44:48.427+0000] {processor.py:186} INFO - Started process (PID=334) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:44:48.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:44:48.431+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:44:48.431+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:44:48.449+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:44:48.473+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:44:48.473+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:44:48.488+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:44:48.488+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:44:48.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.089 seconds
[2024-09-22T15:45:18.815+0000] {processor.py:186} INFO - Started process (PID=347) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:45:18.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:45:18.818+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:45:18.818+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:45:18.837+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:45:18.860+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:45:18.860+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:45:18.874+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:45:18.874+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:45:18.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T15:45:49.070+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:45:49.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:45:49.073+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:45:49.073+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:45:49.090+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:45:49.114+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:45:49.114+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:45:49.128+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:45:49.128+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:45:49.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.085 seconds
[2024-09-22T15:46:19.264+0000] {processor.py:186} INFO - Started process (PID=373) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:46:19.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:46:19.268+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:46:19.268+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:46:19.286+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:46:19.310+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:46:19.310+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:46:19.324+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:46:19.323+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:46:19.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T15:46:49.461+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:46:49.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:46:49.465+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:46:49.464+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:46:49.481+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:46:49.504+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:46:49.504+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:46:49.519+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:46:49.519+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:46:49.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T15:47:59.670+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:47:59.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:47:59.674+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:47:59.674+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:47:59.710+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:47:59.749+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:47:59.748+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:47:59.764+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:47:59.764+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:47:59.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.129 seconds
[2024-09-22T15:48:29.925+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:48:29.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:48:29.929+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:48:29.928+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:48:29.946+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:48:29.975+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:48:29.975+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:48:29.990+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:48:29.990+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:48:30.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T15:49:00.313+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:49:00.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:49:00.317+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:49:00.316+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:49:00.341+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:49:00.367+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:49:00.367+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:49:00.381+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:49:00.381+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:49:00.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.097 seconds
[2024-09-22T15:49:30.584+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:49:30.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:49:30.588+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:49:30.588+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:49:30.605+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:49:30.629+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:49:30.629+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:49:30.644+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:49:30.644+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:49:30.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T15:50:00.747+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:50:00.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:50:00.750+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:50:00.750+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:50:00.768+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:50:00.793+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:50:00.793+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:50:00.806+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:50:00.806+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:50:00.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.084 seconds
[2024-09-22T15:50:30.966+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:50:30.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:50:30.970+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:50:30.969+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:50:30.987+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:50:31.011+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:50:31.011+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:50:31.025+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:50:31.024+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:50:31.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.084 seconds
[2024-09-22T15:51:01.252+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:51:01.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:51:01.255+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:51:01.255+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:51:01.272+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:51:01.304+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:51:01.303+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:51:01.439+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:51:01.438+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:51:01.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.211 seconds
[2024-09-22T15:51:31.658+0000] {processor.py:186} INFO - Started process (PID=142) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:51:31.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:51:31.661+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:51:31.661+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:51:31.678+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:51:31.818+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:51:31.818+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:51:31.830+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:51:31.829+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:51:31.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.196 seconds
[2024-09-22T15:52:01.953+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:52:01.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:52:01.956+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:52:01.956+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:52:02.101+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:52:02.125+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:52:02.125+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:52:02.137+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:52:02.137+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:52:02.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.207 seconds
[2024-09-22T15:52:32.573+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:52:32.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:52:32.576+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:52:32.576+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:52:32.593+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:52:32.616+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:52:32.616+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:52:32.630+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:52:32.629+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:52:32.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.083 seconds
[2024-09-22T15:53:03.098+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:53:03.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:53:03.101+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:53:03.101+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:53:03.120+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:53:03.145+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:53:03.144+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:53:03.158+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:53:03.158+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:53:03.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.090 seconds
[2024-09-22T15:53:33.504+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:53:33.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:53:33.510+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:53:33.510+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:53:33.532+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:53:33.558+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:53:33.557+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:53:33.575+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:53:33.575+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:53:33.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T15:54:03.667+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:54:03.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:54:03.670+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:54:03.670+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:54:03.691+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:54:03.724+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:54:03.724+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:54:03.742+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:54:03.741+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:54:03.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T15:54:34.086+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:54:34.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:54:34.089+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:54:34.089+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:54:34.106+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:54:34.131+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:54:34.130+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:54:34.149+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:54:34.149+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:54:34.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T15:55:04.334+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:55:04.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:55:04.341+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:55:04.341+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:55:04.367+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:55:04.397+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:55:04.397+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:55:04.415+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:55:04.414+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:55:04.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T15:55:34.779+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:55:34.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:55:34.785+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:55:34.783+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:55:34.800+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:55:34.828+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:55:34.828+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:55:34.842+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:55:34.842+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:55:34.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T15:56:05.903+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:56:05.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:56:05.906+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:56:05.906+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:56:05.923+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:56:05.948+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:56:05.947+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:56:05.962+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:56:05.962+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:56:05.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T15:56:36.349+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:56:36.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:56:36.353+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:56:36.352+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:56:36.370+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:56:36.394+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:56:36.394+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:56:36.408+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:56:36.408+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:56:36.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.086 seconds
[2024-09-22T15:57:06.482+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:57:06.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:57:06.486+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:57:06.486+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:57:06.504+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:57:06.527+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:57:06.527+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:57:06.542+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:57:06.542+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:57:06.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.086 seconds
[2024-09-22T15:57:36.647+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:57:36.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:57:36.651+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:57:36.651+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:57:36.667+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:57:36.690+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:57:36.690+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:57:36.704+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:57:36.704+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:57:36.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.082 seconds
[2024-09-22T15:58:06.890+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:58:06.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:58:06.893+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:58:06.893+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:58:06.909+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:58:06.932+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:58:06.931+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:58:06.946+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:58:06.945+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:58:06.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.084 seconds
[2024-09-22T15:58:37.072+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:58:37.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:58:37.075+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:58:37.075+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:58:37.094+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:58:37.118+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:58:37.117+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:58:37.131+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:58:37.131+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:58:37.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T15:59:07.335+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:59:07.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:59:07.338+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:59:07.338+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:59:07.356+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:59:07.381+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:59:07.380+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:59:07.397+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:59:07.396+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:59:07.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.089 seconds
[2024-09-22T15:59:38.237+0000] {processor.py:186} INFO - Started process (PID=358) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:59:38.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T15:59:38.242+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:59:38.242+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:59:38.259+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T15:59:38.283+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:59:38.283+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T15:59:38.297+0000] {logging_mixin.py:190} INFO - [2024-09-22T15:59:38.297+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T15:59:38.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.085 seconds
[2024-09-22T16:00:08.434+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:00:08.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:00:08.439+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:00:08.438+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:00:08.454+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:00:08.477+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:00:08.477+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:00:08.491+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:00:08.491+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:00:08.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.085 seconds
[2024-09-22T16:00:38.586+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:00:38.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:00:38.589+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:00:38.589+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:00:38.608+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:00:38.630+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:00:38.630+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:00:38.644+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:00:38.644+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:00:38.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.085 seconds
[2024-09-22T16:01:08.812+0000] {processor.py:186} INFO - Started process (PID=397) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:01:08.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:01:08.815+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:01:08.815+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:01:08.833+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:01:08.855+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:01:08.855+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:01:08.868+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:01:08.868+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:01:08.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.082 seconds
[2024-09-22T16:01:38.992+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:01:38.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:01:38.995+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:01:38.995+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:01:39.011+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:01:39.036+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:01:39.036+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:01:39.052+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:01:39.051+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:01:39.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.086 seconds
[2024-09-22T16:02:09.832+0000] {processor.py:186} INFO - Started process (PID=423) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:02:09.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:02:09.836+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:02:09.835+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:02:09.854+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:02:09.879+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:02:09.878+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:02:09.894+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:02:09.894+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:02:09.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T16:02:40.103+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:02:40.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:02:40.107+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:02:40.107+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:02:40.126+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:02:40.152+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:02:40.152+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:02:40.166+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:02:40.165+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:02:40.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T16:03:10.501+0000] {processor.py:186} INFO - Started process (PID=449) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:03:10.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:03:10.504+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:03:10.504+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:03:10.522+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:03:10.547+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:03:10.546+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:03:10.562+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:03:10.561+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:03:10.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.092 seconds
[2024-09-22T16:03:40.802+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:03:40.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:03:40.806+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:03:40.805+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:03:40.823+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:03:40.847+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:03:40.847+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:03:40.862+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:03:40.862+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:03:40.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T16:04:41.404+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:04:41.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:04:41.407+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:04:41.407+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:04:41.449+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:04:41.505+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:04:41.505+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:04:41.519+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:04:41.519+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:04:41.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.143 seconds
[2024-09-22T16:05:12.465+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:05:12.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:05:12.468+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:05:12.467+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:05:12.484+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:05:12.509+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:05:12.509+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:05:12.523+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:05:12.523+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:05:12.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.084 seconds
[2024-09-22T16:05:42.962+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:05:42.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:05:42.965+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:05:42.965+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:05:42.985+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:05:43.009+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:05:43.009+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:05:43.023+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:05:43.023+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:05:43.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T16:06:13.352+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:06:13.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:06:13.356+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:06:13.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:06:13.372+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:06:13.397+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:06:13.396+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:06:13.411+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:06:13.411+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:06:13.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.084 seconds
[2024-09-22T16:06:43.543+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:06:43.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:06:43.546+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:06:43.546+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:06:43.562+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:06:43.585+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:06:43.585+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:06:43.598+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:06:43.598+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:06:43.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.081 seconds
[2024-09-22T16:07:13.991+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:07:13.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:07:13.994+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:07:13.994+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:07:14.018+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:07:14.046+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:07:14.046+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:07:14.063+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:07:14.063+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:07:14.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.234 seconds
[2024-09-22T16:07:44.345+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:07:44.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:07:44.348+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:07:44.347+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:07:44.366+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:07:44.390+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:07:44.389+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:07:44.528+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:07:44.528+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:07:44.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.211 seconds
[2024-09-22T16:08:14.635+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:08:14.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:08:14.638+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:08:14.638+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:08:14.655+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:08:14.814+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:08:14.813+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:08:14.827+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:08:14.826+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:08:14.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.218 seconds
[2024-09-22T16:09:05.105+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:09:05.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:09:05.108+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:09:05.108+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:09:05.143+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:09:05.178+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:09:05.178+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:09:05.191+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:09:05.191+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:09:05.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T16:09:35.294+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:09:35.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:09:35.297+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:09:35.297+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:09:35.315+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:09:35.341+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:09:35.341+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:09:35.356+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:09:35.355+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:09:35.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T16:10:05.810+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:10:05.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:10:05.813+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:10:05.812+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:10:05.831+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:10:05.856+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:10:05.856+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:10:05.872+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:10:05.872+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:10:05.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.091 seconds
[2024-09-22T16:10:36.169+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:10:36.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:10:36.172+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:10:36.172+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:10:36.192+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:10:36.219+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:10:36.219+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:10:36.235+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:10:36.234+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:10:36.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.091 seconds
[2024-09-22T16:11:06.438+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:11:06.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:11:06.442+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:11:06.442+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:11:06.458+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:11:06.486+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:11:06.486+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:11:06.504+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:11:06.504+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:11:06.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.095 seconds
[2024-09-22T16:11:36.674+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:11:36.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:11:36.677+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:11:36.677+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:11:36.694+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:11:36.716+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:11:36.716+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:11:36.730+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:11:36.729+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:11:36.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.088 seconds
[2024-09-22T16:12:07.150+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:07.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:12:07.153+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:12:07.153+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:07.169+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:07.191+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:12:07.191+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:12:07.328+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:12:07.328+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:12:07.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.205 seconds
[2024-09-22T16:12:20.057+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:20.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:12:20.060+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:12:20.060+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:20.079+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:12:20.077+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:12:20.080+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:20.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T16:12:26.238+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:26.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:12:26.241+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:12:26.241+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:26.261+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:12:26.259+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:12:26.262+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:26.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T16:12:31.321+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:31.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:12:31.325+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:12:31.325+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:31.347+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:12:31.345+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:12:31.347+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:12:31.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.052 seconds
[2024-09-22T16:13:01.828+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:13:01.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:13:01.831+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:13:01.831+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:13:01.844+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:13:01.842+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:13:01.845+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:13:01.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.169 seconds
[2024-09-22T16:13:25.858+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:13:25.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:13:25.861+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:13:25.861+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:13:25.886+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:13:26.095+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:13:26.095+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:13:26.115+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:13:26.115+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-22 00:00:00+00:00
[2024-09-22T16:13:26.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.293 seconds
[2024-09-22T16:15:22.453+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:15:22.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:15:22.457+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:15:22.456+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:15:22.496+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:15:22.493+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:15:22.501+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:15:22.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.087 seconds
[2024-09-22T16:15:52.854+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:15:52.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:15:52.858+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:15:52.857+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:15:52.876+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:15:52.873+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:15:52.876+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:15:52.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.051 seconds
[2024-09-22T16:16:23.243+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:16:23.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:16:23.249+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:16:23.248+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:16:23.263+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:16:23.261+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:16:23.263+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:16:23.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T16:16:53.355+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:16:53.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:16:53.357+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:16:53.357+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:16:53.369+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:16:53.367+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:16:53.370+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:16:53.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.041 seconds
[2024-09-22T16:17:23.726+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:17:23.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:17:23.728+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:17:23.728+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:17:23.742+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:17:23.740+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:17:23.743+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:17:23.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T16:17:53.849+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:17:53.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:17:53.851+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:17:53.851+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:17:53.867+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:17:53.865+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:17:53.870+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:17:53.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.051 seconds
[2024-09-22T16:18:24.248+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:18:24.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:18:24.250+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:18:24.250+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:18:24.265+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:18:24.263+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:18:24.265+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:18:24.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T16:18:54.369+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:18:54.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:18:54.371+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:18:54.371+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:18:54.385+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:18:54.383+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:18:54.386+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:18:54.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T16:19:24.545+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:19:24.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:19:24.668+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:19:24.667+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:19:24.680+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:19:24.678+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:19:24.681+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:19:24.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.157 seconds
[2024-09-22T16:19:54.946+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:19:54.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:19:54.949+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:19:54.948+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:19:54.964+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:19:54.961+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:19:54.964+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:19:54.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T16:20:25.104+0000] {processor.py:186} INFO - Started process (PID=189) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:20:25.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:20:25.106+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:20:25.106+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:20:25.122+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:20:25.119+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:20:25.122+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:20:25.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T16:20:55.213+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:20:55.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:20:55.216+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:20:55.215+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:20:55.230+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:20:55.228+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:20:55.231+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:20:55.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T16:21:25.325+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:21:25.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:21:25.327+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:21:25.327+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:21:25.339+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:21:25.336+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:21:25.340+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:21:25.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.040 seconds
[2024-09-22T16:21:55.404+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:21:55.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:21:55.407+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:21:55.406+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:21:55.503+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:21:55.500+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:21:55.503+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:21:55.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.131 seconds
[2024-09-22T16:22:25.682+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:22:25.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:22:25.684+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:22:25.684+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:22:25.720+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:22:25.717+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:22:25.721+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:22:25.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.063 seconds
[2024-09-22T16:22:55.991+0000] {processor.py:186} INFO - Started process (PID=254) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:22:55.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:22:55.993+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:22:55.992+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:22:56.008+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:22:56.006+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:22:56.009+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:22:56.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.044 seconds
[2024-09-22T16:23:26.926+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:23:26.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:23:26.929+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:23:26.929+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:23:26.942+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:23:26.940+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:23:26.942+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:23:26.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.042 seconds
[2024-09-22T16:23:57.867+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:23:57.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:23:57.870+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:23:57.869+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:23:57.886+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:23:57.883+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:23:57.887+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:23:57.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T16:24:28.668+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:24:28.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:24:28.670+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:24:28.670+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:24:28.687+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:24:28.684+0000] {dagbag.py:483} ERROR - Failed to bag_dag: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 852, in validate_executor_field
    ExecutorLoader.lookup_executor_name_by_str(task.executor)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/executors/executor_loader.py", line 211, in lookup_executor_name_by_str
    raise UnknownExecutorException(f"Unknown executor being loaded: {executor_name_str}")
airflow.exceptions.UnknownExecutorException: Unknown executor being loaded: local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 478, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 843, in validate
    self.validate_executor_field()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 854, in validate_executor_field
    raise UnknownExecutorException(
airflow.exceptions.UnknownExecutorException: The specified executor local for task submit_spark_job is not configured. Review the core.executors Airflow configuration to add it or update the executor configuration for this task.
[2024-09-22T16:24:28.688+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:24:28.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T16:24:58.606+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:24:58.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:24:58.608+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:24:58.608+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:24:58.633+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:24:58.852+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:24:58.852+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:24:58.874+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:24:58.874+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:24:58.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.305 seconds
[2024-09-22T16:27:37.784+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:27:37.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:27:37.792+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:27:37.791+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:27:37.815+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:27:37.865+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:27:37.865+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:27:37.915+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:27:37.914+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:27:38.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.374 seconds
[2024-09-22T16:28:08.607+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:28:08.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:28:08.610+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:28:08.610+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:28:08.647+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:28:08.675+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:28:08.675+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:28:08.831+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:28:08.830+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:28:08.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.252 seconds
[2024-09-22T16:28:38.930+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:28:38.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:28:38.938+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:28:38.937+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:28:38.970+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:28:39.127+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:28:39.127+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:28:39.149+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:28:39.149+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:28:39.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.247 seconds
[2024-09-22T16:29:09.518+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:29:09.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:29:09.522+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:29:09.522+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:29:09.551+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:29:09.576+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:29:09.576+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:29:09.600+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:29:09.600+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:29:09.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T16:29:40.517+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:29:40.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:29:40.520+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:29:40.520+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:29:40.543+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:29:40.567+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:29:40.566+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:29:40.590+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:29:40.590+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:29:40.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T16:30:10.800+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:30:10.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:30:10.804+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:30:10.803+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:30:10.830+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:30:10.857+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:30:10.857+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:30:10.882+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:30:10.882+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:30:10.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T16:30:41.414+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:30:41.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:30:41.421+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:30:41.421+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:30:41.458+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:30:41.493+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:30:41.493+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:30:41.522+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:30:41.522+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:30:41.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.144 seconds
[2024-09-22T16:31:11.803+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:31:11.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:31:11.806+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:31:11.806+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:31:11.831+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:31:11.854+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:31:11.853+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:31:11.875+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:31:11.875+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to None, run_after=None
[2024-09-22T16:31:11.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T16:31:27.615+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:31:27.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:31:27.619+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:31:27.619+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:31:27.654+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:31:27.770+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:31:27.770+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:31:27.791+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:31:27.791+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:31:27.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.214 seconds
[2024-09-22T16:32:26.287+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:32:26.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:32:26.296+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:32:26.296+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:32:26.335+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:32:26.385+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:32:26.385+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:32:26.420+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:32:26.419+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:32:26.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.352 seconds
[2024-09-22T16:32:57.173+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:32:57.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:32:57.178+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:32:57.178+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:32:57.220+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:32:57.251+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:32:57.251+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:32:57.471+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:32:57.470+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:32:57.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.332 seconds
[2024-09-22T16:33:27.644+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:33:27.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:33:27.649+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:33:27.649+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:33:27.673+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:33:27.820+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:33:27.820+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:33:27.843+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:33:27.843+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:33:27.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.224 seconds
[2024-09-22T16:33:58.254+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:33:58.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:33:58.257+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:33:58.257+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:33:58.282+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:33:58.308+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:33:58.308+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:33:58.332+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:33:58.331+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:33:58.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T16:34:28.556+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:34:28.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:34:28.559+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:34:28.559+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:34:28.584+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:34:28.607+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:34:28.607+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:34:28.634+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:34:28.634+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:34:28.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T16:34:58.758+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:34:58.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:34:58.761+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:34:58.761+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:34:58.786+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:34:58.810+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:34:58.809+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:34:58.834+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:34:58.833+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:34:58.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T16:35:29.075+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:35:29.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:35:29.078+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:35:29.078+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:35:29.103+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:35:29.129+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:35:29.128+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:35:29.153+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:35:29.153+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:35:29.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T16:35:59.344+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:35:59.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:35:59.348+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:35:59.348+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:35:59.372+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:35:59.396+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:35:59.396+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:35:59.420+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:35:59.420+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:35:59.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T16:36:29.681+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:36:29.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:36:29.684+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:36:29.683+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:36:29.714+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:36:29.738+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:36:29.738+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:36:29.761+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:36:29.761+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:36:29.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T16:37:00.067+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:37:00.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:37:00.070+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:37:00.070+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:37:00.097+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:37:00.122+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:37:00.122+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:37:00.147+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:37:00.147+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:37:00.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T16:37:30.358+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:37:30.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:37:30.361+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:37:30.361+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:37:30.386+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:37:30.409+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:37:30.409+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:37:30.433+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:37:30.433+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:37:30.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T16:38:00.591+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:38:00.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:38:00.595+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:38:00.595+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:38:00.623+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:38:00.646+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:38:00.646+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:38:00.669+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:38:00.669+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:38:00.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T16:38:31.053+0000] {processor.py:186} INFO - Started process (PID=211) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:38:31.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:38:31.057+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:38:31.057+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:38:31.081+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:38:31.105+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:38:31.105+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:38:31.128+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:38:31.128+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:38:31.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T16:39:01.210+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:39:01.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:39:01.214+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:39:01.214+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:39:01.241+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:39:01.265+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:39:01.265+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:39:01.290+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:39:01.289+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:39:01.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T16:39:31.379+0000] {processor.py:186} INFO - Started process (PID=238) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:39:31.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:39:31.382+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:39:31.381+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:39:31.407+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:39:31.430+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:39:31.430+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:39:31.454+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:39:31.454+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:39:31.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T16:40:01.613+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:40:01.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:40:01.616+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:40:01.615+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:40:01.642+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:40:01.666+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:40:01.665+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:40:01.689+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:40:01.689+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:40:01.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T16:40:31.980+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:40:31.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:40:31.983+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:40:31.983+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:40:32.012+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:40:32.036+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:40:32.036+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:40:32.061+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:40:32.061+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:40:32.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T16:41:02.337+0000] {processor.py:186} INFO - Started process (PID=277) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:41:02.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:41:02.342+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:41:02.341+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:41:02.369+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:41:02.397+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:41:02.396+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:41:02.423+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:41:02.423+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:41:02.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T16:41:32.541+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:41:32.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:41:32.545+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:41:32.544+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:41:32.574+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:41:32.602+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:41:32.602+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:41:32.629+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:41:32.629+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:41:32.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T16:42:02.885+0000] {processor.py:186} INFO - Started process (PID=304) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:42:02.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:42:02.889+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:42:02.889+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:42:02.917+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:42:02.943+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:42:02.943+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:42:02.969+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:42:02.969+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:42:02.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T16:42:33.057+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:42:33.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:42:33.060+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:42:33.060+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:42:33.084+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:42:33.106+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:42:33.106+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:42:33.131+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:42:33.131+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:42:33.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T16:43:03.274+0000] {processor.py:186} INFO - Started process (PID=329) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:43:03.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:43:03.278+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:43:03.278+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:43:03.301+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:43:03.325+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:43:03.325+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:43:03.350+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:43:03.350+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:43:03.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T16:43:33.724+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:43:33.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:43:33.728+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:43:33.728+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:43:33.753+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:43:33.777+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:43:33.777+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:43:33.804+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:43:33.803+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:43:33.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T16:44:04.090+0000] {processor.py:186} INFO - Started process (PID=354) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:44:04.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:44:04.094+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:44:04.094+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:44:04.119+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:44:04.144+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:44:04.143+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:44:04.168+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:44:04.168+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:44:04.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T16:44:34.369+0000] {processor.py:186} INFO - Started process (PID=367) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:44:34.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:44:34.372+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:44:34.372+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:44:34.398+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:44:34.421+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:44:34.421+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:44:34.445+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:44:34.444+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:44:34.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T16:45:04.641+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:45:04.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:45:04.644+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:45:04.644+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:45:04.671+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:45:04.694+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:45:04.694+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:45:04.717+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:45:04.717+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:45:04.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T16:45:34.929+0000] {processor.py:186} INFO - Started process (PID=394) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:45:34.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:45:34.932+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:45:34.932+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:45:34.957+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:45:34.979+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:45:34.979+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:45:35.002+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:45:35.002+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:45:35.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T16:46:05.134+0000] {processor.py:186} INFO - Started process (PID=407) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:46:05.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:46:05.138+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:46:05.137+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:46:05.162+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:46:05.185+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:46:05.185+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:46:05.210+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:46:05.210+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:46:05.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T16:46:35.377+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:46:35.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:46:35.381+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:46:35.381+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:46:35.404+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:46:35.427+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:46:35.427+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:46:35.451+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:46:35.450+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:46:35.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T16:47:05.645+0000] {processor.py:186} INFO - Started process (PID=433) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:47:05.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:47:05.649+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:47:05.649+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:47:05.674+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:47:05.698+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:47:05.698+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:47:05.720+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:47:05.720+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:47:05.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T16:47:36.086+0000] {processor.py:186} INFO - Started process (PID=445) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:47:36.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:47:36.089+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:47:36.088+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:47:36.115+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:47:36.138+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:47:36.138+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:47:36.163+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:47:36.162+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:47:36.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T16:48:06.403+0000] {processor.py:186} INFO - Started process (PID=458) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:48:06.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:48:06.406+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:48:06.406+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:48:06.433+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:48:06.457+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:48:06.456+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:48:06.481+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:48:06.481+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:48:06.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T16:48:36.638+0000] {processor.py:186} INFO - Started process (PID=471) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:48:36.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:48:36.642+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:48:36.642+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:48:36.668+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:48:36.693+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:48:36.693+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:48:36.721+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:48:36.721+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:48:36.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T16:49:06.826+0000] {processor.py:186} INFO - Started process (PID=484) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:49:06.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:49:06.830+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:49:06.830+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:49:06.856+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:49:06.879+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:49:06.879+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:49:06.902+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:49:06.902+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:49:06.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T16:49:37.102+0000] {processor.py:186} INFO - Started process (PID=497) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:49:37.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:49:37.105+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:49:37.105+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:49:37.131+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:49:37.155+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:49:37.155+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:49:37.178+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:49:37.178+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:49:37.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T16:50:07.542+0000] {processor.py:186} INFO - Started process (PID=510) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:50:07.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:50:07.545+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:50:07.545+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:50:07.570+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:50:07.593+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:50:07.593+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:50:07.617+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:50:07.617+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:50:07.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T16:50:37.780+0000] {processor.py:186} INFO - Started process (PID=523) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:50:37.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:50:37.783+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:50:37.783+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:50:37.811+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:50:37.835+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:50:37.835+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:50:37.858+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:50:37.858+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:50:37.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T16:51:08.157+0000] {processor.py:186} INFO - Started process (PID=536) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:51:08.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:51:08.161+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:51:08.161+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:51:08.186+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:51:08.209+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:51:08.208+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:51:08.231+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:51:08.231+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:51:08.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T16:51:38.374+0000] {processor.py:186} INFO - Started process (PID=550) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:51:38.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:51:38.378+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:51:38.378+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:51:38.403+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:51:38.432+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:51:38.432+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:51:38.459+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:51:38.459+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:51:38.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T16:52:08.870+0000] {processor.py:186} INFO - Started process (PID=563) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:52:08.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:52:08.873+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:52:08.873+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:52:08.899+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:52:08.923+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:52:08.923+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:52:08.949+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:52:08.949+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:52:08.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T16:52:39.288+0000] {processor.py:186} INFO - Started process (PID=576) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:52:39.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:52:39.292+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:52:39.291+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:52:39.319+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:52:39.343+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:52:39.343+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:52:39.367+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:52:39.367+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:52:39.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T16:53:09.765+0000] {processor.py:186} INFO - Started process (PID=589) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:53:09.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:53:09.769+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:53:09.769+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:53:09.797+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:53:09.820+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:53:09.820+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:53:09.843+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:53:09.843+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:53:09.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T16:53:40.011+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:53:40.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:53:40.016+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:53:40.015+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:53:40.043+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:53:40.067+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:53:40.067+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:53:40.091+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:53:40.091+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:53:40.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T16:54:10.213+0000] {processor.py:186} INFO - Started process (PID=616) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:54:10.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:54:10.217+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:54:10.216+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:54:10.240+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:54:10.263+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:54:10.263+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:54:10.287+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:54:10.287+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:54:10.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T16:54:40.459+0000] {processor.py:186} INFO - Started process (PID=628) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:54:40.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:54:40.462+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:54:40.462+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:54:40.490+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:54:40.513+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:54:40.513+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:54:40.537+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:54:40.537+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:54:40.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T16:55:10.887+0000] {processor.py:186} INFO - Started process (PID=641) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:55:10.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:55:10.890+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:55:10.890+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:55:10.915+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:55:10.938+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:55:10.938+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:55:10.961+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:55:10.961+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:55:10.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T16:55:41.132+0000] {processor.py:186} INFO - Started process (PID=655) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:55:41.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:55:41.135+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:55:41.135+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:55:41.160+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:55:41.184+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:55:41.184+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:55:41.208+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:55:41.207+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:55:41.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T16:56:11.308+0000] {processor.py:186} INFO - Started process (PID=668) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:56:11.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:56:11.312+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:56:11.312+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:56:11.340+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:56:11.362+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:56:11.362+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:56:11.384+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:56:11.384+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:56:11.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T16:56:41.537+0000] {processor.py:186} INFO - Started process (PID=680) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:56:41.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:56:41.541+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:56:41.541+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:56:41.566+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:56:41.590+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:56:41.590+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:56:41.614+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:56:41.614+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:56:41.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T16:57:11.803+0000] {processor.py:186} INFO - Started process (PID=693) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:57:11.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:57:11.808+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:57:11.807+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:57:11.835+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:57:11.859+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:57:11.859+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:57:11.884+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:57:11.883+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:57:11.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T16:57:41.976+0000] {processor.py:186} INFO - Started process (PID=706) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:57:41.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:57:41.979+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:57:41.979+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:57:42.010+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:57:42.034+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:57:42.034+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:57:42.057+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:57:42.057+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:57:42.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T16:58:12.234+0000] {processor.py:186} INFO - Started process (PID=719) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:58:12.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:58:12.238+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:58:12.237+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:58:12.263+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:58:12.286+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:58:12.286+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:58:12.310+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:58:12.310+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:58:12.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T16:58:42.405+0000] {processor.py:186} INFO - Started process (PID=732) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:58:42.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:58:42.408+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:58:42.408+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:58:42.435+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:58:42.460+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:58:42.459+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:58:42.485+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:58:42.485+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:58:42.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T16:59:12.632+0000] {processor.py:186} INFO - Started process (PID=745) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:59:12.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:59:12.635+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:59:12.635+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:59:12.662+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:59:12.685+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:59:12.685+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:59:12.708+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:59:12.708+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:59:12.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T16:59:43.194+0000] {processor.py:186} INFO - Started process (PID=758) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:59:43.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T16:59:43.198+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:59:43.197+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:59:43.228+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T16:59:43.254+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:59:43.254+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T16:59:43.283+0000] {logging_mixin.py:190} INFO - [2024-09-22T16:59:43.282+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T16:59:43.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.125 seconds
[2024-09-22T17:00:13.656+0000] {processor.py:186} INFO - Started process (PID=771) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:00:13.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:00:13.659+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:00:13.659+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:00:13.693+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:00:13.726+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:00:13.726+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:00:13.759+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:00:13.759+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:00:13.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.142 seconds
[2024-09-22T17:00:44.611+0000] {processor.py:186} INFO - Started process (PID=784) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:00:44.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:00:44.615+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:00:44.615+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:00:44.644+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:00:44.668+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:00:44.668+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:00:44.693+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:00:44.692+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:00:44.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T17:01:15.542+0000] {processor.py:186} INFO - Started process (PID=797) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:01:15.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:01:15.546+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:01:15.546+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:01:15.571+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:01:15.594+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:01:15.594+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:01:15.618+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:01:15.618+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:01:15.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T17:01:46.468+0000] {processor.py:186} INFO - Started process (PID=810) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:01:46.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:01:46.472+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:01:46.471+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:01:46.507+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:01:46.533+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:01:46.533+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:01:46.558+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:01:46.558+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:01:46.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.123 seconds
[2024-09-22T17:02:17.396+0000] {processor.py:186} INFO - Started process (PID=823) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:02:17.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:02:17.400+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:02:17.400+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:02:17.433+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:02:17.459+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:02:17.459+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:02:17.484+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:02:17.484+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:02:17.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T17:02:47.638+0000] {processor.py:186} INFO - Started process (PID=836) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:02:47.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:02:47.642+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:02:47.642+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:02:47.667+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:02:47.691+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:02:47.691+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:02:47.715+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:02:47.715+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:02:47.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T17:03:17.784+0000] {processor.py:186} INFO - Started process (PID=849) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:03:17.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:03:17.788+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:03:17.788+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:03:17.814+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:03:17.838+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:03:17.838+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:03:17.864+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:03:17.863+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:03:17.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T17:03:48.325+0000] {processor.py:186} INFO - Started process (PID=862) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:03:48.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:03:48.328+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:03:48.328+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:03:48.353+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:03:48.377+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:03:48.377+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:03:48.405+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:03:48.405+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:03:48.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T17:04:19.217+0000] {processor.py:186} INFO - Started process (PID=876) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:04:19.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:04:19.221+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:04:19.220+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:04:19.248+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:04:19.271+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:04:19.271+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:04:19.296+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:04:19.296+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:04:19.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T17:04:49.388+0000] {processor.py:186} INFO - Started process (PID=889) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:04:49.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:04:49.391+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:04:49.391+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:04:49.417+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:04:49.443+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:04:49.442+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:04:49.468+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:04:49.468+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:04:49.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T17:05:20.150+0000] {processor.py:186} INFO - Started process (PID=900) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:05:20.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:05:20.154+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:05:20.154+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:05:20.179+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:05:20.202+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:05:20.202+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:05:20.227+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:05:20.226+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:05:20.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T17:05:50.844+0000] {processor.py:186} INFO - Started process (PID=913) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:05:50.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:05:50.850+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:05:50.849+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:05:50.887+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:05:50.918+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:05:50.917+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:05:50.946+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:05:50.946+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:05:50.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.141 seconds
[2024-09-22T17:06:21.295+0000] {processor.py:186} INFO - Started process (PID=926) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:06:21.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:06:21.298+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:06:21.298+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:06:21.326+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:06:21.349+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:06:21.349+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:06:21.373+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:06:21.373+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:06:21.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T17:06:51.564+0000] {processor.py:186} INFO - Started process (PID=939) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:06:51.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:06:51.568+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:06:51.568+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:06:51.595+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:06:51.619+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:06:51.619+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:06:51.644+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:06:51.643+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:06:51.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T17:07:22.524+0000] {processor.py:186} INFO - Started process (PID=952) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:07:22.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:07:22.528+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:07:22.528+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:07:22.554+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:07:22.578+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:07:22.577+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:07:22.601+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:07:22.601+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:07:22.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T17:07:38.360+0000] {processor.py:186} INFO - Started process (PID=964) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:07:38.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:07:38.363+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:07:38.363+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:07:38.385+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:07:38.381+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 23, in <module>
    dag=dag
        ^^^
NameError: name 'dag' is not defined
[2024-09-22T17:07:38.387+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:07:38.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.055 seconds
[2024-09-22T17:08:08.717+0000] {processor.py:186} INFO - Started process (PID=977) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:08.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:08:08.721+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:08:08.721+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:08.735+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:08:08.732+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 23, in <module>
    dag=dag
        ^^^
NameError: name 'dag' is not defined
[2024-09-22T17:08:08.737+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:08.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T17:08:38.562+0000] {processor.py:186} INFO - Started process (PID=990) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:38.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:08:38.566+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:08:38.565+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:38.594+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:08:38.588+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    'retry_delay': timedelta(minutes=5),
                   ^^^^^^^^^
NameError: name 'timedelta' is not defined
[2024-09-22T17:08:38.598+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:38.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.064 seconds
[2024-09-22T17:08:44.759+0000] {processor.py:186} INFO - Started process (PID=992) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:44.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:08:44.763+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:08:44.763+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:44.795+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:44.954+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:08:44.953+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:08:44.973+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:08:44.973+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:08:45.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.250 seconds
[2024-09-22T17:08:56.168+0000] {processor.py:186} INFO - Started process (PID=994) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:56.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:08:56.172+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:08:56.172+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:56.204+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:08:56.216+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:08:56.216+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:08:56.241+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:08:56.240+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:08:56.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T17:10:29.993+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:10:29.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:10:29.998+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:10:29.997+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:10:30.040+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:10:30.376+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:10:30.376+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:10:30.726+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:10:30.726+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:10:30.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.827 seconds
[2024-09-22T17:11:00.893+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:11:00.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:11:00.897+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:11:00.897+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:11:00.919+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:11:00.957+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:11:00.957+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:11:00.983+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:11:00.983+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:11:01.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.147 seconds
[2024-09-22T17:11:32.002+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:11:32.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:11:32.005+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:11:32.005+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:11:32.027+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:11:32.057+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:11:32.056+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:11:32.079+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:11:32.079+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:11:32.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T17:12:02.422+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:12:02.423+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:12:02.428+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:12:02.427+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:12:02.461+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:12:02.504+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:12:02.504+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:12:02.533+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:12:02.533+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:12:02.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.154 seconds
[2024-09-22T17:12:32.995+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:12:32.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:12:32.999+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:12:32.998+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:12:33.015+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:12:33.040+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:12:33.040+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:12:33.063+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:12:33.063+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:12:33.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T17:13:03.352+0000] {processor.py:186} INFO - Started process (PID=122) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:13:03.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:13:03.355+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:13:03.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:13:03.373+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:13:03.398+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:13:03.398+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:13:03.554+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:13:03.554+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:13:03.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.228 seconds
[2024-09-22T17:15:55.799+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:15:55.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:15:55.802+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:15:55.802+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:15:55.826+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:15:55.868+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:15:55.867+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:15:55.893+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:15:55.893+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:15:55.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.122 seconds
[2024-09-22T17:16:26.140+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:16:26.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:16:26.143+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:16:26.143+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:16:26.161+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:16:26.187+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:16:26.186+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:16:26.209+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:16:26.209+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:16:26.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T17:16:56.314+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:16:56.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:16:56.318+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:16:56.317+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:16:56.337+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:16:56.361+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:16:56.360+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:16:56.383+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:16:56.383+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:16:56.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T17:17:26.575+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:17:26.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:17:26.580+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:17:26.580+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:17:26.599+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:17:26.626+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:17:26.625+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:17:26.650+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:17:26.649+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:17:26.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T17:17:57.185+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:17:57.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:17:57.190+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:17:57.189+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:17:57.210+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:17:57.243+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:17:57.243+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:17:57.266+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:17:57.266+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:17:57.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T17:18:27.888+0000] {processor.py:186} INFO - Started process (PID=122) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:18:27.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:18:27.892+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:18:27.892+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:18:27.910+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:18:27.936+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:18:27.936+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:18:27.960+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:18:27.960+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:18:28.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.235 seconds
[2024-09-22T17:18:59.073+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:18:59.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:18:59.077+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:18:59.076+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:18:59.097+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:18:59.125+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:18:59.124+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:18:59.295+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:18:59.295+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:18:59.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.317 seconds
[2024-09-22T17:19:29.576+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:19:29.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:19:29.584+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:19:29.584+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:19:29.611+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:19:29.821+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:19:29.821+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:19:29.845+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:19:29.845+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:19:29.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.344 seconds
[2024-09-22T17:20:00.164+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:20:00.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:20:00.167+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:20:00.167+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:20:00.316+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:20:00.338+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:20:00.338+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:20:00.359+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:20:00.358+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:20:00.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.222 seconds
[2024-09-22T17:20:30.476+0000] {processor.py:186} INFO - Started process (PID=175) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:20:30.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:20:30.480+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:20:30.480+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:20:30.499+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:20:30.522+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:20:30.522+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:20:30.545+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:20:30.545+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:20:30.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T17:21:01.504+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:21:01.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:21:01.508+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:21:01.508+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:21:01.528+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:21:01.552+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:21:01.552+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:21:01.575+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:21:01.575+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:21:01.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T17:21:31.678+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:21:31.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:21:31.684+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:21:31.683+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:21:31.702+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:21:31.727+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:21:31.726+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:21:31.751+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:21:31.751+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:21:31.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T17:22:37.859+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:22:37.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:22:37.863+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:22:37.863+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:22:37.902+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:22:37.945+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:22:37.945+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:22:37.976+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:22:37.976+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:22:38.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.152 seconds
[2024-09-22T17:23:08.132+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:23:08.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:23:08.135+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:23:08.135+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:23:08.153+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:23:08.180+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:23:08.179+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:23:08.202+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:23:08.202+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:23:08.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T17:23:38.370+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:23:38.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:23:38.373+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:23:38.373+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:23:38.393+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:23:38.418+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:23:38.418+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:23:38.442+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:23:38.441+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:23:38.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T17:24:08.892+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:24:08.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:24:08.896+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:24:08.895+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:24:08.916+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:24:08.940+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:24:08.940+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:24:08.964+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:24:08.963+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:24:08.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T17:24:39.447+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:24:39.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:24:39.451+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:24:39.451+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:24:39.469+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:24:39.493+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:24:39.493+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:24:39.516+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:24:39.516+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:24:39.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.099 seconds
[2024-09-22T17:25:10.111+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:25:10.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:25:10.114+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:25:10.114+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:25:10.133+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:25:10.158+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:25:10.158+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:25:10.310+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:25:10.310+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:25:10.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.225 seconds
[2024-09-22T17:25:40.531+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:25:40.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:25:40.534+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:25:40.533+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:25:40.551+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:25:40.575+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:25:40.574+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:25:40.720+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:25:40.719+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:25:40.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.213 seconds
[2024-09-22T17:26:10.824+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:26:10.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:26:10.828+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:26:10.827+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:26:10.846+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:26:11.001+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:26:11.001+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:26:11.022+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:26:11.021+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:26:11.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.224 seconds
[2024-09-22T17:26:41.212+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:26:41.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:26:41.335+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:26:41.335+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:26:41.351+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:26:41.370+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:26:41.369+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:26:41.388+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:26:41.388+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:26:41.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.199 seconds
[2024-09-22T17:27:12.088+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:27:12.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:27:12.092+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:27:12.092+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:27:12.111+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:27:12.136+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:27:12.136+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:27:12.158+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:27:12.158+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:27:12.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T17:27:42.289+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:27:42.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:27:42.297+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:27:42.296+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:27:42.315+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:27:42.338+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:27:42.338+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:27:42.366+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:27:42.365+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:27:42.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T17:28:12.561+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:28:12.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:28:12.564+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:28:12.564+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:28:12.583+0000] {processor.py:925} INFO - DAG(s) 'spark_example_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:28:12.608+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:28:12.608+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:28:12.632+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:28:12.631+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_example_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:28:12.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.129 seconds
[2024-09-22T17:28:41.615+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:28:41.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:28:41.619+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:28:41.619+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:28:41.645+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:28:41.640+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:28:41.646+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:28:41.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.059 seconds
[2024-09-22T17:28:51.185+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:28:51.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:28:51.189+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:28:51.189+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:28:51.215+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:28:51.210+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:28:51.216+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:28:51.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.060 seconds
[2024-09-22T17:29:53.255+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:29:53.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:29:53.263+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:29:53.263+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:29:53.291+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:29:53.285+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:29:53.293+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:29:53.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.076 seconds
[2024-09-22T17:30:23.466+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:30:23.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:30:23.470+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:30:23.469+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:30:23.488+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:30:23.483+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:30:23.489+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:30:23.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T17:30:53.602+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:30:53.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:30:53.604+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:30:53.604+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:30:53.621+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:30:53.617+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:30:53.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:30:53.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.172 seconds
[2024-09-22T17:31:24.016+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:31:24.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:31:24.018+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:31:24.018+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:31:24.037+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:31:24.031+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:31:24.038+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:31:24.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T17:31:54.309+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:31:54.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:31:54.311+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:31:54.311+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:31:54.332+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:31:54.327+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:31:54.333+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:31:54.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T17:32:24.521+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:32:24.522+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:32:24.523+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:32:24.523+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:32:24.542+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:32:24.537+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:32:24.543+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:32:24.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T17:32:54.741+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:32:54.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:32:54.743+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:32:54.743+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:32:54.763+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:32:54.758+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:32:54.764+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:32:54.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T17:33:24.962+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:33:24.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:33:24.965+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:33:24.964+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:33:24.982+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:33:24.978+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:33:24.983+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:33:25.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T17:33:55.917+0000] {processor.py:186} INFO - Started process (PID=157) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:33:55.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:33:55.919+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:33:55.919+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:33:55.939+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:33:55.933+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:33:55.940+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:33:55.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T17:34:26.846+0000] {processor.py:186} INFO - Started process (PID=170) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:34:26.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:34:26.848+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:34:26.848+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:34:26.868+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:34:26.862+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:34:26.869+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:34:26.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T17:43:05.202+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:43:05.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:43:05.206+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:43:05.206+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:43:05.224+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:43:05.220+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:43:05.225+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:43:05.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.052 seconds
[2024-09-22T17:43:35.687+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:43:35.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:43:35.693+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:43:35.692+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:43:35.715+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:43:35.709+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:43:35.716+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:43:35.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.079 seconds
[2024-09-22T17:44:06.121+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:06.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:44:06.124+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:06.124+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:06.145+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:06.140+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:44:06.146+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:06.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.055 seconds
[2024-09-22T17:44:15.819+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:15.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:44:15.822+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:15.822+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:15.838+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:15.837+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17
    spark_task = SparkSubmitOperator(
    ^^^^^^^^^^
IndentationError: expected an indented block after 'with' statement on line 15
[2024-09-22T17:44:15.839+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:15.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T17:44:46.232+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:46.233+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:44:46.235+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:46.235+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:46.251+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:46.250+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17
    spark_task = SparkSubmitOperator(
    ^^^^^^^^^^
IndentationError: expected an indented block after 'with' statement on line 15
[2024-09-22T17:44:46.252+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:46.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.045 seconds
[2024-09-22T17:44:55.339+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:55.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:44:55.342+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.341+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:55.368+0000] {processor.py:925} INFO - DAG(s) 'my_spark_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:44:55.631+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.629+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:my_spark_dag
[2024-09-22T17:44:55.658+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.657+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:my_spark_dag
[2024-09-22T17:44:55.668+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.668+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:my_spark_dag
[2024-09-22T17:44:55.682+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.681+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:my_spark_dag
[2024-09-22T17:44:55.692+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.692+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:my_spark_dag
[2024-09-22T17:44:55.702+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.701+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:my_spark_dag
[2024-09-22T17:44:55.710+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.710+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:my_spark_dag
[2024-09-22T17:44:55.711+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.711+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:44:55.724+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.724+0000] {dag.py:3252} INFO - Creating ORM DAG for my_spark_dag
[2024-09-22T17:44:55.732+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:44:55.732+0000] {dag.py:4156} INFO - Setting next_dagrun for my_spark_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:44:55.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.425 seconds
[2024-09-22T17:46:00.942+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:46:00.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:46:00.951+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:46:00.950+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:46:00.995+0000] {processor.py:925} INFO - DAG(s) 'my_spark_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:46:01.041+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:46:01.040+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:46:01.074+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:46:01.074+0000] {dag.py:4156} INFO - Setting next_dagrun for my_spark_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:46:01.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.166 seconds
[2024-09-22T17:46:23.314+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:46:23.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:46:23.319+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:46:23.318+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:46:23.341+0000] {processor.py:925} INFO - DAG(s) 'my_spark_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:46:23.375+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:46:23.375+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:46:23.402+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:46:23.402+0000] {dag.py:4156} INFO - Setting next_dagrun for my_spark_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:46:23.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.265 seconds
[2024-09-22T17:46:53.670+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:46:53.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:46:53.673+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:46:53.673+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:46:53.701+0000] {processor.py:925} INFO - DAG(s) 'my_spark_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:46:53.728+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:46:53.728+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:46:53.876+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:46:53.875+0000] {dag.py:4156} INFO - Setting next_dagrun for my_spark_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:46:53.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.232 seconds
[2024-09-22T17:47:16.548+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:47:16.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:47:16.551+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:47:16.551+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:47:16.577+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:47:16.571+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:47:16.578+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:47:16.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.061 seconds
[2024-09-22T17:48:17.202+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:48:17.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:48:17.205+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:48:17.205+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:48:17.224+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:48:17.220+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:48:17.225+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:48:17.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.067 seconds
[2024-09-22T17:48:47.705+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:48:47.706+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:48:47.708+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:48:47.708+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:48:47.726+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:48:47.722+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:48:47.727+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:48:47.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.053 seconds
[2024-09-22T17:49:17.902+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:49:17.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:49:17.904+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:49:17.904+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:49:17.921+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:49:17.917+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:49:17.921+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:49:18.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.205 seconds
[2024-09-22T17:49:48.563+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:49:48.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:49:48.567+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:49:48.566+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:49:48.583+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:49:48.578+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:49:48.584+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:49:48.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T17:50:19.087+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:50:19.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:50:19.090+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:50:19.089+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:50:19.112+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:50:19.105+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:50:19.113+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:50:19.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.057 seconds
[2024-09-22T17:50:49.208+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:50:49.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:50:49.211+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:50:49.210+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:50:49.226+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:50:49.222+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    spark_task = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_task). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:50:49.227+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:50:49.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T17:50:53.587+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:50:53.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:50:53.589+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:50:53.589+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:50:53.617+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:50:53.612+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:50:53.619+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:50:53.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.059 seconds
[2024-09-22T17:52:11.299+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:52:11.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:52:11.303+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:52:11.302+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:52:11.322+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:52:11.317+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:52:11.323+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:52:11.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.054 seconds
[2024-09-22T17:52:41.470+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:52:41.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:52:41.473+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:52:41.473+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:52:41.493+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:52:41.488+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T17:52:41.494+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:52:41.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.052 seconds
[2024-09-22T17:53:11.768+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:53:11.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:53:11.775+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:53:11.774+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:53:11.800+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:53:11.796+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_master': 'spark://spark:7077'}
[2024-09-22T17:53:11.801+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:53:11.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.060 seconds
[2024-09-22T17:53:42.351+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:53:42.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:53:42.354+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:53:42.354+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:53:42.371+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:53:42.367+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_master': 'spark://spark:7077'}
[2024-09-22T17:53:42.372+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:53:42.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T17:54:13.366+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:54:13.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:54:13.369+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:54:13.369+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:54:13.387+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:54:13.383+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_master': 'spark://spark:7077'}
[2024-09-22T17:54:13.388+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:54:13.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T17:54:44.238+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:54:44.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:54:44.242+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:54:44.242+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:54:44.261+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:54:44.256+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_master': 'spark://spark:7077'}
[2024-09-22T17:54:44.262+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:54:44.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.052 seconds
[2024-09-22T17:55:15.114+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:55:15.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:55:15.119+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:55:15.119+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:55:15.140+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:55:15.135+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_master': 'spark://spark:7077'}
[2024-09-22T17:55:15.140+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:55:15.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.055 seconds
[2024-09-22T17:56:51.581+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:56:51.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:56:51.584+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:56:51.584+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:56:51.601+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:56:51.597+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 17, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_master': 'spark://spark:7077'}
[2024-09-22T17:56:51.602+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:56:51.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T17:57:19.817+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:57:19.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:57:19.820+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:57:19.820+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:57:19.846+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:57:19.842+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 19, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T17:57:19.847+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:57:19.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.057 seconds
[2024-09-22T17:58:30.547+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:58:30.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:58:30.551+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:30.551+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:58:30.578+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:58:30.950+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:30.949+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:spark_job_dag
[2024-09-22T17:58:30.963+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:30.962+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:spark_job_dag
[2024-09-22T17:58:30.973+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:30.972+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:spark_job_dag
[2024-09-22T17:58:30.985+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:30.985+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:spark_job_dag
[2024-09-22T17:58:30.995+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:30.994+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:spark_job_dag
[2024-09-22T17:58:31.004+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:31.004+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:spark_job_dag
[2024-09-22T17:58:31.013+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:31.013+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:spark_job_dag
[2024-09-22T17:58:31.014+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:31.014+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:58:31.027+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:31.027+0000] {dag.py:3252} INFO - Creating ORM DAG for spark_job_dag
[2024-09-22T17:58:31.041+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:58:31.041+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:58:31.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.530 seconds
[2024-09-22T17:59:01.253+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:59:01.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:59:01.258+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:59:01.258+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:59:01.283+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:59:01.311+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:59:01.311+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:59:01.471+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:59:01.471+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:59:01.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.251 seconds
[2024-09-22T17:59:31.591+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:59:31.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:59:31.602+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:59:31.601+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:59:31.633+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:59:31.794+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:59:31.794+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T17:59:31.814+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:59:31.813+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T17:59:31.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.247 seconds
[2024-09-22T17:59:52.315+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:59:52.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T17:59:52.318+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:59:52.318+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:59:52.347+0000] {logging_mixin.py:190} INFO - [2024-09-22T17:59:52.341+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 19, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T17:59:52.348+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T17:59:52.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.058 seconds
[2024-09-22T18:01:08.263+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:01:08.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:01:08.277+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:01:08.276+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:01:08.299+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:01:08.295+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 19, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T18:01:08.301+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:01:08.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.238 seconds
[2024-09-22T18:01:39.269+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:01:39.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:01:39.276+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:01:39.276+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:01:39.294+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:01:39.289+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 19, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T18:01:39.295+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:01:39.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.055 seconds
[2024-09-22T18:02:09.820+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:02:09.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:02:09.825+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:02:09.824+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:02:09.851+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:02:09.846+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 19, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://4f82fc90d306:7077'}
[2024-09-22T18:02:09.852+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:02:10.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.232 seconds
[2024-09-22T18:02:40.602+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:02:40.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:02:40.605+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:02:40.604+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:02:40.640+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:02:40.756+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:02:40.756+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:02:40.778+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:02:40.778+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:02:40.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.211 seconds
[2024-09-22T18:03:42.976+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:03:42.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:03:42.980+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:03:42.979+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:03:43.012+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:03:43.050+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:03:43.050+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:03:43.081+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:03:43.081+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:03:43.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.410 seconds
[2024-09-22T18:04:13.609+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:04:13.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:04:13.613+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:04:13.612+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:04:13.640+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:04:13.911+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:04:13.911+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:04:13.926+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:04:13.926+0000] {dag.py:3252} INFO - Creating ORM DAG for spark_job_dag
[2024-09-22T18:04:14.021+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:04:14.021+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:04:14.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.441 seconds
[2024-09-22T18:04:44.143+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:04:44.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:04:44.149+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:04:44.149+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:04:44.174+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:04:44.338+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:04:44.337+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:04:44.361+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:04:44.361+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:04:44.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.245 seconds
[2024-09-22T18:05:14.473+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:05:14.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:05:14.477+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:05:14.477+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:05:14.511+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:05:14.540+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:05:14.540+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:05:14.566+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:05:14.566+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:05:14.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.122 seconds
[2024-09-22T18:05:44.639+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:05:44.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:05:44.643+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:05:44.642+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:05:44.669+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:05:44.693+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:05:44.692+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:05:44.720+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:05:44.719+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:05:44.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T18:06:15.593+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:06:15.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:06:15.596+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:06:15.596+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:06:15.619+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:06:15.644+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:06:15.644+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:06:15.669+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:06:15.669+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:06:15.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T18:06:23.185+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:06:23.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:06:23.188+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:06:23.188+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:06:23.214+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:06:23.209+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T18:06:23.215+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:06:23.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.057 seconds
[2024-09-22T18:06:30.309+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:06:30.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:06:30.313+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:06:30.312+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:06:30.341+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:06:30.336+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T18:06:30.342+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:06:30.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.060 seconds
[2024-09-22T18:07:00.478+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:07:00.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:07:00.481+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:07:00.481+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:07:00.500+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:07:00.495+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T18:07:00.501+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:07:00.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.048 seconds
[2024-09-22T18:07:31.380+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:07:31.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:07:31.383+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:07:31.383+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:07:31.405+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:07:31.400+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T18:07:31.406+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:07:31.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.054 seconds
[2024-09-22T18:08:02.265+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:08:02.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:08:02.268+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:08:02.267+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:08:02.289+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:08:02.283+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T18:08:02.290+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:08:02.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.051 seconds
[2024-09-22T18:08:33.352+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:08:33.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:08:33.355+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:08:33.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:08:33.373+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:08:33.369+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T18:08:33.374+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:08:33.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T18:09:03.434+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:09:03.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:09:03.437+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:09:03.437+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:09:03.458+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:09:03.452+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T18:09:03.459+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:09:03.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.049 seconds
[2024-09-22T18:09:33.557+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:09:33.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:09:33.560+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:09:33.559+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:09:33.578+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:09:33.573+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T18:09:33.579+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:09:33.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.046 seconds
[2024-09-22T18:10:04.427+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:10:04.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:10:04.431+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:10:04.430+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:10:04.450+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:10:04.444+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T18:10:04.451+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:10:04.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.050 seconds
[2024-09-22T18:10:35.464+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:10:35.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:10:35.468+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:10:35.468+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:10:35.487+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:10:35.482+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/jobsSpark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/jobsSpark.py", line 16, in <module>
    submit_spark_job = SparkSubmitOperator(
                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'master': 'spark://spark:7077'}
[2024-09-22T18:10:35.488+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:10:35.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.047 seconds
[2024-09-22T18:10:37.530+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:10:37.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:10:37.534+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:10:37.533+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:10:37.566+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:10:37.686+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:10:37.685+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:10:37.698+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:10:37.698+0000] {dag.py:3252} INFO - Creating ORM DAG for spark_job_dag
[2024-09-22T18:10:37.708+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:10:37.708+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:10:37.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.214 seconds
[2024-09-22T18:11:40.040+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:11:40.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:11:40.043+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:11:40.043+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:11:40.066+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:11:40.106+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:11:40.106+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:11:40.142+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:11:40.142+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:11:40.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.312 seconds
[2024-09-22T18:12:10.850+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:12:10.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:12:10.854+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:12:10.854+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:12:10.880+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:12:10.906+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:12:10.906+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:12:11.060+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:12:11.060+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:12:11.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.236 seconds
[2024-09-22T18:12:41.250+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:12:41.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:12:41.256+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:12:41.255+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:12:41.279+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:12:41.414+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:12:41.413+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:12:41.433+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:12:41.432+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:12:41.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.214 seconds
[2024-09-22T18:13:11.526+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:13:11.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:13:11.530+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:13:11.530+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:13:11.556+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:13:11.582+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:13:11.582+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:13:11.611+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:13:11.611+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:13:11.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.136 seconds
[2024-09-22T18:13:41.841+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:13:41.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:13:41.857+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:13:41.857+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:13:41.908+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:13:41.941+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:13:41.941+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:13:41.992+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:13:41.992+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:13:42.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.249 seconds
[2024-09-22T18:14:12.109+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:14:12.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:14:12.112+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:14:12.112+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:14:12.141+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:14:12.165+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:14:12.165+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:14:12.196+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:14:12.196+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:14:12.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T18:14:42.380+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:14:42.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:14:42.383+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:14:42.382+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:14:42.407+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:14:42.431+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:14:42.431+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:14:42.455+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:14:42.454+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:14:42.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T18:15:12.786+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:15:12.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:15:12.789+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:15:12.789+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:15:12.824+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:15:12.856+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:15:12.856+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:15:12.882+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:15:12.881+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:15:12.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.123 seconds
[2024-09-22T18:15:43.082+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:15:43.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:15:43.086+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:15:43.085+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:15:43.111+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:15:43.137+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:15:43.137+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:15:43.162+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:15:43.161+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:15:43.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T18:16:14.088+0000] {processor.py:186} INFO - Started process (PID=169) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:16:14.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:16:14.091+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:16:14.091+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:16:14.117+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:16:14.143+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:16:14.143+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:16:14.167+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:16:14.167+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:16:14.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T18:16:44.289+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:16:44.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:16:44.292+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:16:44.292+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:16:44.320+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:16:44.343+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:16:44.343+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:16:44.368+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:16:44.367+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:16:44.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T18:17:14.525+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:17:14.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:17:14.529+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:17:14.528+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:17:14.554+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:17:14.579+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:17:14.579+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:17:14.609+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:17:14.608+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:17:14.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T18:17:44.706+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:17:44.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:17:44.709+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:17:44.709+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:17:44.736+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:17:44.760+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:17:44.759+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:17:44.785+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:17:44.785+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:17:44.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T18:18:14.913+0000] {processor.py:186} INFO - Started process (PID=221) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:18:14.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:18:14.917+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:18:14.916+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:18:14.941+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:18:14.966+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:18:14.965+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:18:14.989+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:18:14.989+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:18:15.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T18:18:45.191+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:18:45.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:18:45.195+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:18:45.194+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:18:45.220+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:18:45.242+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:18:45.242+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:18:45.265+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:18:45.265+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:18:45.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T18:19:15.617+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:19:15.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:19:15.621+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:19:15.620+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:19:15.649+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:19:15.674+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:19:15.674+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:19:15.702+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:19:15.702+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:19:15.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T18:19:45.818+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:19:45.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:19:45.822+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:19:45.822+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:19:45.848+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:19:45.871+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:19:45.870+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:19:45.895+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:19:45.894+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:19:45.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T18:20:16.041+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:20:16.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:20:16.045+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:20:16.044+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:20:16.072+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:20:16.098+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:20:16.097+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:20:16.121+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:20:16.121+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:20:16.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T18:20:46.346+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:20:46.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:20:46.356+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:20:46.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:20:46.385+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:20:46.410+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:20:46.409+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:20:46.433+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:20:46.433+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:20:46.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T18:21:16.855+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:21:16.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:21:16.858+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:21:16.858+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:21:16.885+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:21:16.909+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:21:16.909+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:21:16.933+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:21:16.932+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:21:16.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T18:21:47.432+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:21:47.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:21:47.437+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:21:47.436+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:21:47.463+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:21:47.486+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:21:47.486+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:21:47.508+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:21:47.508+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:21:47.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T18:22:17.711+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:22:17.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:22:17.715+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:22:17.714+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:22:17.741+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:22:17.764+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:22:17.764+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:22:17.788+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:22:17.788+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:22:17.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T18:22:48.043+0000] {processor.py:186} INFO - Started process (PID=339) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:22:48.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:22:48.046+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:22:48.046+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:22:48.075+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:22:48.099+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:22:48.099+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:22:48.123+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:22:48.123+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:22:48.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T18:23:18.358+0000] {processor.py:186} INFO - Started process (PID=352) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:23:18.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:23:18.361+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:23:18.361+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:23:18.387+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:23:18.410+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:23:18.410+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:23:18.434+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:23:18.434+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:23:18.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T18:23:48.607+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:23:48.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:23:48.611+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:23:48.610+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:23:48.639+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:23:48.663+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:23:48.663+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:23:48.688+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:23:48.687+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:23:48.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T18:24:18.995+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:24:18.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:24:18.999+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:24:18.998+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:24:19.026+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:24:19.052+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:24:19.052+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:24:19.082+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:24:19.082+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:24:19.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T18:24:49.251+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:24:49.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:24:49.254+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:24:49.254+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:24:49.281+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:24:49.304+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:24:49.304+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:24:49.329+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:24:49.329+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:24:49.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T18:25:19.394+0000] {processor.py:186} INFO - Started process (PID=405) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:25:19.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:25:19.397+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:25:19.397+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:25:19.422+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:25:19.446+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:25:19.445+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:25:19.469+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:25:19.469+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:25:19.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.099 seconds
[2024-09-22T18:25:50.391+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:25:50.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:25:50.395+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:25:50.395+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:25:50.426+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:25:50.450+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:25:50.450+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:25:50.474+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:25:50.474+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:25:50.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T18:26:21.011+0000] {processor.py:186} INFO - Started process (PID=430) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:26:21.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:26:21.015+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:26:21.015+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:26:21.042+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:26:21.068+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:26:21.068+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:26:21.094+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:26:21.093+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:26:21.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T18:26:52.057+0000] {processor.py:186} INFO - Started process (PID=443) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:26:52.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:26:52.064+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:26:52.064+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:26:52.093+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:26:52.120+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:26:52.120+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:26:52.145+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:26:52.145+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:26:52.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T18:27:22.996+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:27:22.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:27:22.999+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:27:22.999+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:27:23.028+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:27:23.055+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:27:23.054+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:27:23.080+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:27:23.080+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:27:23.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T18:27:53.249+0000] {processor.py:186} INFO - Started process (PID=469) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:27:53.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:27:53.253+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:27:53.252+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:27:53.284+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:27:53.308+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:27:53.308+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:27:53.335+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:27:53.334+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:27:53.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T18:28:23.773+0000] {processor.py:186} INFO - Started process (PID=482) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:28:23.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:28:23.777+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:28:23.777+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:28:23.807+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:28:23.832+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:28:23.832+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:28:23.856+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:28:23.856+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:28:23.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T18:28:53.988+0000] {processor.py:186} INFO - Started process (PID=495) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:28:53.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:28:53.992+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:28:53.992+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:28:54.017+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:28:54.044+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:28:54.044+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:28:54.068+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:28:54.068+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:28:54.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T18:29:24.240+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:29:24.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:29:24.244+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:29:24.243+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:29:24.270+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:29:24.295+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:29:24.295+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:29:24.320+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:29:24.320+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:29:24.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T18:29:54.419+0000] {processor.py:186} INFO - Started process (PID=521) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:29:54.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:29:54.422+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:29:54.422+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:29:54.448+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:29:54.474+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:29:54.473+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:29:54.497+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:29:54.497+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:29:54.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T18:30:24.718+0000] {processor.py:186} INFO - Started process (PID=534) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:30:24.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:30:24.722+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:30:24.721+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:30:24.751+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:30:24.777+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:30:24.777+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:30:24.806+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:30:24.806+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:30:24.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T18:30:55.223+0000] {processor.py:186} INFO - Started process (PID=547) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:30:55.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:30:55.227+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:30:55.226+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:30:55.253+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:30:55.277+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:30:55.277+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:30:55.305+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:30:55.305+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:30:55.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T18:31:26.192+0000] {processor.py:186} INFO - Started process (PID=560) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:31:26.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:31:26.196+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:31:26.196+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:31:26.225+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:31:26.250+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:31:26.250+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:31:26.274+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:31:26.274+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:31:26.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T18:31:57.136+0000] {processor.py:186} INFO - Started process (PID=573) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:31:57.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:31:57.139+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:31:57.139+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:31:57.166+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:31:57.189+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:31:57.189+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:31:57.214+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:31:57.214+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:31:57.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T18:32:27.389+0000] {processor.py:186} INFO - Started process (PID=586) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:32:27.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:32:27.393+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:32:27.392+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:32:27.422+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:32:27.448+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:32:27.447+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:32:27.473+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:32:27.472+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:32:27.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T18:32:57.650+0000] {processor.py:186} INFO - Started process (PID=599) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:32:57.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:32:57.653+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:32:57.653+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:32:57.681+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:32:57.706+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:32:57.706+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:32:57.733+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:32:57.732+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:32:57.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T18:33:27.915+0000] {processor.py:186} INFO - Started process (PID=613) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:33:27.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:33:27.918+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:33:27.918+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:33:27.945+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:33:27.968+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:33:27.968+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:33:27.993+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:33:27.993+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:33:28.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T18:33:58.142+0000] {processor.py:186} INFO - Started process (PID=626) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:33:58.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:33:58.146+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:33:58.146+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:33:58.174+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:33:58.213+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:33:58.213+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:33:58.241+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:33:58.240+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:33:58.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.127 seconds
[2024-09-22T18:34:28.339+0000] {processor.py:186} INFO - Started process (PID=639) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:34:28.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:34:28.343+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:34:28.343+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:34:28.368+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:34:28.393+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:34:28.393+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:34:28.418+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:34:28.418+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:34:28.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T18:34:58.506+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:34:58.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:34:58.509+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:34:58.509+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:34:58.540+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:34:58.563+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:34:58.563+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:34:58.590+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:34:58.590+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:34:58.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T18:35:28.782+0000] {processor.py:186} INFO - Started process (PID=664) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:35:28.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:35:28.786+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:35:28.786+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:35:28.816+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:35:28.843+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:35:28.843+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:35:28.867+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:35:28.867+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:35:28.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T18:35:58.958+0000] {processor.py:186} INFO - Started process (PID=676) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:35:58.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:35:58.961+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:35:58.961+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:35:58.990+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:35:59.018+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:35:59.017+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:35:59.044+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:35:59.044+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:35:59.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T18:36:29.247+0000] {processor.py:186} INFO - Started process (PID=689) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:36:29.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:36:29.251+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:36:29.250+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:36:29.277+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:36:29.305+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:36:29.305+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:36:29.330+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:36:29.330+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:36:29.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T18:36:59.428+0000] {processor.py:186} INFO - Started process (PID=702) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:36:59.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:36:59.432+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:36:59.431+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:36:59.458+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:36:59.485+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:36:59.485+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:36:59.510+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:36:59.510+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:36:59.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T18:37:29.666+0000] {processor.py:186} INFO - Started process (PID=715) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:37:29.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:37:29.669+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:37:29.669+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:37:29.696+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:37:29.720+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:37:29.720+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:37:29.746+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:37:29.745+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:37:29.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T18:38:00.165+0000] {processor.py:186} INFO - Started process (PID=728) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:38:00.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:38:00.170+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:38:00.169+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:38:00.199+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:38:00.224+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:38:00.224+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:38:00.250+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:38:00.250+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:38:00.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T18:38:30.744+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:38:30.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:38:30.748+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:38:30.748+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:38:30.775+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:38:30.800+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:38:30.800+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:38:30.825+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:38:30.824+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:38:30.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T18:39:01.004+0000] {processor.py:186} INFO - Started process (PID=755) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:39:01.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:39:01.007+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:39:01.007+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:39:01.033+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:39:01.056+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:39:01.056+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:39:01.081+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:39:01.081+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:39:01.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T18:39:31.149+0000] {processor.py:186} INFO - Started process (PID=767) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:39:31.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:39:31.156+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:39:31.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:39:31.190+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:39:31.250+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:39:31.249+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:39:31.285+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:39:31.285+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:39:31.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.185 seconds
[2024-09-22T18:40:01.428+0000] {processor.py:186} INFO - Started process (PID=780) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:40:01.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:40:01.431+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:40:01.431+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:40:01.457+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:40:01.483+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:40:01.483+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:40:01.512+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:40:01.512+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:40:01.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T18:40:31.927+0000] {processor.py:186} INFO - Started process (PID=793) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:40:31.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:40:31.930+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:40:31.930+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:40:31.959+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:40:31.983+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:40:31.983+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:40:32.006+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:40:32.006+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:40:32.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T18:41:02.209+0000] {processor.py:186} INFO - Started process (PID=807) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:41:02.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:41:02.213+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:41:02.212+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:41:02.238+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:41:02.263+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:41:02.263+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:41:02.286+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:41:02.286+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:41:02.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T18:41:32.724+0000] {processor.py:186} INFO - Started process (PID=819) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:41:32.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:41:32.729+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:41:32.728+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:41:32.757+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:41:32.784+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:41:32.784+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:41:32.812+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:41:32.812+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:41:32.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T18:42:02.957+0000] {processor.py:186} INFO - Started process (PID=832) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:42:02.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:42:02.960+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:42:02.960+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:42:03.002+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:42:03.036+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:42:03.036+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:42:03.061+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:42:03.061+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:42:03.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.136 seconds
[2024-09-22T18:42:33.870+0000] {processor.py:186} INFO - Started process (PID=845) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:42:33.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:42:33.873+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:42:33.873+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:42:33.901+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:42:33.928+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:42:33.928+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:42:33.952+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:42:33.952+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:42:33.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T18:43:04.895+0000] {processor.py:186} INFO - Started process (PID=858) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:43:04.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:43:04.899+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:43:04.899+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:43:04.928+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:43:04.952+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:43:04.952+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:43:04.975+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:43:04.975+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:43:04.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T18:43:35.077+0000] {processor.py:186} INFO - Started process (PID=871) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:43:35.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:43:35.081+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:43:35.081+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:43:35.106+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:43:35.130+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:43:35.130+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:43:35.153+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:43:35.153+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:43:35.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T18:44:05.228+0000] {processor.py:186} INFO - Started process (PID=884) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:44:05.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:44:05.231+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:44:05.231+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:44:05.258+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:44:05.282+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:44:05.282+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:44:05.307+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:44:05.306+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:44:05.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T18:44:35.587+0000] {processor.py:186} INFO - Started process (PID=897) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:44:35.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:44:35.591+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:44:35.591+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:44:35.623+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:44:35.646+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:44:35.646+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:44:35.678+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:44:35.677+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:44:35.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.125 seconds
[2024-09-22T18:45:06.039+0000] {processor.py:186} INFO - Started process (PID=910) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:45:06.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:45:06.043+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:45:06.043+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:45:06.076+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:45:06.101+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:45:06.101+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:45:06.125+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:45:06.125+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:45:06.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T18:45:36.520+0000] {processor.py:186} INFO - Started process (PID=923) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:45:36.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:45:36.530+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:45:36.530+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:45:36.563+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:45:36.594+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:45:36.593+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:45:36.621+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:45:36.620+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:45:36.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.133 seconds
[2024-09-22T18:46:07.019+0000] {processor.py:186} INFO - Started process (PID=936) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:46:07.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:46:07.023+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:46:07.022+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:46:07.046+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:46:07.070+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:46:07.069+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:46:07.093+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:46:07.093+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:46:07.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T18:46:37.430+0000] {processor.py:186} INFO - Started process (PID=949) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:46:37.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:46:37.433+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:46:37.433+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:46:37.468+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:46:37.492+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:46:37.492+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:46:37.515+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:46:37.515+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:46:37.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T18:47:07.790+0000] {processor.py:186} INFO - Started process (PID=962) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:47:07.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:47:07.794+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:47:07.794+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:47:07.827+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:47:07.851+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:47:07.851+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:47:07.877+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:47:07.877+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:47:07.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T18:47:38.076+0000] {processor.py:186} INFO - Started process (PID=977) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:47:38.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:47:38.080+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:47:38.080+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:47:38.107+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:47:38.131+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:47:38.131+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:47:38.154+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:47:38.154+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:47:38.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T18:48:08.341+0000] {processor.py:186} INFO - Started process (PID=990) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:48:08.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:48:08.345+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:48:08.345+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:48:08.373+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:48:08.402+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:48:08.402+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:48:08.435+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:48:08.430+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:48:08.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.125 seconds
[2024-09-22T18:48:39.608+0000] {processor.py:186} INFO - Started process (PID=1003) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:48:39.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:48:39.616+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:48:39.616+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:48:39.645+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:48:39.670+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:48:39.669+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:48:39.694+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:48:39.694+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:48:39.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.130 seconds
[2024-09-22T18:49:10.418+0000] {processor.py:186} INFO - Started process (PID=1016) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:49:10.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:49:10.421+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:49:10.421+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:49:10.448+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:49:10.471+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:49:10.471+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:49:10.494+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:49:10.494+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:49:10.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T18:49:41.194+0000] {processor.py:186} INFO - Started process (PID=1029) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:49:41.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:49:41.197+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:49:41.196+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:49:41.222+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:49:41.246+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:49:41.246+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:49:41.271+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:49:41.270+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:49:41.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T18:50:11.351+0000] {processor.py:186} INFO - Started process (PID=1042) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:50:11.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:50:11.355+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:50:11.354+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:50:11.380+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:50:11.404+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:50:11.403+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:50:11.429+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:50:11.429+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:50:11.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T18:50:42.107+0000] {processor.py:186} INFO - Started process (PID=1053) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:50:42.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:50:42.111+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:50:42.111+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:50:42.137+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:50:42.161+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:50:42.161+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:50:42.183+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:50:42.183+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:50:42.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T18:51:12.429+0000] {processor.py:186} INFO - Started process (PID=1066) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:51:12.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:51:12.433+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:51:12.433+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:51:12.461+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:51:12.485+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:51:12.485+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:51:12.510+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:51:12.510+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:51:12.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T18:51:43.365+0000] {processor.py:186} INFO - Started process (PID=1079) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:51:43.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:51:43.368+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:51:43.368+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:51:43.399+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:51:43.445+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:51:43.445+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:51:43.500+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:51:43.500+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:51:43.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.186 seconds
[2024-09-22T18:52:13.829+0000] {processor.py:186} INFO - Started process (PID=1092) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:52:13.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:52:13.833+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:52:13.833+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:52:13.858+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:52:13.884+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:52:13.883+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:52:13.913+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:52:13.912+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:52:13.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T18:52:44.661+0000] {processor.py:186} INFO - Started process (PID=1105) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:52:44.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:52:44.665+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:52:44.664+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:52:44.690+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:52:44.715+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:52:44.715+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:52:44.743+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:52:44.743+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:52:44.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T18:53:15.491+0000] {processor.py:186} INFO - Started process (PID=1124) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:53:15.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:53:15.495+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:53:15.495+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:53:15.521+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:53:15.557+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:53:15.556+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:53:15.580+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:53:15.580+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:53:15.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T18:53:46.202+0000] {processor.py:186} INFO - Started process (PID=1137) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:53:46.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:53:46.206+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:53:46.206+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:53:46.236+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:53:46.260+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:53:46.260+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:53:46.287+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:53:46.287+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:53:46.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T18:54:16.960+0000] {processor.py:186} INFO - Started process (PID=1150) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:54:16.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:54:16.963+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:54:16.963+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:54:16.992+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:54:17.018+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:54:17.017+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:54:17.042+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:54:17.042+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:54:17.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T18:54:47.306+0000] {processor.py:186} INFO - Started process (PID=1163) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:54:47.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:54:47.310+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:54:47.310+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:54:47.342+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:54:47.368+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:54:47.368+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:54:47.395+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:54:47.394+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:54:47.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.132 seconds
[2024-09-22T18:55:17.606+0000] {processor.py:186} INFO - Started process (PID=1176) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:55:17.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:55:17.609+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:55:17.609+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:55:17.641+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:55:17.667+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:55:17.667+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:55:17.693+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:55:17.693+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:55:17.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T18:55:48.379+0000] {processor.py:186} INFO - Started process (PID=1189) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:55:48.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:55:48.382+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:55:48.382+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:55:48.411+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:55:48.436+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:55:48.435+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:55:48.459+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:55:48.459+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:55:48.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T18:56:19.242+0000] {processor.py:186} INFO - Started process (PID=1202) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:56:19.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:56:19.249+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:56:19.248+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:56:19.287+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:56:19.321+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:56:19.320+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:56:19.348+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:56:19.348+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:56:19.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.140 seconds
[2024-09-22T18:56:49.511+0000] {processor.py:186} INFO - Started process (PID=1215) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:56:49.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:56:49.515+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:56:49.514+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:56:49.541+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:56:49.570+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:56:49.570+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:56:49.595+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:56:49.595+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:56:49.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T18:57:20.297+0000] {processor.py:186} INFO - Started process (PID=1227) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:57:20.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:57:20.300+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:57:20.300+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:57:20.325+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:57:20.351+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:57:20.350+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:57:20.377+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:57:20.377+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:57:20.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T18:57:50.513+0000] {processor.py:186} INFO - Started process (PID=1240) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:57:50.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:57:50.517+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:57:50.517+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:57:50.541+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:57:50.565+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:57:50.564+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:57:50.588+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:57:50.588+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:57:50.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T18:58:20.702+0000] {processor.py:186} INFO - Started process (PID=1253) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:58:20.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:58:20.705+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:58:20.705+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:58:20.728+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:58:20.749+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:58:20.749+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:58:20.772+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:58:20.772+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:58:20.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.096 seconds
[2024-09-22T18:58:50.960+0000] {processor.py:186} INFO - Started process (PID=1266) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:58:50.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:58:50.966+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:58:50.966+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:58:50.993+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:58:51.018+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:58:51.018+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:58:51.044+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:58:51.043+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:58:51.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T18:59:21.179+0000] {processor.py:186} INFO - Started process (PID=1279) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:59:21.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:59:21.181+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:59:21.181+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:59:21.204+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:59:21.229+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:59:21.229+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:59:21.264+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:59:21.264+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:59:21.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T18:59:51.539+0000] {processor.py:186} INFO - Started process (PID=1292) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:59:51.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T18:59:51.542+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:59:51.542+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:59:51.567+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T18:59:51.591+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:59:51.591+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T18:59:51.615+0000] {logging_mixin.py:190} INFO - [2024-09-22T18:59:51.614+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T18:59:51.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T19:00:21.729+0000] {processor.py:186} INFO - Started process (PID=1305) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:00:21.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:00:21.733+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:00:21.732+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:00:21.759+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:00:21.783+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:00:21.783+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:00:21.808+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:00:21.808+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:00:21.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T19:00:51.894+0000] {processor.py:186} INFO - Started process (PID=1318) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:00:51.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:00:51.898+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:00:51.898+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:00:51.928+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:00:51.953+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:00:51.953+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:00:51.977+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:00:51.976+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:00:51.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T19:01:22.324+0000] {processor.py:186} INFO - Started process (PID=1331) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:01:22.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:01:22.328+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:01:22.327+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:01:22.354+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:01:22.392+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:01:22.391+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:01:22.443+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:01:22.443+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:01:22.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.179 seconds
[2024-09-22T19:01:52.634+0000] {processor.py:186} INFO - Started process (PID=1344) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:01:52.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:01:52.637+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:01:52.637+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:01:52.663+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:01:52.688+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:01:52.688+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:01:52.711+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:01:52.711+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:01:52.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:02:22.863+0000] {processor.py:186} INFO - Started process (PID=1357) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:02:22.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:02:22.867+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:02:22.867+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:02:22.892+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:02:22.918+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:02:22.918+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:02:22.945+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:02:22.945+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:02:22.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T19:02:53.332+0000] {processor.py:186} INFO - Started process (PID=1370) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:02:53.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:02:53.337+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:02:53.337+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:02:53.364+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:02:53.390+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:02:53.390+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:02:53.415+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:02:53.415+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:02:53.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T19:03:23.645+0000] {processor.py:186} INFO - Started process (PID=1383) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:03:23.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:03:23.648+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:03:23.648+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:03:23.676+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:03:23.702+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:03:23.702+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:03:23.726+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:03:23.726+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:03:23.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:03:54.155+0000] {processor.py:186} INFO - Started process (PID=1396) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:03:54.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:03:54.159+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:03:54.159+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:03:54.183+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:03:54.208+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:03:54.208+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:03:54.235+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:03:54.235+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:03:54.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T19:04:24.643+0000] {processor.py:186} INFO - Started process (PID=1409) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:04:24.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:04:24.648+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:04:24.647+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:04:24.675+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:04:24.700+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:04:24.700+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:04:24.724+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:04:24.724+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:04:24.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T19:04:54.848+0000] {processor.py:186} INFO - Started process (PID=1422) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:04:54.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:04:54.854+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:04:54.853+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:04:54.878+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:04:54.904+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:04:54.904+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:04:54.940+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:04:54.939+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:04:54.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.121 seconds
[2024-09-22T19:05:25.087+0000] {processor.py:186} INFO - Started process (PID=1435) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:05:25.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:05:25.091+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:05:25.090+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:05:25.121+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:05:25.144+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:05:25.144+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:05:25.171+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:05:25.171+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:05:25.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T19:05:55.256+0000] {processor.py:186} INFO - Started process (PID=1448) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:05:55.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:05:55.260+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:05:55.260+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:05:55.288+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:05:55.313+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:05:55.313+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:05:55.339+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:05:55.339+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:05:55.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.219 seconds
[2024-09-22T19:06:25.622+0000] {processor.py:186} INFO - Started process (PID=1461) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:06:25.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:06:25.625+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:06:25.625+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:06:25.650+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:06:25.675+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:06:25.675+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:06:25.700+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:06:25.699+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:06:25.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:06:55.842+0000] {processor.py:186} INFO - Started process (PID=1474) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:06:55.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:06:55.846+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:06:55.846+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:06:55.871+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:06:55.897+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:06:55.897+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:06:55.921+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:06:55.920+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:06:55.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:07:26.057+0000] {processor.py:186} INFO - Started process (PID=1487) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:07:26.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:07:26.060+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:07:26.060+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:07:26.089+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:07:26.127+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:07:26.127+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:07:26.160+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:07:26.159+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:07:26.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.134 seconds
[2024-09-22T19:07:56.342+0000] {processor.py:186} INFO - Started process (PID=1500) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:07:56.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:07:56.347+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:07:56.347+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:07:56.374+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:07:56.401+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:07:56.401+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:07:56.425+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:07:56.425+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:07:56.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T19:08:26.631+0000] {processor.py:186} INFO - Started process (PID=1513) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:08:26.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:08:26.635+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:08:26.634+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:08:26.665+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:08:26.690+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:08:26.690+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:08:26.718+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:08:26.717+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:08:26.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T19:08:57.624+0000] {processor.py:186} INFO - Started process (PID=1526) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:08:57.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:08:57.628+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:08:57.628+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:08:57.653+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:08:57.678+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:08:57.678+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:08:57.702+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:08:57.702+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:08:57.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T19:09:27.872+0000] {processor.py:186} INFO - Started process (PID=1539) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:09:27.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:09:27.877+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:09:27.877+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:09:27.906+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:09:27.929+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:09:27.929+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:09:27.953+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:09:27.952+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:09:27.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:09:58.199+0000] {processor.py:186} INFO - Started process (PID=1552) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:09:58.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:09:58.203+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:09:58.202+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:09:58.228+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:09:58.254+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:09:58.254+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:09:58.281+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:09:58.281+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:09:58.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T19:10:29.220+0000] {processor.py:186} INFO - Started process (PID=1565) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:10:29.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:10:29.224+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:10:29.223+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:10:29.248+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:10:29.273+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:10:29.273+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:10:29.298+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:10:29.298+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:10:29.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:10:59.486+0000] {processor.py:186} INFO - Started process (PID=1579) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:10:59.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:10:59.489+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:10:59.489+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:10:59.518+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:10:59.543+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:10:59.543+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:10:59.568+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:10:59.568+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:10:59.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T19:11:29.984+0000] {processor.py:186} INFO - Started process (PID=1592) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:11:29.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:11:29.989+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:11:29.989+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:11:30.015+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:11:30.040+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:11:30.040+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:11:30.065+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:11:30.064+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:11:30.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T19:12:00.260+0000] {processor.py:186} INFO - Started process (PID=1605) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:12:00.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:12:00.263+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:12:00.263+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:12:00.289+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:12:00.315+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:12:00.314+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:12:00.343+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:12:00.343+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:12:00.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T19:12:30.409+0000] {processor.py:186} INFO - Started process (PID=1618) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:12:30.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:12:30.412+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:12:30.412+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:12:30.439+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:12:30.464+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:12:30.463+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:12:30.488+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:12:30.488+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:12:30.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:13:01.409+0000] {processor.py:186} INFO - Started process (PID=1631) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:13:01.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:13:01.413+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:13:01.413+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:13:01.439+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:13:01.463+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:13:01.463+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:13:01.487+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:13:01.487+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:13:01.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:13:31.625+0000] {processor.py:186} INFO - Started process (PID=1644) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:13:31.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:13:31.630+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:13:31.629+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:13:31.658+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:13:31.683+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:13:31.683+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:13:31.707+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:13:31.707+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:13:31.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.132 seconds
[2024-09-22T19:14:02.660+0000] {processor.py:186} INFO - Started process (PID=1657) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:14:02.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:14:02.664+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:14:02.663+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:14:02.689+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:14:02.712+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:14:02.712+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:14:02.735+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:14:02.735+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:14:02.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T19:14:32.960+0000] {processor.py:186} INFO - Started process (PID=1670) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:14:32.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:14:32.964+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:14:32.964+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:14:32.989+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:14:33.022+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:14:33.022+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:14:33.055+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:14:33.055+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:14:33.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.121 seconds
[2024-09-22T19:15:03.410+0000] {processor.py:186} INFO - Started process (PID=1683) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:15:03.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:15:03.413+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:15:03.413+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:15:03.440+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:15:03.465+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:15:03.465+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:15:03.492+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:15:03.491+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:15:03.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T19:15:33.595+0000] {processor.py:186} INFO - Started process (PID=1696) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:15:33.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:15:33.599+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:15:33.599+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:15:33.626+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:15:33.651+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:15:33.651+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:15:33.688+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:15:33.687+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:15:33.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.127 seconds
[2024-09-22T19:16:03.837+0000] {processor.py:186} INFO - Started process (PID=1709) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:16:03.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:16:03.842+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:16:03.841+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:16:03.869+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:16:03.892+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:16:03.892+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:16:03.915+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:16:03.915+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:16:03.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T19:16:34.086+0000] {processor.py:186} INFO - Started process (PID=1722) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:16:34.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:16:34.090+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:16:34.090+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:16:34.118+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:16:34.143+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:16:34.143+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:16:34.167+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:16:34.167+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:16:34.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T19:17:04.306+0000] {processor.py:186} INFO - Started process (PID=1735) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:17:04.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:17:04.309+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:17:04.309+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:17:04.338+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:17:04.362+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:17:04.361+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:17:04.390+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:17:04.389+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:17:04.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T19:17:34.878+0000] {processor.py:186} INFO - Started process (PID=1749) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:17:34.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:17:34.883+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:17:34.882+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:17:34.909+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:17:34.935+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:17:34.935+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:17:34.960+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:17:34.960+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:17:34.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T19:18:05.204+0000] {processor.py:186} INFO - Started process (PID=1762) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:18:05.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:18:05.210+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:18:05.209+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:18:05.245+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:18:05.273+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:18:05.272+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:18:05.298+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:18:05.298+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:18:05.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.127 seconds
[2024-09-22T19:18:35.393+0000] {processor.py:186} INFO - Started process (PID=1775) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:18:35.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:18:35.397+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:18:35.396+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:18:35.424+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:18:35.448+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:18:35.448+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:18:35.471+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:18:35.471+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:18:35.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T19:19:06.211+0000] {processor.py:186} INFO - Started process (PID=1787) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:19:06.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:19:06.215+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:19:06.214+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:19:06.238+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:19:06.263+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:19:06.263+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:19:06.286+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:19:06.286+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:19:06.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T19:19:36.971+0000] {processor.py:186} INFO - Started process (PID=1800) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:19:36.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:19:36.975+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:19:36.974+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:19:37.000+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:19:37.024+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:19:37.023+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:19:37.047+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:19:37.047+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:19:37.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T19:20:07.133+0000] {processor.py:186} INFO - Started process (PID=1814) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:20:07.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:20:07.137+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:20:07.137+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:20:07.163+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:20:07.187+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:20:07.186+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:20:07.210+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:20:07.210+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:20:07.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T19:20:37.938+0000] {processor.py:186} INFO - Started process (PID=1827) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:20:37.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:20:37.949+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:20:37.949+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:20:37.990+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:20:38.043+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:20:38.043+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:20:38.098+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:20:38.098+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:20:38.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.226 seconds
[2024-09-22T19:21:08.503+0000] {processor.py:186} INFO - Started process (PID=1840) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:21:08.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:21:08.507+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:21:08.506+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:21:08.540+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:21:08.575+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:21:08.574+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:21:08.608+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:21:08.607+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:21:08.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.140 seconds
[2024-09-22T19:21:38.690+0000] {processor.py:186} INFO - Started process (PID=1853) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:21:38.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:21:38.694+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:21:38.694+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:21:38.721+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:21:38.749+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:21:38.748+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:21:38.776+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:21:38.776+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:21:38.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T19:22:09.001+0000] {processor.py:186} INFO - Started process (PID=1865) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:22:09.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:22:09.004+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:22:09.004+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:22:09.030+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:22:09.053+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:22:09.053+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:22:09.079+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:22:09.078+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:22:09.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T19:22:39.325+0000] {processor.py:186} INFO - Started process (PID=1878) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:22:39.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:22:39.329+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:22:39.329+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:22:39.354+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:22:39.378+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:22:39.378+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:22:39.402+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:22:39.402+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:22:39.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:23:09.527+0000] {processor.py:186} INFO - Started process (PID=1891) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:23:09.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:23:09.530+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:23:09.530+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:23:09.554+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:23:09.578+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:23:09.578+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:23:09.602+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:23:09.601+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:23:09.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T19:23:40.081+0000] {processor.py:186} INFO - Started process (PID=1904) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:23:40.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:23:40.087+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:23:40.087+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:23:40.114+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:23:40.143+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:23:40.143+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:23:40.168+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:23:40.168+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:23:40.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T19:24:10.654+0000] {processor.py:186} INFO - Started process (PID=1917) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:24:10.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:24:10.658+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:24:10.658+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:24:10.687+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:24:10.712+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:24:10.712+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:24:10.741+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:24:10.741+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:24:10.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T19:24:41.146+0000] {processor.py:186} INFO - Started process (PID=1929) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:24:41.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:24:41.154+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:24:41.153+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:24:41.179+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:24:41.208+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:24:41.208+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:24:41.232+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:24:41.232+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:24:41.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T19:25:11.646+0000] {processor.py:186} INFO - Started process (PID=1942) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:25:11.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:25:11.654+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:25:11.653+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:25:11.685+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:25:11.709+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:25:11.709+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:25:11.739+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:25:11.739+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:25:11.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.123 seconds
[2024-09-22T19:25:42.142+0000] {processor.py:186} INFO - Started process (PID=1955) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:25:42.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:25:42.149+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:25:42.148+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:25:42.175+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:25:42.202+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:25:42.202+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:25:42.228+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:25:42.228+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:25:42.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T19:26:12.361+0000] {processor.py:186} INFO - Started process (PID=1966) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:26:12.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:26:12.365+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:26:12.365+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:26:12.391+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:26:12.419+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:26:12.419+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:26:12.446+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:26:12.446+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:26:12.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T19:26:42.588+0000] {processor.py:186} INFO - Started process (PID=1979) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:26:42.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:26:42.591+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:26:42.590+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:26:42.621+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:26:42.649+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:26:42.648+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:26:42.674+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:26:42.674+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:26:42.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T19:27:12.836+0000] {processor.py:186} INFO - Started process (PID=1992) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:27:12.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:27:12.843+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:27:12.842+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:27:12.871+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:27:12.898+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:27:12.898+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:27:12.923+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:27:12.922+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:27:12.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T19:27:43.126+0000] {processor.py:186} INFO - Started process (PID=2005) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:27:43.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:27:43.131+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:27:43.131+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:27:43.163+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:27:43.189+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:27:43.188+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:27:43.219+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:27:43.219+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:27:43.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.127 seconds
[2024-09-22T19:28:13.412+0000] {processor.py:186} INFO - Started process (PID=2018) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:28:13.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:28:13.417+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:28:13.416+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:28:13.448+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:28:13.477+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:28:13.477+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:28:13.503+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:28:13.503+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:28:13.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.130 seconds
[2024-09-22T19:28:43.676+0000] {processor.py:186} INFO - Started process (PID=2031) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:28:43.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:28:43.682+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:28:43.681+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:28:43.721+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:28:43.753+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:28:43.750+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:28:43.781+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:28:43.781+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:28:43.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.144 seconds
[2024-09-22T19:29:14.174+0000] {processor.py:186} INFO - Started process (PID=2044) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:29:14.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:29:14.177+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:29:14.177+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:29:14.211+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:29:14.238+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:29:14.238+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:29:14.262+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:29:14.262+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:29:14.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T19:29:44.539+0000] {processor.py:186} INFO - Started process (PID=2057) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:29:44.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:29:44.542+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:29:44.542+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:29:44.570+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:29:44.596+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:29:44.596+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:29:44.623+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:29:44.623+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:29:44.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T19:30:14.952+0000] {processor.py:186} INFO - Started process (PID=2070) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:30:14.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:30:14.957+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:30:14.956+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:30:14.986+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:30:15.011+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:30:15.010+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:30:15.037+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:30:15.037+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:30:15.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T19:30:45.459+0000] {processor.py:186} INFO - Started process (PID=2084) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:30:45.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:30:45.466+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:30:45.465+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:30:45.496+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:30:45.520+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:30:45.520+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:30:45.544+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:30:45.543+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:30:45.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T19:31:15.921+0000] {processor.py:186} INFO - Started process (PID=2097) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:31:15.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:31:15.924+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:31:15.924+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:31:15.956+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:31:15.986+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:31:15.986+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:31:16.014+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:31:16.014+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:31:16.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T19:31:46.560+0000] {processor.py:186} INFO - Started process (PID=2110) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:31:46.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:31:46.564+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:31:46.564+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:31:46.594+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:31:46.621+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:31:46.620+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:31:46.650+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:31:46.649+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:31:46.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T19:32:16.787+0000] {processor.py:186} INFO - Started process (PID=2123) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:32:16.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:32:16.792+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:32:16.792+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:32:16.820+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:32:16.844+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:32:16.844+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:32:16.867+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:32:16.867+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:32:16.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T19:32:47.017+0000] {processor.py:186} INFO - Started process (PID=2136) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:32:47.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:32:47.021+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:32:47.020+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:32:47.048+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:32:47.071+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:32:47.071+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:32:47.097+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:32:47.096+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:32:47.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:33:17.174+0000] {processor.py:186} INFO - Started process (PID=2149) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:33:17.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:33:17.177+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:33:17.177+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:33:17.204+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:33:17.228+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:33:17.228+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:33:17.251+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:33:17.251+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:33:17.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T19:33:47.474+0000] {processor.py:186} INFO - Started process (PID=2162) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:33:47.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:33:47.478+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:33:47.478+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:33:47.508+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:33:47.535+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:33:47.535+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:33:47.565+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:33:47.565+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:33:47.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.124 seconds
[2024-09-22T19:34:17.966+0000] {processor.py:186} INFO - Started process (PID=2176) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:34:17.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:34:17.972+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:34:17.971+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:34:18.006+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:34:18.032+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:34:18.032+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:34:18.064+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:34:18.063+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:34:18.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.129 seconds
[2024-09-22T19:34:48.344+0000] {processor.py:186} INFO - Started process (PID=2189) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:34:48.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:34:48.351+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:34:48.350+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:34:48.386+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:34:48.414+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:34:48.413+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:34:48.443+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:34:48.443+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:34:48.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.138 seconds
[2024-09-22T19:35:18.528+0000] {processor.py:186} INFO - Started process (PID=2202) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:35:18.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:35:18.533+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:35:18.532+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:35:18.561+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:35:18.587+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:35:18.587+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:35:18.613+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:35:18.612+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:35:18.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T19:35:49.345+0000] {processor.py:186} INFO - Started process (PID=2221) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:35:49.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:35:49.350+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:35:49.349+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:35:49.376+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:35:49.401+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:35:49.400+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:35:49.425+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:35:49.425+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:35:49.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:36:20.378+0000] {processor.py:186} INFO - Started process (PID=2234) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:36:20.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:36:20.383+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:36:20.382+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:36:20.409+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:36:20.434+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:36:20.434+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:36:20.459+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:36:20.459+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:36:20.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T19:36:50.551+0000] {processor.py:186} INFO - Started process (PID=2247) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:36:50.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:36:50.555+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:36:50.555+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:36:50.581+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:36:50.605+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:36:50.605+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:36:50.629+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:36:50.629+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:36:50.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:37:20.699+0000] {processor.py:186} INFO - Started process (PID=2260) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:37:20.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:37:20.703+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:37:20.703+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:37:20.732+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:37:20.757+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:37:20.757+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:37:20.808+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:37:20.808+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:37:20.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.147 seconds
[2024-09-22T19:37:50.969+0000] {processor.py:186} INFO - Started process (PID=2273) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:37:50.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:37:50.972+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:37:50.972+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:37:50.997+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:37:51.020+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:37:51.020+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:37:51.045+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:37:51.045+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:37:51.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T19:38:21.153+0000] {processor.py:186} INFO - Started process (PID=2286) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:38:21.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:38:21.157+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:38:21.157+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:38:21.183+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:38:21.207+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:38:21.207+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:38:21.230+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:38:21.230+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:38:21.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T19:38:51.421+0000] {processor.py:186} INFO - Started process (PID=2299) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:38:51.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:38:51.424+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:38:51.424+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:38:51.452+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:38:51.476+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:38:51.476+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:38:51.500+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:38:51.499+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:38:51.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:39:21.726+0000] {processor.py:186} INFO - Started process (PID=2312) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:39:21.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:39:21.729+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:39:21.729+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:39:21.757+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:39:21.781+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:39:21.781+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:39:21.805+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:39:21.804+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:39:21.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:39:51.984+0000] {processor.py:186} INFO - Started process (PID=2325) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:39:51.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:39:51.989+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:39:51.989+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:39:52.017+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:39:52.041+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:39:52.041+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:39:52.065+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:39:52.065+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:39:52.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:40:22.248+0000] {processor.py:186} INFO - Started process (PID=2338) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:40:22.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:40:22.251+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:40:22.251+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:40:22.277+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:40:22.301+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:40:22.301+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:40:22.328+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:40:22.327+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:40:22.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T19:40:52.497+0000] {processor.py:186} INFO - Started process (PID=2351) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:40:52.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:40:52.500+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:40:52.500+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:40:52.526+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:40:52.550+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:40:52.549+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:40:52.573+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:40:52.572+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:40:52.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T19:41:22.752+0000] {processor.py:186} INFO - Started process (PID=2364) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:41:22.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:41:22.755+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:41:22.755+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:41:22.780+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:41:22.804+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:41:22.804+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:41:22.828+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:41:22.827+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:41:22.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:41:53.085+0000] {processor.py:186} INFO - Started process (PID=2377) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:41:53.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:41:53.089+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:41:53.089+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:41:53.115+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:41:53.140+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:41:53.139+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:41:53.164+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:41:53.164+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:41:53.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T19:42:23.379+0000] {processor.py:186} INFO - Started process (PID=2390) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:42:23.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:42:23.382+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:42:23.382+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:42:23.411+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:42:23.434+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:42:23.434+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:42:23.459+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:42:23.458+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:42:23.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T19:42:53.671+0000] {processor.py:186} INFO - Started process (PID=2403) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:42:53.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:42:53.674+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:42:53.674+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:42:53.700+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:42:53.725+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:42:53.725+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:42:53.748+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:42:53.748+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:42:53.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T19:43:23.994+0000] {processor.py:186} INFO - Started process (PID=2416) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:43:23.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:43:23.998+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:43:23.997+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:43:24.025+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:43:24.049+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:43:24.048+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:43:24.072+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:43:24.071+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:43:24.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:43:54.981+0000] {processor.py:186} INFO - Started process (PID=2429) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:43:54.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:43:54.984+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:43:54.984+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:43:55.013+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:43:55.036+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:43:55.036+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:43:55.061+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:43:55.061+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:43:55.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:44:25.150+0000] {processor.py:186} INFO - Started process (PID=2442) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:44:25.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:44:25.154+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:44:25.153+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:44:25.178+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:44:25.202+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:44:25.202+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:44:25.227+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:44:25.226+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:44:25.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:44:55.417+0000] {processor.py:186} INFO - Started process (PID=2455) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:44:55.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:44:55.421+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:44:55.421+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:44:55.448+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:44:55.472+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:44:55.472+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:44:55.496+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:44:55.496+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:44:55.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T19:45:25.578+0000] {processor.py:186} INFO - Started process (PID=2468) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:45:25.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:45:25.582+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:45:25.581+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:45:25.611+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:45:25.634+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:45:25.634+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:45:25.657+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:45:25.657+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:45:25.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:45:55.797+0000] {processor.py:186} INFO - Started process (PID=2481) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:45:55.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:45:55.800+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:45:55.800+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:45:55.826+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:45:55.850+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:45:55.850+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:45:55.873+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:45:55.873+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:45:55.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T19:46:26.046+0000] {processor.py:186} INFO - Started process (PID=2492) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:46:26.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:46:26.049+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:46:26.049+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:46:26.076+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:46:26.101+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:46:26.100+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:46:26.124+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:46:26.123+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:46:26.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T19:46:56.395+0000] {processor.py:186} INFO - Started process (PID=2505) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:46:56.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:46:56.399+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:46:56.398+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:46:56.424+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:46:56.448+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:46:56.448+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:46:56.471+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:46:56.470+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:46:56.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T19:47:27.285+0000] {processor.py:186} INFO - Started process (PID=2517) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:47:27.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:47:27.288+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:47:27.288+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:47:27.314+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:47:27.339+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:47:27.339+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:47:27.362+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:47:27.362+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:47:27.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:47:57.784+0000] {processor.py:186} INFO - Started process (PID=2530) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:47:57.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:47:57.787+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:47:57.787+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:47:57.815+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:47:57.839+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:47:57.838+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:47:57.862+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:47:57.862+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:47:57.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:48:28.132+0000] {processor.py:186} INFO - Started process (PID=2543) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:48:28.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:48:28.135+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:48:28.135+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:48:28.163+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:48:28.188+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:48:28.188+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:48:28.216+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:48:28.215+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:48:28.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T19:48:58.441+0000] {processor.py:186} INFO - Started process (PID=2556) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:48:58.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:48:58.445+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:48:58.444+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:48:58.471+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:48:58.496+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:48:58.496+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:48:58.521+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:48:58.521+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:48:58.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T19:49:28.884+0000] {processor.py:186} INFO - Started process (PID=2569) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:49:28.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:49:28.888+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:49:28.887+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:49:28.914+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:49:28.938+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:49:28.938+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:49:28.962+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:49:28.962+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:49:28.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:49:59.335+0000] {processor.py:186} INFO - Started process (PID=2582) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:49:59.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:49:59.339+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:49:59.338+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:49:59.364+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:49:59.388+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:49:59.387+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:49:59.412+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:49:59.412+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:49:59.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T19:50:29.576+0000] {processor.py:186} INFO - Started process (PID=2595) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:50:29.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:50:29.579+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:50:29.579+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:50:29.607+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:50:29.631+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:50:29.631+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:50:29.664+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:50:29.664+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:50:29.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T19:50:59.810+0000] {processor.py:186} INFO - Started process (PID=2608) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:50:59.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:50:59.813+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:50:59.813+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:50:59.845+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:50:59.875+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:50:59.875+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:50:59.900+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:50:59.899+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:50:59.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T19:51:30.046+0000] {processor.py:186} INFO - Started process (PID=2621) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:51:30.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:51:30.051+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:51:30.051+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:51:30.081+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:51:30.111+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:51:30.111+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:51:30.140+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:51:30.140+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:51:30.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.126 seconds
[2024-09-22T19:52:00.566+0000] {processor.py:186} INFO - Started process (PID=2634) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:52:00.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:52:00.570+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:52:00.570+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:52:00.598+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:52:00.621+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:52:00.621+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:52:00.645+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:52:00.645+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:52:00.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:52:31.178+0000] {processor.py:186} INFO - Started process (PID=2647) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:52:31.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:52:31.182+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:52:31.181+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:52:31.209+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:52:31.235+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:52:31.235+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:52:31.258+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:52:31.258+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:52:31.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T19:53:01.389+0000] {processor.py:186} INFO - Started process (PID=2660) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:53:01.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:53:01.392+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:53:01.392+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:53:01.434+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:53:01.466+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:53:01.465+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:53:01.491+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:53:01.491+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:53:01.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.128 seconds
[2024-09-22T19:53:31.605+0000] {processor.py:186} INFO - Started process (PID=2674) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:53:31.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:53:31.608+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:53:31.608+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:53:31.635+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:53:31.659+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:53:31.659+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:53:31.684+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:53:31.683+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:53:31.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:54:01.826+0000] {processor.py:186} INFO - Started process (PID=2687) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:54:01.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:54:01.830+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:54:01.830+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:54:01.855+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:54:01.879+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:54:01.879+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:54:01.902+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:54:01.902+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:54:01.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T19:54:32.039+0000] {processor.py:186} INFO - Started process (PID=2700) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:54:32.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:54:32.043+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:54:32.043+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:54:32.071+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:54:32.095+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:54:32.095+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:54:32.118+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:54:32.118+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:54:32.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:55:02.943+0000] {processor.py:186} INFO - Started process (PID=2713) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:55:02.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:55:02.946+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:55:02.946+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:55:02.971+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:55:02.995+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:55:02.995+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:55:03.018+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:55:03.018+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:55:03.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T19:55:33.141+0000] {processor.py:186} INFO - Started process (PID=2726) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:55:33.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:55:33.145+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:55:33.144+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:55:33.171+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:55:33.195+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:55:33.195+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:55:33.219+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:55:33.218+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:55:33.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T19:56:03.329+0000] {processor.py:186} INFO - Started process (PID=2739) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:56:03.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:56:03.332+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:56:03.332+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:56:03.359+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:56:03.396+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:56:03.395+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:56:03.429+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:56:03.429+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:56:03.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.126 seconds
[2024-09-22T19:56:33.554+0000] {processor.py:186} INFO - Started process (PID=2752) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:56:33.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:56:33.558+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:56:33.558+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:56:33.584+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:56:33.609+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:56:33.609+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:56:33.632+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:56:33.632+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:56:33.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T19:57:03.797+0000] {processor.py:186} INFO - Started process (PID=2765) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:57:03.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:57:03.801+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:57:03.801+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:57:03.828+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:57:03.851+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:57:03.851+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:57:03.875+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:57:03.875+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:57:03.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T19:57:34.103+0000] {processor.py:186} INFO - Started process (PID=2778) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:57:34.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:57:34.107+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:57:34.106+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:57:34.135+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:57:34.160+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:57:34.160+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:57:34.187+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:57:34.187+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:57:34.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T19:58:04.542+0000] {processor.py:186} INFO - Started process (PID=2791) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:58:04.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:58:04.545+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:58:04.545+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:58:04.575+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:58:04.600+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:58:04.600+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:58:04.623+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:58:04.623+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:58:04.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T19:58:34.849+0000] {processor.py:186} INFO - Started process (PID=2804) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:58:34.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:58:34.853+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:58:34.852+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:58:34.888+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:58:34.941+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:58:34.940+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:58:34.977+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:58:34.977+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:58:35.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.165 seconds
[2024-09-22T19:59:05.100+0000] {processor.py:186} INFO - Started process (PID=2817) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:59:05.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:59:05.104+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:59:05.104+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:59:05.132+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:59:05.156+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:59:05.156+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:59:05.179+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:59:05.179+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:59:05.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T19:59:35.315+0000] {processor.py:186} INFO - Started process (PID=2830) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:59:35.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T19:59:35.318+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:59:35.318+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:59:35.342+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T19:59:35.366+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:59:35.366+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T19:59:35.389+0000] {logging_mixin.py:190} INFO - [2024-09-22T19:59:35.388+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T19:59:35.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T20:00:05.551+0000] {processor.py:186} INFO - Started process (PID=2843) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:00:05.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:00:05.555+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:00:05.554+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:00:05.583+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:00:05.610+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:00:05.609+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:00:05.634+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:00:05.634+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:00:05.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T20:00:36.608+0000] {processor.py:186} INFO - Started process (PID=2856) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:00:36.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:00:36.611+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:00:36.611+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:00:36.635+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:00:36.658+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:00:36.658+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:00:36.681+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:00:36.681+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:00:36.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T20:01:07.428+0000] {processor.py:186} INFO - Started process (PID=2869) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:01:07.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:01:07.432+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:01:07.431+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:01:07.459+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:01:07.483+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:01:07.483+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:01:07.507+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:01:07.507+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:01:07.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T20:01:38.506+0000] {processor.py:186} INFO - Started process (PID=2882) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:01:38.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:01:38.510+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:01:38.510+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:01:38.562+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:01:38.592+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:01:38.592+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:01:38.619+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:01:38.619+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:01:38.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.145 seconds
[2024-09-22T20:02:08.917+0000] {processor.py:186} INFO - Started process (PID=2895) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:02:08.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:02:08.920+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:02:08.919+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:02:08.946+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:02:08.969+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:02:08.969+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:02:08.992+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:02:08.992+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:02:09.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T20:02:39.250+0000] {processor.py:186} INFO - Started process (PID=2908) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:02:39.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:02:39.253+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:02:39.253+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:02:39.284+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:02:39.309+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:02:39.309+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:02:39.334+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:02:39.334+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:02:39.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T20:03:10.190+0000] {processor.py:186} INFO - Started process (PID=2921) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:03:10.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:03:10.194+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:03:10.194+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:03:10.219+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:03:10.243+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:03:10.243+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:03:10.267+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:03:10.266+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:03:10.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:03:40.355+0000] {processor.py:186} INFO - Started process (PID=2934) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:03:40.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:03:40.360+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:03:40.360+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:03:40.391+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:03:40.434+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:03:40.434+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:03:40.478+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:03:40.478+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:03:40.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.151 seconds
[2024-09-22T20:04:10.595+0000] {processor.py:186} INFO - Started process (PID=2947) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:04:10.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:04:10.598+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:04:10.598+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:04:10.624+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:04:10.648+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:04:10.648+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:04:10.677+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:04:10.677+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:04:10.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T20:04:40.844+0000] {processor.py:186} INFO - Started process (PID=2960) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:04:40.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:04:40.848+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:04:40.848+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:04:40.877+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:04:40.904+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:04:40.904+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:04:40.939+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:04:40.938+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:04:40.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.130 seconds
[2024-09-22T20:05:11.447+0000] {processor.py:186} INFO - Started process (PID=2973) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:05:11.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:05:11.451+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:05:11.450+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:05:11.474+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:05:11.498+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:05:11.497+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:05:11.523+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:05:11.523+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:05:11.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T20:05:42.409+0000] {processor.py:186} INFO - Started process (PID=2986) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:05:42.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:05:42.414+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:05:42.413+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:05:42.439+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:05:42.474+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:05:42.474+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:05:42.498+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:05:42.497+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:05:42.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T20:06:12.627+0000] {processor.py:186} INFO - Started process (PID=2999) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:06:12.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:06:12.631+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:06:12.630+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:06:12.659+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:06:12.683+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:06:12.682+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:06:12.706+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:06:12.705+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:06:12.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T20:06:42.842+0000] {processor.py:186} INFO - Started process (PID=3012) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:06:42.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:06:42.845+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:06:42.845+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:06:42.873+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:06:42.897+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:06:42.896+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:06:42.920+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:06:42.920+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:06:42.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:07:13.015+0000] {processor.py:186} INFO - Started process (PID=3025) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:07:13.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:07:13.019+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:07:13.019+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:07:13.043+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:07:13.067+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:07:13.067+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:07:13.091+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:07:13.090+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:07:13.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:07:43.236+0000] {processor.py:186} INFO - Started process (PID=3038) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:07:43.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:07:43.241+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:07:43.240+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:07:43.266+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:07:43.291+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:07:43.291+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:07:43.318+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:07:43.318+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:07:43.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T20:08:13.408+0000] {processor.py:186} INFO - Started process (PID=3051) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:08:13.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:08:13.411+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:08:13.411+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:08:13.436+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:08:13.462+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:08:13.461+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:08:13.486+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:08:13.486+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:08:13.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T20:08:43.853+0000] {processor.py:186} INFO - Started process (PID=3064) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:08:43.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:08:43.856+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:08:43.856+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:08:43.888+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:08:43.912+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:08:43.912+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:08:43.935+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:08:43.935+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:08:43.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T20:09:14.118+0000] {processor.py:186} INFO - Started process (PID=3077) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:09:14.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:09:14.122+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:09:14.121+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:09:14.149+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:09:14.174+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:09:14.173+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:09:14.197+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:09:14.197+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:09:14.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T20:09:44.289+0000] {processor.py:186} INFO - Started process (PID=3090) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:09:44.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:09:44.293+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:09:44.293+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:09:44.317+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:09:44.341+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:09:44.341+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:09:44.366+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:09:44.366+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:09:44.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:10:14.541+0000] {processor.py:186} INFO - Started process (PID=3102) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:10:14.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:10:14.545+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:10:14.545+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:10:14.570+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:10:14.593+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:10:14.593+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:10:14.618+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:10:14.617+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:10:14.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T20:10:44.732+0000] {processor.py:186} INFO - Started process (PID=3115) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:10:44.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:10:44.736+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:10:44.735+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:10:44.762+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:10:44.786+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:10:44.786+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:10:44.809+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:10:44.809+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:10:44.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T20:11:14.971+0000] {processor.py:186} INFO - Started process (PID=3128) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:11:14.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:11:14.974+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:11:14.974+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:11:15.000+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:11:15.024+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:11:15.024+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:11:15.048+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:11:15.047+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:11:15.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:11:45.229+0000] {processor.py:186} INFO - Started process (PID=3141) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:11:45.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:11:45.233+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:11:45.233+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:11:45.260+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:11:45.283+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:11:45.283+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:11:45.307+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:11:45.306+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:11:45.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T20:12:15.415+0000] {processor.py:186} INFO - Started process (PID=3154) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:12:15.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:12:15.418+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:12:15.418+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:12:15.443+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:12:15.466+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:12:15.466+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:12:15.491+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:12:15.491+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:12:15.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:12:45.634+0000] {processor.py:186} INFO - Started process (PID=3167) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:12:45.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:12:45.637+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:12:45.637+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:12:45.671+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:12:45.708+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:12:45.708+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:12:45.733+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:12:45.732+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:12:45.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.133 seconds
[2024-09-22T20:13:16.153+0000] {processor.py:186} INFO - Started process (PID=3180) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:13:16.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:13:16.156+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:13:16.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:13:16.181+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:13:16.205+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:13:16.205+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:13:16.229+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:13:16.229+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:13:16.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:13:46.723+0000] {processor.py:186} INFO - Started process (PID=3194) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:13:46.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:13:46.727+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:13:46.726+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:13:46.752+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:13:46.777+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:13:46.777+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:13:46.801+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:13:46.801+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:13:46.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T20:14:17.659+0000] {processor.py:186} INFO - Started process (PID=3207) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:14:17.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:14:17.663+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:14:17.663+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:14:17.691+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:14:17.717+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:14:17.717+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:14:17.744+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:14:17.743+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:14:17.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T20:14:47.940+0000] {processor.py:186} INFO - Started process (PID=3220) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:14:47.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:14:47.943+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:14:47.943+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:14:47.969+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:14:47.995+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:14:47.994+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:14:48.019+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:14:48.019+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:14:48.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T20:15:18.398+0000] {processor.py:186} INFO - Started process (PID=3233) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:15:18.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:15:18.402+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:15:18.401+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:15:18.433+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:15:18.458+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:15:18.458+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:15:18.491+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:15:18.491+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:15:18.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.125 seconds
[2024-09-22T20:15:48.661+0000] {processor.py:186} INFO - Started process (PID=3246) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:15:48.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:15:48.664+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:15:48.664+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:15:48.692+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:15:48.717+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:15:48.717+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:15:48.743+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:15:48.743+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:15:48.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T20:16:19.115+0000] {processor.py:186} INFO - Started process (PID=3259) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:16:19.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:16:19.119+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:16:19.119+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:16:19.145+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:16:19.171+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:16:19.171+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:16:19.195+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:16:19.194+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:16:19.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T20:16:49.321+0000] {processor.py:186} INFO - Started process (PID=3272) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:16:49.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:16:49.326+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:16:49.325+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:16:49.354+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:16:49.379+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:16:49.379+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:16:49.405+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:16:49.404+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:16:49.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T20:17:19.513+0000] {processor.py:186} INFO - Started process (PID=3285) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:17:19.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:17:19.517+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:17:19.516+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:17:19.543+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:17:19.567+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:17:19.567+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:17:19.600+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:17:19.600+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:17:19.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T20:17:50.328+0000] {processor.py:186} INFO - Started process (PID=3298) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:17:50.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:17:50.332+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:17:50.332+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:17:50.358+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:17:50.382+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:17:50.381+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:17:50.405+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:17:50.404+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:17:50.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T20:18:21.189+0000] {processor.py:186} INFO - Started process (PID=3311) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:18:21.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:18:21.194+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:18:21.193+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:18:21.220+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:18:21.247+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:18:21.247+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:18:21.274+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:18:21.274+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:18:21.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T20:18:51.339+0000] {processor.py:186} INFO - Started process (PID=3324) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:18:51.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:18:51.343+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:18:51.343+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:18:51.368+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:18:51.392+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:18:51.392+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:18:51.415+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:18:51.414+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:18:51.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T20:19:21.543+0000] {processor.py:186} INFO - Started process (PID=3337) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:19:21.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:19:21.547+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:19:21.546+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:19:21.570+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:19:21.593+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:19:21.593+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:19:21.617+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:19:21.616+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:19:21.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T20:19:51.880+0000] {processor.py:186} INFO - Started process (PID=3350) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:19:51.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:19:51.883+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:19:51.883+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:19:51.908+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:19:51.931+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:19:51.931+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:19:51.954+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:19:51.954+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:19:51.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T20:20:22.406+0000] {processor.py:186} INFO - Started process (PID=3369) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:20:22.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:20:22.410+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:20:22.409+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:20:22.434+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:20:22.457+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:20:22.457+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:20:22.482+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:20:22.481+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:20:22.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T20:20:53.159+0000] {processor.py:186} INFO - Started process (PID=3380) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:20:53.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:20:53.163+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:20:53.163+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:20:53.189+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:20:53.213+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:20:53.212+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:20:53.236+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:20:53.236+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:20:53.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:21:23.376+0000] {processor.py:186} INFO - Started process (PID=3393) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:21:23.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:21:23.380+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:21:23.380+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:21:23.405+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:21:23.430+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:21:23.430+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:21:23.455+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:21:23.455+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:21:23.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T20:21:53.561+0000] {processor.py:186} INFO - Started process (PID=3405) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:21:53.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:21:53.565+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:21:53.564+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:21:53.589+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:21:53.613+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:21:53.613+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:21:53.637+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:21:53.637+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:21:53.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:22:23.903+0000] {processor.py:186} INFO - Started process (PID=3418) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:22:23.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:22:23.906+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:22:23.905+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:22:23.931+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:22:23.958+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:22:23.957+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:22:23.982+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:22:23.982+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:22:24.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T20:22:54.630+0000] {processor.py:186} INFO - Started process (PID=3431) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:22:54.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:22:54.633+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:22:54.633+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:22:54.661+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:22:54.686+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:22:54.686+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:22:54.712+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:22:54.711+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:22:54.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T20:23:25.490+0000] {processor.py:186} INFO - Started process (PID=3444) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:23:25.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:23:25.494+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:23:25.493+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:23:25.521+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:23:25.546+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:23:25.546+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:23:25.572+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:23:25.572+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:23:25.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T20:23:56.471+0000] {processor.py:186} INFO - Started process (PID=3457) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:23:56.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:23:56.475+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:23:56.475+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:23:56.502+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:23:56.526+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:23:56.526+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:23:56.549+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:23:56.549+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:23:56.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:24:26.735+0000] {processor.py:186} INFO - Started process (PID=3470) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:24:26.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:24:26.738+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:24:26.738+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:24:26.764+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:24:26.788+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:24:26.787+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:24:26.812+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:24:26.811+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:24:26.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:24:56.872+0000] {processor.py:186} INFO - Started process (PID=3483) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:24:56.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:24:56.876+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:24:56.875+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:24:56.902+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:24:56.925+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:24:56.925+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:24:56.948+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:24:56.948+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:24:56.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:25:27.153+0000] {processor.py:186} INFO - Started process (PID=3496) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:25:27.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:25:27.157+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:25:27.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:25:27.185+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:25:27.212+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:25:27.212+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:25:27.236+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:25:27.236+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:25:27.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T20:25:57.781+0000] {processor.py:186} INFO - Started process (PID=3509) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:25:57.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:25:57.787+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:25:57.785+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:25:57.815+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:25:57.839+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:25:57.839+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:25:57.864+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:25:57.863+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:25:57.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T20:26:27.964+0000] {processor.py:186} INFO - Started process (PID=3522) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:26:27.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:26:27.968+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:26:27.967+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:26:27.994+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:26:28.019+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:26:28.019+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:26:28.041+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:26:28.041+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:26:28.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T20:26:58.341+0000] {processor.py:186} INFO - Started process (PID=3535) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:26:58.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:26:58.345+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:26:58.344+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:26:58.371+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:26:58.394+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:26:58.394+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:26:58.418+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:26:58.418+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:26:58.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T20:27:28.737+0000] {processor.py:186} INFO - Started process (PID=3548) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:27:28.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:27:28.740+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:27:28.740+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:27:28.768+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:27:28.794+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:27:28.793+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:27:28.819+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:27:28.818+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:27:28.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T20:27:58.992+0000] {processor.py:186} INFO - Started process (PID=3561) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:27:58.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:27:58.997+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:27:58.996+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:27:59.027+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:27:59.062+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:27:59.061+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:27:59.094+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:27:59.094+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:27:59.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.132 seconds
[2024-09-22T20:28:29.685+0000] {processor.py:186} INFO - Started process (PID=3574) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:28:29.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:28:29.689+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:28:29.688+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:28:29.715+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:28:29.740+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:28:29.740+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:28:29.764+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:28:29.764+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:28:29.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T20:29:00.802+0000] {processor.py:186} INFO - Started process (PID=3587) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:29:00.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:29:00.806+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:29:00.805+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:29:00.830+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:29:00.853+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:29:00.853+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:29:00.876+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:29:00.876+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:29:00.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T20:29:31.021+0000] {processor.py:186} INFO - Started process (PID=3600) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:29:31.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:29:31.025+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:29:31.024+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:29:31.051+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:29:31.075+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:29:31.075+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:29:31.098+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:29:31.098+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:29:31.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:30:01.197+0000] {processor.py:186} INFO - Started process (PID=3612) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:30:01.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:30:01.201+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:30:01.200+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:30:01.243+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:30:01.278+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:30:01.278+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:30:01.309+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:30:01.309+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:30:01.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.145 seconds
[2024-09-22T20:30:31.531+0000] {processor.py:186} INFO - Started process (PID=3625) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:30:31.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:30:31.535+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:30:31.535+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:30:31.561+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:30:31.585+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:30:31.584+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:30:31.609+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:30:31.609+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:30:31.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T20:31:01.743+0000] {processor.py:186} INFO - Started process (PID=3638) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:31:01.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:31:01.747+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:31:01.746+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:31:01.782+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:31:01.814+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:31:01.814+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:31:01.838+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:31:01.838+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:31:01.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.123 seconds
[2024-09-22T20:31:32.828+0000] {processor.py:186} INFO - Started process (PID=3651) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:31:32.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:31:32.832+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:31:32.832+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:31:32.870+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:31:32.917+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:31:32.916+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:31:32.952+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:31:32.952+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:31:32.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.157 seconds
[2024-09-22T20:32:03.343+0000] {processor.py:186} INFO - Started process (PID=3664) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:32:03.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:32:03.347+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:32:03.346+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:32:03.382+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:32:03.411+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:32:03.411+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:32:03.450+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:32:03.450+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:32:03.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.143 seconds
[2024-09-22T20:32:33.955+0000] {processor.py:186} INFO - Started process (PID=3677) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:32:33.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:32:33.961+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:32:33.961+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:32:33.994+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:32:34.020+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:32:34.019+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:32:34.051+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:32:34.050+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:32:34.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.129 seconds
[2024-09-22T20:33:04.444+0000] {processor.py:186} INFO - Started process (PID=3690) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:33:04.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:33:04.452+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:33:04.451+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:33:04.481+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:33:04.509+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:33:04.509+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:33:04.537+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:33:04.537+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:33:04.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.132 seconds
[2024-09-22T20:33:34.766+0000] {processor.py:186} INFO - Started process (PID=3703) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:33:34.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:33:34.771+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:33:34.770+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:33:34.801+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:33:34.826+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:33:34.825+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:33:34.849+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:33:34.849+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:33:34.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T20:34:05.461+0000] {processor.py:186} INFO - Started process (PID=3716) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:34:05.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:34:05.464+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:34:05.464+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:34:05.492+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:34:05.516+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:34:05.516+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:34:05.540+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:34:05.540+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:34:05.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T20:34:36.402+0000] {processor.py:186} INFO - Started process (PID=3729) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:34:36.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:34:36.405+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:34:36.405+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:34:36.429+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:34:36.454+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:34:36.454+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:34:36.480+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:34:36.479+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:34:36.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T20:35:07.367+0000] {processor.py:186} INFO - Started process (PID=3742) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:35:07.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:35:07.371+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:35:07.370+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:35:07.394+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:35:07.417+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:35:07.417+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:35:07.441+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:35:07.440+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:35:07.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T20:35:38.091+0000] {processor.py:186} INFO - Started process (PID=3755) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:35:38.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:35:38.095+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:35:38.095+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:35:38.122+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:35:38.146+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:35:38.146+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:35:38.173+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:35:38.173+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:35:38.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T20:36:08.538+0000] {processor.py:186} INFO - Started process (PID=3767) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:36:08.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:36:08.542+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:36:08.542+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:36:08.573+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:36:08.609+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:36:08.608+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:36:08.631+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:36:08.631+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:36:08.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T20:36:39.242+0000] {processor.py:186} INFO - Started process (PID=3780) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:36:39.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:36:39.246+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:36:39.246+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:36:39.276+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:36:39.307+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:36:39.307+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:36:39.332+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:36:39.332+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:36:39.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T20:37:10.153+0000] {processor.py:186} INFO - Started process (PID=3793) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:37:10.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:37:10.157+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:37:10.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:37:10.185+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:37:10.210+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:37:10.209+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:37:10.234+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:37:10.234+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:37:10.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T20:37:41.230+0000] {processor.py:186} INFO - Started process (PID=3806) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:37:41.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:37:41.234+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:37:41.234+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:37:41.261+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:37:41.286+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:37:41.286+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:37:41.310+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:37:41.309+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:37:41.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T20:38:12.099+0000] {processor.py:186} INFO - Started process (PID=3819) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:38:12.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:38:12.102+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:38:12.102+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:38:12.136+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:38:12.162+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:38:12.162+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:38:12.191+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:38:12.190+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:38:12.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.121 seconds
[2024-09-22T20:38:42.782+0000] {processor.py:186} INFO - Started process (PID=3832) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:38:42.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:38:42.785+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:38:42.785+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:38:42.813+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:38:42.838+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:38:42.837+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:38:42.862+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:38:42.862+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:38:42.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T20:39:13.114+0000] {processor.py:186} INFO - Started process (PID=3845) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:39:13.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:39:13.122+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:39:13.121+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:39:13.167+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:39:13.199+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:39:13.199+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:39:13.226+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:39:13.226+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:39:13.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.147 seconds
[2024-09-22T20:39:43.518+0000] {processor.py:186} INFO - Started process (PID=3858) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:39:43.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:39:43.522+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:39:43.522+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:39:43.554+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:39:43.586+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:39:43.586+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:39:43.616+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:39:43.616+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:39:43.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.127 seconds
[2024-09-22T20:40:13.811+0000] {processor.py:186} INFO - Started process (PID=3871) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:40:13.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:40:13.815+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:40:13.815+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:40:13.843+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:40:13.873+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:40:13.872+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:40:13.905+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:40:13.905+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:40:13.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.122 seconds
[2024-09-22T20:40:44.864+0000] {processor.py:186} INFO - Started process (PID=3884) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:40:44.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:40:44.868+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:40:44.868+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:40:44.896+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:40:44.929+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:40:44.929+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:40:44.959+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:40:44.959+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:40:44.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.126 seconds
[2024-09-22T20:41:15.076+0000] {processor.py:186} INFO - Started process (PID=3897) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:41:15.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:41:15.079+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:41:15.079+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:41:15.109+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:41:15.134+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:41:15.133+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:41:15.158+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:41:15.158+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:41:15.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T20:41:45.250+0000] {processor.py:186} INFO - Started process (PID=3910) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:41:45.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:41:45.253+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:41:45.253+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:41:45.278+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:41:45.301+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:41:45.301+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:41:45.324+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:41:45.324+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:41:45.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T20:42:15.433+0000] {processor.py:186} INFO - Started process (PID=3923) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:42:15.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:42:15.437+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:42:15.437+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:42:15.462+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:42:15.487+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:42:15.486+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:42:15.512+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:42:15.512+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:42:15.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T20:42:46.128+0000] {processor.py:186} INFO - Started process (PID=3936) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:42:46.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:42:46.132+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:42:46.132+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:42:46.158+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:42:46.182+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:42:46.182+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:42:46.206+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:42:46.205+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:42:46.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:43:16.334+0000] {processor.py:186} INFO - Started process (PID=3949) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:43:16.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:43:16.340+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:43:16.339+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:43:16.381+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:43:16.418+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:43:16.417+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:43:16.450+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:43:16.450+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:43:16.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.151 seconds
[2024-09-22T20:43:46.832+0000] {processor.py:186} INFO - Started process (PID=3962) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:43:46.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:43:46.836+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:43:46.836+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:43:46.867+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:43:46.892+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:43:46.891+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:43:46.921+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:43:46.921+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:43:46.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.125 seconds
[2024-09-22T20:44:17.434+0000] {processor.py:186} INFO - Started process (PID=3975) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:44:17.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:44:17.440+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:44:17.440+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:44:17.476+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:44:17.507+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:44:17.506+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:44:17.537+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:44:17.537+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:44:17.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.145 seconds
[2024-09-22T20:44:47.830+0000] {processor.py:186} INFO - Started process (PID=3988) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:44:47.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:44:47.834+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:44:47.834+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:44:47.862+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:44:47.887+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:44:47.887+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:44:47.914+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:44:47.913+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:44:47.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T20:45:18.196+0000] {processor.py:186} INFO - Started process (PID=4001) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:45:18.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:45:18.200+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:45:18.199+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:45:18.227+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:45:18.257+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:45:18.257+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:45:18.281+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:45:18.281+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:45:18.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T20:45:48.535+0000] {processor.py:186} INFO - Started process (PID=4014) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:45:48.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:45:48.539+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:45:48.539+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:45:48.568+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:45:48.599+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:45:48.598+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:45:48.627+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:45:48.627+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:45:48.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.121 seconds
[2024-09-22T20:46:18.813+0000] {processor.py:186} INFO - Started process (PID=4027) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:46:18.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:46:18.816+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:46:18.816+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:46:18.842+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:46:18.865+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:46:18.865+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:46:18.888+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:46:18.888+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:46:18.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:46:49.002+0000] {processor.py:186} INFO - Started process (PID=4040) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:46:49.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:46:49.006+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:46:49.006+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:46:49.035+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:46:49.060+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:46:49.059+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:46:49.085+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:46:49.085+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:46:49.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T20:47:19.365+0000] {processor.py:186} INFO - Started process (PID=4053) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:47:19.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:47:19.368+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:47:19.368+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:47:19.396+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:47:19.420+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:47:19.419+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:47:19.445+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:47:19.444+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:47:19.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T20:47:49.543+0000] {processor.py:186} INFO - Started process (PID=4066) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:47:49.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:47:49.547+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:47:49.547+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:47:49.574+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:47:49.599+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:47:49.599+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:47:49.624+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:47:49.624+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:47:49.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T20:48:19.742+0000] {processor.py:186} INFO - Started process (PID=4079) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:48:19.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:48:19.746+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:48:19.745+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:48:19.772+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:48:19.798+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:48:19.797+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:48:19.823+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:48:19.823+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:48:19.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T20:48:49.941+0000] {processor.py:186} INFO - Started process (PID=4092) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:48:49.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:48:49.944+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:48:49.944+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:48:49.969+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:48:49.992+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:48:49.992+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:48:50.016+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:48:50.016+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:48:50.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:49:20.077+0000] {processor.py:186} INFO - Started process (PID=4104) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:49:20.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:49:20.080+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:49:20.080+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:49:20.105+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:49:20.129+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:49:20.129+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:49:20.152+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:49:20.151+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:49:20.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T20:49:50.280+0000] {processor.py:186} INFO - Started process (PID=4118) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:49:50.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:49:50.285+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:49:50.285+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:49:50.315+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:49:50.342+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:49:50.342+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:49:50.368+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:49:50.367+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:49:50.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T20:50:20.706+0000] {processor.py:186} INFO - Started process (PID=4131) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:50:20.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:50:20.710+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:50:20.709+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:50:20.734+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:50:20.758+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:50:20.758+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:50:20.786+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:50:20.786+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:50:20.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T20:50:51.567+0000] {processor.py:186} INFO - Started process (PID=4143) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:50:51.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:50:51.570+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:50:51.570+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:50:51.597+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:50:51.621+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:50:51.621+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:50:51.646+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:50:51.646+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:50:51.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T20:51:21.793+0000] {processor.py:186} INFO - Started process (PID=4156) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:51:21.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:51:21.797+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:51:21.797+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:51:21.826+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:51:21.850+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:51:21.849+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:51:21.875+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:51:21.875+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:51:21.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.135 seconds
[2024-09-22T20:51:51.958+0000] {processor.py:186} INFO - Started process (PID=4169) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:51:51.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:51:51.962+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:51:51.962+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:51:51.986+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:51:52.010+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:51:52.010+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:51:52.034+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:51:52.033+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:51:52.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:52:22.256+0000] {processor.py:186} INFO - Started process (PID=4183) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:52:22.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:52:22.260+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:52:22.259+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:52:22.285+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:52:22.309+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:52:22.309+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:52:22.334+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:52:22.333+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:52:22.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T20:52:52.556+0000] {processor.py:186} INFO - Started process (PID=4196) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:52:52.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:52:52.559+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:52:52.559+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:52:52.585+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:52:52.608+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:52:52.608+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:52:52.631+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:52:52.630+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:52:52.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T20:53:22.831+0000] {processor.py:186} INFO - Started process (PID=4209) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:53:22.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:53:22.835+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:53:22.834+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:53:22.861+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:53:22.885+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:53:22.885+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:53:22.909+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:53:22.909+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:53:22.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T20:53:53.686+0000] {processor.py:186} INFO - Started process (PID=4222) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:53:53.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:53:53.690+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:53:53.690+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:53:53.718+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:53:53.741+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:53:53.741+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:53:53.764+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:53:53.764+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:53:53.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:54:24.690+0000] {processor.py:186} INFO - Started process (PID=4235) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:54:24.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:54:24.696+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:54:24.696+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:54:24.728+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:54:24.751+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:54:24.751+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:54:24.775+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:54:24.775+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:54:24.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T20:54:55.636+0000] {processor.py:186} INFO - Started process (PID=4254) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:54:55.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:54:55.639+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:54:55.639+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:54:55.666+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:54:55.690+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:54:55.690+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:54:55.714+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:54:55.714+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:54:55.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T20:55:26.440+0000] {processor.py:186} INFO - Started process (PID=4266) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:55:26.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:55:26.444+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:55:26.443+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:55:26.473+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:55:26.498+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:55:26.498+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:55:26.523+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:55:26.523+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:55:26.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T20:55:56.628+0000] {processor.py:186} INFO - Started process (PID=4279) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:55:56.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:55:56.632+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:55:56.632+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:55:56.656+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:55:56.679+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:55:56.679+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:55:56.703+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:55:56.703+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:55:56.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T20:56:27.503+0000] {processor.py:186} INFO - Started process (PID=4292) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:56:27.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:56:27.508+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:56:27.508+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:56:27.534+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:56:27.559+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:56:27.559+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:56:27.582+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:56:27.582+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:56:27.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T20:56:57.788+0000] {processor.py:186} INFO - Started process (PID=4305) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:56:57.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:56:57.791+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:56:57.791+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:56:57.816+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:56:57.841+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:56:57.841+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:56:57.864+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:56:57.864+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:56:57.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T20:57:28.011+0000] {processor.py:186} INFO - Started process (PID=4319) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:57:28.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:57:28.014+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:57:28.014+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:57:28.040+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:57:28.065+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:57:28.064+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:57:28.087+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:57:28.087+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:57:28.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T20:57:58.350+0000] {processor.py:186} INFO - Started process (PID=4332) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:57:58.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:57:58.354+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:57:58.354+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:57:58.379+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:57:58.403+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:57:58.403+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:57:58.425+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:57:58.425+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:57:58.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T20:58:29.344+0000] {processor.py:186} INFO - Started process (PID=4345) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:58:29.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:58:29.350+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:58:29.349+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:58:29.375+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:58:29.398+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:58:29.398+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:58:29.423+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:58:29.423+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:58:29.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T20:59:00.311+0000] {processor.py:186} INFO - Started process (PID=4358) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:59:00.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:59:00.315+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:59:00.315+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:59:00.339+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:59:00.362+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:59:00.362+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:59:00.386+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:59:00.386+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:59:00.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T20:59:31.169+0000] {processor.py:186} INFO - Started process (PID=4371) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:59:31.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T20:59:31.172+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:59:31.172+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:59:31.197+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T20:59:31.222+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:59:31.221+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T20:59:31.246+0000] {logging_mixin.py:190} INFO - [2024-09-22T20:59:31.246+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T20:59:31.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T21:00:01.369+0000] {processor.py:186} INFO - Started process (PID=4384) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:00:01.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:00:01.372+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:00:01.372+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:00:01.402+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:00:01.428+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:00:01.428+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:00:01.454+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:00:01.454+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:00:01.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T21:00:31.562+0000] {processor.py:186} INFO - Started process (PID=4397) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:00:31.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:00:31.566+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:00:31.565+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:00:31.591+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:00:31.615+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:00:31.615+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:00:31.638+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:00:31.638+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:00:31.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T21:01:02.476+0000] {processor.py:186} INFO - Started process (PID=4410) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:01:02.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:01:02.479+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:01:02.479+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:01:02.504+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:01:02.528+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:01:02.528+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:01:02.551+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:01:02.551+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:01:02.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T21:01:32.669+0000] {processor.py:186} INFO - Started process (PID=4423) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:01:32.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:01:32.673+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:01:32.672+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:01:32.697+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:01:32.720+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:01:32.720+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:01:32.743+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:01:32.743+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:01:32.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.098 seconds
[2024-09-22T21:02:03.055+0000] {processor.py:186} INFO - Started process (PID=4436) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:02:03.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:02:03.059+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:02:03.059+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:02:03.085+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:02:03.110+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:02:03.109+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:02:03.135+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:02:03.135+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:02:03.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:02:33.283+0000] {processor.py:186} INFO - Started process (PID=4449) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:02:33.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:02:33.287+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:02:33.287+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:02:33.314+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:02:33.339+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:02:33.339+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:02:33.362+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:02:33.362+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:02:33.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:03:03.464+0000] {processor.py:186} INFO - Started process (PID=4462) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:03:03.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:03:03.467+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:03:03.467+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:03:03.493+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:03:03.517+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:03:03.516+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:03:03.539+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:03:03.539+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:03:03.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T21:03:33.719+0000] {processor.py:186} INFO - Started process (PID=4475) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:03:33.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:03:33.722+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:03:33.722+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:03:33.748+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:03:33.773+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:03:33.772+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:03:33.796+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:03:33.796+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:03:33.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T21:04:03.881+0000] {processor.py:186} INFO - Started process (PID=4488) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:04:03.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:04:03.884+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:04:03.884+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:04:03.910+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:04:03.934+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:04:03.933+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:04:03.959+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:04:03.958+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:04:03.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T21:04:34.139+0000] {processor.py:186} INFO - Started process (PID=4501) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:04:34.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:04:34.143+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:04:34.142+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:04:34.168+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:04:34.192+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:04:34.192+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:04:34.215+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:04:34.215+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:04:34.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T21:05:04.367+0000] {processor.py:186} INFO - Started process (PID=4514) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:05:04.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:05:04.371+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:05:04.371+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:05:04.397+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:05:04.425+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:05:04.425+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:05:04.452+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:05:04.451+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:05:04.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T21:05:34.796+0000] {processor.py:186} INFO - Started process (PID=4527) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:05:34.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:05:34.800+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:05:34.799+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:05:34.825+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:05:34.850+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:05:34.849+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:05:34.873+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:05:34.873+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:05:34.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T21:06:05.045+0000] {processor.py:186} INFO - Started process (PID=4541) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:06:05.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:06:05.049+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:06:05.049+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:06:05.079+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:06:05.105+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:06:05.104+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:06:05.130+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:06:05.130+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:06:05.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T21:06:35.996+0000] {processor.py:186} INFO - Started process (PID=4554) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:06:35.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:06:35.999+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:06:35.999+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:06:36.026+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:06:36.050+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:06:36.049+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:06:36.074+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:06:36.073+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:06:36.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T21:07:06.142+0000] {processor.py:186} INFO - Started process (PID=4567) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:07:06.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:07:06.146+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:07:06.146+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:07:06.173+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:07:06.199+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:07:06.199+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:07:06.228+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:07:06.228+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:07:06.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T21:07:37.145+0000] {processor.py:186} INFO - Started process (PID=4580) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:07:37.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:07:37.149+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:07:37.149+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:07:37.175+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:07:37.198+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:07:37.198+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:07:37.221+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:07:37.221+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:07:37.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T21:08:08.120+0000] {processor.py:186} INFO - Started process (PID=4593) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:08:08.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:08:08.123+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:08:08.123+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:08:08.149+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:08:08.172+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:08:08.172+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:08:08.198+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:08:08.198+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:08:08.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T21:08:39.079+0000] {processor.py:186} INFO - Started process (PID=4606) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:08:39.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:08:39.083+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:08:39.082+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:08:39.109+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:08:39.133+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:08:39.133+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:08:39.158+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:08:39.158+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:08:39.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:09:09.913+0000] {processor.py:186} INFO - Started process (PID=4619) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:09:09.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:09:09.917+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:09:09.917+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:09:09.941+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:09:09.965+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:09:09.965+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:09:09.990+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:09:09.990+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:09:10.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:09:40.065+0000] {processor.py:186} INFO - Started process (PID=4632) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:09:40.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:09:40.069+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:09:40.069+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:09:40.094+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:09:40.120+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:09:40.119+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:09:40.146+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:09:40.145+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:09:40.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:10:10.243+0000] {processor.py:186} INFO - Started process (PID=4645) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:10:10.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:10:10.246+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:10:10.246+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:10:10.270+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:10:10.294+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:10:10.293+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:10:10.318+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:10:10.318+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:10:10.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T21:10:41.013+0000] {processor.py:186} INFO - Started process (PID=4658) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:10:41.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:10:41.016+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:10:41.016+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:10:41.042+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:10:41.066+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:10:41.065+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:10:41.089+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:10:41.089+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:10:41.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:11:11.928+0000] {processor.py:186} INFO - Started process (PID=4671) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:11:11.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:11:11.931+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:11:11.931+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:11:11.959+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:11:11.984+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:11:11.984+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:11:12.010+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:11:12.010+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:11:12.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T21:11:42.756+0000] {processor.py:186} INFO - Started process (PID=4684) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:11:42.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:11:42.760+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:11:42.760+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:11:42.786+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:11:42.810+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:11:42.810+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:11:42.833+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:11:42.833+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:11:42.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T21:12:12.920+0000] {processor.py:186} INFO - Started process (PID=4697) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:12:12.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:12:12.924+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:12:12.923+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:12:12.949+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:12:12.973+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:12:12.973+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:12:12.997+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:12:12.997+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:12:13.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T21:12:43.954+0000] {processor.py:186} INFO - Started process (PID=4711) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:12:43.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:12:43.957+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:12:43.957+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:12:43.984+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:12:44.008+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:12:44.007+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:12:44.033+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:12:44.033+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:12:44.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T21:13:14.152+0000] {processor.py:186} INFO - Started process (PID=4724) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:13:14.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:13:14.156+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:13:14.155+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:13:14.180+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:13:14.205+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:13:14.205+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:13:14.228+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:13:14.228+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:13:14.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T21:13:44.554+0000] {processor.py:186} INFO - Started process (PID=4737) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:13:44.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:13:44.558+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:13:44.558+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:13:44.583+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:13:44.606+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:13:44.606+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:13:44.629+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:13:44.629+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:13:44.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T21:14:14.727+0000] {processor.py:186} INFO - Started process (PID=4750) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:14:14.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:14:14.730+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:14:14.730+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:14:14.754+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:14:14.778+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:14:14.777+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:14:14.800+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:14:14.800+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:14:14.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T21:14:45.785+0000] {processor.py:186} INFO - Started process (PID=4763) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:14:45.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:14:45.789+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:14:45.789+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:14:45.818+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:14:45.841+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:14:45.841+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:14:45.864+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:14:45.864+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:14:45.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:15:16.082+0000] {processor.py:186} INFO - Started process (PID=4777) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:15:16.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:15:16.085+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:15:16.085+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:15:16.109+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:15:16.133+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:15:16.132+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:15:16.157+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:15:16.157+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:15:16.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T21:15:46.986+0000] {processor.py:186} INFO - Started process (PID=4789) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:15:46.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:15:46.990+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:15:46.989+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:15:47.017+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:15:47.042+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:15:47.042+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:15:47.065+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:15:47.065+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:15:47.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T21:16:17.968+0000] {processor.py:186} INFO - Started process (PID=4802) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:16:17.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:16:17.971+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:16:17.971+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:16:17.998+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:16:18.022+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:16:18.021+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:16:18.045+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:16:18.045+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:16:18.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:16:48.946+0000] {processor.py:186} INFO - Started process (PID=4815) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:16:48.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:16:48.950+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:16:48.949+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:16:48.981+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:16:49.005+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:16:49.005+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:16:49.028+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:16:49.028+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:16:49.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T21:17:19.239+0000] {processor.py:186} INFO - Started process (PID=4828) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:17:19.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:17:19.242+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:17:19.242+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:17:19.271+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:17:19.300+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:17:19.300+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:17:19.325+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:17:19.325+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:17:19.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T21:17:50.150+0000] {processor.py:186} INFO - Started process (PID=4841) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:17:50.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:17:50.155+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:17:50.155+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:17:50.182+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:17:50.209+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:17:50.209+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:17:50.233+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:17:50.233+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:17:50.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T21:18:20.343+0000] {processor.py:186} INFO - Started process (PID=4853) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:18:20.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:18:20.346+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:18:20.346+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:18:20.375+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:18:20.401+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:18:20.401+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:18:20.429+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:18:20.428+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:18:20.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.121 seconds
[2024-09-22T21:18:51.603+0000] {processor.py:186} INFO - Started process (PID=4866) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:18:51.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:18:51.607+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:18:51.607+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:18:51.633+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:18:51.656+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:18:51.656+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:18:51.678+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:18:51.678+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:18:51.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T21:19:21.784+0000] {processor.py:186} INFO - Started process (PID=4879) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:19:21.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:19:21.787+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:19:21.787+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:19:21.818+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:19:21.841+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:19:21.841+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:19:21.864+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:19:21.863+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:19:21.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:19:52.725+0000] {processor.py:186} INFO - Started process (PID=4892) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:19:52.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:19:52.729+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:19:52.728+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:19:52.755+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:19:52.782+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:19:52.782+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:19:52.808+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:19:52.807+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:19:52.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T21:20:23.601+0000] {processor.py:186} INFO - Started process (PID=4905) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:20:23.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:20:23.605+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:20:23.604+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:20:23.632+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:20:23.658+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:20:23.657+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:20:23.683+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:20:23.683+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:20:23.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T21:20:54.712+0000] {processor.py:186} INFO - Started process (PID=4918) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:20:54.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:20:54.716+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:20:54.716+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:20:54.742+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:20:54.766+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:20:54.766+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:20:54.791+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:20:54.790+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:20:54.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:21:25.630+0000] {processor.py:186} INFO - Started process (PID=4931) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:21:25.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:21:25.633+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:21:25.632+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:21:25.658+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:21:25.683+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:21:25.683+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:21:25.706+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:21:25.706+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:21:25.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T21:21:55.888+0000] {processor.py:186} INFO - Started process (PID=4945) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:21:55.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:21:55.892+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:21:55.892+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:21:55.917+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:21:55.941+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:21:55.941+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:21:55.965+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:21:55.964+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:21:55.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T21:22:26.128+0000] {processor.py:186} INFO - Started process (PID=4958) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:22:26.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:22:26.132+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:22:26.132+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:22:26.155+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:22:26.181+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:22:26.181+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:22:26.204+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:22:26.204+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:22:26.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T21:22:56.310+0000] {processor.py:186} INFO - Started process (PID=4970) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:22:56.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:22:56.313+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:22:56.312+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:22:56.340+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:22:56.363+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:22:56.362+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:22:56.385+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:22:56.385+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:22:56.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:23:27.138+0000] {processor.py:186} INFO - Started process (PID=4989) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:23:27.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:23:27.142+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:23:27.141+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:23:27.169+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:23:27.195+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:23:27.195+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:23:27.219+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:23:27.219+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:23:27.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T21:23:58.182+0000] {processor.py:186} INFO - Started process (PID=5002) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:23:58.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:23:58.185+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:23:58.184+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:23:58.210+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:23:58.233+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:23:58.233+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:23:58.259+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:23:58.258+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:23:58.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:24:28.354+0000] {processor.py:186} INFO - Started process (PID=5015) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:24:28.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:24:28.358+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:24:28.357+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:24:28.387+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:24:28.411+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:24:28.410+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:24:28.434+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:24:28.434+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:24:28.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:24:59.183+0000] {processor.py:186} INFO - Started process (PID=5028) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:24:59.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:24:59.187+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:24:59.187+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:24:59.212+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:24:59.236+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:24:59.235+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:24:59.259+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:24:59.259+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:24:59.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:25:30.019+0000] {processor.py:186} INFO - Started process (PID=5041) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:25:30.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:25:30.022+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:25:30.022+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:25:30.050+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:25:30.074+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:25:30.074+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:25:30.098+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:25:30.098+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:25:30.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:26:01.131+0000] {processor.py:186} INFO - Started process (PID=5054) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:26:01.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:26:01.134+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:26:01.134+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:26:01.161+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:26:01.184+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:26:01.184+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:26:01.208+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:26:01.208+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:26:01.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T21:26:32.236+0000] {processor.py:186} INFO - Started process (PID=5067) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:26:32.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:26:32.240+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:26:32.240+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:26:32.266+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:26:32.290+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:26:32.290+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:26:32.314+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:26:32.313+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:26:32.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T21:27:02.523+0000] {processor.py:186} INFO - Started process (PID=5080) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:27:02.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:27:02.527+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:27:02.526+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:27:02.553+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:27:02.579+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:27:02.578+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:27:02.602+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:27:02.602+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:27:02.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T21:27:33.458+0000] {processor.py:186} INFO - Started process (PID=5093) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:27:33.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:27:33.462+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:27:33.461+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:27:33.487+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:27:33.511+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:27:33.511+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:27:33.535+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:27:33.535+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:27:33.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:28:04.366+0000] {processor.py:186} INFO - Started process (PID=5107) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:28:04.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:28:04.370+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:28:04.369+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:28:04.397+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:28:04.421+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:28:04.421+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:28:04.446+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:28:04.446+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:28:04.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:28:35.437+0000] {processor.py:186} INFO - Started process (PID=5120) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:28:35.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:28:35.441+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:28:35.441+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:28:35.467+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:28:35.491+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:28:35.491+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:28:35.515+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:28:35.514+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:28:35.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T21:29:06.563+0000] {processor.py:186} INFO - Started process (PID=5133) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:29:06.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:29:06.567+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:29:06.566+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:29:06.594+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:29:06.617+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:29:06.617+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:29:06.640+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:29:06.640+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:29:06.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T21:29:36.734+0000] {processor.py:186} INFO - Started process (PID=5146) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:29:36.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:29:36.737+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:29:36.737+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:29:36.765+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:29:36.791+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:29:36.791+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:29:36.819+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:29:36.819+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:29:36.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.114 seconds
[2024-09-22T21:30:07.744+0000] {processor.py:186} INFO - Started process (PID=5159) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:30:07.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:30:07.748+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:30:07.748+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:30:07.776+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:30:07.799+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:30:07.799+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:30:07.822+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:30:07.822+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:30:07.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:30:38.854+0000] {processor.py:186} INFO - Started process (PID=5172) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:30:38.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:30:38.858+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:30:38.858+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:30:38.887+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:30:38.911+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:30:38.911+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:30:38.935+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:30:38.934+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:30:38.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:31:09.973+0000] {processor.py:186} INFO - Started process (PID=5185) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:31:09.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:31:09.977+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:31:09.976+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:31:10.004+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:31:10.027+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:31:10.027+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:31:10.051+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:31:10.050+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:31:10.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:31:41.064+0000] {processor.py:186} INFO - Started process (PID=5198) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:31:41.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:31:41.068+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:31:41.067+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:31:41.096+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:31:41.120+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:31:41.120+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:31:41.144+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:31:41.144+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:31:41.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T21:32:11.357+0000] {processor.py:186} INFO - Started process (PID=5211) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:32:11.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:32:11.361+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:32:11.361+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:32:11.389+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:32:11.413+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:32:11.413+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:32:11.437+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:32:11.437+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:32:11.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:32:42.412+0000] {processor.py:186} INFO - Started process (PID=5225) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:32:42.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:32:42.415+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:32:42.415+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:32:42.445+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:32:42.470+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:32:42.469+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:32:42.493+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:32:42.493+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:32:42.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T21:33:13.281+0000] {processor.py:186} INFO - Started process (PID=5238) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:33:13.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:33:13.285+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:33:13.284+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:33:13.312+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:33:13.336+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:33:13.336+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:33:13.362+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:33:13.362+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:33:13.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:33:44.251+0000] {processor.py:186} INFO - Started process (PID=5251) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:33:44.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:33:44.255+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:33:44.255+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:33:44.281+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:33:44.304+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:33:44.304+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:33:44.329+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:33:44.329+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:33:44.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T21:34:14.434+0000] {processor.py:186} INFO - Started process (PID=5264) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:34:14.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:34:14.439+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:34:14.438+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:34:14.463+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:34:14.487+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:34:14.487+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:34:14.512+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:34:14.511+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:34:14.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T21:34:44.727+0000] {processor.py:186} INFO - Started process (PID=5277) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:34:44.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:34:44.731+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:34:44.731+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:34:44.760+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:34:44.784+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:34:44.784+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:34:44.808+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:34:44.808+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:34:44.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T21:35:14.896+0000] {processor.py:186} INFO - Started process (PID=5290) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:35:14.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:35:14.900+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:35:14.899+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:35:14.926+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:35:14.951+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:35:14.950+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:35:14.975+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:35:14.975+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:35:14.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T21:35:45.049+0000] {processor.py:186} INFO - Started process (PID=5303) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:35:45.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:35:45.053+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:35:45.053+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:35:45.086+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:35:45.117+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:35:45.116+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:35:45.147+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:35:45.147+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:35:45.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.130 seconds
[2024-09-22T21:36:16.153+0000] {processor.py:186} INFO - Started process (PID=5316) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:36:16.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:36:16.157+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:36:16.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:36:16.184+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:36:16.210+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:36:16.210+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:36:16.236+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:36:16.236+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:36:16.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T21:36:46.335+0000] {processor.py:186} INFO - Started process (PID=5330) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:36:46.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:36:46.340+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:36:46.340+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:36:46.363+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:36:46.388+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:36:46.387+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:36:46.413+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:36:46.412+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:36:46.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T21:37:16.628+0000] {processor.py:186} INFO - Started process (PID=5342) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:37:16.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:37:16.631+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:37:16.631+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:37:16.658+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:37:16.683+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:37:16.683+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:37:16.707+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:37:16.706+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:37:16.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:37:46.803+0000] {processor.py:186} INFO - Started process (PID=5355) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:37:46.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:37:46.806+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:37:46.806+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:37:46.832+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:37:46.855+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:37:46.855+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:37:46.878+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:37:46.877+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:37:46.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T21:38:17.686+0000] {processor.py:186} INFO - Started process (PID=5364) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:38:17.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:38:17.689+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:38:17.689+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:38:17.716+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:38:17.740+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:38:17.740+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:38:17.764+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:38:17.764+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:38:17.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:38:47.948+0000] {processor.py:186} INFO - Started process (PID=5378) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:38:47.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:38:47.952+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:38:47.951+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:38:47.980+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:38:48.009+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:38:48.009+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:38:48.034+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:38:48.034+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:38:48.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T21:39:18.327+0000] {processor.py:186} INFO - Started process (PID=5391) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:39:18.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:39:18.331+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:39:18.330+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:39:18.380+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:39:18.403+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:39:18.403+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:39:18.427+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:39:18.426+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:39:18.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.128 seconds
[2024-09-22T21:39:48.683+0000] {processor.py:186} INFO - Started process (PID=5404) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:39:48.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:39:48.686+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:39:48.686+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:39:48.709+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:39:48.732+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:39:48.732+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:39:48.757+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:39:48.757+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:39:48.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:40:18.979+0000] {processor.py:186} INFO - Started process (PID=5417) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:40:18.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:40:18.982+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:40:18.982+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:40:19.010+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:40:19.033+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:40:19.033+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:40:19.058+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:40:19.058+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:40:19.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:40:49.420+0000] {processor.py:186} INFO - Started process (PID=5430) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:40:49.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:40:49.423+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:40:49.423+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:40:49.450+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:40:49.475+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:40:49.475+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:40:49.498+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:40:49.498+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:40:49.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:41:19.642+0000] {processor.py:186} INFO - Started process (PID=5443) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:41:19.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:41:19.646+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:41:19.646+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:41:19.673+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:41:19.698+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:41:19.697+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:41:19.722+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:41:19.722+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:41:19.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T21:41:50.063+0000] {processor.py:186} INFO - Started process (PID=5456) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:41:50.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:41:50.067+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:41:50.066+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:41:50.091+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:41:50.115+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:41:50.115+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:41:50.138+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:41:50.138+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:41:50.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T21:42:20.361+0000] {processor.py:186} INFO - Started process (PID=5469) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:42:20.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:42:20.365+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:42:20.365+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:42:20.393+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:42:20.419+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:42:20.419+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:42:20.445+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:42:20.445+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:42:20.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T21:42:50.556+0000] {processor.py:186} INFO - Started process (PID=5483) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:42:50.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:42:50.559+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:42:50.559+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:42:50.588+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:42:50.614+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:42:50.614+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:42:50.639+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:42:50.639+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:42:50.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T21:43:20.788+0000] {processor.py:186} INFO - Started process (PID=5496) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:43:20.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:43:20.792+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:43:20.791+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:43:20.818+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:43:20.843+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:43:20.842+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:43:20.872+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:43:20.872+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:43:20.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T21:43:50.970+0000] {processor.py:186} INFO - Started process (PID=5509) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:43:50.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:43:50.973+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:43:50.973+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:43:50.999+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:43:51.022+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:43:51.022+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:43:51.046+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:43:51.046+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:43:51.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T21:44:21.208+0000] {processor.py:186} INFO - Started process (PID=5522) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:44:21.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:44:21.212+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:44:21.212+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:44:21.240+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:44:21.264+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:44:21.264+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:44:21.288+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:44:21.287+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:44:21.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T21:44:51.460+0000] {processor.py:186} INFO - Started process (PID=5536) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:44:51.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:44:51.463+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:44:51.463+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:44:51.488+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:44:51.512+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:44:51.512+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:44:51.535+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:44:51.535+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:44:51.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:45:21.737+0000] {processor.py:186} INFO - Started process (PID=5548) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:45:21.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:45:21.741+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:45:21.740+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:45:21.767+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:45:21.790+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:45:21.790+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:45:21.814+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:45:21.814+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:45:21.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T21:45:52.077+0000] {processor.py:186} INFO - Started process (PID=5561) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:45:52.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:45:52.080+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:45:52.080+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:45:52.107+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:45:52.130+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:45:52.130+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:45:52.155+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:45:52.155+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:45:52.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:46:22.259+0000] {processor.py:186} INFO - Started process (PID=5575) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:46:22.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:46:22.262+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:46:22.262+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:46:22.291+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:46:22.318+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:46:22.317+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:46:22.342+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:46:22.342+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:46:22.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T21:46:52.471+0000] {processor.py:186} INFO - Started process (PID=5588) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:46:52.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:46:52.476+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:46:52.475+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:46:52.502+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:46:52.526+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:46:52.525+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:46:52.550+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:46:52.549+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:46:52.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:47:22.690+0000] {processor.py:186} INFO - Started process (PID=5601) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:47:22.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:47:22.694+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:47:22.694+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:47:22.721+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:47:22.744+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:47:22.744+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:47:22.769+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:47:22.768+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:47:22.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:47:53.072+0000] {processor.py:186} INFO - Started process (PID=5614) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:47:53.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:47:53.075+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:47:53.075+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:47:53.102+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:47:53.126+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:47:53.125+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:47:53.153+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:47:53.152+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:47:53.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:48:23.220+0000] {processor.py:186} INFO - Started process (PID=5627) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:48:23.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:48:23.223+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:48:23.223+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:48:23.248+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:48:23.271+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:48:23.271+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:48:23.296+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:48:23.296+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:48:23.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T21:48:53.634+0000] {processor.py:186} INFO - Started process (PID=5640) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:48:53.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:48:53.637+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:48:53.637+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:48:53.664+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:48:53.689+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:48:53.689+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:48:53.714+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:48:53.714+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:48:53.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:49:23.824+0000] {processor.py:186} INFO - Started process (PID=5653) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:49:23.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:49:23.829+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:49:23.829+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:49:23.862+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:49:23.886+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:49:23.886+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:49:23.914+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:49:23.914+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:49:23.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T21:49:54.173+0000] {processor.py:186} INFO - Started process (PID=5666) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:49:54.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:49:54.180+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:49:54.180+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:49:54.213+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:49:54.239+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:49:54.239+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:49:54.268+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:49:54.268+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:49:54.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.131 seconds
[2024-09-22T21:50:24.373+0000] {processor.py:186} INFO - Started process (PID=5679) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:50:24.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:50:24.376+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:50:24.376+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:50:24.403+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:50:24.428+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:50:24.428+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:50:24.455+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:50:24.454+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:50:24.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T21:50:54.636+0000] {processor.py:186} INFO - Started process (PID=5692) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:50:54.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:50:54.639+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:50:54.639+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:50:54.665+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:50:54.690+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:50:54.690+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:50:54.715+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:50:54.715+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:50:54.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:51:24.962+0000] {processor.py:186} INFO - Started process (PID=5705) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:51:24.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:51:24.966+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:51:24.966+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:51:24.995+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:51:25.022+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:51:25.022+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:51:25.048+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:51:25.048+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:51:25.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T21:51:55.250+0000] {processor.py:186} INFO - Started process (PID=5719) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:51:55.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:51:55.254+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:51:55.254+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:51:55.281+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:51:55.306+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:51:55.306+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:51:55.330+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:51:55.330+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:51:55.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.134 seconds
[2024-09-22T21:52:25.423+0000] {processor.py:186} INFO - Started process (PID=5731) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:52:25.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:52:25.426+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:52:25.426+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:52:25.454+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:52:25.481+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:52:25.481+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:52:25.507+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:52:25.507+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:52:25.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T21:52:55.661+0000] {processor.py:186} INFO - Started process (PID=5744) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:52:55.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:52:55.664+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:52:55.664+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:52:55.690+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:52:55.714+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:52:55.713+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:52:55.747+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:52:55.747+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:52:56.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.351 seconds
[2024-09-22T21:53:26.067+0000] {processor.py:186} INFO - Started process (PID=5758) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:53:26.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:53:26.070+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:53:26.070+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:53:26.097+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:53:26.121+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:53:26.121+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:53:26.145+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:53:26.145+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:53:26.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:53:56.244+0000] {processor.py:186} INFO - Started process (PID=5771) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:53:56.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:53:56.248+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:53:56.247+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:53:56.273+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:53:56.297+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:53:56.297+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:53:56.323+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:53:56.323+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:53:56.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:54:26.721+0000] {processor.py:186} INFO - Started process (PID=5783) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:54:26.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:54:26.725+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:54:26.724+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:54:26.751+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:54:26.775+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:54:26.775+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:54:26.799+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:54:26.799+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:54:26.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.199 seconds
[2024-09-22T21:54:57.148+0000] {processor.py:186} INFO - Started process (PID=5796) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:54:57.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:54:57.151+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:54:57.151+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:54:57.178+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:54:57.201+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:54:57.201+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:54:57.226+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:54:57.226+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:54:57.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:55:27.323+0000] {processor.py:186} INFO - Started process (PID=5809) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:55:27.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:55:27.327+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:55:27.326+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:55:27.354+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:55:27.379+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:55:27.379+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:55:27.404+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:55:27.404+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:55:27.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T21:55:57.590+0000] {processor.py:186} INFO - Started process (PID=5822) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:55:57.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:55:57.593+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:55:57.593+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:55:57.618+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:55:57.642+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:55:57.642+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:55:57.665+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:55:57.665+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:55:57.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T21:56:27.854+0000] {processor.py:186} INFO - Started process (PID=5835) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:56:27.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:56:27.858+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:56:27.858+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:56:27.884+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:56:27.909+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:56:27.909+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:56:27.936+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:56:27.936+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:56:27.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T21:56:58.036+0000] {processor.py:186} INFO - Started process (PID=5848) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:56:58.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:56:58.039+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:56:58.039+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:56:58.064+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:56:58.088+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:56:58.088+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:56:58.113+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:56:58.113+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:56:58.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T21:57:28.220+0000] {processor.py:186} INFO - Started process (PID=5860) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:57:28.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:57:28.223+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:57:28.223+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:57:28.249+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:57:28.278+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:57:28.277+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:57:28.301+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:57:28.301+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:57:28.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T21:57:58.777+0000] {processor.py:186} INFO - Started process (PID=5873) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:57:58.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:57:58.780+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:57:58.780+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:57:58.807+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:57:58.832+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:57:58.831+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:57:58.855+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:57:58.855+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:57:58.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T21:58:28.944+0000] {processor.py:186} INFO - Started process (PID=5886) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:58:28.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:58:28.948+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:58:28.948+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:58:28.976+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:58:29.000+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:58:29.000+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:58:29.023+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:58:29.023+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:58:29.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T21:58:59.163+0000] {processor.py:186} INFO - Started process (PID=5899) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:58:59.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:58:59.167+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:58:59.167+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:58:59.193+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:58:59.217+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:58:59.216+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:58:59.242+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:58:59.242+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:58:59.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:59:29.412+0000] {processor.py:186} INFO - Started process (PID=5918) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:59:29.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:59:29.415+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:59:29.415+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:59:29.441+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:59:29.466+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:59:29.465+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:59:29.489+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:59:29.489+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:59:29.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T21:59:59.644+0000] {processor.py:186} INFO - Started process (PID=5931) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:59:59.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T21:59:59.647+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:59:59.647+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:59:59.675+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T21:59:59.700+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:59:59.700+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T21:59:59.723+0000] {logging_mixin.py:190} INFO - [2024-09-22T21:59:59.723+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T21:59:59.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T22:00:29.980+0000] {processor.py:186} INFO - Started process (PID=5944) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:00:29.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:00:29.983+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:00:29.983+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:00:30.009+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:00:30.032+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:00:30.032+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:00:30.056+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:00:30.056+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:00:30.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T22:01:01.008+0000] {processor.py:186} INFO - Started process (PID=5957) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:01:01.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:01:01.012+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:01:01.012+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:01:01.037+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:01:01.061+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:01:01.061+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:01:01.085+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:01:01.085+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:01:01.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T22:01:31.310+0000] {processor.py:186} INFO - Started process (PID=5970) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:01:31.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:01:31.314+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:01:31.314+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:01:31.339+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:01:31.363+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:01:31.362+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:01:31.386+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:01:31.385+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:01:31.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:02:01.564+0000] {processor.py:186} INFO - Started process (PID=5982) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:02:01.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:02:01.567+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:02:01.567+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:02:01.594+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:02:01.618+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:02:01.617+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:02:01.646+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:02:01.645+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:02:01.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:02:31.837+0000] {processor.py:186} INFO - Started process (PID=5996) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:02:31.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:02:31.840+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:02:31.840+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:02:31.868+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:02:31.893+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:02:31.893+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:02:31.917+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:02:31.917+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:02:31.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T22:03:01.985+0000] {processor.py:186} INFO - Started process (PID=6009) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:03:01.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:03:01.988+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:03:01.988+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:03:02.016+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:03:02.041+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:03:02.041+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:03:02.065+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:03:02.065+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:03:02.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:03:32.237+0000] {processor.py:186} INFO - Started process (PID=6023) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:03:32.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:03:32.241+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:03:32.240+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:03:32.267+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:03:32.291+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:03:32.291+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:03:32.315+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:03:32.315+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:03:32.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:04:02.524+0000] {processor.py:186} INFO - Started process (PID=6035) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:04:02.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:04:02.528+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:04:02.528+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:04:02.564+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:04:02.592+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:04:02.591+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:04:02.616+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:04:02.616+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:04:02.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.121 seconds
[2024-09-22T22:04:32.824+0000] {processor.py:186} INFO - Started process (PID=6048) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:04:32.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:04:32.827+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:04:32.827+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:04:32.854+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:04:32.877+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:04:32.877+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:04:32.902+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:04:32.902+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:04:32.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:05:03.082+0000] {processor.py:186} INFO - Started process (PID=6062) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:05:03.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:05:03.085+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:05:03.084+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:05:03.111+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:05:03.135+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:05:03.135+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:05:03.161+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:05:03.161+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:05:03.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:05:33.290+0000] {processor.py:186} INFO - Started process (PID=6076) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:05:33.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:05:33.294+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:05:33.294+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:05:33.319+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:05:33.344+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:05:33.343+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:05:33.367+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:05:33.367+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:05:33.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T22:06:03.606+0000] {processor.py:186} INFO - Started process (PID=6088) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:06:03.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:06:03.610+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:06:03.610+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:06:03.640+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:06:03.664+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:06:03.664+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:06:03.686+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:06:03.686+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:06:03.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:06:34.108+0000] {processor.py:186} INFO - Started process (PID=6101) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:06:34.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:06:34.112+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:06:34.112+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:06:34.139+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:06:34.164+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:06:34.164+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:06:34.187+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:06:34.187+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:06:34.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T22:07:04.354+0000] {processor.py:186} INFO - Started process (PID=6115) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:07:04.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:07:04.358+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:07:04.358+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:07:04.388+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:07:04.421+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:07:04.420+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:07:04.448+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:07:04.448+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:07:04.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.126 seconds
[2024-09-22T22:07:34.683+0000] {processor.py:186} INFO - Started process (PID=6128) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:07:34.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:07:34.687+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:07:34.687+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:07:34.714+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:07:34.739+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:07:34.739+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:07:34.765+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:07:34.765+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:07:34.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:08:04.899+0000] {processor.py:186} INFO - Started process (PID=6139) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:08:04.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:08:04.903+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:08:04.903+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:08:04.931+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:08:04.957+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:08:04.957+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:08:04.981+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:08:04.981+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:08:05.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T22:08:35.150+0000] {processor.py:186} INFO - Started process (PID=6153) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:08:35.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:08:35.155+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:08:35.155+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:08:35.180+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:08:35.204+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:08:35.204+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:08:35.228+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:08:35.228+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:08:35.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:09:05.660+0000] {processor.py:186} INFO - Started process (PID=6165) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:09:05.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:09:05.665+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:09:05.664+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:09:05.691+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:09:05.715+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:09:05.715+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:09:05.740+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:09:05.739+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:09:05.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:09:36.025+0000] {processor.py:186} INFO - Started process (PID=6178) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:09:36.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:09:36.028+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:09:36.027+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:09:36.055+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:09:36.081+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:09:36.080+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:09:36.105+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:09:36.105+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:09:36.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:10:06.768+0000] {processor.py:186} INFO - Started process (PID=6191) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:10:06.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:10:06.771+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:10:06.771+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:10:06.798+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:10:06.822+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:10:06.822+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:10:06.848+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:10:06.848+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:10:06.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T22:10:36.938+0000] {processor.py:186} INFO - Started process (PID=6204) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:10:36.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:10:36.942+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:10:36.942+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:10:36.972+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:10:37.024+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:10:37.024+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:10:37.049+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:10:37.049+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:10:37.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.140 seconds
[2024-09-22T22:11:07.217+0000] {processor.py:186} INFO - Started process (PID=6217) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:11:07.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:11:07.221+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:11:07.220+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:11:07.248+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:11:07.272+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:11:07.272+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:11:07.297+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:11:07.297+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:11:07.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:11:37.423+0000] {processor.py:186} INFO - Started process (PID=6230) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:11:37.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:11:37.427+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:11:37.427+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:11:37.454+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:11:37.478+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:11:37.478+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:11:37.501+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:11:37.501+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:11:37.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T22:12:07.598+0000] {processor.py:186} INFO - Started process (PID=6243) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:12:07.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:12:07.601+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:12:07.601+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:12:07.627+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:12:07.651+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:12:07.651+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:12:07.675+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:12:07.675+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:12:07.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:12:37.873+0000] {processor.py:186} INFO - Started process (PID=6256) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:12:37.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:12:37.877+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:12:37.876+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:12:37.902+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:12:37.926+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:12:37.926+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:12:37.950+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:12:37.950+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:12:37.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:13:08.087+0000] {processor.py:186} INFO - Started process (PID=6269) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:13:08.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:13:08.091+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:13:08.090+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:13:08.118+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:13:08.142+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:13:08.142+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:13:08.166+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:13:08.166+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:13:08.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:13:38.412+0000] {processor.py:186} INFO - Started process (PID=6282) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:13:38.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:13:38.416+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:13:38.416+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:13:38.441+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:13:38.465+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:13:38.465+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:13:38.489+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:13:38.489+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:13:38.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:14:08.580+0000] {processor.py:186} INFO - Started process (PID=6295) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:14:08.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:14:08.585+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:14:08.585+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:14:08.611+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:14:08.638+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:14:08.638+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:14:08.663+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:14:08.663+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:14:08.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T22:14:38.759+0000] {processor.py:186} INFO - Started process (PID=6307) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:14:38.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:14:38.763+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:14:38.763+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:14:38.790+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:14:38.815+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:14:38.814+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:14:38.839+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:14:38.839+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:14:38.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T22:15:09.118+0000] {processor.py:186} INFO - Started process (PID=6320) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:15:09.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:15:09.121+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:15:09.121+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:15:09.148+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:15:09.176+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:15:09.176+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:15:09.200+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:15:09.200+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:15:09.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:15:39.491+0000] {processor.py:186} INFO - Started process (PID=6333) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:15:39.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:15:39.494+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:15:39.494+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:15:39.519+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:15:39.544+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:15:39.544+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:15:39.569+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:15:39.569+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:15:39.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:16:09.839+0000] {processor.py:186} INFO - Started process (PID=6346) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:16:09.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:16:09.842+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:16:09.842+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:16:09.868+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:16:09.892+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:16:09.891+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:16:09.916+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:16:09.916+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:16:09.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T22:16:40.263+0000] {processor.py:186} INFO - Started process (PID=6360) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:16:40.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:16:40.266+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:16:40.266+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:16:40.293+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:16:40.317+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:16:40.317+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:16:40.340+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:16:40.340+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:16:40.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:17:10.708+0000] {processor.py:186} INFO - Started process (PID=6373) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:17:10.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:17:10.711+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:17:10.711+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:17:10.733+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:17:10.762+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:17:10.762+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:17:10.786+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:17:10.785+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:17:10.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T22:17:41.038+0000] {processor.py:186} INFO - Started process (PID=6386) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:17:41.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:17:41.042+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:17:41.041+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:17:41.073+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:17:41.101+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:17:41.100+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:17:41.130+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:17:41.129+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:17:41.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.123 seconds
[2024-09-22T22:18:11.526+0000] {processor.py:186} INFO - Started process (PID=6399) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:18:11.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:18:11.530+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:18:11.529+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:18:11.554+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:18:11.579+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:18:11.579+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:18:11.604+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:18:11.603+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:18:11.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:18:41.951+0000] {processor.py:186} INFO - Started process (PID=6412) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:18:41.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:18:41.956+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:18:41.956+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:18:41.984+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:18:42.009+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:18:42.009+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:18:42.034+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:18:42.034+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:18:42.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T22:19:12.281+0000] {processor.py:186} INFO - Started process (PID=6425) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:19:12.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:19:12.284+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:19:12.284+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:19:12.310+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:19:12.335+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:19:12.334+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:19:12.358+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:19:12.358+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:19:12.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:19:42.665+0000] {processor.py:186} INFO - Started process (PID=6438) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:19:42.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:19:42.669+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:19:42.669+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:19:42.697+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:19:42.721+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:19:42.720+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:19:42.744+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:19:42.744+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:19:42.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T22:20:13.055+0000] {processor.py:186} INFO - Started process (PID=6451) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:20:13.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:20:13.058+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:20:13.058+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:20:13.086+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:20:13.111+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:20:13.110+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:20:13.134+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:20:13.134+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:20:13.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:20:43.355+0000] {processor.py:186} INFO - Started process (PID=6464) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:20:43.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:20:43.359+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:20:43.358+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:20:43.390+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:20:43.414+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:20:43.413+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:20:43.437+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:20:43.437+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:20:43.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:21:13.616+0000] {processor.py:186} INFO - Started process (PID=6477) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:21:13.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:21:13.620+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:21:13.619+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:21:13.646+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:21:13.670+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:21:13.670+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:21:13.696+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:21:13.696+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:21:13.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:21:44.050+0000] {processor.py:186} INFO - Started process (PID=6490) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:21:44.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:21:44.053+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:21:44.053+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:21:44.081+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:21:44.107+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:21:44.107+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:21:44.133+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:21:44.132+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:21:44.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T22:22:14.269+0000] {processor.py:186} INFO - Started process (PID=6502) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:22:14.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:22:14.273+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:22:14.272+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:22:14.305+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:22:14.333+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:22:14.333+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:22:14.360+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:22:14.360+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:22:14.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.121 seconds
[2024-09-22T22:22:44.522+0000] {processor.py:186} INFO - Started process (PID=6515) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:22:44.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:22:44.526+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:22:44.526+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:22:44.552+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:22:44.577+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:22:44.577+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:22:44.602+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:22:44.602+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:22:44.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:23:14.707+0000] {processor.py:186} INFO - Started process (PID=6528) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:23:14.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:23:14.713+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:23:14.712+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:23:14.740+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:23:14.764+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:23:14.764+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:23:14.790+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:23:14.790+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:23:14.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T22:23:45.215+0000] {processor.py:186} INFO - Started process (PID=6541) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:23:45.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:23:45.219+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:23:45.218+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:23:45.245+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:23:45.269+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:23:45.268+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:23:45.296+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:23:45.295+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:23:45.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T22:24:15.369+0000] {processor.py:186} INFO - Started process (PID=6554) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:24:15.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:24:15.373+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:24:15.373+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:24:15.401+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:24:15.427+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:24:15.426+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:24:15.451+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:24:15.450+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:24:15.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T22:24:45.641+0000] {processor.py:186} INFO - Started process (PID=6567) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:24:45.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:24:45.644+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:24:45.644+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:24:45.673+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:24:45.699+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:24:45.698+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:24:45.726+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:24:45.726+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:24:45.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.186 seconds
[2024-09-22T22:25:16.152+0000] {processor.py:186} INFO - Started process (PID=6580) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:25:16.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:25:16.157+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:25:16.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:25:16.190+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:25:16.219+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:25:16.219+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:25:16.245+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:25:16.245+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:25:16.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.131 seconds
[2024-09-22T22:25:46.324+0000] {processor.py:186} INFO - Started process (PID=6593) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:25:46.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:25:46.328+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:25:46.327+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:25:46.356+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:25:46.384+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:25:46.384+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:25:46.409+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:25:46.409+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:25:46.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T22:26:16.590+0000] {processor.py:186} INFO - Started process (PID=6606) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:26:16.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:26:16.594+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:26:16.593+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:26:16.620+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:26:16.644+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:26:16.644+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:26:16.669+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:26:16.668+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:26:16.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:26:46.852+0000] {processor.py:186} INFO - Started process (PID=6619) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:26:46.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:26:46.856+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:26:46.855+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:26:46.883+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:26:46.906+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:26:46.906+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:26:46.931+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:26:46.931+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:26:46.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T22:27:17.298+0000] {processor.py:186} INFO - Started process (PID=6632) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:27:17.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:27:17.302+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:27:17.301+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:27:17.329+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:27:17.353+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:27:17.353+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:27:17.376+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:27:17.376+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:27:17.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T22:27:47.491+0000] {processor.py:186} INFO - Started process (PID=6645) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:27:47.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:27:47.495+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:27:47.495+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:27:47.520+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:27:47.546+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:27:47.546+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:27:47.570+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:27:47.570+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:27:47.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:28:17.782+0000] {processor.py:186} INFO - Started process (PID=6658) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:28:17.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:28:17.785+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:28:17.785+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:28:17.811+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:28:17.835+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:28:17.835+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:28:17.859+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:28:17.859+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:28:17.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:28:48.002+0000] {processor.py:186} INFO - Started process (PID=6671) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:28:48.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:28:48.005+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:28:48.005+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:28:48.030+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:28:48.053+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:28:48.053+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:28:48.077+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:28:48.077+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:28:48.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T22:29:18.439+0000] {processor.py:186} INFO - Started process (PID=6684) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:29:18.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:29:18.442+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:29:18.442+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:29:18.468+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:29:18.493+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:29:18.492+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:29:18.517+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:29:18.517+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:29:18.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T22:29:48.924+0000] {processor.py:186} INFO - Started process (PID=6697) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:29:48.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:29:48.927+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:29:48.927+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:29:48.953+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:29:48.977+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:29:48.977+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:29:49.001+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:29:49.001+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:29:49.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T22:30:19.860+0000] {processor.py:186} INFO - Started process (PID=6710) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:30:19.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:30:19.865+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:30:19.864+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:30:19.891+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:30:19.916+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:30:19.915+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:30:19.941+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:30:19.941+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:30:19.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T22:30:50.054+0000] {processor.py:186} INFO - Started process (PID=6723) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:30:50.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:30:50.058+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:30:50.058+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:30:50.086+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:30:50.110+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:30:50.109+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:30:50.133+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:30:50.133+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:30:50.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:31:20.570+0000] {processor.py:186} INFO - Started process (PID=6736) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:31:20.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:31:20.574+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:31:20.573+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:31:20.600+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:31:20.624+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:31:20.624+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:31:20.648+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:31:20.647+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:31:20.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:31:51.391+0000] {processor.py:186} INFO - Started process (PID=6747) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:31:51.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:31:51.394+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:31:51.394+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:31:51.422+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:31:51.447+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:31:51.447+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:31:51.472+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:31:51.472+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:31:51.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:32:21.581+0000] {processor.py:186} INFO - Started process (PID=6760) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:32:21.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:32:21.585+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:32:21.584+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:32:21.613+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:32:21.640+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:32:21.639+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:32:21.665+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:32:21.664+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:32:21.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:32:51.866+0000] {processor.py:186} INFO - Started process (PID=6774) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:32:51.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:32:51.870+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:32:51.869+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:32:51.893+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:32:51.916+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:32:51.916+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:32:51.939+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:32:51.939+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:32:51.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.100 seconds
[2024-09-22T22:33:22.107+0000] {processor.py:186} INFO - Started process (PID=6786) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:33:22.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:33:22.111+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:33:22.111+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:33:22.138+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:33:22.162+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:33:22.162+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:33:22.186+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:33:22.185+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:33:22.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:33:52.948+0000] {processor.py:186} INFO - Started process (PID=6799) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:33:52.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:33:52.951+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:33:52.951+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:33:52.977+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:33:53.000+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:33:53.000+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:33:53.023+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:33:53.023+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:33:53.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T22:34:23.989+0000] {processor.py:186} INFO - Started process (PID=6812) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:34:23.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:34:23.993+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:34:23.992+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:34:24.019+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:34:24.043+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:34:24.043+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:34:24.067+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:34:24.066+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:34:24.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:34:54.443+0000] {processor.py:186} INFO - Started process (PID=6825) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:34:54.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:34:54.447+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:34:54.447+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:34:54.472+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:34:54.497+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:34:54.497+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:34:54.522+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:34:54.522+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:34:54.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:35:24.636+0000] {processor.py:186} INFO - Started process (PID=6838) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:35:24.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:35:24.640+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:35:24.640+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:35:24.665+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:35:24.692+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:35:24.691+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:35:24.718+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:35:24.718+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:35:24.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T22:35:54.818+0000] {processor.py:186} INFO - Started process (PID=6852) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:35:54.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:35:54.823+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:35:54.822+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:35:54.848+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:35:54.871+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:35:54.870+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:35:54.896+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:35:54.896+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:35:54.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T22:36:25.051+0000] {processor.py:186} INFO - Started process (PID=6864) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:36:25.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:36:25.055+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:36:25.054+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:36:25.084+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:36:25.108+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:36:25.108+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:36:25.133+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:36:25.132+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:36:25.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T22:36:55.237+0000] {processor.py:186} INFO - Started process (PID=6877) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:36:55.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:36:55.240+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:36:55.240+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:36:55.266+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:36:55.290+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:36:55.290+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:36:55.315+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:36:55.315+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:36:55.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T22:37:25.470+0000] {processor.py:186} INFO - Started process (PID=6890) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:37:25.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:37:25.474+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:37:25.473+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:37:25.502+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:37:25.526+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:37:25.525+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:37:25.551+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:37:25.551+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:37:25.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.269 seconds
[2024-09-22T22:37:55.838+0000] {processor.py:186} INFO - Started process (PID=6904) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:37:55.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:37:55.842+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:37:55.841+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:37:55.868+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:37:55.892+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:37:55.892+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:37:55.916+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:37:55.916+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:37:55.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:38:26.395+0000] {processor.py:186} INFO - Started process (PID=6916) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:38:26.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:38:26.399+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:38:26.399+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:38:26.424+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:38:26.449+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:38:26.449+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:38:26.473+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:38:26.472+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:38:26.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.175 seconds
[2024-09-22T22:38:57.282+0000] {processor.py:186} INFO - Started process (PID=6929) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:38:57.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:38:57.286+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:38:57.285+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:38:57.315+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:38:57.340+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:38:57.340+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:38:57.366+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:38:57.366+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:38:57.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.125 seconds
[2024-09-22T22:39:28.150+0000] {processor.py:186} INFO - Started process (PID=6942) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:39:28.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:39:28.153+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:39:28.153+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:39:28.182+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:39:28.207+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:39:28.207+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:39:28.232+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:39:28.232+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:39:28.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T22:39:58.961+0000] {processor.py:186} INFO - Started process (PID=6955) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:39:58.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:39:58.965+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:39:58.964+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:39:58.990+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:39:59.014+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:39:59.014+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:39:59.043+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:39:59.042+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:39:59.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T22:40:29.948+0000] {processor.py:186} INFO - Started process (PID=6968) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:40:29.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:40:29.953+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:40:29.952+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:40:29.978+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:40:30.002+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:40:30.001+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:40:30.027+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:40:30.027+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:40:30.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:41:00.105+0000] {processor.py:186} INFO - Started process (PID=6981) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:41:00.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:41:00.109+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:41:00.109+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:41:00.138+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:41:00.163+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:41:00.163+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:41:00.187+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:41:00.186+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:41:00.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T22:41:31.006+0000] {processor.py:186} INFO - Started process (PID=6994) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:41:31.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:41:31.010+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:41:31.009+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:41:31.035+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:41:31.074+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:41:31.074+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:41:31.099+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:41:31.098+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:41:31.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T22:42:01.890+0000] {processor.py:186} INFO - Started process (PID=7007) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:42:01.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:42:01.894+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:42:01.894+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:42:01.920+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:42:01.945+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:42:01.945+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:42:01.969+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:42:01.969+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:42:01.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T22:42:32.144+0000] {processor.py:186} INFO - Started process (PID=7022) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:42:32.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:42:32.148+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:42:32.148+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:42:32.174+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:42:32.198+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:42:32.198+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:42:32.225+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:42:32.225+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:42:32.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T22:43:02.357+0000] {processor.py:186} INFO - Started process (PID=7034) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:43:02.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:43:02.361+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:43:02.361+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:43:02.389+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:43:02.412+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:43:02.412+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:43:02.437+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:43:02.437+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:43:02.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:43:32.503+0000] {processor.py:186} INFO - Started process (PID=7047) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:43:32.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:43:32.507+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:43:32.507+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:43:32.554+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:43:32.582+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:43:32.581+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:43:32.607+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:43:32.607+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:43:32.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.131 seconds
[2024-09-22T22:44:02.877+0000] {processor.py:186} INFO - Started process (PID=7066) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:44:02.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:44:02.881+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:44:02.880+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:44:02.907+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:44:02.931+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:44:02.930+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:44:02.955+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:44:02.955+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:44:02.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:44:33.189+0000] {processor.py:186} INFO - Started process (PID=7079) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:44:33.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:44:33.193+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:44:33.192+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:44:33.222+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:44:33.248+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:44:33.248+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:44:33.272+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:44:33.272+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:44:33.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:45:03.960+0000] {processor.py:186} INFO - Started process (PID=7092) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:45:03.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:45:03.965+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:45:03.964+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:45:03.996+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:45:04.020+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:45:04.020+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:45:04.044+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:45:04.044+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:45:04.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T22:45:34.228+0000] {processor.py:186} INFO - Started process (PID=7105) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:45:34.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:45:34.232+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:45:34.231+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:45:34.255+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:45:34.279+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:45:34.279+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:45:34.302+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:45:34.302+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:45:34.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T22:46:04.513+0000] {processor.py:186} INFO - Started process (PID=7119) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:46:04.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:46:04.517+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:46:04.517+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:46:04.542+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:46:04.566+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:46:04.565+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:46:04.589+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:46:04.589+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:46:04.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T22:46:34.675+0000] {processor.py:186} INFO - Started process (PID=7132) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:46:34.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:46:34.679+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:46:34.678+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:46:34.704+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:46:34.729+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:46:34.729+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:46:34.753+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:46:34.753+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:46:34.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.124 seconds
[2024-09-22T22:47:05.633+0000] {processor.py:186} INFO - Started process (PID=7144) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:47:05.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:47:05.636+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:47:05.636+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:47:05.662+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:47:05.685+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:47:05.685+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:47:05.711+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:47:05.711+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:47:05.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:47:35.780+0000] {processor.py:186} INFO - Started process (PID=7157) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:47:35.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:47:35.784+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:47:35.784+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:47:35.814+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:47:35.839+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:47:35.838+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:47:35.864+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:47:35.864+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:47:35.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T22:48:05.992+0000] {processor.py:186} INFO - Started process (PID=7170) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:48:05.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:48:05.996+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:48:05.996+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:48:06.024+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:48:06.048+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:48:06.048+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:48:06.078+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:48:06.077+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:48:06.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T22:48:36.175+0000] {processor.py:186} INFO - Started process (PID=7183) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:48:36.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:48:36.178+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:48:36.178+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:48:36.208+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:48:36.232+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:48:36.231+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:48:36.256+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:48:36.256+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:48:36.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T22:49:06.368+0000] {processor.py:186} INFO - Started process (PID=7197) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:49:06.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:49:06.372+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:49:06.371+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:49:06.398+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:49:06.424+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:49:06.424+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:49:06.471+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:49:06.471+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:49:06.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.133 seconds
[2024-09-22T22:49:36.607+0000] {processor.py:186} INFO - Started process (PID=7210) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:49:36.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:49:36.610+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:49:36.610+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:49:36.637+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:49:36.661+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:49:36.661+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:49:36.684+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:49:36.684+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:49:36.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:50:06.914+0000] {processor.py:186} INFO - Started process (PID=7223) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:50:06.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:50:06.918+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:50:06.917+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:50:06.944+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:50:06.968+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:50:06.968+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:50:06.991+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:50:06.991+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:50:07.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:50:37.155+0000] {processor.py:186} INFO - Started process (PID=7236) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:50:37.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:50:37.159+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:50:37.159+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:50:37.186+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:50:37.210+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:50:37.210+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:50:37.234+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:50:37.234+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:50:37.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T22:51:07.633+0000] {processor.py:186} INFO - Started process (PID=7249) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:51:07.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:51:07.637+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:51:07.636+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:51:07.662+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:51:07.686+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:51:07.686+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:51:07.709+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:51:07.709+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:51:07.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:51:38.642+0000] {processor.py:186} INFO - Started process (PID=7262) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:51:38.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:51:38.647+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:51:38.646+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:51:38.675+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:51:38.699+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:51:38.699+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:51:38.723+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:51:38.723+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:51:38.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:52:08.919+0000] {processor.py:186} INFO - Started process (PID=7276) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:52:08.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:52:08.922+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:52:08.922+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:52:08.949+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:52:08.972+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:52:08.972+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:52:08.996+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:52:08.996+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:52:09.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:52:39.346+0000] {processor.py:186} INFO - Started process (PID=7289) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:52:39.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:52:39.350+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:52:39.350+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:52:39.377+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:52:39.401+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:52:39.401+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:52:39.425+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:52:39.425+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:52:39.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T22:53:09.779+0000] {processor.py:186} INFO - Started process (PID=7302) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:53:09.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:53:09.783+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:53:09.783+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:53:09.810+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:53:09.834+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:53:09.834+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:53:09.858+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:53:09.857+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:53:09.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:53:40.236+0000] {processor.py:186} INFO - Started process (PID=7315) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:53:40.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:53:40.240+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:53:40.240+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:53:40.266+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:53:40.290+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:53:40.290+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:53:40.314+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:53:40.314+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:53:40.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T22:54:10.619+0000] {processor.py:186} INFO - Started process (PID=7329) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:54:10.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:54:10.623+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:54:10.622+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:54:10.648+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:54:10.673+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:54:10.672+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:54:10.697+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:54:10.697+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:54:10.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T22:54:41.095+0000] {processor.py:186} INFO - Started process (PID=7342) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:54:41.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:54:41.098+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:54:41.098+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:54:41.126+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:54:41.150+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:54:41.150+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:54:41.176+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:54:41.176+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:54:41.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:55:11.516+0000] {processor.py:186} INFO - Started process (PID=7355) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:55:11.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:55:11.520+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:55:11.520+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:55:11.544+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:55:11.568+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:55:11.568+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:55:11.592+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:55:11.591+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:55:11.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T22:55:41.758+0000] {processor.py:186} INFO - Started process (PID=7368) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:55:41.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:55:41.762+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:55:41.762+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:55:41.790+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:55:41.814+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:55:41.814+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:55:41.838+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:55:41.838+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:55:41.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:56:11.963+0000] {processor.py:186} INFO - Started process (PID=7381) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:56:11.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:56:11.968+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:56:11.967+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:56:11.991+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:56:12.018+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:56:12.018+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:56:12.042+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:56:12.041+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:56:12.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:56:42.248+0000] {processor.py:186} INFO - Started process (PID=7394) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:56:42.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:56:42.251+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:56:42.251+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:56:42.278+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:56:42.303+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:56:42.302+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:56:42.327+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:56:42.327+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:56:42.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T22:57:12.777+0000] {processor.py:186} INFO - Started process (PID=7407) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:57:12.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:57:12.780+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:57:12.780+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:57:12.804+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:57:12.830+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:57:12.829+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:57:12.856+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:57:12.856+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:57:12.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T22:57:43.338+0000] {processor.py:186} INFO - Started process (PID=7420) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:57:43.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:57:43.342+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:57:43.342+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:57:43.367+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:57:43.391+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:57:43.390+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:57:43.414+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:57:43.414+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:57:43.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T22:58:13.773+0000] {processor.py:186} INFO - Started process (PID=7433) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:58:13.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:58:13.778+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:58:13.778+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:58:13.804+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:58:13.828+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:58:13.828+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:58:13.851+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:58:13.851+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:58:13.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T22:58:43.921+0000] {processor.py:186} INFO - Started process (PID=7446) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:58:43.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:58:43.925+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:58:43.924+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:58:43.950+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:58:43.976+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:58:43.975+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:58:44.000+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:58:44.000+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:58:44.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T22:59:14.828+0000] {processor.py:186} INFO - Started process (PID=7459) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:59:14.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:59:14.831+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:59:14.831+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:59:14.859+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:59:14.885+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:59:14.884+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:59:14.911+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:59:14.911+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:59:14.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T22:59:45.786+0000] {processor.py:186} INFO - Started process (PID=7472) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:59:45.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T22:59:45.790+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:59:45.790+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:59:45.818+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T22:59:45.847+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:59:45.847+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T22:59:45.876+0000] {logging_mixin.py:190} INFO - [2024-09-22T22:59:45.875+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T22:59:45.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.123 seconds
[2024-09-22T23:00:16.031+0000] {processor.py:186} INFO - Started process (PID=7486) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:00:16.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:00:16.035+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:00:16.035+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:00:16.060+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:00:16.084+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:00:16.083+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:00:16.108+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:00:16.108+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:00:16.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T23:00:46.214+0000] {processor.py:186} INFO - Started process (PID=7498) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:00:46.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:00:46.219+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:00:46.218+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:00:46.244+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:00:46.268+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:00:46.268+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:00:46.292+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:00:46.292+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:00:46.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T23:01:16.471+0000] {processor.py:186} INFO - Started process (PID=7511) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:01:16.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:01:16.475+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:01:16.474+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:01:16.500+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:01:16.524+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:01:16.524+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:01:16.547+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:01:16.547+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:01:16.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T23:01:46.978+0000] {processor.py:186} INFO - Started process (PID=7524) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:01:46.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:01:46.984+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:01:46.983+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:01:47.011+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:01:47.034+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:01:47.034+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:01:47.058+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:01:47.058+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:01:47.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:02:17.123+0000] {processor.py:186} INFO - Started process (PID=7537) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:02:17.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:02:17.127+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:02:17.127+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:02:17.154+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:02:17.179+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:02:17.178+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:02:17.205+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:02:17.205+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:02:17.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T23:02:47.388+0000] {processor.py:186} INFO - Started process (PID=7550) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:02:47.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:02:47.393+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:02:47.392+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:02:47.419+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:02:47.452+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:02:47.451+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:02:47.480+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:02:47.480+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:02:47.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.123 seconds
[2024-09-22T23:03:17.691+0000] {processor.py:186} INFO - Started process (PID=7564) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:03:17.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:03:17.697+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:03:17.697+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:03:17.722+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:03:17.745+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:03:17.744+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:03:17.768+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:03:17.768+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:03:17.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.101 seconds
[2024-09-22T23:03:48.089+0000] {processor.py:186} INFO - Started process (PID=7576) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:03:48.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:03:48.092+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:03:48.091+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:03:48.120+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:03:48.144+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:03:48.144+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:03:48.167+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:03:48.167+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:03:48.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T23:04:18.305+0000] {processor.py:186} INFO - Started process (PID=7589) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:04:18.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:04:18.308+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:04:18.308+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:04:18.334+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:04:18.359+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:04:18.359+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:04:18.384+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:04:18.383+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:04:18.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.185 seconds
[2024-09-22T23:04:48.598+0000] {processor.py:186} INFO - Started process (PID=7600) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:04:48.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:04:48.602+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:04:48.601+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:04:48.628+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:04:48.652+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:04:48.651+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:04:48.676+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:04:48.676+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:04:48.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T23:05:19.414+0000] {processor.py:186} INFO - Started process (PID=7613) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:05:19.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:05:19.418+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:05:19.418+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:05:19.445+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:05:19.469+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:05:19.469+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:05:19.494+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:05:19.494+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:05:19.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T23:05:49.811+0000] {processor.py:186} INFO - Started process (PID=7626) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:05:49.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:05:49.815+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:05:49.815+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:05:49.841+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:05:49.865+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:05:49.865+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:05:49.889+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:05:49.889+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:05:49.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T23:06:20.013+0000] {processor.py:186} INFO - Started process (PID=7639) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:06:20.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:06:20.017+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:06:20.016+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:06:20.044+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:06:20.068+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:06:20.068+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:06:20.091+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:06:20.091+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:06:20.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T23:06:50.237+0000] {processor.py:186} INFO - Started process (PID=7652) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:06:50.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:06:50.240+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:06:50.240+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:06:50.268+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:06:50.291+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:06:50.291+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:06:50.315+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:06:50.315+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:06:50.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:07:20.550+0000] {processor.py:186} INFO - Started process (PID=7665) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:07:20.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:07:20.554+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:07:20.553+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:07:20.578+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:07:20.603+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:07:20.603+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:07:20.627+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:07:20.627+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:07:20.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T23:07:50.686+0000] {processor.py:186} INFO - Started process (PID=7678) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:07:50.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:07:50.690+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:07:50.690+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:07:50.714+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:07:50.736+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:07:50.736+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:07:50.760+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:07:50.760+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:07:50.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T23:08:20.846+0000] {processor.py:186} INFO - Started process (PID=7690) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:08:20.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:08:20.849+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:08:20.849+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:08:20.873+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:08:20.898+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:08:20.898+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:08:20.922+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:08:20.922+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:08:20.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.102 seconds
[2024-09-22T23:08:51.195+0000] {processor.py:186} INFO - Started process (PID=7703) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:08:51.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:08:51.199+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:08:51.199+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:08:51.224+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:08:51.248+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:08:51.248+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:08:51.272+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:08:51.271+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:08:51.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T23:09:21.542+0000] {processor.py:186} INFO - Started process (PID=7716) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:09:21.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:09:21.546+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:09:21.546+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:09:21.572+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:09:21.598+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:09:21.598+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:09:21.625+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:09:21.625+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:09:21.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T23:09:51.847+0000] {processor.py:186} INFO - Started process (PID=7729) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:09:51.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:09:51.850+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:09:51.849+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:09:51.878+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:09:51.902+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:09:51.902+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:09:51.926+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:09:51.925+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:09:51.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T23:10:22.230+0000] {processor.py:186} INFO - Started process (PID=7741) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:10:22.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:10:22.234+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:10:22.234+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:10:22.267+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:10:22.291+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:10:22.291+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:10:22.315+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:10:22.314+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:10:22.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.113 seconds
[2024-09-22T23:10:53.086+0000] {processor.py:186} INFO - Started process (PID=7754) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:10:53.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:10:53.091+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:10:53.090+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:10:53.114+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:10:53.139+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:10:53.138+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:10:53.164+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:10:53.164+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:10:53.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T23:11:23.379+0000] {processor.py:186} INFO - Started process (PID=7767) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:11:23.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:11:23.383+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:11:23.382+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:11:23.412+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:11:23.436+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:11:23.436+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:11:23.460+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:11:23.460+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:11:23.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.265 seconds
[2024-09-22T23:11:53.929+0000] {processor.py:186} INFO - Started process (PID=7780) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:11:53.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:11:53.933+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:11:53.932+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:11:53.961+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:11:53.987+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:11:53.987+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:11:54.011+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:11:54.011+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:11:54.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T23:12:24.224+0000] {processor.py:186} INFO - Started process (PID=7793) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:12:24.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:12:24.227+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:12:24.227+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:12:24.255+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:12:24.280+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:12:24.279+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:12:24.304+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:12:24.303+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:12:24.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T23:12:55.004+0000] {processor.py:186} INFO - Started process (PID=7806) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:12:55.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:12:55.007+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:12:55.007+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:12:55.032+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:12:55.056+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:12:55.056+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:12:55.080+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:12:55.080+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:12:55.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T23:13:25.279+0000] {processor.py:186} INFO - Started process (PID=7819) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:13:25.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:13:25.283+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:13:25.283+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:13:25.308+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:13:25.332+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:13:25.331+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:13:25.356+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:13:25.356+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:13:25.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T23:13:55.461+0000] {processor.py:186} INFO - Started process (PID=7832) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:13:55.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:13:55.465+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:13:55.464+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:13:55.492+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:13:55.516+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:13:55.516+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:13:55.541+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:13:55.541+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:13:55.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.201 seconds
[2024-09-22T23:14:25.883+0000] {processor.py:186} INFO - Started process (PID=7845) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:14:25.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:14:25.886+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:14:25.886+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:14:25.913+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:14:25.964+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:14:25.964+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:14:25.990+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:14:25.989+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:14:26.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.135 seconds
[2024-09-22T23:14:56.086+0000] {processor.py:186} INFO - Started process (PID=7858) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:14:56.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:14:56.089+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:14:56.089+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:14:56.117+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:14:56.141+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:14:56.140+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:14:56.165+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:14:56.165+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:14:56.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:15:26.298+0000] {processor.py:186} INFO - Started process (PID=7871) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:15:26.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:15:26.302+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:15:26.302+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:15:26.330+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:15:26.355+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:15:26.355+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:15:26.383+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:15:26.383+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:15:26.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T23:15:56.720+0000] {processor.py:186} INFO - Started process (PID=7884) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:15:56.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:15:56.725+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:15:56.725+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:15:56.753+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:15:56.778+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:15:56.778+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:15:56.803+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:15:56.803+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:15:56.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.122 seconds
[2024-09-22T23:16:27.135+0000] {processor.py:186} INFO - Started process (PID=7897) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:16:27.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:16:27.138+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:16:27.138+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:16:27.164+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:16:27.190+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:16:27.190+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:16:27.217+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:16:27.217+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:16:27.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T23:16:57.507+0000] {processor.py:186} INFO - Started process (PID=7910) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:16:57.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:16:57.510+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:16:57.510+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:16:57.540+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:16:57.565+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:16:57.564+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:16:57.588+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:16:57.588+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:16:57.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:17:28.037+0000] {processor.py:186} INFO - Started process (PID=7923) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:17:28.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:17:28.041+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:17:28.041+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:17:28.067+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:17:28.091+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:17:28.091+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:17:28.115+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:17:28.114+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:17:28.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T23:17:58.488+0000] {processor.py:186} INFO - Started process (PID=7936) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:17:58.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:17:58.491+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:17:58.491+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:17:58.519+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:17:58.543+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:17:58.543+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:17:58.567+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:17:58.567+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:17:58.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T23:18:28.857+0000] {processor.py:186} INFO - Started process (PID=7949) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:18:28.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:18:28.860+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:18:28.860+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:18:28.886+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:18:28.910+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:18:28.909+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:18:28.933+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:18:28.933+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:18:28.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T23:18:59.196+0000] {processor.py:186} INFO - Started process (PID=7962) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:18:59.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:18:59.200+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:18:59.199+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:18:59.226+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:18:59.250+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:18:59.250+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:18:59.275+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:18:59.275+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:18:59.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:19:29.579+0000] {processor.py:186} INFO - Started process (PID=7975) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:19:29.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:19:29.583+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:19:29.583+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:19:29.611+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:19:29.636+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:19:29.636+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:19:29.659+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:19:29.659+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:19:29.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T23:19:59.908+0000] {processor.py:186} INFO - Started process (PID=7988) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:19:59.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:19:59.912+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:19:59.911+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:19:59.938+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:19:59.962+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:19:59.962+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:19:59.986+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:19:59.985+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:20:00.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:20:30.191+0000] {processor.py:186} INFO - Started process (PID=8002) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:20:30.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:20:30.195+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:20:30.194+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:20:30.221+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:20:30.245+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:20:30.245+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:20:30.268+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:20:30.268+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:20:30.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T23:21:00.642+0000] {processor.py:186} INFO - Started process (PID=8015) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:21:00.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:21:00.645+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:21:00.645+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:21:00.671+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:21:00.696+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:21:00.696+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:21:00.720+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:21:00.720+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:21:00.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:21:30.916+0000] {processor.py:186} INFO - Started process (PID=8028) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:21:30.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:21:30.919+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:21:30.919+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:21:30.944+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:21:30.968+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:21:30.968+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:21:30.993+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:21:30.993+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:21:31.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:22:01.435+0000] {processor.py:186} INFO - Started process (PID=8041) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:22:01.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:22:01.439+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:22:01.439+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:22:01.465+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:22:01.489+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:22:01.489+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:22:01.515+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:22:01.515+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:22:01.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:22:31.938+0000] {processor.py:186} INFO - Started process (PID=8054) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:22:31.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:22:31.943+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:22:31.942+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:22:31.968+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:22:31.999+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:22:31.999+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:22:32.028+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:22:32.028+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:22:32.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T23:23:02.346+0000] {processor.py:186} INFO - Started process (PID=8067) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:23:02.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:23:02.350+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:23:02.349+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:23:02.377+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:23:02.401+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:23:02.401+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:23:02.426+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:23:02.425+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:23:02.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:23:32.795+0000] {processor.py:186} INFO - Started process (PID=8079) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:23:32.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:23:32.798+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:23:32.798+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:23:32.829+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:23:32.857+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:23:32.857+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:23:32.882+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:23:32.882+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:23:32.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.117 seconds
[2024-09-22T23:24:03.201+0000] {processor.py:186} INFO - Started process (PID=8092) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:24:03.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:24:03.205+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:24:03.205+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:24:03.232+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:24:03.256+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:24:03.256+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:24:03.280+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:24:03.279+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:24:03.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T23:24:33.653+0000] {processor.py:186} INFO - Started process (PID=8105) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:24:33.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:24:33.656+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:24:33.656+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:24:33.682+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:24:33.706+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:24:33.706+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:24:33.729+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:24:33.729+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:24:33.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T23:25:04.012+0000] {processor.py:186} INFO - Started process (PID=8118) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:25:04.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:25:04.016+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:25:04.015+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:25:04.042+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:25:04.068+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:25:04.068+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:25:04.092+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:25:04.091+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:25:04.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T23:25:34.362+0000] {processor.py:186} INFO - Started process (PID=8131) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:25:34.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:25:34.366+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:25:34.366+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:25:34.392+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:25:34.416+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:25:34.416+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:25:34.441+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:25:34.440+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:25:34.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:26:04.799+0000] {processor.py:186} INFO - Started process (PID=8144) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:26:04.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:26:04.803+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:26:04.803+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:26:04.828+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:26:04.853+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:26:04.853+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:26:04.876+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:26:04.876+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:26:04.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T23:26:35.054+0000] {processor.py:186} INFO - Started process (PID=8157) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:26:35.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:26:35.058+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:26:35.058+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:26:35.087+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:26:35.112+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:26:35.111+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:26:35.135+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:26:35.135+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:26:35.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T23:27:05.391+0000] {processor.py:186} INFO - Started process (PID=8170) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:27:05.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:27:05.395+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:27:05.395+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:27:05.422+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:27:05.447+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:27:05.447+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:27:05.471+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:27:05.471+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:27:05.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:27:35.947+0000] {processor.py:186} INFO - Started process (PID=8189) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:27:35.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:27:35.950+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:27:35.950+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:27:35.976+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:27:36.001+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:27:36.001+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:27:36.027+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:27:36.026+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:27:36.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T23:28:06.293+0000] {processor.py:186} INFO - Started process (PID=8202) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:28:06.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:28:06.296+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:28:06.296+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:28:06.324+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:28:06.348+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:28:06.348+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:28:06.372+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:28:06.372+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:28:06.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:28:36.786+0000] {processor.py:186} INFO - Started process (PID=8215) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:28:36.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:28:36.793+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:28:36.792+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:28:36.818+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:28:36.843+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:28:36.842+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:28:36.866+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:28:36.866+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:28:36.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:29:07.229+0000] {processor.py:186} INFO - Started process (PID=8228) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:29:07.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:29:07.233+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:29:07.233+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:29:07.259+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:29:07.283+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:29:07.283+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:29:07.309+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:29:07.308+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:29:07.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:29:37.650+0000] {processor.py:186} INFO - Started process (PID=8241) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:29:37.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:29:37.654+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:29:37.654+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:29:37.684+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:29:37.711+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:29:37.710+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:29:37.738+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:29:37.738+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:29:37.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T23:30:08.541+0000] {processor.py:186} INFO - Started process (PID=8252) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:30:08.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:30:08.545+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:30:08.544+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:30:08.572+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:30:08.597+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:30:08.597+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:30:08.622+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:30:08.622+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:30:08.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.111 seconds
[2024-09-22T23:30:38.995+0000] {processor.py:186} INFO - Started process (PID=8265) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:30:38.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:30:38.999+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:30:38.998+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:30:39.027+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:30:39.052+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:30:39.052+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:30:39.076+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:30:39.075+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:30:39.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T23:31:09.389+0000] {processor.py:186} INFO - Started process (PID=8278) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:31:09.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:31:09.393+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:31:09.392+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:31:09.418+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:31:09.444+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:31:09.444+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:31:09.479+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:31:09.479+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:31:09.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.118 seconds
[2024-09-22T23:31:39.808+0000] {processor.py:186} INFO - Started process (PID=8291) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:31:39.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:31:39.812+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:31:39.811+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:31:39.837+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:31:39.861+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:31:39.861+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:31:39.885+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:31:39.885+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:31:39.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T23:32:10.312+0000] {processor.py:186} INFO - Started process (PID=8304) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:32:10.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:32:10.315+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:32:10.315+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:32:10.341+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:32:10.366+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:32:10.366+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:32:10.391+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:32:10.390+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:32:10.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:32:40.571+0000] {processor.py:186} INFO - Started process (PID=8318) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:32:40.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:32:40.574+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:32:40.574+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:32:40.599+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:32:40.623+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:32:40.623+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:32:40.647+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:32:40.647+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:32:40.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T23:33:10.709+0000] {processor.py:186} INFO - Started process (PID=8331) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:33:10.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:33:10.713+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:33:10.713+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:33:10.737+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:33:10.762+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:33:10.761+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:33:10.785+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:33:10.785+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:33:10.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T23:33:40.846+0000] {processor.py:186} INFO - Started process (PID=8344) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:33:40.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:33:40.849+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:33:40.849+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:33:40.874+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:33:40.897+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:33:40.897+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:33:40.920+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:33:40.920+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:33:40.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T23:34:11.184+0000] {processor.py:186} INFO - Started process (PID=8356) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:34:11.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:34:11.188+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:34:11.187+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:34:11.213+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:34:11.238+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:34:11.237+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:34:11.263+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:34:11.263+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:34:11.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:34:41.470+0000] {processor.py:186} INFO - Started process (PID=8369) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:34:41.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:34:41.474+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:34:41.474+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:34:41.501+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:34:41.525+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:34:41.525+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:34:41.550+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:34:41.550+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:34:41.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:35:11.624+0000] {processor.py:186} INFO - Started process (PID=8382) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:35:11.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:35:11.627+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:35:11.627+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:35:11.654+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:35:11.678+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:35:11.677+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:35:11.702+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:35:11.701+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:35:11.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:35:41.758+0000] {processor.py:186} INFO - Started process (PID=8395) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:35:41.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:35:41.762+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:35:41.762+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:35:41.789+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:35:41.812+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:35:41.812+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:35:41.836+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:35:41.836+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:35:41.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.115 seconds
[2024-09-22T23:36:12.694+0000] {processor.py:186} INFO - Started process (PID=8408) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:36:12.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:36:12.698+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:36:12.698+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:36:12.730+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:36:12.755+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:36:12.755+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:36:12.780+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:36:12.779+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:36:12.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.116 seconds
[2024-09-22T23:36:43.702+0000] {processor.py:186} INFO - Started process (PID=8421) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:36:43.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:36:43.705+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:36:43.705+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:36:43.731+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:36:43.756+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:36:43.756+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:36:43.780+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:36:43.780+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:36:43.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T23:37:14.783+0000] {processor.py:186} INFO - Started process (PID=8434) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:37:14.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:37:14.786+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:37:14.786+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:37:14.812+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:37:14.837+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:37:14.837+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:37:14.861+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:37:14.861+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:37:14.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:37:45.685+0000] {processor.py:186} INFO - Started process (PID=8447) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:37:45.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:37:45.688+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:37:45.688+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:37:45.711+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:37:45.735+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:37:45.735+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:37:45.759+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:37:45.759+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:37:45.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.103 seconds
[2024-09-22T23:38:16.734+0000] {processor.py:186} INFO - Started process (PID=8460) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:38:16.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:38:16.738+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:38:16.737+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:38:16.766+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:38:16.791+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:38:16.791+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:38:16.816+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:38:16.816+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:38:16.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.109 seconds
[2024-09-22T23:38:47.688+0000] {processor.py:186} INFO - Started process (PID=8473) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:38:47.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:38:47.691+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:38:47.691+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:38:47.717+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:38:47.743+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:38:47.743+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:38:47.768+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:38:47.768+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:38:47.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:39:17.845+0000] {processor.py:186} INFO - Started process (PID=8486) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:39:17.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:39:17.848+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:39:17.848+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:39:17.874+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:39:17.904+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:39:17.904+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:39:17.934+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:39:17.933+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:39:17.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.120 seconds
[2024-09-22T23:39:48.892+0000] {processor.py:186} INFO - Started process (PID=8499) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:39:48.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:39:48.896+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:39:48.896+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:39:48.924+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:39:48.952+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:39:48.952+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:39:48.977+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:39:48.977+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:39:49.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.119 seconds
[2024-09-22T23:40:19.083+0000] {processor.py:186} INFO - Started process (PID=8512) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:40:19.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:40:19.087+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:40:19.087+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:40:19.114+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:40:19.138+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:40:19.138+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:40:19.163+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:40:19.163+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:40:19.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.194 seconds
[2024-09-22T23:40:49.420+0000] {processor.py:186} INFO - Started process (PID=8525) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:40:49.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:40:49.424+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:40:49.423+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:40:49.451+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:40:49.475+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:40:49.475+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:40:49.499+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:40:49.499+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:40:49.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T23:41:19.772+0000] {processor.py:186} INFO - Started process (PID=8538) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:41:19.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:41:19.775+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:41:19.774+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:41:19.800+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:41:19.825+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:41:19.824+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:41:19.848+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:41:19.848+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:41:19.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
[2024-09-22T23:41:50.011+0000] {processor.py:186} INFO - Started process (PID=8551) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:41:50.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:41:50.015+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:41:50.014+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:41:50.041+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:41:50.065+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:41:50.065+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:41:50.090+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:41:50.090+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:41:50.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.107 seconds
[2024-09-22T23:42:20.268+0000] {processor.py:186} INFO - Started process (PID=8564) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:42:20.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:42:20.273+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:42:20.273+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:42:20.299+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:42:20.325+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:42:20.325+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:42:20.349+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:42:20.349+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:42:20.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.110 seconds
[2024-09-22T23:42:50.679+0000] {processor.py:186} INFO - Started process (PID=8577) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:42:50.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:42:50.683+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:42:50.683+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:42:50.710+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:42:50.735+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:42:50.734+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:42:50.759+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:42:50.758+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:42:50.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.108 seconds
[2024-09-22T23:43:20.930+0000] {processor.py:186} INFO - Started process (PID=8590) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:43:20.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:43:20.934+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:43:20.934+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:43:20.961+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:43:20.985+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:43:20.985+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:43:21.009+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:43:21.008+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:43:21.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T23:43:51.421+0000] {processor.py:186} INFO - Started process (PID=8603) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:43:51.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:43:51.425+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:43:51.425+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:43:51.452+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:43:51.478+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:43:51.477+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:43:51.504+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:43:51.504+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:43:51.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.112 seconds
[2024-09-22T23:44:21.584+0000] {processor.py:186} INFO - Started process (PID=8616) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:44:21.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:44:21.588+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:44:21.588+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:44:21.614+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:44:21.638+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:44:21.638+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:44:21.662+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:44:21.661+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:44:21.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T23:44:51.812+0000] {processor.py:186} INFO - Started process (PID=8629) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:44:51.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:44:51.815+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:44:51.815+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:44:51.841+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:44:51.865+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:44:51.865+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:44:51.889+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:44:51.888+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:44:51.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.104 seconds
[2024-09-22T23:45:22.000+0000] {processor.py:186} INFO - Started process (PID=8642) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:45:22.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:45:22.003+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:45:22.003+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:45:22.030+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:45:22.055+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:45:22.055+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:45:22.080+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:45:22.079+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:45:22.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.106 seconds
[2024-09-22T23:45:52.344+0000] {processor.py:186} INFO - Started process (PID=8656) to work on /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:45:52.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/jobsSpark.py for tasks to queue
[2024-09-22T23:45:52.347+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:45:52.347+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:45:52.372+0000] {processor.py:925} INFO - DAG(s) 'spark_job_dag' retrieved from /opt/airflow/dags/jobsSpark.py
[2024-09-22T23:45:52.396+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:45:52.396+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-09-22T23:45:52.420+0000] {logging_mixin.py:190} INFO - [2024-09-22T23:45:52.419+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_job_dag to 2024-09-22 00:00:00+00:00, run_after=2024-09-23 00:00:00+00:00
[2024-09-22T23:45:52.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/jobsSpark.py took 0.105 seconds
