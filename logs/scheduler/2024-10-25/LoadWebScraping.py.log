[2024-10-25T02:18:24.696+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:18:24.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:18:24.704+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:18:24.703+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:18:24.746+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:18:24.786+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:18:24.785+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:18:24.806+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:18:24.806+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:18:24.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.142 seconds
[2024-10-25T02:18:55.510+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:18:55.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:18:55.513+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:18:55.513+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:18:55.540+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:18:55.567+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:18:55.567+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:18:55.582+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:18:55.582+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:18:55.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.208 seconds
[2024-10-25T02:19:26.317+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:19:26.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:19:26.323+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:19:26.322+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:19:26.346+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:19:26.389+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:19:26.389+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:19:26.406+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:19:26.405+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:19:26.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.178 seconds
[2024-10-25T02:19:57.120+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:19:57.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:19:57.123+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:19:57.123+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:19:57.145+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:19:57.172+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:19:57.172+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:19:57.185+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:19:57.185+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:19:57.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.093 seconds
[2024-10-25T02:20:28.241+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:20:28.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:20:28.244+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:20:28.244+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:20:28.259+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:20:28.283+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:20:28.282+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:20:28.296+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:20:28.296+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:20:28.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T02:20:59.029+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:20:59.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:20:59.032+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:20:59.032+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:20:59.048+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:20:59.074+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:20:59.074+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:20:59.092+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:20:59.092+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:20:59.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.090 seconds
[2024-10-25T02:21:29.515+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:21:29.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:21:29.521+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:21:29.521+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:21:29.545+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:21:29.581+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:21:29.581+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:21:29.604+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:21:29.604+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:21:29.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.116 seconds
[2024-10-25T02:22:00.438+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:22:00.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:22:00.444+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:22:00.443+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:22:00.460+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:22:00.486+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:22:00.486+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:22:00.499+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:22:00.499+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:22:00.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.088 seconds
[2024-10-25T02:22:31.381+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:22:31.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:22:31.384+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:22:31.384+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:22:31.414+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:22:31.442+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:22:31.441+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:22:31.457+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:22:31.457+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:22:31.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.105 seconds
[2024-10-25T02:23:01.600+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:23:01.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:23:01.603+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:23:01.602+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:23:01.620+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:23:01.648+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:23:01.648+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:23:01.662+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:23:01.662+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:23:01.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.092 seconds
[2024-10-25T02:23:32.139+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:23:32.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:23:32.144+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:23:32.143+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:23:32.169+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:23:32.206+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:23:32.206+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:23:32.222+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:23:32.222+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:23:32.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.115 seconds
[2024-10-25T02:24:03.263+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:24:03.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:24:03.270+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:24:03.269+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:24:03.309+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:24:03.361+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:24:03.361+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:24:03.383+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:24:03.382+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:24:03.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.152 seconds
[2024-10-25T02:24:33.570+0000] {processor.py:186} INFO - Started process (PID=363) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:24:33.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:24:33.575+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:24:33.575+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:24:33.593+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:24:33.669+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:24:33.668+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:24:33.689+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:24:33.689+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:24:33.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.147 seconds
[2024-10-25T02:25:03.834+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:25:03.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:25:03.838+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:25:03.838+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:25:03.867+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:25:03.907+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:25:03.907+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:25:03.934+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:25:03.934+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:25:03.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.141 seconds
[2024-10-25T02:25:34.948+0000] {processor.py:186} INFO - Started process (PID=413) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:25:34.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T02:25:34.953+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:25:34.953+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:25:34.976+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T02:25:35.004+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:25:35.004+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T02:25:35.040+0000] {logging_mixin.py:190} INFO - [2024-10-25T02:25:35.040+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T02:25:35.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.191 seconds
[2024-10-25T11:05:54.415+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:05:54.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:05:54.433+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:05:54.432+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:05:54.473+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:05:54.600+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:05:54.599+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:05:54.656+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:05:54.655+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:05:54.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.322 seconds
[2024-10-25T11:06:24.944+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:06:24.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:06:24.947+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:06:24.946+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:06:24.963+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:06:24.985+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:06:24.985+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:06:24.998+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:06:24.998+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:06:25.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.091 seconds
[2024-10-25T11:06:55.223+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:06:55.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:06:55.226+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:06:55.226+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:06:55.241+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:06:55.263+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:06:55.263+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:06:55.275+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:06:55.275+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:06:55.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.091 seconds
[2024-10-25T11:07:25.402+0000] {processor.py:186} INFO - Started process (PID=134) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:07:25.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:07:25.406+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:07:25.406+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:07:25.421+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:07:25.443+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:07:25.443+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:07:25.458+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:07:25.458+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:07:25.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.086 seconds
[2024-10-25T11:07:56.365+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:07:56.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:07:56.368+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:07:56.367+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:07:56.381+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:07:56.403+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:07:56.403+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:07:56.417+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:07:56.416+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:07:56.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T11:08:27.050+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:08:27.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:08:27.054+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:08:27.053+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:08:27.069+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:08:27.098+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:08:27.097+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:08:27.113+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:08:27.113+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:08:27.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.091 seconds
[2024-10-25T11:08:57.874+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:08:57.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:08:57.878+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:08:57.877+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:08:57.895+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:08:57.917+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:08:57.917+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:08:57.929+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:08:57.929+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:08:57.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T11:09:28.398+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:09:28.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:09:28.402+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:09:28.401+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:09:28.417+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:09:28.440+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:09:28.439+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:09:28.452+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:09:28.451+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:09:28.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T11:09:58.929+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:09:58.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:09:58.932+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:09:58.931+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:09:58.949+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:09:58.972+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:09:58.972+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:09:58.985+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:09:58.985+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:09:59.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
[2024-10-25T11:10:29.604+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:10:29.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:10:29.607+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:10:29.606+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:10:29.622+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:10:29.644+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:10:29.644+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:10:29.657+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:10:29.657+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:10:29.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T11:11:00.616+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:11:00.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:11:00.619+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:11:00.619+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:11:00.633+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:11:00.655+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:11:00.655+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:11:00.667+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:11:00.667+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:11:00.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T11:11:30.890+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:11:30.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:11:30.893+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:11:30.893+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:11:30.907+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:11:30.929+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:11:30.928+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:11:30.941+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:11:30.941+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:11:30.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T11:12:01.146+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:12:01.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:12:01.148+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:12:01.148+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:12:01.164+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:12:01.186+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:12:01.186+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:12:01.199+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:12:01.198+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:12:01.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T11:12:31.913+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:12:31.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:12:31.916+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:12:31.916+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:12:31.929+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:12:31.951+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:12:31.950+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:12:31.964+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:12:31.964+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:12:31.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T11:13:02.802+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:13:02.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:13:02.805+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:13:02.805+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:13:02.822+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:13:02.844+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:13:02.844+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:13:02.856+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:13:02.856+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:13:02.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T11:13:33.479+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:13:33.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:13:33.482+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:13:33.482+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:13:33.497+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:13:33.520+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:13:33.520+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:13:33.535+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:13:33.534+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:13:33.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T11:14:04.328+0000] {processor.py:186} INFO - Started process (PID=465) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:14:04.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:14:04.332+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:14:04.331+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:14:04.348+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:14:04.370+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:14:04.370+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:14:04.383+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:14:04.383+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:14:04.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T11:14:35.110+0000] {processor.py:186} INFO - Started process (PID=490) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:14:35.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:14:35.113+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:14:35.113+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:14:35.129+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:14:35.151+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:14:35.150+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:14:35.163+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:14:35.163+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:14:35.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T11:15:05.279+0000] {processor.py:186} INFO - Started process (PID=515) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:15:05.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:15:05.282+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:15:05.281+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:15:05.295+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:15:05.321+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:15:05.321+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:15:05.337+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:15:05.336+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:15:05.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.088 seconds
[2024-10-25T11:15:36.268+0000] {processor.py:186} INFO - Started process (PID=540) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:15:36.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:15:36.271+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:15:36.271+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:15:36.287+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:15:36.310+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:15:36.309+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:15:36.322+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:15:36.321+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:15:36.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T11:15:48.578+0000] {processor.py:186} INFO - Started process (PID=559) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:15:48.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:15:48.581+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:15:48.580+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:15:48.595+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:15:48.594+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 19
    teste = 
            ^
SyntaxError: invalid syntax
[2024-10-25T11:15:48.596+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:15:48.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.045 seconds
[2024-10-25T11:16:18.686+0000] {processor.py:186} INFO - Started process (PID=584) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:16:18.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:16:18.690+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:16:18.690+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:16:18.704+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:16:18.703+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 19
    teste = 
            ^
SyntaxError: invalid syntax
[2024-10-25T11:16:18.705+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:16:18.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.047 seconds
[2024-10-25T11:16:49.361+0000] {processor.py:186} INFO - Started process (PID=609) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:16:49.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:16:49.365+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:16:49.365+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:16:49.380+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:16:49.378+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 19
    teste = 
            ^
SyntaxError: invalid syntax
[2024-10-25T11:16:49.380+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:16:49.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.045 seconds
[2024-10-25T11:17:20.022+0000] {processor.py:186} INFO - Started process (PID=634) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:17:20.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:17:20.024+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:17:20.023+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:17:20.037+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:17:20.036+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 19
    teste = 
            ^
SyntaxError: invalid syntax
[2024-10-25T11:17:20.038+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:17:20.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.039 seconds
[2024-10-25T11:17:50.670+0000] {processor.py:186} INFO - Started process (PID=659) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:17:50.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:17:50.673+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:17:50.673+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:17:50.686+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:17:50.685+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 19
    teste = 
            ^
SyntaxError: invalid syntax
[2024-10-25T11:17:50.687+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:17:50.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.040 seconds
[2024-10-25T11:18:21.412+0000] {processor.py:186} INFO - Started process (PID=684) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:18:21.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:18:21.417+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:18:21.416+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:18:21.433+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:18:21.432+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 19
    teste = 
            ^
SyntaxError: invalid syntax
[2024-10-25T11:18:21.433+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:18:21.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.053 seconds
[2024-10-25T11:18:51.848+0000] {processor.py:186} INFO - Started process (PID=709) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:18:51.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:18:51.850+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:18:51.849+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:18:51.862+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:18:51.861+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 19
    teste = 
            ^
SyntaxError: invalid syntax
[2024-10-25T11:18:51.862+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:18:51.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.037 seconds
[2024-10-25T11:19:13.310+0000] {processor.py:186} INFO - Started process (PID=734) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:19:13.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:19:13.313+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:13.312+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:19:13.352+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:13.351+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:19:13.352+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:13.352+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:19:14.157+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:19:14.271+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:14.271+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:19:14.281+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:14.281+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:19:14.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 1.001 seconds
[2024-10-25T11:19:27.003+0000] {processor.py:186} INFO - Started process (PID=738) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:19:27.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:19:27.005+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:27.005+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:19:27.033+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:27.033+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:19:27.034+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:27.034+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:19:27.523+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:27.521+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('conte√∫do do arquivo', 'nome_do_arquivo.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key nome_do_arquivo.txt already exists.
[2024-10-25T11:19:27.524+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:19:27.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.535 seconds
[2024-10-25T11:19:58.406+0000] {processor.py:186} INFO - Started process (PID=770) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:19:58.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:19:58.408+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:58.408+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:19:58.434+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:58.434+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:19:58.435+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:58.435+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:19:58.893+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:19:58.892+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('conte√∫do do arquivo', 'nome_do_arquivo.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key nome_do_arquivo.txt already exists.
[2024-10-25T11:19:58.894+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:19:58.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.502 seconds
[2024-10-25T11:20:15.229+0000] {processor.py:186} INFO - Started process (PID=788) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:20:15.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:20:15.231+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:15.231+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:20:15.262+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:15.262+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:20:15.263+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:15.262+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:20:15.619+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:15.617+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'nome_do_arquivo.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key nome_do_arquivo.txt already exists.
[2024-10-25T11:20:15.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:20:15.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.412 seconds
[2024-10-25T11:20:16.354+0000] {processor.py:186} INFO - Started process (PID=789) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:20:16.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:20:16.356+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:16.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:20:16.386+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:16.386+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:20:16.387+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:16.387+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:20:16.728+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:20:16.735+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:16.734+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:20:16.752+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:16.751+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:20:16.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.565 seconds
[2024-10-25T11:20:47.608+0000] {processor.py:186} INFO - Started process (PID=816) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:20:47.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:20:47.610+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:47.610+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:20:47.631+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:47.631+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:20:47.635+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:47.635+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:20:47.958+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:20:47.957+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key teste.txt already exists.
[2024-10-25T11:20:47.959+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:20:47.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.369 seconds
[2024-10-25T11:21:18.811+0000] {processor.py:186} INFO - Started process (PID=841) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:21:18.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:21:18.813+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:21:18.813+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:21:18.835+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:21:18.834+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:21:18.835+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:21:18.835+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:21:19.287+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:21:19.285+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key teste.txt already exists.
[2024-10-25T11:21:19.288+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:21:19.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.493 seconds
[2024-10-25T11:21:49.540+0000] {processor.py:186} INFO - Started process (PID=866) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:21:49.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:21:49.542+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:21:49.542+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:21:49.565+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:21:49.564+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:21:49.565+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:21:49.565+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:21:50.047+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:21:50.063+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:21:50.063+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:21:50.078+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:21:50.078+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:21:50.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.563 seconds
[2024-10-25T11:22:12.379+0000] {processor.py:186} INFO - Started process (PID=883) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:22:12.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:22:12.381+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:22:12.381+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:22:12.410+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:22:12.410+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:22:12.411+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:22:12.411+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:22:12.880+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:22:12.877+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:22:12.881+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:22:12.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.518 seconds
[2024-10-25T11:22:43.763+0000] {processor.py:186} INFO - Started process (PID=908) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:22:43.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:22:43.765+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:22:43.765+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:22:43.794+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:22:43.794+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:22:43.795+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:22:43.795+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:22:44.116+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:22:44.113+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:22:44.117+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:22:44.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.374 seconds
[2024-10-25T11:23:14.270+0000] {processor.py:186} INFO - Started process (PID=936) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:23:14.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:23:14.272+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:23:14.271+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:23:14.295+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:23:14.295+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:23:14.296+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:23:14.296+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:23:14.620+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:23:14.618+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:23:14.621+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:23:14.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.367 seconds
[2024-10-25T11:36:40.824+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:36:40.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:36:40.830+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:36:40.829+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:36:40.861+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:36:40.861+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:36:40.861+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:36:40.861+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:36:41.496+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:36:41.412+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:36:41.497+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:36:41.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.692 seconds
[2024-10-25T11:37:11.989+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:37:11.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:37:11.993+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:37:11.992+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:37:12.016+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:37:12.016+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:37:12.017+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:37:12.017+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:37:12.476+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:37:12.471+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:37:12.477+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:37:12.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.505 seconds
[2024-10-25T11:37:42.968+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:37:42.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:37:42.972+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:37:42.972+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:37:42.996+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:37:42.996+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:37:42.997+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:37:42.997+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:37:43.329+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:37:43.326+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:37:43.330+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:37:43.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.380 seconds
[2024-10-25T11:38:13.491+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:38:13.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:38:13.493+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:38:13.493+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:38:13.515+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:38:13.515+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:38:13.516+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:38:13.515+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:38:13.843+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:38:13.841+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:38:13.845+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:38:13.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.373 seconds
[2024-10-25T11:38:44.078+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:38:44.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:38:44.082+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:38:44.081+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:38:44.105+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:38:44.105+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:38:44.106+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:38:44.106+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:38:44.435+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:38:44.432+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:38:44.436+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:38:44.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.374 seconds
[2024-10-25T11:39:15.267+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:39:15.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:39:15.271+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:39:15.271+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:39:15.296+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:39:15.295+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:39:15.296+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:39:15.296+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:39:15.653+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:39:15.651+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:39:15.654+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:39:15.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.405 seconds
[2024-10-25T11:39:45.867+0000] {processor.py:186} INFO - Started process (PID=212) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:39:45.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:39:45.871+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:39:45.870+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:39:45.895+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:39:45.895+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:39:45.896+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:39:45.896+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:39:46.240+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:39:46.237+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:39:46.241+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:39:46.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.394 seconds
[2024-10-25T11:40:16.396+0000] {processor.py:186} INFO - Started process (PID=239) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:40:16.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:40:16.399+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:40:16.398+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:40:16.423+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:40:16.423+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:40:16.424+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:40:16.424+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:40:16.735+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:40:16.732+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:40:16.736+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:40:16.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.357 seconds
[2024-10-25T11:40:46.856+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:40:46.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:40:46.859+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:40:46.859+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:40:46.881+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:40:46.880+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:40:46.881+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:40:46.881+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:40:47.328+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:40:47.325+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'teste.txt', bucket_name='rawzone/kabum')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 964, in _make_api_call
    api_params = self._emit_api_params(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1083, in _emit_api_params
    self.meta.events.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/handlers.py", line 297, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "rawzone/kabum": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-10-25T11:40:47.329+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:40:47.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.490 seconds
[2024-10-25T11:41:15.670+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:41:15.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:41:15.673+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:41:15.673+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:41:15.704+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:41:15.703+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:41:15.704+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:41:15.704+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:41:16.171+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:41:16.169+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 924, in head_object
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1023, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (403) when calling the HeadObject operation: Forbidden
[2024-10-25T11:41:16.173+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:41:16.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.519 seconds
[2024-10-25T11:41:46.248+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:41:46.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:41:46.254+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:41:46.254+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:41:46.295+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:41:46.294+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:41:46.295+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:41:46.295+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:41:46.638+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:41:46.636+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 924, in head_object
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1023, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (403) when calling the HeadObject operation: Forbidden
[2024-10-25T11:41:46.639+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:41:46.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.408 seconds
[2024-10-25T11:42:17.335+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:42:17.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:42:17.339+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:42:17.338+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:42:17.364+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:42:17.364+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:42:17.365+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:42:17.365+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:42:17.707+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:42:17.704+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 924, in head_object
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1023, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (403) when calling the HeadObject operation: Forbidden
[2024-10-25T11:42:17.708+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:42:17.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.398 seconds
[2024-10-25T11:42:48.541+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:42:48.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:42:48.545+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:42:48.544+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:42:48.573+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:42:48.573+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:42:48.574+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:42:48.574+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:42:49.072+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:42:49.069+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 924, in head_object
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1023, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (403) when calling the HeadObject operation: Forbidden
[2024-10-25T11:42:49.073+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:42:49.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.549 seconds
[2024-10-25T11:43:19.925+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:43:19.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:43:19.928+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:43:19.927+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:43:19.949+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:43:19.949+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:43:19.950+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:43:19.950+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:43:20.436+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:43:20.433+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 924, in head_object
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1023, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (403) when calling the HeadObject operation: Forbidden
[2024-10-25T11:43:20.437+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:43:20.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.529 seconds
[2024-10-25T11:43:51.124+0000] {processor.py:186} INFO - Started process (PID=413) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:43:51.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:43:51.128+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:43:51.127+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:43:51.153+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:43:51.153+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:43:51.154+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:43:51.154+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:43:51.492+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:43:51.489+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 924, in head_object
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1023, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (403) when calling the HeadObject operation: Forbidden
[2024-10-25T11:43:51.493+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:43:51.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.386 seconds
[2024-10-25T11:44:22.048+0000] {processor.py:186} INFO - Started process (PID=438) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:44:22.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:44:22.052+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:44:22.051+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:44:22.075+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:44:22.075+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:44:22.076+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:44:22.076+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:44:22.437+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:44:22.794+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:44:22.794+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T11:44:22.805+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:44:22.804+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T11:44:22.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.792 seconds
[2024-10-25T11:44:52.953+0000] {processor.py:186} INFO - Started process (PID=471) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:44:52.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:44:52.956+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:44:52.956+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:44:52.979+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:44:52.979+0000] {base.py:84} INFO - Retrieving connection 'datalake_s3'
[2024-10-25T11:44:52.980+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:44:52.980+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='datalake_s3', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:44:53.464+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:44:53.462+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:44:53.465+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:44:53.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.529 seconds
[2024-10-25T11:45:23.557+0000] {processor.py:186} INFO - Started process (PID=498) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:45:23.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:45:23.560+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:45:23.560+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:45:23.581+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:45:23.580+0000] {base_aws.py:606} WARNING - Unable to find AWS Connection ID 'datalake_s3', switching to empty.
[2024-10-25T11:45:23.581+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:45:23.581+0000] {base_aws.py:180} INFO - No connection ID provided. Fallback on boto3 credential strategy (region_name=None). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
[2024-10-25T11:45:24.103+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:45:24.100+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1245, in _upload_file_obj
    if not replace and self.check_for_key(key, bucket_name):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 939, in check_for_key
    obj = self.head_object(key, bucket_name)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 919, in head_object
    return self.get_conn().head_object(Bucket=bucket_name, Key=key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 569, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1005, in _make_api_call
    http, parsed_response = self._make_request(
                            ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/client.py", line 1029, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/endpoint.py", line 119, in make_request
    return self._send_request(request_dict, operation_model)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/endpoint.py", line 196, in _send_request
    request = self.create_request(request_dict, operation_model)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/endpoint.py", line 132, in create_request
    self._event_emitter.emit(
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/signers.py", line 105, in handler
    return self.sign(operation_name, request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/signers.py", line 197, in sign
    auth.add_auth(request)
  File "/home/airflow/.local/lib/python3.12/site-packages/botocore/auth.py", line 423, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials
[2024-10-25T11:45:24.104+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:45:24.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.565 seconds
[2024-10-25T11:45:54.130+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:45:54.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:45:54.132+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:45:54.131+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:45:54.162+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:45:54.162+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:45:54.163+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:45:54.163+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:45:54.497+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:45:54.495+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:45:54.498+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:45:54.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.383 seconds
[2024-10-25T11:46:25.346+0000] {processor.py:186} INFO - Started process (PID=542) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:46:25.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:46:25.348+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:46:25.348+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:46:25.372+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:46:25.371+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:46:25.372+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:46:25.372+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:46:25.703+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:46:25.702+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:46:25.704+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:46:25.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.380 seconds
[2024-10-25T11:46:56.495+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:46:56.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:46:56.497+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:46:56.497+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:46:56.521+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:46:56.521+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:46:56.522+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:46:56.522+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:46:57.064+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:46:57.062+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:46:57.065+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:46:57.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.587 seconds
[2024-10-25T11:47:27.492+0000] {processor.py:186} INFO - Started process (PID=592) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:47:27.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:47:27.495+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:47:27.495+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:47:27.520+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:47:27.520+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:47:27.521+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:47:27.521+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:47:28.028+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:47:28.026+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:47:28.029+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:47:28.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.554 seconds
[2024-10-25T11:47:58.652+0000] {processor.py:186} INFO - Started process (PID=617) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:47:58.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:47:58.654+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:47:58.654+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:47:58.685+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:47:58.684+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:47:58.685+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:47:58.685+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:47:59.016+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:47:59.014+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:47:59.017+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:47:59.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.382 seconds
[2024-10-25T11:48:29.584+0000] {processor.py:186} INFO - Started process (PID=642) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:48:29.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:48:29.587+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:48:29.586+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:48:29.612+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:48:29.612+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:48:29.612+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:48:29.612+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:48:29.937+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:48:29.935+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:48:29.938+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:48:29.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.378 seconds
[2024-10-25T11:49:00.548+0000] {processor.py:186} INFO - Started process (PID=667) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:49:00.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:49:00.550+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:49:00.550+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:49:00.573+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:49:00.573+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:49:00.574+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:49:00.574+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:49:01.051+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:49:01.049+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:49:01.051+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:49:01.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.518 seconds
[2024-10-25T11:49:31.595+0000] {processor.py:186} INFO - Started process (PID=692) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:49:31.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:49:31.597+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:49:31.597+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:49:31.621+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:49:31.621+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:49:31.622+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:49:31.621+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:49:32.096+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:49:32.095+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:49:32.097+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:49:32.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.516 seconds
[2024-10-25T11:50:02.640+0000] {processor.py:186} INFO - Started process (PID=717) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:50:02.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:50:02.642+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:50:02.642+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:50:02.671+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:50:02.671+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:50:02.672+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:50:02.672+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:50:03.010+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:50:03.008+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:50:03.011+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:50:03.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.388 seconds
[2024-10-25T11:50:33.559+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:50:33.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:50:33.562+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:50:33.561+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:50:33.585+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:50:33.585+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:50:33.586+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:50:33.586+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:50:33.924+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:50:33.922+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:50:33.924+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:50:33.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.387 seconds
[2024-10-25T11:51:04.106+0000] {processor.py:186} INFO - Started process (PID=768) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:51:04.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:51:04.108+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:51:04.108+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:51:04.133+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:51:04.133+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:51:04.134+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:51:04.134+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:51:04.624+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:51:04.623+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:51:04.625+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:51:04.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.537 seconds
[2024-10-25T11:51:34.698+0000] {processor.py:186} INFO - Started process (PID=797) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:51:34.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:51:34.700+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:51:34.699+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:51:34.722+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:51:34.721+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:51:34.722+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:51:34.722+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:51:35.182+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:51:35.181+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:51:35.183+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:51:35.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.501 seconds
[2024-10-25T11:52:06.150+0000] {processor.py:186} INFO - Started process (PID=822) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:52:06.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:52:06.152+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:52:06.152+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:52:06.175+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:52:06.175+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:52:06.176+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:52:06.176+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:52:06.518+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:52:06.516+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:52:06.518+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:52:06.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.385 seconds
[2024-10-25T11:52:37.121+0000] {processor.py:186} INFO - Started process (PID=847) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:52:37.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:52:37.123+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:52:37.123+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:52:37.148+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:52:37.148+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:52:37.149+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:52:37.149+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:52:37.473+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:52:37.471+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:52:37.474+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:52:37.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.372 seconds
[2024-10-25T11:53:07.983+0000] {processor.py:186} INFO - Started process (PID=872) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:53:07.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:53:07.985+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:53:07.985+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:53:08.009+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:53:08.008+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:53:08.009+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:53:08.009+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:53:08.478+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:53:08.477+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:53:08.479+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:53:08.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.511 seconds
[2024-10-25T11:53:39.065+0000] {processor.py:186} INFO - Started process (PID=897) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:53:39.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:53:39.067+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:53:39.067+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:53:39.092+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:53:39.092+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:53:39.093+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:53:39.092+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:53:39.567+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:53:39.565+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:53:39.568+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:53:39.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.520 seconds
[2024-10-25T11:54:10.062+0000] {processor.py:186} INFO - Started process (PID=922) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:54:10.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:54:10.065+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:54:10.064+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:54:10.091+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:54:10.091+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:54:10.092+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:54:10.092+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:54:10.419+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:54:10.417+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:54:10.420+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:54:10.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.375 seconds
[2024-10-25T11:54:40.517+0000] {processor.py:186} INFO - Started process (PID=950) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:54:40.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:54:40.519+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:54:40.519+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:54:40.543+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:54:40.543+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:54:40.544+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:54:40.544+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:54:40.865+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:54:40.864+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:54:40.866+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:54:40.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.365 seconds
[2024-10-25T11:55:10.971+0000] {processor.py:186} INFO - Started process (PID=978) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:55:10.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:55:10.973+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:55:10.972+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:55:10.996+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:55:10.995+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:55:10.996+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:55:10.996+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:55:11.486+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:55:11.484+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:55:11.487+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:55:11.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.532 seconds
[2024-10-25T11:55:42.342+0000] {processor.py:186} INFO - Started process (PID=1005) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:55:42.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:55:42.344+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:55:42.344+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:55:42.372+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:55:42.371+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:55:42.372+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:55:42.372+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:55:42.837+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:55:42.836+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:55:42.838+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:55:42.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.512 seconds
[2024-10-25T11:56:13.744+0000] {processor.py:186} INFO - Started process (PID=1036) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:56:13.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:56:13.746+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:56:13.746+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:56:13.771+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:56:13.771+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:56:13.772+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:56:13.772+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:56:14.092+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:56:14.090+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:56:14.092+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:56:14.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.363 seconds
[2024-10-25T11:56:44.171+0000] {processor.py:186} INFO - Started process (PID=1061) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:56:44.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:56:44.173+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:56:44.173+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:56:44.200+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:56:44.200+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T11:56:44.201+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:56:44.200+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T11:56:44.517+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:56:44.516+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T11:56:44.518+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:56:44.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.365 seconds
[2024-10-25T11:56:52.759+0000] {processor.py:186} INFO - Started process (PID=1062) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:56:52.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:56:52.761+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:56:52.761+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:56:52.775+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:56:52.774+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20
    for file_name in 
                     ^
SyntaxError: invalid syntax
[2024-10-25T11:56:52.776+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:56:52.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.042 seconds
[2024-10-25T11:57:23.537+0000] {processor.py:186} INFO - Started process (PID=1087) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:57:23.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:57:23.539+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:57:23.539+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:57:23.556+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:57:23.555+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20
    for file_name in 
                     ^
SyntaxError: invalid syntax
[2024-10-25T11:57:23.557+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:57:23.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.045 seconds
[2024-10-25T11:57:54.460+0000] {processor.py:186} INFO - Started process (PID=1111) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:57:54.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:57:54.462+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:57:54.462+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:57:54.475+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:57:54.474+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20
    for file_name in 
                     ^
SyntaxError: invalid syntax
[2024-10-25T11:57:54.475+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:57:54.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.038 seconds
[2024-10-25T11:58:25.290+0000] {processor.py:186} INFO - Started process (PID=1136) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:58:25.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:58:25.292+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:58:25.292+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:58:25.307+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:58:25.306+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20
    for file_name in 
                     ^
SyntaxError: invalid syntax
[2024-10-25T11:58:25.308+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:58:25.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.042 seconds
[2024-10-25T11:58:55.994+0000] {processor.py:186} INFO - Started process (PID=1161) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:58:55.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:58:55.996+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:58:55.996+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:58:56.011+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:58:56.009+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20
    for file_name in 
                     ^
SyntaxError: invalid syntax
[2024-10-25T11:58:56.011+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:58:56.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.043 seconds
[2024-10-25T11:59:26.526+0000] {processor.py:186} INFO - Started process (PID=1186) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:59:26.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:59:26.528+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:59:26.528+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:59:26.541+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:59:26.540+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20
    for file_name in 
                     ^
SyntaxError: invalid syntax
[2024-10-25T11:59:26.541+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:59:26.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.040 seconds
[2024-10-25T11:59:57.193+0000] {processor.py:186} INFO - Started process (PID=1211) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:59:57.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T11:59:57.195+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:59:57.194+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:59:57.208+0000] {logging_mixin.py:190} INFO - [2024-10-25T11:59:57.207+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20
    for file_name in 
                     ^
SyntaxError: invalid syntax
[2024-10-25T11:59:57.209+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T11:59:57.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.040 seconds
[2024-10-25T12:00:28.094+0000] {processor.py:186} INFO - Started process (PID=1236) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:00:28.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:00:28.096+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:00:28.096+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:00:28.111+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:00:28.110+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20
    for file_name in 
                     ^
SyntaxError: invalid syntax
[2024-10-25T12:00:28.112+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:00:28.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.042 seconds
[2024-10-25T12:00:58.843+0000] {processor.py:186} INFO - Started process (PID=1261) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:00:58.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:00:58.844+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:00:58.844+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:00:58.856+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:00:58.856+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 20
    for file_name in 
                     ^
SyntaxError: invalid syntax
[2024-10-25T12:00:58.857+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:00:58.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.038 seconds
[2024-10-25T12:01:01.009+0000] {processor.py:186} INFO - Started process (PID=1262) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:01.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:01:01.011+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:01.011+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:01.039+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:01.039+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T12:01:01.040+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:01.040+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T12:01:01.367+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:01.365+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 45, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T12:01:01.368+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:01.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.375 seconds
[2024-10-25T12:01:12.903+0000] {processor.py:186} INFO - Started process (PID=1268) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:12.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:01:12.905+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:12.905+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:12.934+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:12.934+0000] {base.py:84} INFO - Retrieving connection 's3_connect'
[2024-10-25T12:01:12.935+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:12.935+0000] {connection_wrapper.py:388} INFO - AWS Connection (conn_id='s3_connect', conn_type='aws') credentials retrieved from login and password.
[2024-10-25T12:01:13.402+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:13.400+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 46, in <module>
    teste.load_string('teste', 'kabum/teste.txt', bucket_name='rawzone')
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 158, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 132, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1172, in load_string
    self._upload_file_obj(f, key, bucket_name, replace, encrypt, acl_policy)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 1246, in _upload_file_obj
    raise ValueError(f"The key {key} already exists.")
ValueError: The key kabum/teste.txt already exists.
[2024-10-25T12:01:13.403+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:13.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.514 seconds
[2024-10-25T12:01:19.027+0000] {processor.py:186} INFO - Started process (PID=1288) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:19.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:01:19.029+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:19.029+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:19.044+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:19.044+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 157
    # CREATE_TABLES>>INSERT_TABLES
                                  ^
IndentationError: expected an indented block after 'with' statement on line 38
[2024-10-25T12:01:19.045+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:19.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.040 seconds
[2024-10-25T12:01:49.997+0000] {processor.py:186} INFO - Started process (PID=1313) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:49.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:01:49.999+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:49.998+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:50.013+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:01:50.012+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 157
    # CREATE_TABLES>>INSERT_TABLES
                                  ^
IndentationError: expected an indented block after 'with' statement on line 38
[2024-10-25T12:01:50.014+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:01:50.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.039 seconds
[2024-10-25T12:02:20.853+0000] {processor.py:186} INFO - Started process (PID=1338) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:02:20.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:02:20.856+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:02:20.856+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:02:20.873+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:02:20.872+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 157
    # CREATE_TABLES>>INSERT_TABLES
                                  ^
IndentationError: expected an indented block after 'with' statement on line 38
[2024-10-25T12:02:20.874+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:02:20.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.045 seconds
[2024-10-25T12:02:51.589+0000] {processor.py:186} INFO - Started process (PID=1363) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:02:51.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:02:51.591+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:02:51.591+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:02:51.606+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:02:51.605+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 157
    # CREATE_TABLES>>INSERT_TABLES
                                  ^
IndentationError: expected an indented block after 'with' statement on line 38
[2024-10-25T12:02:51.607+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:02:51.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.041 seconds
[2024-10-25T12:03:22.159+0000] {processor.py:186} INFO - Started process (PID=1388) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:03:22.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:03:22.161+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:03:22.160+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:03:22.178+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:03:22.177+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 157
    # CREATE_TABLES>>INSERT_TABLES
                                  ^
IndentationError: expected an indented block after 'with' statement on line 38
[2024-10-25T12:03:22.179+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:03:22.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.045 seconds
[2024-10-25T12:03:53.192+0000] {processor.py:186} INFO - Started process (PID=1413) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:03:53.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:03:53.194+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:03:53.194+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:03:53.212+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:03:53.211+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 157
    # CREATE_TABLES>>INSERT_TABLES
                                  ^
IndentationError: expected an indented block after 'with' statement on line 38
[2024-10-25T12:03:53.212+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:03:53.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.043 seconds
[2024-10-25T12:04:24.181+0000] {processor.py:186} INFO - Started process (PID=1438) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:04:24.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:04:24.183+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:04:24.183+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:04:24.197+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:04:24.196+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 157
    # CREATE_TABLES>>INSERT_TABLES
                                  ^
IndentationError: expected an indented block after 'with' statement on line 38
[2024-10-25T12:04:24.198+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:04:24.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.041 seconds
[2024-10-25T12:04:54.883+0000] {processor.py:186} INFO - Started process (PID=1463) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:04:54.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:04:54.886+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:04:54.886+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:04:54.903+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:04:54.902+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 157
    # CREATE_TABLES>>INSERT_TABLES
                                  ^
IndentationError: expected an indented block after 'with' statement on line 38
[2024-10-25T12:04:54.904+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:04:54.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.047 seconds
[2024-10-25T12:05:06.233+0000] {processor.py:186} INFO - Started process (PID=1464) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:05:06.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:05:06.236+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:05:06.235+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:05:06.257+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:05:06.253+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 162, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:05:06.259+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:05:06.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.051 seconds
[2024-10-25T12:05:37.155+0000] {processor.py:186} INFO - Started process (PID=1489) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:05:37.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:05:37.158+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:05:37.157+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:05:37.174+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:05:37.170+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 162, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:05:37.175+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:05:37.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.044 seconds
[2024-10-25T12:06:08.050+0000] {processor.py:186} INFO - Started process (PID=1514) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:06:08.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:06:08.052+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:06:08.051+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:06:08.066+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:06:08.063+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 162, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:06:08.068+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:06:08.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.098 seconds
[2024-10-25T12:06:26.028+0000] {processor.py:186} INFO - Started process (PID=1532) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:06:26.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:06:26.030+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:06:26.030+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:06:26.052+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:06:26.048+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:06:26.053+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:06:26.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.049 seconds
[2024-10-25T12:06:56.173+0000] {processor.py:186} INFO - Started process (PID=1557) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:06:56.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:06:56.175+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:06:56.175+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:06:56.192+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:06:56.188+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:06:56.193+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:06:56.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.118 seconds
[2024-10-25T12:07:26.438+0000] {processor.py:186} INFO - Started process (PID=1582) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:07:26.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:07:26.440+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:07:26.440+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:07:26.456+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:07:26.452+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:07:26.457+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:07:26.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.046 seconds
[2024-10-25T12:07:56.663+0000] {processor.py:186} INFO - Started process (PID=1607) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:07:56.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:07:56.665+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:07:56.665+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:07:56.682+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:07:56.678+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:07:56.683+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:07:56.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.045 seconds
[2024-10-25T12:08:26.851+0000] {processor.py:186} INFO - Started process (PID=1632) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:08:26.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:08:26.853+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:08:26.853+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:08:26.870+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:08:26.866+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:08:26.872+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:08:26.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.045 seconds
[2024-10-25T12:08:56.944+0000] {processor.py:186} INFO - Started process (PID=1657) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:08:56.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:08:56.947+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:08:56.946+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:08:56.965+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:08:56.961+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:08:56.967+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:08:56.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.049 seconds
[2024-10-25T12:09:27.119+0000] {processor.py:186} INFO - Started process (PID=1682) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:09:27.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:09:27.121+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:09:27.121+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:09:27.139+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:09:27.134+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:09:27.141+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:09:27.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.045 seconds
[2024-10-25T12:09:57.288+0000] {processor.py:186} INFO - Started process (PID=1707) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:09:57.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:09:57.290+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:09:57.290+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:09:57.303+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:09:57.299+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:09:57.304+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:09:57.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.041 seconds
[2024-10-25T12:10:27.425+0000] {processor.py:186} INFO - Started process (PID=1732) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:10:27.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:10:27.427+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:10:27.427+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:10:27.441+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:10:27.437+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:10:27.443+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:10:27.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.042 seconds
[2024-10-25T12:10:58.278+0000] {processor.py:186} INFO - Started process (PID=1757) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:10:58.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:10:58.280+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:10:58.280+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:10:58.303+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:10:58.297+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:10:58.305+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:10:58.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.052 seconds
[2024-10-25T12:11:29.216+0000] {processor.py:186} INFO - Started process (PID=1782) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:11:29.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:11:29.219+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:11:29.218+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:11:29.233+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:11:29.229+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:11:29.235+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:11:29.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.043 seconds
[2024-10-25T12:11:59.741+0000] {processor.py:186} INFO - Started process (PID=1807) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:11:59.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:11:59.743+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:11:59.743+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:11:59.760+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:11:59.756+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:11:59.762+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:11:59.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.045 seconds
[2024-10-25T12:12:30.100+0000] {processor.py:186} INFO - Started process (PID=1832) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:12:30.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:12:30.102+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:12:30.102+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:12:30.117+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:12:30.113+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:12:30.119+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:12:30.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.044 seconds
[2024-10-25T12:13:00.298+0000] {processor.py:186} INFO - Started process (PID=1858) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:13:00.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:13:00.300+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:13:00.300+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:13:00.316+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:13:00.312+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:13:00.317+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:13:00.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.042 seconds
[2024-10-25T12:13:30.488+0000] {processor.py:186} INFO - Started process (PID=1883) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:13:30.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:13:30.490+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:13:30.489+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:13:30.504+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:13:30.500+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:13:30.506+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:13:30.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.040 seconds
[2024-10-25T12:14:00.790+0000] {processor.py:186} INFO - Started process (PID=1908) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:14:00.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:14:00.792+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:14:00.792+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:14:00.806+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:14:00.802+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:14:00.807+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:14:00.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.040 seconds
[2024-10-25T12:14:31.563+0000] {processor.py:186} INFO - Started process (PID=1933) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:14:31.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:14:31.566+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:14:31.566+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:14:31.581+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:14:31.577+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:14:31.582+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:14:31.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.042 seconds
[2024-10-25T12:15:02.351+0000] {processor.py:186} INFO - Started process (PID=1958) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:15:02.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:15:02.354+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:15:02.354+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:15:02.369+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:15:02.365+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:15:02.370+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:15:02.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.042 seconds
[2024-10-25T12:15:33.271+0000] {processor.py:186} INFO - Started process (PID=1983) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:15:33.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:15:33.273+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:15:33.273+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:15:33.288+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:15:33.284+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:15:33.290+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:15:33.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.042 seconds
[2024-10-25T12:16:03.794+0000] {processor.py:186} INFO - Started process (PID=2008) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:16:03.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:16:03.797+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:16:03.797+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:16:03.810+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:16:03.807+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:16:03.812+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:16:03.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.041 seconds
[2024-10-25T12:16:34.519+0000] {processor.py:186} INFO - Started process (PID=2033) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:16:34.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:16:34.521+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:16:34.521+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:16:34.537+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:16:34.533+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:16:34.539+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:16:34.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.042 seconds
[2024-10-25T12:17:04.653+0000] {processor.py:186} INFO - Started process (PID=2058) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:17:04.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:17:04.655+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:17:04.655+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:17:04.672+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:17:04.668+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:17:04.673+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:17:04.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.047 seconds
[2024-10-25T12:17:35.135+0000] {processor.py:186} INFO - Started process (PID=2083) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:17:35.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:17:35.138+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:17:35.138+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:17:35.164+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:17:35.156+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:17:35.170+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:17:35.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T12:18:05.794+0000] {processor.py:186} INFO - Started process (PID=2108) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:05.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:18:05.797+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:18:05.796+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:05.810+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:18:05.807+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = Pyth
            ^^^^
NameError: name 'Pyth' is not defined
[2024-10-25T12:18:05.812+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:05.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.042 seconds
[2024-10-25T12:18:12.183+0000] {processor.py:186} INFO - Started process (PID=2115) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:12.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:18:12.185+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:18:12.185+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:12.211+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:18:12.204+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = PythonOperator(task_id='upload_files_in_datalake',python_callable='upload_files_to_minio')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-25T12:18:12.211+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:12.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.053 seconds
[2024-10-25T12:18:16.796+0000] {processor.py:186} INFO - Started process (PID=2123) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:16.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:18:16.798+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:18:16.798+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:16.822+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:18:16.818+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/LoadWebScraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/LoadWebScraping.py", line 163, in <module>
    teste = PythonOperator(task_id='upload_files_in_datalake',python_callable='upload_files_to_minio')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 224, in __init__
    raise AirflowException("`python_callable` param must be callable")
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2024-10-25T12:18:16.823+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:16.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.055 seconds
[2024-10-25T12:18:45.607+0000] {processor.py:186} INFO - Started process (PID=2148) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:45.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:18:45.609+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:18:45.609+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:45.629+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:18:45.729+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:18:45.728+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:18:45.741+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:18:45.741+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:18:45.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.180 seconds
[2024-10-25T12:19:16.378+0000] {processor.py:186} INFO - Started process (PID=2172) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:19:16.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:19:16.381+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:19:16.380+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:19:16.399+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:19:16.435+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:19:16.435+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:19:16.460+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:19:16.460+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:19:16.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.129 seconds
[2024-10-25T12:19:47.194+0000] {processor.py:186} INFO - Started process (PID=2197) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:19:47.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:19:47.196+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:19:47.195+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:19:47.210+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:19:47.230+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:19:47.230+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:19:47.244+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:19:47.243+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:19:47.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T12:20:17.754+0000] {processor.py:186} INFO - Started process (PID=2222) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:20:17.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:20:17.756+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:20:17.756+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:20:17.773+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:20:17.791+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:20:17.791+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:20:17.804+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:20:17.804+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:20:17.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T12:20:48.435+0000] {processor.py:186} INFO - Started process (PID=2247) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:20:48.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:20:48.438+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:20:48.437+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:20:48.456+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:20:48.483+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:20:48.483+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:20:48.499+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:20:48.498+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:20:48.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.092 seconds
[2024-10-25T12:21:18.764+0000] {processor.py:186} INFO - Started process (PID=2272) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:21:18.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:21:18.766+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:21:18.766+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:21:18.781+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:21:18.801+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:21:18.800+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:21:18.814+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:21:18.814+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:21:18.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:21:49.144+0000] {processor.py:186} INFO - Started process (PID=2297) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:21:49.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:21:49.146+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:21:49.146+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:21:49.161+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:21:49.180+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:21:49.180+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:21:49.193+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:21:49.193+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:21:49.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:22:19.532+0000] {processor.py:186} INFO - Started process (PID=2322) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:22:19.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:22:19.535+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:22:19.534+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:22:19.550+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:22:19.574+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:22:19.574+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:22:19.591+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:22:19.591+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:22:19.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.089 seconds
[2024-10-25T12:22:49.718+0000] {processor.py:186} INFO - Started process (PID=2347) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:22:49.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:22:49.720+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:22:49.720+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:22:49.734+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:22:49.753+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:22:49.753+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:22:49.765+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:22:49.765+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:22:49.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T12:23:20.487+0000] {processor.py:186} INFO - Started process (PID=2372) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:23:20.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:23:20.489+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:23:20.489+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:23:20.505+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:23:20.523+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:23:20.523+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:23:20.536+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:23:20.535+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:23:20.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T12:23:51.038+0000] {processor.py:186} INFO - Started process (PID=2397) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:23:51.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:23:51.040+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:23:51.040+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:23:51.054+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:23:51.072+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:23:51.072+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:23:51.085+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:23:51.085+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:23:51.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.069 seconds
[2024-10-25T12:24:21.678+0000] {processor.py:186} INFO - Started process (PID=2423) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:24:21.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:24:21.680+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:24:21.680+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:24:21.696+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:24:21.716+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:24:21.715+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:24:21.729+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:24:21.729+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:24:21.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T12:24:52.494+0000] {processor.py:186} INFO - Started process (PID=2448) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:24:52.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:24:52.496+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:24:52.496+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:24:52.508+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:24:52.527+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:24:52.527+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:24:52.540+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:24:52.540+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:24:52.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T12:25:23.066+0000] {processor.py:186} INFO - Started process (PID=2473) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:25:23.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:25:23.068+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:25:23.068+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:25:23.083+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:25:23.102+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:25:23.102+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:25:23.115+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:25:23.115+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:25:23.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T12:25:53.638+0000] {processor.py:186} INFO - Started process (PID=2498) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:25:53.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:25:53.640+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:25:53.640+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:25:53.654+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:25:53.673+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:25:53.673+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:25:53.686+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:25:53.686+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:25:53.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T12:26:24.216+0000] {processor.py:186} INFO - Started process (PID=2523) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:26:24.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:26:24.218+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:26:24.218+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:26:24.232+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:26:24.252+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:26:24.251+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:26:24.264+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:26:24.264+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:26:24.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T12:26:55.272+0000] {processor.py:186} INFO - Started process (PID=2548) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:26:55.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:26:55.274+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:26:55.274+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:26:55.290+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:26:55.310+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:26:55.310+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:26:55.324+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:26:55.324+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:26:55.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T12:27:26.195+0000] {processor.py:186} INFO - Started process (PID=2573) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:27:26.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:27:26.197+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:27:26.197+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:27:26.212+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:27:26.230+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:27:26.229+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:27:26.242+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:27:26.242+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:27:26.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T12:27:56.650+0000] {processor.py:186} INFO - Started process (PID=2598) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:27:56.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:27:56.652+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:27:56.652+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:27:56.668+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:27:56.686+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:27:56.686+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:27:56.699+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:27:56.698+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:27:56.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T12:28:27.181+0000] {processor.py:186} INFO - Started process (PID=2623) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:28:27.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:28:27.183+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:28:27.182+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:28:27.195+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:28:27.216+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:28:27.215+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:28:27.231+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:28:27.231+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:28:27.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T12:28:57.968+0000] {processor.py:186} INFO - Started process (PID=2648) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:28:57.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:28:57.970+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:28:57.970+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:28:57.984+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:28:58.005+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:28:58.004+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:28:58.018+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:28:58.017+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:28:58.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:29:28.715+0000] {processor.py:186} INFO - Started process (PID=2673) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:29:28.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:29:28.717+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:29:28.717+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:29:28.731+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:29:28.750+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:29:28.750+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:29:28.763+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:29:28.763+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:29:28.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T12:29:59.702+0000] {processor.py:186} INFO - Started process (PID=2698) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:29:59.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:29:59.704+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:29:59.704+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:29:59.718+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:29:59.736+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:29:59.736+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:29:59.749+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:29:59.748+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:29:59.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.069 seconds
[2024-10-25T12:30:30.043+0000] {processor.py:186} INFO - Started process (PID=2724) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:30:30.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:30:30.045+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:30:30.045+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:30:30.059+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:30:30.079+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:30:30.079+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:30:30.093+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:30:30.093+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:30:30.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:31:00.238+0000] {processor.py:186} INFO - Started process (PID=2749) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:31:00.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:31:00.240+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:31:00.240+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:31:00.256+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:31:00.276+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:31:00.276+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:31:00.290+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:31:00.289+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:31:00.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:31:31.082+0000] {processor.py:186} INFO - Started process (PID=2775) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:31:31.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:31:31.084+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:31:31.083+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:31:31.099+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:31:31.117+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:31:31.117+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:31:31.130+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:31:31.130+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:31:31.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T12:32:01.283+0000] {processor.py:186} INFO - Started process (PID=2800) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:32:01.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:32:01.285+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:32:01.285+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:32:01.301+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:32:01.319+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:32:01.319+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:32:01.331+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:32:01.331+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:32:01.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T12:32:31.394+0000] {processor.py:186} INFO - Started process (PID=2825) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:32:31.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:32:31.396+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:32:31.395+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:32:31.408+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:32:31.426+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:32:31.426+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:32:31.439+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:32:31.439+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:32:31.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T12:33:01.590+0000] {processor.py:186} INFO - Started process (PID=2850) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:33:01.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:33:01.593+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:33:01.592+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:33:01.607+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:33:01.625+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:33:01.624+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:33:01.639+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:33:01.638+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:33:01.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T12:33:32.102+0000] {processor.py:186} INFO - Started process (PID=2875) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:33:32.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:33:32.104+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:33:32.104+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:33:32.119+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:33:32.137+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:33:32.137+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:33:32.150+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:33:32.150+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:33:32.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T12:34:02.916+0000] {processor.py:186} INFO - Started process (PID=2900) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:34:02.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:34:02.918+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:34:02.918+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:34:02.932+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:34:02.951+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:34:02.951+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:34:02.964+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:34:02.964+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:34:02.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T12:34:33.834+0000] {processor.py:186} INFO - Started process (PID=2925) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:34:33.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:34:33.836+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:34:33.836+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:34:33.850+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:34:33.868+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:34:33.867+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:34:33.880+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:34:33.880+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:34:33.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T12:35:04.085+0000] {processor.py:186} INFO - Started process (PID=2951) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:35:04.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:35:04.087+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:35:04.086+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:35:04.100+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:35:04.119+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:35:04.118+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:35:04.132+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:35:04.131+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:35:04.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T12:35:34.500+0000] {processor.py:186} INFO - Started process (PID=2976) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:35:34.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:35:34.502+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:35:34.502+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:35:34.519+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:35:34.537+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:35:34.537+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:35:34.550+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:35:34.550+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:35:34.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T12:36:04.643+0000] {processor.py:186} INFO - Started process (PID=3001) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:36:04.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:36:04.645+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:36:04.645+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:36:04.660+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:36:04.680+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:36:04.680+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:36:04.694+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:36:04.694+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:36:04.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T12:36:34.828+0000] {processor.py:186} INFO - Started process (PID=3026) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:36:34.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:36:34.830+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:36:34.829+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:36:34.844+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:36:34.864+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:36:34.864+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:36:34.877+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:36:34.877+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:36:34.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T12:37:05.050+0000] {processor.py:186} INFO - Started process (PID=3051) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:37:05.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:37:05.052+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:37:05.052+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:37:05.065+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:37:05.084+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:37:05.084+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:37:05.097+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:37:05.097+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:37:05.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T12:37:35.735+0000] {processor.py:186} INFO - Started process (PID=3076) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:37:35.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:37:35.737+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:37:35.737+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:37:35.753+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:37:35.771+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:37:35.771+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:37:35.784+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:37:35.783+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:37:35.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T12:38:06.616+0000] {processor.py:186} INFO - Started process (PID=3101) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:38:06.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:38:06.618+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:38:06.618+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:38:06.632+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:38:06.651+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:38:06.650+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:38:06.664+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:38:06.663+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:38:06.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T12:38:37.483+0000] {processor.py:186} INFO - Started process (PID=3126) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:38:37.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:38:37.485+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:38:37.484+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:38:37.500+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:38:37.519+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:38:37.519+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:38:37.532+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:38:37.532+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:38:37.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T12:39:08.288+0000] {processor.py:186} INFO - Started process (PID=3151) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:39:08.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:39:08.290+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:39:08.290+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:39:08.304+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:39:08.324+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:39:08.323+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:39:08.337+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:39:08.337+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:39:08.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T12:39:39.054+0000] {processor.py:186} INFO - Started process (PID=3176) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:39:39.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:39:39.056+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:39:39.056+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:39:39.072+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:39:39.091+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:39:39.091+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:39:39.105+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:39:39.105+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:39:39.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T12:40:09.864+0000] {processor.py:186} INFO - Started process (PID=3201) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:40:09.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:40:09.866+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:40:09.866+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:40:09.881+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:40:09.899+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:40:09.899+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:40:09.912+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:40:09.912+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:40:09.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T12:40:40.303+0000] {processor.py:186} INFO - Started process (PID=3226) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:40:40.304+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:40:40.305+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:40:40.304+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:40:40.317+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:40:40.336+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:40:40.336+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:40:40.349+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:40:40.349+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:40:40.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T12:41:10.602+0000] {processor.py:186} INFO - Started process (PID=3251) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:41:10.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:41:10.604+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:41:10.604+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:41:10.618+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:41:10.637+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:41:10.636+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:41:10.649+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:41:10.649+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:41:10.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T12:41:41.506+0000] {processor.py:186} INFO - Started process (PID=3276) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:41:41.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:41:41.508+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:41:41.507+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:41:41.523+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:41:41.542+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:41:41.541+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:41:41.554+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:41:41.554+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:41:41.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T12:42:12.385+0000] {processor.py:186} INFO - Started process (PID=3301) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:42:12.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:42:12.387+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:42:12.387+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:42:12.401+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:42:12.421+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:42:12.421+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:42:12.435+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:42:12.434+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:42:12.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:42:43.186+0000] {processor.py:186} INFO - Started process (PID=3326) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:42:43.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:42:43.188+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:42:43.187+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:42:43.203+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:42:43.222+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:42:43.222+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:42:43.235+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:42:43.234+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:42:43.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T12:43:14.180+0000] {processor.py:186} INFO - Started process (PID=3351) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:43:14.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:43:14.182+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:43:14.181+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:43:14.198+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:43:14.216+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:43:14.216+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:43:14.230+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:43:14.230+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:43:14.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:43:44.405+0000] {processor.py:186} INFO - Started process (PID=3376) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:43:44.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:43:44.407+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:43:44.407+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:43:44.421+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:43:44.441+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:43:44.440+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:43:44.456+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:43:44.455+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:43:44.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T12:44:15.075+0000] {processor.py:186} INFO - Started process (PID=3401) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:44:15.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:44:15.077+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:44:15.077+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:44:15.093+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:44:15.113+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:44:15.113+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:44:15.126+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:44:15.126+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:44:15.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T12:44:45.785+0000] {processor.py:186} INFO - Started process (PID=3426) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:44:45.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:44:45.787+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:44:45.787+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:44:45.807+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:44:45.830+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:44:45.830+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:44:45.844+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:44:45.844+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:44:45.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.094 seconds
[2024-10-25T12:45:16.598+0000] {processor.py:186} INFO - Started process (PID=3457) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:45:16.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:45:16.600+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:45:16.600+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:45:16.613+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:45:16.632+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:45:16.632+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:45:16.646+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:45:16.646+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:45:16.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:45:47.190+0000] {processor.py:186} INFO - Started process (PID=3482) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:45:47.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:45:47.192+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:45:47.192+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:45:47.207+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:45:47.226+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:45:47.226+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:45:47.238+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:45:47.238+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:45:47.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T12:46:17.780+0000] {processor.py:186} INFO - Started process (PID=3507) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:46:17.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:46:17.782+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:46:17.782+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:46:17.797+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:46:17.817+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:46:17.817+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:46:17.830+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:46:17.830+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:46:17.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T12:46:48.716+0000] {processor.py:186} INFO - Started process (PID=3533) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:46:48.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:46:48.718+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:46:48.718+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:46:48.732+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:46:48.751+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:46:48.750+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:46:48.763+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:46:48.763+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:46:48.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:47:19.741+0000] {processor.py:186} INFO - Started process (PID=3558) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:47:19.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:47:19.743+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:47:19.743+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:47:19.759+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:47:19.781+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:47:19.780+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:47:19.796+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:47:19.795+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:47:19.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T12:47:50.544+0000] {processor.py:186} INFO - Started process (PID=3583) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:47:50.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:47:50.547+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:47:50.547+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:47:50.564+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:47:50.584+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:47:50.584+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:47:50.598+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:47:50.598+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:47:50.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T12:48:20.739+0000] {processor.py:186} INFO - Started process (PID=3608) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:48:20.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:48:20.741+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:48:20.740+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:48:20.755+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:48:20.773+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:48:20.773+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:48:20.786+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:48:20.786+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:48:20.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T12:48:50.879+0000] {processor.py:186} INFO - Started process (PID=3633) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:48:50.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:48:50.881+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:48:50.880+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:48:50.897+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:48:50.916+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:48:50.916+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:48:50.929+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:48:50.929+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:48:50.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T12:49:21.624+0000] {processor.py:186} INFO - Started process (PID=3658) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:49:21.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:49:21.626+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:49:21.625+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:49:21.639+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:49:21.657+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:49:21.657+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:49:21.670+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:49:21.669+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:49:21.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.068 seconds
[2024-10-25T12:49:52.549+0000] {processor.py:186} INFO - Started process (PID=3683) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:49:52.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:49:52.551+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:49:52.551+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:49:52.567+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:49:52.585+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:49:52.585+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:49:52.597+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:49:52.597+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:49:52.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T12:50:22.708+0000] {processor.py:186} INFO - Started process (PID=3708) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:50:22.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:50:22.710+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:50:22.710+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:50:22.725+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:50:22.745+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:50:22.745+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:50:22.758+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:50:22.758+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:50:22.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T12:50:52.912+0000] {processor.py:186} INFO - Started process (PID=3733) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:50:52.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:50:52.914+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:50:52.914+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:50:52.930+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:50:52.949+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:50:52.949+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:50:52.961+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:50:52.961+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:50:52.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T12:51:23.161+0000] {processor.py:186} INFO - Started process (PID=3758) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:51:23.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:51:23.164+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:51:23.164+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:51:23.181+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:51:23.200+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:51:23.200+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:51:23.213+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:51:23.213+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:51:23.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.084 seconds
[2024-10-25T12:51:53.811+0000] {processor.py:186} INFO - Started process (PID=3783) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:51:53.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:51:53.813+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:51:53.813+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:51:53.828+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:51:53.847+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:51:53.847+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:51:53.861+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:51:53.861+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:51:53.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T12:52:24.039+0000] {processor.py:186} INFO - Started process (PID=3808) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:52:24.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:52:24.041+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:52:24.040+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:52:24.054+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:52:24.074+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:52:24.073+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:52:24.086+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:52:24.086+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:52:24.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T12:52:54.234+0000] {processor.py:186} INFO - Started process (PID=3833) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:52:54.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:52:54.237+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:52:54.236+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:52:54.251+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:52:54.272+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:52:54.271+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:52:54.285+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:52:54.284+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:52:54.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T12:53:24.516+0000] {processor.py:186} INFO - Started process (PID=3858) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:53:24.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:53:24.518+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:53:24.517+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:53:24.532+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:53:24.552+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:53:24.552+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:53:24.565+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:53:24.565+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:53:24.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T12:53:54.752+0000] {processor.py:186} INFO - Started process (PID=3883) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:53:54.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:53:54.754+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:53:54.754+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:53:54.769+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:53:54.789+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:53:54.789+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:53:54.803+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:53:54.803+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:53:54.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T12:54:25.688+0000] {processor.py:186} INFO - Started process (PID=3908) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:54:25.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:54:25.690+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:54:25.690+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:54:25.704+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:54:25.724+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:54:25.723+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:54:25.737+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:54:25.737+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:54:25.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T12:54:55.892+0000] {processor.py:186} INFO - Started process (PID=3933) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:54:55.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:54:55.894+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:54:55.894+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:54:55.910+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:54:55.929+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:54:55.929+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:54:55.943+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:54:55.942+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:54:55.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:55:26.078+0000] {processor.py:186} INFO - Started process (PID=3958) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:55:26.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:55:26.080+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:55:26.080+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:55:26.094+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:55:26.114+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:55:26.114+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:55:26.128+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:55:26.128+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:55:26.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T12:55:56.915+0000] {processor.py:186} INFO - Started process (PID=3983) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:55:56.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:55:56.918+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:55:56.917+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:55:56.933+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:55:56.953+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:55:56.953+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:55:56.966+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:55:56.966+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:55:56.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T12:56:27.706+0000] {processor.py:186} INFO - Started process (PID=4008) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:56:27.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:56:27.708+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:56:27.708+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:56:27.720+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:56:27.738+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:56:27.738+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:56:27.752+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:56:27.752+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:56:27.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.069 seconds
[2024-10-25T12:56:57.966+0000] {processor.py:186} INFO - Started process (PID=4033) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:56:57.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:56:57.968+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:56:57.968+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:56:57.981+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:56:57.999+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:56:57.999+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:56:58.012+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:56:58.012+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:56:58.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.068 seconds
[2024-10-25T12:57:28.859+0000] {processor.py:186} INFO - Started process (PID=4058) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:57:28.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:57:28.861+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:57:28.861+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:57:28.877+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:57:28.897+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:57:28.897+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:57:28.912+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:57:28.912+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:57:28.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.121 seconds
[2024-10-25T12:57:59.228+0000] {processor.py:186} INFO - Started process (PID=4083) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:57:59.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:57:59.230+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:57:59.230+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:57:59.243+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:57:59.262+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:57:59.262+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:57:59.275+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:57:59.275+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:57:59.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T12:58:29.416+0000] {processor.py:186} INFO - Started process (PID=4108) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:58:29.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:58:29.418+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:58:29.418+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:58:29.433+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:58:29.452+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:58:29.452+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:58:29.465+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:58:29.465+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:58:29.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T12:58:59.662+0000] {processor.py:186} INFO - Started process (PID=4133) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:58:59.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:58:59.664+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:58:59.664+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:58:59.681+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:58:59.700+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:58:59.700+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:58:59.713+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:58:59.713+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:58:59.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T12:59:29.994+0000] {processor.py:186} INFO - Started process (PID=4158) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:59:29.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T12:59:29.997+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:59:29.996+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:59:30.011+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T12:59:30.030+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:59:30.030+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T12:59:30.044+0000] {logging_mixin.py:190} INFO - [2024-10-25T12:59:30.044+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T12:59:30.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T13:00:00.612+0000] {processor.py:186} INFO - Started process (PID=4183) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:00:00.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:00:00.614+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:00:00.614+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:00:00.630+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:00:00.648+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:00:00.648+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:00:00.661+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:00:00.661+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:00:00.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T13:00:30.973+0000] {processor.py:186} INFO - Started process (PID=4208) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:00:30.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:00:30.975+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:00:30.975+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:00:30.991+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:00:31.010+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:00:31.010+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:00:31.023+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:00:31.023+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:00:31.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:01:01.717+0000] {processor.py:186} INFO - Started process (PID=4233) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:01:01.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:01:01.719+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:01:01.719+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:01:01.734+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:01:01.755+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:01:01.754+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:01:01.769+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:01:01.769+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:01:01.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:01:32.009+0000] {processor.py:186} INFO - Started process (PID=4258) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:01:32.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:01:32.011+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:01:32.011+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:01:32.028+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:01:32.046+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:01:32.045+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:01:32.059+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:01:32.059+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:01:32.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:02:02.263+0000] {processor.py:186} INFO - Started process (PID=4283) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:02:02.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:02:02.265+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:02:02.265+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:02:02.279+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:02:02.301+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:02:02.301+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:02:02.315+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:02:02.314+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:02:02.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:02:32.510+0000] {processor.py:186} INFO - Started process (PID=4308) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:02:32.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:02:32.513+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:02:32.513+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:02:32.533+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:02:32.569+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:02:32.569+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:02:32.594+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:02:32.594+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:02:32.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.130 seconds
[2024-10-25T13:03:02.765+0000] {processor.py:186} INFO - Started process (PID=4333) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:03:02.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:03:02.767+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:03:02.767+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:03:02.782+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:03:02.801+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:03:02.800+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:03:02.814+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:03:02.814+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:03:02.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T13:03:32.942+0000] {processor.py:186} INFO - Started process (PID=4358) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:03:32.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:03:32.944+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:03:32.943+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:03:32.956+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:03:32.977+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:03:32.977+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:03:32.991+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:03:32.991+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:03:33.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:04:03.577+0000] {processor.py:186} INFO - Started process (PID=4383) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:04:03.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:04:03.579+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:04:03.578+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:04:03.592+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:04:03.621+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:04:03.619+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:04:03.643+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:04:03.642+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:04:03.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.097 seconds
[2024-10-25T13:04:34.480+0000] {processor.py:186} INFO - Started process (PID=4408) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:04:34.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:04:34.482+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:04:34.482+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:04:34.498+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:04:34.519+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:04:34.518+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:04:34.533+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:04:34.532+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:04:34.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:05:05.328+0000] {processor.py:186} INFO - Started process (PID=4433) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:05:05.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:05:05.331+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:05:05.330+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:05:05.346+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:05:05.366+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:05:05.366+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:05:05.380+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:05:05.380+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:05:05.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T13:05:36.255+0000] {processor.py:186} INFO - Started process (PID=4458) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:05:36.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:05:36.258+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:05:36.257+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:05:36.273+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:05:36.295+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:05:36.294+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:05:36.309+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:05:36.308+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:05:36.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T13:06:07.151+0000] {processor.py:186} INFO - Started process (PID=4483) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:06:07.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:06:07.154+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:06:07.153+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:06:07.175+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:06:07.198+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:06:07.198+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:06:07.212+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:06:07.212+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:06:07.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.086 seconds
[2024-10-25T13:06:37.776+0000] {processor.py:186} INFO - Started process (PID=4508) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:06:37.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:06:37.778+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:06:37.778+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:06:37.796+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:06:37.817+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:06:37.817+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:06:37.832+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:06:37.832+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:06:37.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.091 seconds
[2024-10-25T13:07:07.903+0000] {processor.py:186} INFO - Started process (PID=4533) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:07:07.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:07:07.905+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:07:07.905+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:07:07.918+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:07:07.938+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:07:07.938+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:07:07.951+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:07:07.951+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:07:07.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T13:07:38.083+0000] {processor.py:186} INFO - Started process (PID=4554) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:07:38.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:07:38.085+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:07:38.085+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:07:38.101+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:07:38.132+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:07:38.131+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:07:38.147+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:07:38.147+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:07:38.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.094 seconds
[2024-10-25T13:08:08.856+0000] {processor.py:186} INFO - Started process (PID=4579) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:08:08.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:08:08.859+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:08:08.858+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:08:08.872+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:08:08.892+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:08:08.892+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:08:08.905+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:08:08.905+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:08:08.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:08:39.619+0000] {processor.py:186} INFO - Started process (PID=4604) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:08:39.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:08:39.622+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:08:39.621+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:08:39.637+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:08:39.661+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:08:39.660+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:08:39.679+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:08:39.679+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:08:39.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.091 seconds
[2024-10-25T13:09:10.497+0000] {processor.py:186} INFO - Started process (PID=4629) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:09:10.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:09:10.499+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:09:10.499+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:09:10.516+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:09:10.540+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:09:10.539+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:09:10.554+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:09:10.554+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:09:10.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.086 seconds
[2024-10-25T13:09:41.392+0000] {processor.py:186} INFO - Started process (PID=4654) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:09:41.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:09:41.395+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:09:41.394+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:09:41.412+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:09:41.444+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:09:41.443+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:09:41.474+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:09:41.474+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:09:41.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.119 seconds
[2024-10-25T13:10:12.236+0000] {processor.py:186} INFO - Started process (PID=4680) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:10:12.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:10:12.238+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:10:12.238+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:10:12.257+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:10:12.278+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:10:12.277+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:10:12.291+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:10:12.291+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:10:12.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T13:10:43.140+0000] {processor.py:186} INFO - Started process (PID=4705) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:10:43.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:10:43.142+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:10:43.142+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:10:43.161+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:10:43.182+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:10:43.181+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:10:43.195+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:10:43.195+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:10:43.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T13:11:13.363+0000] {processor.py:186} INFO - Started process (PID=4730) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:11:13.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:11:13.365+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:11:13.365+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:11:13.379+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:11:13.398+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:11:13.398+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:11:13.413+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:11:13.413+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:11:13.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:11:43.597+0000] {processor.py:186} INFO - Started process (PID=4755) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:11:43.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:11:43.599+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:11:43.599+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:11:43.614+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:11:43.634+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:11:43.634+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:11:43.649+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:11:43.648+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:11:43.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.121 seconds
[2024-10-25T13:12:13.776+0000] {processor.py:186} INFO - Started process (PID=4780) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:12:13.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:12:13.779+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:12:13.778+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:12:13.792+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:12:13.812+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:12:13.812+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:12:13.827+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:12:13.827+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:12:13.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:12:44.463+0000] {processor.py:186} INFO - Started process (PID=4805) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:12:44.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:12:44.466+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:12:44.465+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:12:44.483+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:12:44.504+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:12:44.503+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:12:44.517+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:12:44.517+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:12:44.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:13:15.428+0000] {processor.py:186} INFO - Started process (PID=4830) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:13:15.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:13:15.431+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:13:15.430+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:13:15.448+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:13:15.468+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:13:15.467+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:13:15.482+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:13:15.481+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:13:15.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T13:13:46.474+0000] {processor.py:186} INFO - Started process (PID=4855) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:13:46.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:13:46.478+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:13:46.478+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:13:46.498+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:13:46.521+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:13:46.521+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:13:46.536+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:13:46.536+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:13:46.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.093 seconds
[2024-10-25T13:14:16.692+0000] {processor.py:186} INFO - Started process (PID=4880) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:14:16.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:14:16.695+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:14:16.695+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:14:16.712+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:14:16.737+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:14:16.737+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:14:16.750+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:14:16.750+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:14:16.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.097 seconds
[2024-10-25T13:14:47.052+0000] {processor.py:186} INFO - Started process (PID=4905) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:14:47.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:14:47.055+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:14:47.055+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:14:47.073+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:14:47.102+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:14:47.102+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:14:47.128+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:14:47.128+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:14:47.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.419 seconds
[2024-10-25T13:15:17.751+0000] {processor.py:186} INFO - Started process (PID=4928) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:15:17.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:15:17.754+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:15:17.753+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:15:17.767+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:15:17.790+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:15:17.789+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:15:17.805+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:15:17.805+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:15:17.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.085 seconds
[2024-10-25T13:15:48.526+0000] {processor.py:186} INFO - Started process (PID=4960) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:15:48.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:15:48.528+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:15:48.528+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:15:48.543+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:15:48.567+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:15:48.567+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:15:48.582+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:15:48.582+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:15:48.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.085 seconds
[2024-10-25T13:16:18.963+0000] {processor.py:186} INFO - Started process (PID=4985) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:16:18.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:16:18.965+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:16:18.965+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:16:18.983+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:16:19.022+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:16:19.022+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:16:19.042+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:16:19.041+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:16:19.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.111 seconds
[2024-10-25T13:16:49.204+0000] {processor.py:186} INFO - Started process (PID=5010) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:16:49.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:16:49.206+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:16:49.206+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:16:49.221+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:16:49.242+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:16:49.242+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:16:49.257+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:16:49.257+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:16:49.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T13:17:19.390+0000] {processor.py:186} INFO - Started process (PID=5035) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:17:19.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:17:19.393+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:17:19.392+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:17:19.408+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:17:19.429+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:17:19.429+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:17:19.444+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:17:19.444+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:17:19.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T13:17:49.802+0000] {processor.py:186} INFO - Started process (PID=5060) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:17:49.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:17:49.804+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:17:49.804+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:17:49.819+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:17:49.839+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:17:49.839+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:17:49.852+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:17:49.852+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:17:49.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:18:20.812+0000] {processor.py:186} INFO - Started process (PID=5085) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:18:20.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:18:20.816+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:18:20.815+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:18:20.843+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:18:20.884+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:18:20.883+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:18:20.903+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:18:20.903+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:18:20.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.129 seconds
[2024-10-25T13:18:51.554+0000] {processor.py:186} INFO - Started process (PID=5110) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:18:51.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:18:51.561+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:18:51.560+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:18:51.581+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:18:51.627+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:18:51.627+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:18:51.655+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:18:51.654+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:18:51.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.136 seconds
[2024-10-25T13:19:22.275+0000] {processor.py:186} INFO - Started process (PID=5135) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:19:22.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:19:22.277+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:19:22.277+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:19:22.292+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:19:22.319+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:19:22.319+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:19:22.334+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:19:22.334+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:19:22.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.092 seconds
[2024-10-25T13:19:52.800+0000] {processor.py:186} INFO - Started process (PID=5160) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:19:52.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:19:52.802+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:19:52.802+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:19:52.825+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:19:52.851+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:19:52.851+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:19:52.870+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:19:52.870+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:19:52.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.108 seconds
[2024-10-25T13:20:23.324+0000] {processor.py:186} INFO - Started process (PID=5185) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:20:23.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:20:23.327+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:20:23.326+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:20:23.340+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:20:23.363+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:20:23.363+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:20:23.378+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:20:23.378+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:20:23.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.084 seconds
[2024-10-25T13:20:53.740+0000] {processor.py:186} INFO - Started process (PID=5210) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:20:53.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:20:53.742+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:20:53.742+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:20:53.764+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:20:53.789+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:20:53.789+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:20:53.806+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:20:53.806+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:20:53.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.103 seconds
[2024-10-25T13:21:24.504+0000] {processor.py:186} INFO - Started process (PID=5235) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:21:24.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:21:24.507+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:21:24.506+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:21:24.523+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:21:24.546+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:21:24.545+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:21:24.561+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:21:24.561+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:21:24.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
[2024-10-25T13:21:54.887+0000] {processor.py:186} INFO - Started process (PID=5259) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:21:54.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:21:54.889+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:21:54.889+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:21:54.903+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:21:54.923+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:21:54.923+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:21:54.936+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:21:54.936+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:21:54.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:22:25.787+0000] {processor.py:186} INFO - Started process (PID=5284) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:22:25.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:22:25.789+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:22:25.788+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:22:25.803+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:22:25.824+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:22:25.824+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:22:25.838+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:22:25.838+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:22:25.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T13:22:56.229+0000] {processor.py:186} INFO - Started process (PID=5310) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:22:56.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:22:56.231+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:22:56.231+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:22:56.247+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:22:56.270+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:22:56.270+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:22:56.290+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:22:56.290+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:22:56.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.085 seconds
[2024-10-25T13:23:27.005+0000] {processor.py:186} INFO - Started process (PID=5335) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:23:27.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:23:27.007+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:23:27.007+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:23:27.022+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:23:27.041+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:23:27.041+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:23:27.055+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:23:27.055+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:23:27.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:23:57.730+0000] {processor.py:186} INFO - Started process (PID=5360) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:23:57.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:23:57.732+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:23:57.732+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:23:57.747+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:23:57.767+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:23:57.767+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:23:57.781+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:23:57.781+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:23:57.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:24:27.915+0000] {processor.py:186} INFO - Started process (PID=5385) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:24:27.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:24:27.917+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:24:27.917+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:24:27.934+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:24:27.954+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:24:27.954+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:24:27.971+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:24:27.970+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:24:27.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T13:24:58.077+0000] {processor.py:186} INFO - Started process (PID=5410) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:24:58.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:24:58.079+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:24:58.079+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:24:58.094+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:24:58.114+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:24:58.114+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:24:58.128+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:24:58.128+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:24:58.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.103 seconds
[2024-10-25T13:25:28.439+0000] {processor.py:186} INFO - Started process (PID=5435) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:25:28.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:25:28.441+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:25:28.440+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:25:28.461+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:25:28.486+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:25:28.486+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:25:28.500+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:25:28.500+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:25:28.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.089 seconds
[2024-10-25T13:25:58.794+0000] {processor.py:186} INFO - Started process (PID=5459) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:25:58.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:25:58.796+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:25:58.796+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:25:58.814+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:25:58.842+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:25:58.842+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:25:58.858+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:25:58.857+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:25:58.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.183 seconds
[2024-10-25T13:26:29.102+0000] {processor.py:186} INFO - Started process (PID=5484) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:26:29.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:26:29.104+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:26:29.104+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:26:29.119+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:26:29.142+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:26:29.142+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:26:29.158+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:26:29.158+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:26:29.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.096 seconds
[2024-10-25T13:27:00.070+0000] {processor.py:186} INFO - Started process (PID=5509) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:27:00.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:27:00.072+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:27:00.072+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:27:00.091+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:27:00.111+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:27:00.111+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:27:00.124+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:27:00.124+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:27:00.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T13:27:30.719+0000] {processor.py:186} INFO - Started process (PID=5534) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:27:30.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:27:30.721+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:27:30.721+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:27:30.734+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:27:30.755+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:27:30.754+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:27:30.768+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:27:30.768+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:27:30.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T13:28:01.377+0000] {processor.py:186} INFO - Started process (PID=5559) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:28:01.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:28:01.379+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:28:01.379+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:28:01.393+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:28:01.413+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:28:01.413+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:28:01.426+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:28:01.426+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:28:01.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T13:28:32.029+0000] {processor.py:186} INFO - Started process (PID=5584) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:28:32.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:28:32.032+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:28:32.031+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:28:32.049+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:28:32.068+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:28:32.068+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:28:32.082+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:28:32.082+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:28:32.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:29:02.973+0000] {processor.py:186} INFO - Started process (PID=5609) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:29:02.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:29:02.975+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:29:02.974+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:29:02.989+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:29:03.008+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:29:03.008+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:29:03.021+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:29:03.021+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:29:03.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T13:29:33.873+0000] {processor.py:186} INFO - Started process (PID=5634) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:29:33.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:29:33.875+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:29:33.875+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:29:33.890+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:29:33.910+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:29:33.910+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:29:33.924+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:29:33.923+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:29:33.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T13:30:04.631+0000] {processor.py:186} INFO - Started process (PID=5659) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:30:04.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:30:04.633+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:30:04.633+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:30:04.646+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:30:04.666+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:30:04.665+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:30:04.679+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:30:04.679+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:30:04.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T13:30:35.548+0000] {processor.py:186} INFO - Started process (PID=5684) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:30:35.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:30:35.551+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:30:35.550+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:30:35.565+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:30:35.585+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:30:35.585+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:30:35.598+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:30:35.598+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:30:35.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:31:06.320+0000] {processor.py:186} INFO - Started process (PID=5709) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:31:06.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:31:06.322+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:31:06.322+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:31:06.339+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:31:06.359+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:31:06.359+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:31:06.372+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:31:06.372+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:31:06.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:31:37.320+0000] {processor.py:186} INFO - Started process (PID=5734) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:31:37.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:31:37.323+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:31:37.322+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:31:37.338+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:31:37.358+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:31:37.358+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:31:37.372+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:31:37.371+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:31:37.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:32:07.601+0000] {processor.py:186} INFO - Started process (PID=5759) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:32:07.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:32:07.603+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:32:07.603+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:32:07.618+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:32:07.639+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:32:07.639+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:32:07.653+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:32:07.653+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:32:07.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:32:37.753+0000] {processor.py:186} INFO - Started process (PID=5784) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:32:37.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:32:37.755+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:32:37.754+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:32:37.770+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:32:37.794+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:32:37.794+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:32:37.808+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:32:37.808+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:32:37.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T13:33:08.289+0000] {processor.py:186} INFO - Started process (PID=5809) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:33:08.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:33:08.291+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:33:08.291+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:33:08.305+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:33:08.324+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:33:08.324+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:33:08.338+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:33:08.338+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:33:08.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T13:33:38.834+0000] {processor.py:186} INFO - Started process (PID=5834) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:33:38.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:33:38.836+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:33:38.836+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:33:38.851+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:33:38.874+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:33:38.873+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:33:38.888+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:33:38.888+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:33:38.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T13:34:09.557+0000] {processor.py:186} INFO - Started process (PID=5859) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:34:09.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:34:09.559+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:34:09.559+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:34:09.575+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:34:09.595+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:34:09.595+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:34:09.608+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:34:09.608+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:34:09.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T13:34:40.172+0000] {processor.py:186} INFO - Started process (PID=5884) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:34:40.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:34:40.174+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:34:40.174+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:34:40.189+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:34:40.208+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:34:40.207+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:34:40.221+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:34:40.221+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:34:40.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:35:10.683+0000] {processor.py:186} INFO - Started process (PID=5909) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:35:10.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:35:10.686+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:35:10.686+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:35:10.701+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:35:10.722+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:35:10.721+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:35:10.735+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:35:10.735+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:35:10.755+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T13:35:41.109+0000] {processor.py:186} INFO - Started process (PID=5934) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:35:41.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:35:41.111+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:35:41.111+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:35:41.127+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:35:41.150+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:35:41.150+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:35:41.166+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:35:41.166+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:35:41.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.083 seconds
[2024-10-25T13:36:11.670+0000] {processor.py:186} INFO - Started process (PID=5959) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:36:11.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:36:11.673+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:36:11.672+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:36:11.688+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:36:11.713+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:36:11.713+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:36:11.730+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:36:11.730+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:36:11.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.089 seconds
[2024-10-25T13:36:41.916+0000] {processor.py:186} INFO - Started process (PID=5984) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:36:41.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:36:41.919+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:36:41.918+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:36:41.933+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:36:41.955+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:36:41.955+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:36:41.971+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:36:41.970+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:36:41.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.086 seconds
[2024-10-25T13:37:12.753+0000] {processor.py:186} INFO - Started process (PID=6009) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:37:12.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:37:12.756+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:37:12.755+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:37:12.773+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:37:12.798+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:37:12.797+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:37:12.815+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:37:12.814+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:37:12.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.092 seconds
[2024-10-25T13:37:43.691+0000] {processor.py:186} INFO - Started process (PID=6034) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:37:43.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:37:43.694+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:37:43.694+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:37:43.711+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:37:43.734+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:37:43.733+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:37:43.750+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:37:43.750+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:37:43.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.085 seconds
[2024-10-25T13:38:14.390+0000] {processor.py:186} INFO - Started process (PID=6060) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:38:14.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:38:14.392+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:38:14.392+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:38:14.406+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:38:14.427+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:38:14.426+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:38:14.441+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:38:14.440+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:38:14.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:38:45.026+0000] {processor.py:186} INFO - Started process (PID=6085) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:38:45.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:38:45.028+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:38:45.028+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:38:45.043+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:38:45.065+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:38:45.065+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:38:45.081+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:38:45.081+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:38:45.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.089 seconds
[2024-10-25T13:39:15.407+0000] {processor.py:186} INFO - Started process (PID=6110) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:39:15.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:39:15.409+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:39:15.409+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:39:15.424+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:39:15.448+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:39:15.447+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:39:15.465+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:39:15.465+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:39:15.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.088 seconds
[2024-10-25T13:39:46.192+0000] {processor.py:186} INFO - Started process (PID=6135) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:39:46.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:39:46.194+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:39:46.194+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:39:46.208+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:39:46.228+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:39:46.228+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:39:46.241+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:39:46.241+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:39:46.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T13:40:16.715+0000] {processor.py:186} INFO - Started process (PID=6160) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:40:16.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:40:16.717+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:40:16.717+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:40:16.736+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:40:16.758+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:40:16.758+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:40:16.772+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:40:16.772+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:40:16.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
[2024-10-25T13:40:47.403+0000] {processor.py:186} INFO - Started process (PID=6185) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:40:47.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:40:47.405+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:40:47.405+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:40:47.419+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:40:47.441+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:40:47.441+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:40:47.457+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:40:47.457+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:40:47.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.083 seconds
[2024-10-25T13:41:18.081+0000] {processor.py:186} INFO - Started process (PID=6210) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:41:18.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:41:18.083+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:41:18.083+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:41:18.098+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:41:18.119+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:41:18.119+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:41:18.133+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:41:18.132+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:41:18.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:41:48.822+0000] {processor.py:186} INFO - Started process (PID=6235) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:41:48.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:41:48.824+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:41:48.824+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:41:48.838+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:41:48.859+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:41:48.859+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:41:48.874+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:41:48.874+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:41:48.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T13:42:19.640+0000] {processor.py:186} INFO - Started process (PID=6265) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:42:19.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:42:19.642+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:42:19.642+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:42:19.658+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:42:19.682+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:42:19.682+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:42:19.700+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:42:19.700+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:42:19.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.093 seconds
[2024-10-25T13:42:50.143+0000] {processor.py:186} INFO - Started process (PID=6290) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:42:50.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:42:50.146+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:42:50.145+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:42:50.160+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:42:50.184+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:42:50.184+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:42:50.199+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:42:50.199+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:42:50.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
[2024-10-25T13:43:20.694+0000] {processor.py:186} INFO - Started process (PID=6316) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:43:20.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:43:20.696+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:43:20.696+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:43:20.710+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:43:20.730+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:43:20.730+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:43:20.744+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:43:20.744+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:43:20.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:43:51.379+0000] {processor.py:186} INFO - Started process (PID=6341) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:43:51.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:43:51.382+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:43:51.381+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:43:51.396+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:43:51.419+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:43:51.419+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:43:51.434+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:43:51.434+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:43:51.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T13:44:21.964+0000] {processor.py:186} INFO - Started process (PID=6366) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:44:21.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:44:21.967+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:44:21.966+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:44:21.982+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:44:22.003+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:44:22.003+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:44:22.017+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:44:22.017+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:44:22.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T13:44:52.641+0000] {processor.py:186} INFO - Started process (PID=6391) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:44:52.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:44:52.644+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:44:52.643+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:44:52.656+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:44:52.679+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:44:52.679+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:44:52.696+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:44:52.696+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:44:52.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.087 seconds
[2024-10-25T13:45:22.897+0000] {processor.py:186} INFO - Started process (PID=6415) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:45:22.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:45:22.900+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:45:22.899+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:45:22.916+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:45:22.937+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:45:22.936+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:45:22.951+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:45:22.950+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:45:22.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T13:45:53.369+0000] {processor.py:186} INFO - Started process (PID=6440) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:45:53.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:45:53.371+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:45:53.371+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:45:53.389+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:45:53.409+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:45:53.409+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:45:53.422+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:45:53.422+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:45:53.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T13:46:23.865+0000] {processor.py:186} INFO - Started process (PID=6465) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:46:23.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:46:23.867+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:46:23.866+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:46:23.881+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:46:23.901+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:46:23.901+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:46:23.915+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:46:23.915+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:46:23.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:46:54.890+0000] {processor.py:186} INFO - Started process (PID=6490) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:46:54.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:46:54.892+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:46:54.892+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:46:54.906+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:46:54.925+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:46:54.925+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:46:54.939+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:46:54.939+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:46:54.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T13:47:25.105+0000] {processor.py:186} INFO - Started process (PID=6516) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:47:25.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:47:25.107+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:47:25.106+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:47:25.121+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:47:25.141+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:47:25.141+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:47:25.155+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:47:25.155+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:47:25.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:47:55.290+0000] {processor.py:186} INFO - Started process (PID=6541) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:47:55.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:47:55.292+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:47:55.292+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:47:55.305+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:47:55.326+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:47:55.325+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:47:55.339+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:47:55.339+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:47:55.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T13:48:25.459+0000] {processor.py:186} INFO - Started process (PID=6567) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:48:25.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:48:25.461+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:48:25.461+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:48:25.475+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:48:25.494+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:48:25.494+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:48:25.507+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:48:25.507+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:48:25.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T13:48:56.110+0000] {processor.py:186} INFO - Started process (PID=6592) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:48:56.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:48:56.113+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:48:56.113+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:48:56.128+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:48:56.148+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:48:56.148+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:48:56.167+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:48:56.167+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:48:56.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.097 seconds
[2024-10-25T13:49:26.674+0000] {processor.py:186} INFO - Started process (PID=6617) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:49:26.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:49:26.678+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:49:26.677+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:49:26.696+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:49:26.718+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:49:26.718+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:49:26.732+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:49:26.732+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:49:26.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.084 seconds
[2024-10-25T13:49:57.224+0000] {processor.py:186} INFO - Started process (PID=6642) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:49:57.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:49:57.227+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:49:57.227+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:49:57.243+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:49:57.263+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:49:57.263+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:49:57.277+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:49:57.276+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:49:57.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:50:27.896+0000] {processor.py:186} INFO - Started process (PID=6667) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:50:27.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:50:27.899+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:50:27.899+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:50:27.913+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:50:27.933+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:50:27.933+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:50:27.946+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:50:27.946+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:50:27.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:50:58.484+0000] {processor.py:186} INFO - Started process (PID=6692) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:50:58.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:50:58.487+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:50:58.486+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:50:58.501+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:50:58.521+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:50:58.520+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:50:58.534+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:50:58.534+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:50:58.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T13:51:28.998+0000] {processor.py:186} INFO - Started process (PID=6717) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:51:28.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:51:29.000+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:51:28.999+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:51:29.014+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:51:29.034+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:51:29.034+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:51:29.048+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:51:29.048+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:51:29.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:51:59.789+0000] {processor.py:186} INFO - Started process (PID=6742) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:51:59.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:51:59.791+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:51:59.791+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:51:59.804+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:51:59.823+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:51:59.823+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:51:59.836+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:51:59.836+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:51:59.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T13:52:30.461+0000] {processor.py:186} INFO - Started process (PID=6767) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:52:30.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:52:30.463+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:52:30.463+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:52:30.480+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:52:30.500+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:52:30.499+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:52:30.513+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:52:30.512+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:52:30.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:53:01.051+0000] {processor.py:186} INFO - Started process (PID=6792) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:53:01.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:53:01.053+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:53:01.053+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:53:01.069+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:53:01.088+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:53:01.088+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:53:01.102+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:53:01.101+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:53:01.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.234 seconds
[2024-10-25T13:53:32.371+0000] {processor.py:186} INFO - Started process (PID=6817) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:53:32.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:53:32.374+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:53:32.374+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:53:32.390+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:53:32.410+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:53:32.409+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:53:32.423+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:53:32.422+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:53:32.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T13:54:03.054+0000] {processor.py:186} INFO - Started process (PID=6842) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:54:03.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:54:03.056+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:54:03.056+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:54:03.071+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:54:03.091+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:54:03.091+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:54:03.105+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:54:03.104+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:54:03.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:54:33.664+0000] {processor.py:186} INFO - Started process (PID=6867) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:54:33.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:54:33.666+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:54:33.665+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:54:33.681+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:54:33.701+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:54:33.701+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:54:33.715+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:54:33.715+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:54:33.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:55:04.060+0000] {processor.py:186} INFO - Started process (PID=6892) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:55:04.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:55:04.062+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:55:04.062+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:55:04.076+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:55:04.097+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:55:04.097+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:55:04.111+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:55:04.111+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:55:04.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.234 seconds
[2024-10-25T13:55:35.255+0000] {processor.py:186} INFO - Started process (PID=6917) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:55:35.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:55:35.258+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:55:35.257+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:55:35.273+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:55:35.293+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:55:35.292+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:55:35.307+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:55:35.307+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:55:35.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:56:06.070+0000] {processor.py:186} INFO - Started process (PID=6942) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:56:06.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:56:06.073+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:56:06.072+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:56:06.091+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:56:06.111+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:56:06.111+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:56:06.124+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:56:06.124+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:56:06.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T13:56:36.286+0000] {processor.py:186} INFO - Started process (PID=6967) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:56:36.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:56:36.288+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:56:36.287+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:56:36.303+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:56:36.324+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:56:36.324+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:56:36.337+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:56:36.337+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:56:36.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T13:57:07.001+0000] {processor.py:186} INFO - Started process (PID=6992) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:57:07.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:57:07.003+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:57:07.003+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:57:07.017+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:57:07.037+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:57:07.037+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:57:07.051+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:57:07.051+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:57:07.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.228 seconds
[2024-10-25T13:57:38.259+0000] {processor.py:186} INFO - Started process (PID=7017) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:57:38.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:57:38.262+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:57:38.262+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:57:38.280+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:57:38.300+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:57:38.300+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:57:38.313+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:57:38.313+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:57:38.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T13:58:09.007+0000] {processor.py:186} INFO - Started process (PID=7042) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:58:09.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:58:09.010+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:58:09.009+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:58:09.030+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:58:09.050+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:58:09.050+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:58:09.067+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:58:09.067+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:58:09.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.085 seconds
[2024-10-25T13:58:39.757+0000] {processor.py:186} INFO - Started process (PID=7066) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:58:39.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:58:39.760+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:58:39.759+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:58:39.775+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:58:39.795+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:58:39.795+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:58:39.808+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:58:39.808+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:58:39.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T13:59:09.982+0000] {processor.py:186} INFO - Started process (PID=7091) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:59:09.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:59:09.984+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:59:09.984+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:59:09.998+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:59:10.018+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:59:10.018+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:59:10.032+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:59:10.032+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:59:10.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.236 seconds
[2024-10-25T13:59:41.194+0000] {processor.py:186} INFO - Started process (PID=7116) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:59:41.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T13:59:41.197+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:59:41.196+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:59:41.213+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T13:59:41.235+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:59:41.235+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T13:59:41.250+0000] {logging_mixin.py:190} INFO - [2024-10-25T13:59:41.250+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T13:59:41.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
[2024-10-25T14:00:11.619+0000] {processor.py:186} INFO - Started process (PID=7141) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:00:11.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:00:11.621+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:00:11.621+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:00:11.636+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:00:11.661+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:00:11.661+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:00:11.675+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:00:11.674+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:00:11.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T14:00:42.348+0000] {processor.py:186} INFO - Started process (PID=7166) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:00:42.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:00:42.350+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:00:42.350+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:00:42.367+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:00:42.387+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:00:42.386+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:00:42.400+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:00:42.400+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:00:42.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:01:12.830+0000] {processor.py:186} INFO - Started process (PID=7191) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:01:12.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:01:12.832+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:01:12.832+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:01:12.850+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:01:12.870+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:01:12.870+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:01:12.883+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:01:12.883+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:01:13.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.236 seconds
[2024-10-25T14:01:43.966+0000] {processor.py:186} INFO - Started process (PID=7216) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:01:43.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:01:43.968+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:01:43.967+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:01:43.984+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:01:44.004+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:01:44.004+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:01:44.017+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:01:44.017+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:01:44.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:02:14.779+0000] {processor.py:186} INFO - Started process (PID=7241) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:02:14.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:02:14.782+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:02:14.781+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:02:14.797+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:02:14.817+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:02:14.817+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:02:14.831+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:02:14.830+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:02:14.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:02:45.725+0000] {processor.py:186} INFO - Started process (PID=7266) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:02:45.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:02:45.728+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:02:45.728+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:02:45.744+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:02:45.765+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:02:45.765+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:02:45.778+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:02:45.778+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:02:45.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:03:16.732+0000] {processor.py:186} INFO - Started process (PID=7291) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:03:16.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:03:16.735+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:03:16.734+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:03:16.752+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:03:16.772+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:03:16.772+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:03:16.786+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:03:16.786+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:03:16.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.234 seconds
[2024-10-25T14:03:47.487+0000] {processor.py:186} INFO - Started process (PID=7316) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:03:47.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:03:47.490+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:03:47.490+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:03:47.506+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:03:47.527+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:03:47.526+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:03:47.540+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:03:47.540+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:03:47.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T14:04:17.894+0000] {processor.py:186} INFO - Started process (PID=7341) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:04:17.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:04:17.896+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:04:17.895+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:04:17.910+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:04:17.932+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:04:17.932+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:04:17.946+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:04:17.946+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:04:17.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T14:04:48.121+0000] {processor.py:186} INFO - Started process (PID=7366) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:04:48.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:04:48.123+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:04:48.123+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:04:48.137+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:04:48.158+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:04:48.157+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:04:48.172+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:04:48.171+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:04:48.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:05:18.635+0000] {processor.py:186} INFO - Started process (PID=7391) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:05:18.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:05:18.637+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:05:18.637+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:05:18.652+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:05:18.673+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:05:18.672+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:05:18.688+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:05:18.688+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:05:18.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.258 seconds
[2024-10-25T14:05:49.627+0000] {processor.py:186} INFO - Started process (PID=7416) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:05:49.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:05:49.629+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:05:49.628+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:05:49.644+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:05:49.861+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:05:49.861+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:05:49.875+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:05:49.874+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:05:49.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.272 seconds
[2024-10-25T14:06:20.096+0000] {processor.py:186} INFO - Started process (PID=7441) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:06:20.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:06:20.098+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:06:20.098+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:06:20.113+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:06:20.133+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:06:20.132+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:06:20.146+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:06:20.146+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:06:20.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:06:50.941+0000] {processor.py:186} INFO - Started process (PID=7466) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:06:50.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:06:50.944+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:06:50.943+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:06:50.958+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:06:50.979+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:06:50.979+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:06:50.993+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:06:50.993+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:06:51.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:07:21.435+0000] {processor.py:186} INFO - Started process (PID=7497) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:07:21.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:07:21.437+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:07:21.437+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:07:21.452+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:07:21.472+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:07:21.472+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:07:21.486+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:07:21.486+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:07:21.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.234 seconds
[2024-10-25T14:07:51.932+0000] {processor.py:186} INFO - Started process (PID=7523) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:07:51.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:07:51.934+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:07:51.933+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:07:51.949+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:07:52.140+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:07:52.140+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:07:52.153+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:07:52.153+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:07:52.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.248 seconds
[2024-10-25T14:08:22.248+0000] {processor.py:186} INFO - Started process (PID=7548) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:08:22.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:08:22.250+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:08:22.250+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:08:22.265+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:08:22.284+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:08:22.284+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:08:22.298+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:08:22.298+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:08:22.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:08:52.815+0000] {processor.py:186} INFO - Started process (PID=7573) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:08:52.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:08:52.817+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:08:52.817+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:08:52.832+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:08:52.852+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:08:52.852+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:08:52.865+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:08:52.865+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:08:52.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:09:23.403+0000] {processor.py:186} INFO - Started process (PID=7598) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:09:23.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:09:23.405+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:09:23.405+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:09:23.419+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:09:23.439+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:09:23.439+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:09:23.453+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:09:23.453+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:09:23.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.237 seconds
[2024-10-25T14:09:54.077+0000] {processor.py:186} INFO - Started process (PID=7623) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:09:54.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:09:54.079+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:09:54.079+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:09:54.095+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:09:54.116+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:09:54.115+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:09:54.288+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:09:54.287+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:09:54.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.235 seconds
[2024-10-25T14:10:25.153+0000] {processor.py:186} INFO - Started process (PID=7648) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:10:25.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:10:25.156+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:10:25.156+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:10:25.174+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:10:25.194+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:10:25.194+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:10:25.207+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:10:25.207+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:10:25.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T14:10:55.928+0000] {processor.py:186} INFO - Started process (PID=7673) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:10:55.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:10:55.930+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:10:55.930+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:10:55.946+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:10:55.966+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:10:55.966+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:10:55.979+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:10:55.979+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:10:56.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:11:26.639+0000] {processor.py:186} INFO - Started process (PID=7698) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:11:26.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:11:26.641+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:11:26.641+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:11:26.659+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:11:26.680+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:11:26.679+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:11:26.694+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:11:26.694+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:11:26.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.308 seconds
[2024-10-25T14:11:57.150+0000] {processor.py:186} INFO - Started process (PID=7724) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:11:57.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:11:57.152+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:11:57.151+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:11:57.165+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:11:57.185+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:11:57.185+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:11:57.375+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:11:57.375+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:11:57.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.252 seconds
[2024-10-25T14:12:27.619+0000] {processor.py:186} INFO - Started process (PID=7749) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:12:27.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:12:27.622+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:12:27.622+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:12:27.637+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:12:27.658+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:12:27.658+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:12:27.671+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:12:27.671+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:12:27.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T14:12:57.995+0000] {processor.py:186} INFO - Started process (PID=7774) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:12:57.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:12:57.998+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:12:57.997+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:12:58.012+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:12:58.032+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:12:58.031+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:12:58.044+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:12:58.044+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:12:58.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:13:28.762+0000] {processor.py:186} INFO - Started process (PID=7799) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:13:28.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:13:28.764+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:13:28.764+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:13:28.783+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:13:28.801+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:13:28.801+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:13:28.815+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:13:28.814+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:13:28.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:13:58.947+0000] {processor.py:186} INFO - Started process (PID=7824) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:13:58.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:13:58.949+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:13:58.949+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:13:58.965+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:13:58.984+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:13:58.983+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:13:58.996+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:13:58.996+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:13:59.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.122 seconds
[2024-10-25T14:14:29.872+0000] {processor.py:186} INFO - Started process (PID=7849) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:14:29.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:14:29.875+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:14:29.874+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:14:29.888+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:14:29.908+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:14:29.908+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:14:29.921+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:14:29.921+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:14:29.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:15:00.607+0000] {processor.py:186} INFO - Started process (PID=7874) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:15:00.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:15:00.609+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:15:00.609+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:15:00.625+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:15:00.645+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:15:00.645+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:15:00.658+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:15:00.658+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:15:00.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:15:31.267+0000] {processor.py:186} INFO - Started process (PID=7899) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:15:31.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:15:31.269+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:15:31.269+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:15:31.284+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:15:31.304+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:15:31.304+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:15:31.318+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:15:31.318+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:15:31.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T14:16:01.919+0000] {processor.py:186} INFO - Started process (PID=7924) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:16:01.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:16:01.921+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:16:01.921+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:16:01.939+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:16:01.959+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:16:01.959+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:16:01.972+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:16:01.972+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:16:01.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:16:32.280+0000] {processor.py:186} INFO - Started process (PID=7949) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:16:32.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:16:32.283+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:16:32.283+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:16:32.298+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:16:32.318+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:16:32.318+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:16:32.332+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:16:32.332+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:16:32.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:17:03.021+0000] {processor.py:186} INFO - Started process (PID=7974) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:17:03.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:17:03.024+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:17:03.024+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:17:03.041+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:17:03.065+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:17:03.065+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:17:03.079+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:17:03.079+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:17:03.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.118 seconds
[2024-10-25T14:17:33.401+0000] {processor.py:186} INFO - Started process (PID=7999) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:17:33.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:17:33.403+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:17:33.403+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:17:33.417+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:17:33.437+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:17:33.437+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:17:33.451+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:17:33.450+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:17:33.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T14:18:03.947+0000] {processor.py:186} INFO - Started process (PID=8024) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:18:03.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:18:03.951+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:18:03.950+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:18:03.971+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:18:03.996+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:18:03.996+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:18:04.014+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:18:04.014+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:18:04.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.097 seconds
[2024-10-25T14:18:34.367+0000] {processor.py:186} INFO - Started process (PID=8049) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:18:34.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:18:34.369+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:18:34.369+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:18:34.384+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:18:34.405+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:18:34.404+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:18:34.418+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:18:34.418+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:18:34.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T14:19:04.755+0000] {processor.py:186} INFO - Started process (PID=8074) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:19:04.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:19:04.757+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:19:04.756+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:19:04.770+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:19:04.790+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:19:04.790+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:19:04.804+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:19:04.803+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:19:04.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:19:35.305+0000] {processor.py:186} INFO - Started process (PID=8099) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:19:35.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:19:35.307+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:19:35.307+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:19:35.322+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:19:35.345+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:19:35.345+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:19:35.361+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:19:35.360+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:19:35.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T14:20:05.726+0000] {processor.py:186} INFO - Started process (PID=8123) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:20:05.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:20:05.728+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:20:05.728+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:20:05.749+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:20:05.771+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:20:05.771+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:20:05.787+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:20:05.787+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:20:05.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.093 seconds
[2024-10-25T14:20:36.139+0000] {processor.py:186} INFO - Started process (PID=8149) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:20:36.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:20:36.146+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:20:36.145+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:20:36.166+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:20:36.225+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:20:36.225+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:20:36.268+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:20:36.268+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:20:36.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.198 seconds
[2024-10-25T14:21:06.398+0000] {processor.py:186} INFO - Started process (PID=8174) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:21:06.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:21:06.400+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:21:06.400+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:21:06.415+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:21:06.437+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:21:06.437+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:21:06.458+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:21:06.457+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:21:06.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.089 seconds
[2024-10-25T14:21:37.104+0000] {processor.py:186} INFO - Started process (PID=8199) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:21:37.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:21:37.106+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:21:37.106+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:21:37.122+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:21:37.144+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:21:37.144+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:21:37.160+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:21:37.160+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:21:37.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.084 seconds
[2024-10-25T14:22:07.809+0000] {processor.py:186} INFO - Started process (PID=8224) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:22:07.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:22:07.812+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:22:07.811+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:22:07.827+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:22:08.180+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:22:08.180+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:22:08.199+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:22:08.199+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:22:08.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.478 seconds
[2024-10-25T14:22:39.035+0000] {processor.py:186} INFO - Started process (PID=8248) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:22:39.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:22:39.044+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:22:39.044+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:22:39.067+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:22:39.102+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:22:39.102+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:22:39.146+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:22:39.133+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:22:39.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.152 seconds
[2024-10-25T14:23:09.976+0000] {processor.py:186} INFO - Started process (PID=8273) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:23:09.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:23:09.979+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:23:09.979+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:23:09.995+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:23:10.016+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:23:10.016+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:23:10.029+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:23:10.029+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:23:10.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T14:23:40.128+0000] {processor.py:186} INFO - Started process (PID=8298) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:23:40.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:23:40.130+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:23:40.129+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:23:40.144+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:23:40.162+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:23:40.162+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:23:40.176+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:23:40.176+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:23:40.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T14:24:10.989+0000] {processor.py:186} INFO - Started process (PID=8324) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:24:10.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:24:10.992+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:24:10.991+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:24:11.012+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:24:11.035+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:24:11.035+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:24:11.050+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:24:11.050+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:24:11.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.088 seconds
[2024-10-25T14:24:41.725+0000] {processor.py:186} INFO - Started process (PID=8350) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:24:41.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:24:41.727+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:24:41.727+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:24:41.741+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:24:41.763+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:24:41.763+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:24:41.776+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:24:41.776+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:24:41.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T14:25:12.073+0000] {processor.py:186} INFO - Started process (PID=8379) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:25:12.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:25:12.076+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:25:12.075+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:25:12.091+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:25:12.113+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:25:12.113+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:25:12.127+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:25:12.126+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:25:12.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T14:25:42.731+0000] {processor.py:186} INFO - Started process (PID=8404) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:25:42.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:25:42.734+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:25:42.734+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:25:42.752+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:25:42.786+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:25:42.786+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:25:42.805+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:25:42.805+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:25:42.827+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.102 seconds
[2024-10-25T14:26:13.545+0000] {processor.py:186} INFO - Started process (PID=8429) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:26:13.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:26:13.548+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:26:13.547+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:26:13.562+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:26:13.582+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:26:13.582+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:26:13.596+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:26:13.596+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:26:13.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:26:44.465+0000] {processor.py:186} INFO - Started process (PID=8454) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:26:44.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:26:44.468+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:26:44.468+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:26:44.485+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:26:44.505+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:26:44.504+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:26:44.518+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:26:44.517+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:26:44.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T14:27:14.764+0000] {processor.py:186} INFO - Started process (PID=8479) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:27:14.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:27:14.767+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:27:14.766+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:27:14.782+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:27:14.802+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:27:14.801+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:27:14.814+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:27:14.814+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:27:14.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:27:44.954+0000] {processor.py:186} INFO - Started process (PID=8504) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:27:44.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:27:44.957+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:27:44.956+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:27:44.971+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:27:44.990+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:27:44.989+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:27:45.003+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:27:45.002+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:27:45.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T14:28:15.300+0000] {processor.py:186} INFO - Started process (PID=8529) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:28:15.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:28:15.303+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:28:15.302+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:28:15.316+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:28:15.336+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:28:15.336+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:28:15.349+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:28:15.349+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:28:15.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:28:46.415+0000] {processor.py:186} INFO - Started process (PID=8554) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:28:46.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:28:46.417+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:28:46.417+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:28:46.435+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:28:46.457+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:28:46.456+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:28:46.469+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:28:46.469+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:28:46.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T14:29:17.131+0000] {processor.py:186} INFO - Started process (PID=8579) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:29:17.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:29:17.134+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:29:17.134+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:29:17.153+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:29:17.175+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:29:17.175+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:29:17.188+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:29:17.188+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:29:17.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
[2024-10-25T14:29:47.834+0000] {processor.py:186} INFO - Started process (PID=8604) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:29:47.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:29:47.836+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:29:47.836+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:29:47.850+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:29:47.870+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:29:47.870+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:29:47.884+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:29:47.884+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:29:47.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.109 seconds
[2024-10-25T14:30:18.268+0000] {processor.py:186} INFO - Started process (PID=8629) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:30:18.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:30:18.271+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:30:18.270+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:30:18.285+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:30:18.305+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:30:18.305+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:30:18.318+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:30:18.318+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:30:18.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:30:49.143+0000] {processor.py:186} INFO - Started process (PID=8654) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:30:49.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:30:49.146+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:30:49.145+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:30:49.161+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:30:49.181+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:30:49.180+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:30:49.194+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:30:49.194+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:30:49.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T14:31:19.858+0000] {processor.py:186} INFO - Started process (PID=8679) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:31:19.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:31:19.861+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:31:19.860+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:31:19.875+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:31:19.896+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:31:19.896+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:31:19.910+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:31:19.909+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:31:19.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T14:31:50.604+0000] {processor.py:186} INFO - Started process (PID=8704) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:31:50.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:31:50.607+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:31:50.607+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:31:50.622+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:31:50.645+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:31:50.645+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:31:50.671+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:31:50.671+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:31:50.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.112 seconds
[2024-10-25T14:32:21.427+0000] {processor.py:186} INFO - Started process (PID=8729) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:32:21.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:32:21.430+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:32:21.430+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:32:21.446+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:32:21.464+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:32:21.464+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:32:21.481+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:32:21.481+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:32:21.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
[2024-10-25T14:32:52.028+0000] {processor.py:186} INFO - Started process (PID=8754) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:32:52.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:32:52.030+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:32:52.030+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:32:52.045+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:32:52.067+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:32:52.066+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:32:52.080+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:32:52.080+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:32:52.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:33:23.032+0000] {processor.py:186} INFO - Started process (PID=8785) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:33:23.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:33:23.035+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:33:23.034+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:33:23.050+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:33:23.073+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:33:23.072+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:33:23.087+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:33:23.087+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:33:23.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T14:33:53.151+0000] {processor.py:186} INFO - Started process (PID=8810) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:33:53.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:33:53.153+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:33:53.153+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:33:53.167+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:33:53.186+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:33:53.186+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:33:53.199+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:33:53.199+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:33:53.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T14:34:23.299+0000] {processor.py:186} INFO - Started process (PID=8835) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:34:23.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:34:23.301+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:34:23.301+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:34:23.318+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:34:23.340+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:34:23.340+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:34:23.355+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:34:23.354+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:34:23.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T14:34:54.398+0000] {processor.py:186} INFO - Started process (PID=8860) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:34:54.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:34:54.400+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:34:54.400+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:34:54.415+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:34:54.435+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:34:54.435+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:34:54.448+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:34:54.448+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:34:54.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:35:25.301+0000] {processor.py:186} INFO - Started process (PID=8885) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:35:25.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:35:25.304+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:35:25.303+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:35:25.319+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:35:25.339+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:35:25.339+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:35:25.352+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:35:25.352+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:35:25.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:35:56.145+0000] {processor.py:186} INFO - Started process (PID=8910) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:35:56.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:35:56.147+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:35:56.147+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:35:56.161+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:35:56.180+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:35:56.180+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:35:56.193+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:35:56.193+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:35:56.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T14:36:27.184+0000] {processor.py:186} INFO - Started process (PID=8935) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:36:27.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:36:27.187+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:36:27.187+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:36:27.201+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:36:27.222+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:36:27.222+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:36:27.236+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:36:27.235+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:36:27.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:36:57.313+0000] {processor.py:186} INFO - Started process (PID=8960) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:36:57.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:36:57.316+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:36:57.315+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:36:57.330+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:36:57.350+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:36:57.350+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:36:57.363+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:36:57.363+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:36:57.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:37:28.347+0000] {processor.py:186} INFO - Started process (PID=8985) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:37:28.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:37:28.350+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:37:28.349+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:37:28.366+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:37:28.389+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:37:28.389+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:37:28.402+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:37:28.402+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:37:28.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T14:37:58.480+0000] {processor.py:186} INFO - Started process (PID=9010) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:37:58.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:37:58.482+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:37:58.482+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:37:58.498+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:37:58.519+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:37:58.519+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:37:58.534+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:37:58.534+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:37:58.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
[2024-10-25T14:38:28.747+0000] {processor.py:186} INFO - Started process (PID=9035) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:38:28.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:38:28.749+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:38:28.748+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:38:28.763+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:38:28.783+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:38:28.783+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:38:28.797+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:38:28.796+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:38:28.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:38:58.968+0000] {processor.py:186} INFO - Started process (PID=9060) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:38:58.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:38:58.971+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:38:58.971+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:38:58.987+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:38:59.008+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:38:59.008+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:38:59.023+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:38:59.023+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:38:59.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T14:39:29.112+0000] {processor.py:186} INFO - Started process (PID=9085) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:39:29.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:39:29.114+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:39:29.114+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:39:29.128+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:39:29.149+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:39:29.149+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:39:29.163+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:39:29.162+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:39:29.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:39:59.357+0000] {processor.py:186} INFO - Started process (PID=9110) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:39:59.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:39:59.360+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:39:59.359+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:39:59.376+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:39:59.396+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:39:59.395+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:39:59.409+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:39:59.409+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:39:59.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:40:29.539+0000] {processor.py:186} INFO - Started process (PID=9135) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:40:29.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:40:29.541+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:40:29.541+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:40:29.554+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:40:29.574+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:40:29.574+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:40:29.587+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:40:29.587+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:40:29.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:40:59.655+0000] {processor.py:186} INFO - Started process (PID=9160) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:40:59.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:40:59.657+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:40:59.657+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:40:59.672+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:40:59.691+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:40:59.691+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:40:59.705+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:40:59.705+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:40:59.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:41:29.838+0000] {processor.py:186} INFO - Started process (PID=9185) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:41:29.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:41:29.840+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:41:29.840+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:41:29.856+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:41:29.877+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:41:29.877+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:41:29.890+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:41:29.890+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:41:29.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:42:00.331+0000] {processor.py:186} INFO - Started process (PID=9210) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:42:00.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:42:00.333+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:42:00.333+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:42:00.348+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:42:00.368+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:42:00.368+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:42:00.382+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:42:00.381+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:42:00.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:42:30.499+0000] {processor.py:186} INFO - Started process (PID=9235) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:42:30.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:42:30.501+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:42:30.501+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:42:30.514+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:42:30.534+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:42:30.534+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:42:30.547+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:42:30.547+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:42:30.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T14:43:00.636+0000] {processor.py:186} INFO - Started process (PID=9260) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:43:00.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:43:00.638+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:43:00.638+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:43:00.653+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:43:00.672+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:43:00.672+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:43:00.685+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:43:00.685+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:43:00.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:43:30.892+0000] {processor.py:186} INFO - Started process (PID=9285) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:43:30.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:43:30.895+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:43:30.894+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:43:30.910+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:43:30.929+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:43:30.929+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:43:30.942+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:43:30.942+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:43:30.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:44:01.024+0000] {processor.py:186} INFO - Started process (PID=9310) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:44:01.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:44:01.026+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:44:01.025+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:44:01.038+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:44:01.058+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:44:01.058+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:44:01.072+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:44:01.071+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:44:01.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T14:44:31.193+0000] {processor.py:186} INFO - Started process (PID=9335) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:44:31.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:44:31.195+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:44:31.195+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:44:31.208+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:44:31.226+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:44:31.226+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:44:31.239+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:44:31.239+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:44:31.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.070 seconds
[2024-10-25T14:45:01.541+0000] {processor.py:186} INFO - Started process (PID=9361) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:45:01.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:45:01.544+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:45:01.544+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:45:01.559+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:45:01.580+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:45:01.580+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:45:01.595+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:45:01.595+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:45:01.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T14:45:31.727+0000] {processor.py:186} INFO - Started process (PID=9386) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:45:31.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:45:31.729+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:45:31.728+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:45:31.744+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:45:31.763+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:45:31.763+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:45:31.777+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:45:31.777+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:45:31.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:46:02.301+0000] {processor.py:186} INFO - Started process (PID=9411) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:46:02.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:46:02.303+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:46:02.303+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:46:02.319+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:46:02.340+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:46:02.340+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:46:02.353+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:46:02.353+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:46:02.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:46:33.107+0000] {processor.py:186} INFO - Started process (PID=9436) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:46:33.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:46:33.109+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:46:33.109+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:46:33.129+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:46:33.150+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:46:33.149+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:46:33.163+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:46:33.163+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:46:33.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
[2024-10-25T14:47:04.004+0000] {processor.py:186} INFO - Started process (PID=9461) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:47:04.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:47:04.005+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:47:04.005+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:47:04.020+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:47:04.039+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:47:04.038+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:47:04.052+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:47:04.052+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:47:04.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:47:34.831+0000] {processor.py:186} INFO - Started process (PID=9486) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:47:34.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:47:34.833+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:47:34.833+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:47:34.847+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:47:34.870+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:47:34.870+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:47:34.883+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:47:34.883+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:47:34.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:48:05.772+0000] {processor.py:186} INFO - Started process (PID=9511) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:48:05.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:48:05.775+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:48:05.774+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:48:05.790+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:48:05.811+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:48:05.811+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:48:05.824+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:48:05.824+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:48:05.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T14:48:36.279+0000] {processor.py:186} INFO - Started process (PID=9536) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:48:36.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:48:36.281+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:48:36.281+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:48:36.296+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:48:36.316+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:48:36.316+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:48:36.330+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:48:36.330+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:48:36.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T14:49:07.107+0000] {processor.py:186} INFO - Started process (PID=9561) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:49:07.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:49:07.112+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:49:07.112+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:49:07.125+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:49:07.144+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:49:07.143+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:49:07.157+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:49:07.157+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:49:07.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:49:38.002+0000] {processor.py:186} INFO - Started process (PID=9586) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:49:38.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:49:38.004+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:49:38.003+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:49:38.019+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:49:38.039+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:49:38.038+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:49:38.052+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:49:38.051+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:49:38.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:50:08.994+0000] {processor.py:186} INFO - Started process (PID=9611) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:50:08.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:50:08.997+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:50:08.997+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:50:09.011+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:50:09.031+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:50:09.030+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:50:09.043+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:50:09.043+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:50:09.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:50:39.724+0000] {processor.py:186} INFO - Started process (PID=9636) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:50:39.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:50:39.726+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:50:39.726+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:50:39.741+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:50:39.761+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:50:39.761+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:50:39.774+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:50:39.774+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:50:39.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:51:10.484+0000] {processor.py:186} INFO - Started process (PID=9661) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:51:10.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:51:10.487+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:51:10.487+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:51:10.501+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:51:10.521+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:51:10.521+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:51:10.535+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:51:10.535+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:51:10.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:51:41.262+0000] {processor.py:186} INFO - Started process (PID=9686) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:51:41.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:51:41.265+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:51:41.265+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:51:41.283+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:51:41.308+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:51:41.308+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:51:41.325+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:51:41.324+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:51:41.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.107 seconds
[2024-10-25T14:52:11.584+0000] {processor.py:186} INFO - Started process (PID=9711) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:52:11.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:52:11.587+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:52:11.586+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:52:11.600+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:52:11.620+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:52:11.619+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:52:11.633+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:52:11.633+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:52:11.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:52:42.540+0000] {processor.py:186} INFO - Started process (PID=9736) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:52:42.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:52:42.542+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:52:42.542+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:52:42.562+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:52:42.582+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:52:42.582+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:52:42.595+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:52:42.595+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:52:42.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T14:53:13.365+0000] {processor.py:186} INFO - Started process (PID=9761) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:53:13.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:53:13.367+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:53:13.367+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:53:13.384+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:53:13.404+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:53:13.404+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:53:13.417+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:53:13.417+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:53:13.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T14:53:44.103+0000] {processor.py:186} INFO - Started process (PID=9786) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:53:44.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:53:44.105+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:53:44.105+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:53:44.121+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:53:44.140+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:53:44.140+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:53:44.153+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:53:44.153+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:53:44.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:54:15.045+0000] {processor.py:186} INFO - Started process (PID=9811) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:54:15.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:54:15.048+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:54:15.047+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:54:15.063+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:54:15.082+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:54:15.081+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:54:15.094+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:54:15.094+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:54:15.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:54:45.259+0000] {processor.py:186} INFO - Started process (PID=9836) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:54:45.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:54:45.261+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:54:45.261+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:54:45.276+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:54:45.295+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:54:45.295+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:54:45.308+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:54:45.308+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:54:45.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:55:15.438+0000] {processor.py:186} INFO - Started process (PID=9861) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:55:15.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:55:15.440+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:55:15.440+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:55:15.456+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:55:15.475+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:55:15.475+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:55:15.488+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:55:15.488+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:55:15.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T14:55:45.789+0000] {processor.py:186} INFO - Started process (PID=9886) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:55:45.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:55:45.791+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:55:45.791+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:55:45.806+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:55:45.826+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:55:45.826+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:55:45.840+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:55:45.840+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:55:45.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:56:16.165+0000] {processor.py:186} INFO - Started process (PID=9911) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:56:16.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:56:16.168+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:56:16.167+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:56:16.183+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:56:16.203+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:56:16.203+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:56:16.216+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:56:16.216+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:56:16.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.156 seconds
[2024-10-25T14:56:46.492+0000] {processor.py:186} INFO - Started process (PID=9936) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:56:46.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:56:46.494+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:56:46.493+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:56:46.510+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:56:46.530+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:56:46.530+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:56:46.544+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:56:46.544+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:56:46.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T14:57:16.878+0000] {processor.py:186} INFO - Started process (PID=9961) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:57:16.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:57:16.880+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:57:16.880+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:57:16.895+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:57:16.915+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:57:16.915+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:57:16.928+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:57:16.928+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:57:17.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.162 seconds
[2024-10-25T14:57:47.862+0000] {processor.py:186} INFO - Started process (PID=9986) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:57:47.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:57:47.864+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:57:47.863+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:57:47.879+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:57:47.899+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:57:47.899+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:57:47.912+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:57:47.912+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:57:47.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:58:18.743+0000] {processor.py:186} INFO - Started process (PID=10011) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:58:18.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:58:18.745+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:58:18.745+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:58:18.762+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:58:18.782+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:58:18.781+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:58:18.794+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:58:18.794+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:58:18.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T14:58:48.971+0000] {processor.py:186} INFO - Started process (PID=10036) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:58:48.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:58:48.973+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:58:48.972+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:58:48.987+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:58:49.007+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:58:49.007+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:58:49.021+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:58:49.021+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:58:49.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T14:59:19.089+0000] {processor.py:186} INFO - Started process (PID=10061) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:59:19.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:59:19.091+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:59:19.091+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:59:19.106+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:59:19.125+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:59:19.125+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:59:19.138+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:59:19.138+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:59:19.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T14:59:49.369+0000] {processor.py:186} INFO - Started process (PID=10086) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:59:49.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T14:59:49.372+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:59:49.371+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:59:49.387+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T14:59:49.407+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:59:49.406+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T14:59:49.420+0000] {logging_mixin.py:190} INFO - [2024-10-25T14:59:49.420+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T14:59:49.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.133 seconds
[2024-10-25T15:00:19.596+0000] {processor.py:186} INFO - Started process (PID=10111) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:00:19.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:00:19.598+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:00:19.597+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:00:19.611+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:00:19.630+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:00:19.630+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:00:19.644+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:00:19.643+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:00:19.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T15:00:49.736+0000] {processor.py:186} INFO - Started process (PID=10136) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:00:49.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:00:49.739+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:00:49.738+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:00:49.752+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:00:49.772+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:00:49.771+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:00:49.785+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:00:49.785+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:00:49.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T15:01:20.057+0000] {processor.py:186} INFO - Started process (PID=10161) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:01:20.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:01:20.059+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:01:20.059+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:01:20.074+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:01:20.094+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:01:20.094+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:01:20.107+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:01:20.107+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:01:20.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T15:01:51.035+0000] {processor.py:186} INFO - Started process (PID=10186) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:01:51.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:01:51.038+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:01:51.037+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:01:51.055+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:01:51.076+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:01:51.076+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:01:51.089+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:01:51.089+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:01:51.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T15:02:21.407+0000] {processor.py:186} INFO - Started process (PID=10211) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:02:21.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:02:21.410+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:02:21.409+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:02:21.425+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:02:21.444+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:02:21.444+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:02:21.457+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:02:21.457+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:02:21.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T15:02:52.355+0000] {processor.py:186} INFO - Started process (PID=10236) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:02:52.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:02:52.357+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:02:52.357+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:02:52.372+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:02:52.395+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:02:52.395+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:02:52.412+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:02:52.412+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:02:52.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.086 seconds
[2024-10-25T15:03:23.401+0000] {processor.py:186} INFO - Started process (PID=10261) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:03:23.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:03:23.403+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:03:23.403+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:03:23.416+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:03:23.436+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:03:23.435+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:03:23.449+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:03:23.449+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:03:23.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.071 seconds
[2024-10-25T15:03:54.516+0000] {processor.py:186} INFO - Started process (PID=10286) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:03:54.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:03:54.518+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:03:54.518+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:03:54.533+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:03:54.552+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:03:54.552+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:03:54.566+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:03:54.566+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:03:54.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T15:04:25.491+0000] {processor.py:186} INFO - Started process (PID=10317) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:04:25.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:04:25.493+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:04:25.493+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:04:25.509+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:04:25.534+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:04:25.533+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:04:25.557+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:04:25.556+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:04:25.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.096 seconds
[2024-10-25T15:04:56.604+0000] {processor.py:186} INFO - Started process (PID=10342) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:04:56.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:04:56.607+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:04:56.606+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:04:56.622+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:04:56.642+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:04:56.642+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:04:56.656+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:04:56.656+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:04:56.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.095 seconds
[2024-10-25T15:05:27.661+0000] {processor.py:186} INFO - Started process (PID=10367) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:05:27.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:05:27.663+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:05:27.663+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:05:27.678+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:05:27.697+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:05:27.697+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:05:27.710+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:05:27.710+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:05:27.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T15:05:57.805+0000] {processor.py:186} INFO - Started process (PID=10392) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:05:57.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:05:57.807+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:05:57.806+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:05:57.821+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:05:57.841+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:05:57.840+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:05:57.854+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:05:57.854+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:05:57.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T15:06:28.050+0000] {processor.py:186} INFO - Started process (PID=10417) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:06:28.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:06:28.053+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:06:28.052+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:06:28.067+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:06:28.087+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:06:28.087+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:06:28.100+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:06:28.100+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:06:28.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T15:06:58.421+0000] {processor.py:186} INFO - Started process (PID=10442) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:06:58.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:06:58.423+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:06:58.423+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:06:58.438+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:06:58.459+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:06:58.459+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:06:58.473+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:06:58.473+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:06:58.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T15:07:28.596+0000] {processor.py:186} INFO - Started process (PID=10467) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:07:28.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:07:28.598+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:07:28.598+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:07:28.613+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:07:28.632+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:07:28.632+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:07:28.645+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:07:28.645+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:07:28.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T15:07:59.511+0000] {processor.py:186} INFO - Started process (PID=10492) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:07:59.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:07:59.513+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:07:59.513+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:07:59.530+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:07:59.552+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:07:59.552+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:07:59.565+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:07:59.565+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:07:59.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T15:08:30.533+0000] {processor.py:186} INFO - Started process (PID=10516) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:08:30.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:08:30.535+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:08:30.534+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:08:30.549+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:08:30.570+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:08:30.569+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:08:30.583+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:08:30.583+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:08:30.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T15:09:01.342+0000] {processor.py:186} INFO - Started process (PID=10541) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:09:01.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:09:01.344+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:09:01.343+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:09:01.358+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:09:01.379+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:09:01.379+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:09:01.393+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:09:01.393+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:09:01.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T15:09:32.221+0000] {processor.py:186} INFO - Started process (PID=10566) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:09:32.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:09:32.223+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:09:32.223+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:09:32.241+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:09:32.261+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:09:32.261+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:09:32.275+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:09:32.274+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:09:32.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T15:10:02.977+0000] {processor.py:186} INFO - Started process (PID=10591) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:10:02.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:10:02.981+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:10:02.981+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:10:02.995+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:10:03.015+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:10:03.015+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:10:03.029+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:10:03.028+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:10:03.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T15:10:33.962+0000] {processor.py:186} INFO - Started process (PID=10616) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:10:33.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:10:33.964+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:10:33.964+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:10:33.981+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:10:34.001+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:10:34.000+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:10:34.014+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:10:34.013+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:10:34.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T15:11:04.647+0000] {processor.py:186} INFO - Started process (PID=10641) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:11:04.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:11:04.649+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:11:04.649+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:11:04.663+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:11:04.683+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:11:04.683+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:11:04.703+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:11:04.702+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:11:04.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T15:11:35.287+0000] {processor.py:186} INFO - Started process (PID=10666) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:11:35.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:11:35.289+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:11:35.289+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:11:35.303+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:11:35.323+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:11:35.323+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:11:35.337+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:11:35.337+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:11:35.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T15:12:05.414+0000] {processor.py:186} INFO - Started process (PID=10691) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:12:05.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:12:05.416+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:12:05.416+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:12:05.430+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:12:05.449+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:12:05.449+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:12:05.462+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:12:05.462+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:12:05.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T15:12:36.476+0000] {processor.py:186} INFO - Started process (PID=10716) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:12:36.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:12:36.478+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:12:36.478+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:12:36.493+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:12:36.512+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:12:36.512+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:12:36.526+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:12:36.526+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:12:36.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T15:13:06.768+0000] {processor.py:186} INFO - Started process (PID=10741) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:13:06.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:13:06.770+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:13:06.770+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:13:06.783+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:13:06.803+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:13:06.803+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:13:06.816+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:13:06.816+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:13:06.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T15:13:37.854+0000] {processor.py:186} INFO - Started process (PID=10766) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:13:37.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:13:37.856+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:13:37.856+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:13:37.871+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:13:37.891+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:13:37.891+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:13:37.904+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:13:37.904+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:13:37.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T15:14:08.058+0000] {processor.py:186} INFO - Started process (PID=10791) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:14:08.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:14:08.060+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:14:08.059+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:14:08.073+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:14:08.093+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:14:08.092+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:14:08.106+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:14:08.106+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:14:08.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T15:14:38.986+0000] {processor.py:186} INFO - Started process (PID=10816) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:14:38.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:14:38.988+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:14:38.988+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:14:39.002+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:14:39.021+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:14:39.021+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:14:39.035+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:14:39.035+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:14:39.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T15:15:09.804+0000] {processor.py:186} INFO - Started process (PID=10841) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:15:09.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:15:09.806+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:15:09.806+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:15:09.820+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:15:09.842+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:15:09.841+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:15:09.856+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:15:09.856+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:15:09.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T15:15:40.733+0000] {processor.py:186} INFO - Started process (PID=10866) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:15:40.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:15:40.736+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:15:40.735+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:15:40.753+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:15:40.774+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:15:40.774+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:15:40.787+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:15:40.787+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:15:40.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T15:16:11.773+0000] {processor.py:186} INFO - Started process (PID=10891) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:16:11.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:16:11.775+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:16:11.775+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:16:11.790+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:16:11.812+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:16:11.812+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:16:11.825+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:16:11.825+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:16:11.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T15:16:42.164+0000] {processor.py:186} INFO - Started process (PID=10916) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:16:42.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:16:42.166+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:16:42.166+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:16:42.181+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:16:42.200+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:16:42.200+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:16:42.213+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:16:42.213+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:16:42.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T15:17:12.318+0000] {processor.py:186} INFO - Started process (PID=10941) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:17:12.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:17:12.320+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:17:12.319+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:17:12.337+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:17:12.358+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:17:12.358+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:17:12.372+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:17:12.371+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:17:12.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T15:17:43.356+0000] {processor.py:186} INFO - Started process (PID=10966) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:17:43.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:17:43.358+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:17:43.358+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:17:43.372+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:17:43.392+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:17:43.392+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:17:43.404+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:17:43.404+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:17:43.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T15:18:14.177+0000] {processor.py:186} INFO - Started process (PID=10991) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:18:14.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:18:14.181+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:18:14.180+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:18:14.197+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:18:14.218+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:18:14.218+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:18:14.233+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:18:14.233+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:18:14.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.083 seconds
[2024-10-25T15:18:44.488+0000] {processor.py:186} INFO - Started process (PID=11016) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:18:44.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:18:44.490+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:18:44.490+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:18:44.504+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:18:44.524+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:18:44.524+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:18:44.538+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:18:44.538+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:18:44.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T15:19:14.638+0000] {processor.py:186} INFO - Started process (PID=11041) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:19:14.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:19:14.641+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:19:14.640+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:19:14.656+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:19:14.676+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:19:14.676+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:19:14.690+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:19:14.690+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:19:14.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T15:19:44.868+0000] {processor.py:186} INFO - Started process (PID=11066) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:19:44.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:19:44.871+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:19:44.870+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:19:44.885+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:19:44.904+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:19:44.904+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:19:44.917+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:19:44.917+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:19:44.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T15:20:15.061+0000] {processor.py:186} INFO - Started process (PID=11091) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:20:15.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:20:15.063+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:20:15.063+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:20:15.077+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:20:15.097+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:20:15.096+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:20:15.110+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:20:15.110+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:20:15.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T15:20:45.220+0000] {processor.py:186} INFO - Started process (PID=11116) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:20:45.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:20:45.222+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:20:45.222+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:20:45.236+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:20:45.257+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:20:45.257+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:20:45.271+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:20:45.271+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:20:45.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T15:21:15.463+0000] {processor.py:186} INFO - Started process (PID=11141) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:21:15.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:21:15.465+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:21:15.465+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:21:15.479+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:21:15.499+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:21:15.498+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:21:15.512+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:21:15.512+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:21:15.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.073 seconds
[2024-10-25T15:21:45.660+0000] {processor.py:186} INFO - Started process (PID=11166) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:21:45.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:21:45.663+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:21:45.663+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:21:45.678+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:21:45.697+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:21:45.697+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:21:45.710+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:21:45.710+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:21:45.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T15:22:16.754+0000] {processor.py:186} INFO - Started process (PID=11191) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:22:16.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:22:16.756+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:22:16.756+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:22:16.772+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:22:16.792+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:22:16.792+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:22:16.806+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:22:16.806+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:22:16.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T15:22:47.695+0000] {processor.py:186} INFO - Started process (PID=11216) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:22:47.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:22:47.698+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:22:47.698+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:22:47.711+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:22:47.733+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:22:47.733+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:22:47.748+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:22:47.748+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:22:47.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.081 seconds
[2024-10-25T15:23:18.523+0000] {processor.py:186} INFO - Started process (PID=11241) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:23:18.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:23:18.525+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:23:18.525+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:23:18.539+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:23:18.559+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:23:18.559+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:23:18.573+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:23:18.573+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:23:18.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T15:23:49.352+0000] {processor.py:186} INFO - Started process (PID=11266) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:23:49.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:23:49.356+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:23:49.355+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:23:49.373+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:23:49.393+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:23:49.393+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:23:49.406+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:23:49.406+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:23:49.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T15:24:19.664+0000] {processor.py:186} INFO - Started process (PID=11291) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:24:19.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:24:19.667+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:24:19.666+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:24:19.682+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:24:19.701+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:24:19.701+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:24:19.715+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:24:19.715+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:24:19.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T15:24:49.947+0000] {processor.py:186} INFO - Started process (PID=11317) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:24:49.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:24:49.950+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:24:49.950+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:24:49.963+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:24:49.982+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:24:49.982+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:24:49.995+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:24:49.995+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:24:50.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.072 seconds
[2024-10-25T15:25:21.106+0000] {processor.py:186} INFO - Started process (PID=11342) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:25:21.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:25:21.109+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:25:21.109+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:25:21.124+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:25:21.144+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:25:21.144+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:25:21.158+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:25:21.158+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:25:21.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T15:25:51.372+0000] {processor.py:186} INFO - Started process (PID=11367) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:25:51.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:25:51.374+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:25:51.374+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:25:51.389+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:25:51.408+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:25:51.408+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:25:51.421+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:25:51.421+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:25:51.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T15:26:21.812+0000] {processor.py:186} INFO - Started process (PID=11392) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:26:21.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:26:21.815+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:26:21.814+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:26:21.829+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:26:21.850+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:26:21.850+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:26:21.864+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:26:21.863+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:26:21.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T15:26:52.464+0000] {processor.py:186} INFO - Started process (PID=11417) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:26:52.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:26:52.466+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:26:52.466+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:26:52.481+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:26:52.501+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:26:52.501+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:26:52.517+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:26:52.516+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:26:52.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
[2024-10-25T15:27:22.604+0000] {processor.py:186} INFO - Started process (PID=11442) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:27:22.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:27:22.607+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:27:22.607+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:27:22.623+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:27:22.643+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:27:22.642+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:27:22.657+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:27:22.657+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:27:22.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T15:27:53.418+0000] {processor.py:186} INFO - Started process (PID=11466) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:27:53.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:27:53.421+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:27:53.421+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:27:53.435+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:27:53.459+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:27:53.459+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:27:53.472+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:27:53.472+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:27:53.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.079 seconds
[2024-10-25T15:28:24.162+0000] {processor.py:186} INFO - Started process (PID=11491) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:28:24.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:28:24.164+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:28:24.164+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:28:24.178+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:28:24.197+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:28:24.197+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:28:24.211+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:28:24.210+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:28:24.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T15:28:54.278+0000] {processor.py:186} INFO - Started process (PID=11517) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:28:54.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:28:54.281+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:28:54.280+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:28:54.296+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:28:54.318+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:28:54.318+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:28:54.332+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:28:54.331+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:28:54.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T15:29:24.416+0000] {processor.py:186} INFO - Started process (PID=11541) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:29:24.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:29:24.418+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:29:24.417+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:29:24.432+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:29:24.451+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:29:24.451+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:29:24.466+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:29:24.465+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:29:24.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T15:29:54.753+0000] {processor.py:186} INFO - Started process (PID=11566) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:29:54.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:29:54.755+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:29:54.754+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:29:54.771+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:29:54.790+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:29:54.790+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:29:54.804+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:29:54.804+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:29:54.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.076 seconds
[2024-10-25T15:30:25.807+0000] {processor.py:186} INFO - Started process (PID=11591) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:30:25.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:30:25.809+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:30:25.808+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:30:25.823+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:30:25.844+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:30:25.844+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:30:25.858+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:30:25.858+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:30:25.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T15:30:56.715+0000] {processor.py:186} INFO - Started process (PID=11616) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:30:56.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:30:56.717+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:30:56.716+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:30:56.729+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:30:56.750+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:30:56.750+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:30:56.768+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:30:56.767+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:30:56.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.080 seconds
[2024-10-25T15:31:27.751+0000] {processor.py:186} INFO - Started process (PID=11648) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:31:27.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:31:27.754+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:31:27.753+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:31:27.770+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:31:27.789+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:31:27.789+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:31:27.803+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:31:27.803+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:31:27.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.078 seconds
[2024-10-25T15:31:58.678+0000] {processor.py:186} INFO - Started process (PID=11673) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:31:58.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:31:58.680+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:31:58.680+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:31:58.693+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:31:58.713+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:31:58.712+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:31:58.726+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:31:58.726+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:31:58.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T15:32:28.979+0000] {processor.py:186} INFO - Started process (PID=11698) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:32:28.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:32:28.981+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:32:28.981+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:32:28.996+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:32:29.015+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:32:29.015+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:32:29.030+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:32:29.030+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:32:29.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T15:32:59.751+0000] {processor.py:186} INFO - Started process (PID=11723) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:32:59.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:32:59.753+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:32:59.752+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:32:59.766+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:32:59.786+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:32:59.786+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:32:59.800+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:32:59.799+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:32:59.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.075 seconds
[2024-10-25T15:33:30.753+0000] {processor.py:186} INFO - Started process (PID=11748) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:33:30.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:33:30.755+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:33:30.755+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:33:30.769+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:33:30.789+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:33:30.788+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:33:30.802+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:33:30.802+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:33:30.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.074 seconds
[2024-10-25T15:34:01.069+0000] {processor.py:186} INFO - Started process (PID=11773) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:34:01.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:34:01.071+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:34:01.071+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:34:01.086+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:34:01.105+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:34:01.105+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:34:01.118+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:34:01.118+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:34:01.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.077 seconds
[2024-10-25T15:34:32.146+0000] {processor.py:186} INFO - Started process (PID=11798) to work on /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:34:32.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/LoadWebScraping.py for tasks to queue
[2024-10-25T15:34:32.148+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:34:32.148+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:34:32.161+0000] {processor.py:925} INFO - DAG(s) 'LoadWebScraping' retrieved from /opt/airflow/dags/LoadWebScraping.py
[2024-10-25T15:34:32.183+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:34:32.183+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2024-10-25T15:34:32.200+0000] {logging_mixin.py:190} INFO - [2024-10-25T15:34:32.199+0000] {dag.py:4156} INFO - Setting next_dagrun for LoadWebScraping to None, run_after=None
[2024-10-25T15:34:32.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/LoadWebScraping.py took 0.082 seconds
