[2024-09-04T00:00:00.843+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: SitesWebScraping.WebScrapint scheduled__2024-09-03T00:00:00+00:00 [queued]>
[2024-09-04T00:00:00.853+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: SitesWebScraping.WebScrapint scheduled__2024-09-03T00:00:00+00:00 [queued]>
[2024-09-04T00:00:00.854+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 1
[2024-09-04T00:00:00.869+0000] {taskinstance.py:2192} INFO - Executing <Task(WebScraping_K): WebScrapint> on 2024-09-03 00:00:00+00:00
[2024-09-04T00:00:00.872+0000] {standard_task_runner.py:60} INFO - Started process 940 to run task
[2024-09-04T00:00:00.875+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'SitesWebScraping', 'WebScrapint', 'scheduled__2024-09-03T00:00:00+00:00', '--job-id', '368', '--raw', '--subdir', 'DAGS_FOLDER/DagWebScraping.py', '--cfg-path', '/tmp/tmp1c2ujj76']
[2024-09-04T00:00:00.880+0000] {standard_task_runner.py:88} INFO - Job 368: Subtask WebScrapint
[2024-09-04T00:00:00.925+0000] {task_command.py:423} INFO - Running <TaskInstance: SitesWebScraping.WebScrapint scheduled__2024-09-03T00:00:00+00:00 [running]> on host 6d24e5a510c9
[2024-09-04T00:00:00.995+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='SitesWebScraping' AIRFLOW_CTX_TASK_ID='WebScrapint' AIRFLOW_CTX_EXECUTION_DATE='2024-09-03T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-09-03T00:00:00+00:00'
[2024-09-04T00:00:00.996+0000] {taskinstance.py:2699} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1182, in execute
    raise NotImplementedError()
NotImplementedError
[2024-09-04T00:00:01.005+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=SitesWebScraping, task_id=WebScrapint, execution_date=20240903T000000, start_date=20240904T000000, end_date=20240904T000001
[2024-09-04T00:00:01.018+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 368 for task WebScrapint (; 940)
[2024-09-04T00:00:01.048+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-09-04T00:00:01.066+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-09-04T19:01:01.293+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: SitesWebScraping.WebScrapint scheduled__2024-09-03T00:00:00+00:00 [queued]>
[2024-09-04T19:01:01.304+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: SitesWebScraping.WebScrapint scheduled__2024-09-03T00:00:00+00:00 [queued]>
[2024-09-04T19:01:01.304+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 1
[2024-09-04T19:01:01.324+0000] {taskinstance.py:2192} INFO - Executing <Task(WebScraping_K): WebScrapint> on 2024-09-03 00:00:00+00:00
[2024-09-04T19:01:01.329+0000] {standard_task_runner.py:60} INFO - Started process 144 to run task
[2024-09-04T19:01:01.332+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'SitesWebScraping', 'WebScrapint', 'scheduled__2024-09-03T00:00:00+00:00', '--job-id', '379', '--raw', '--subdir', 'DAGS_FOLDER/DagWebScraping.py', '--cfg-path', '/tmp/tmp_sef4_o0']
[2024-09-04T19:01:01.337+0000] {standard_task_runner.py:88} INFO - Job 379: Subtask WebScrapint
[2024-09-04T19:01:01.416+0000] {task_command.py:423} INFO - Running <TaskInstance: SitesWebScraping.WebScrapint scheduled__2024-09-03T00:00:00+00:00 [running]> on host c8ccf8b29ab2
[2024-09-04T19:01:01.504+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='SitesWebScraping' AIRFLOW_CTX_TASK_ID='WebScrapint' AIRFLOW_CTX_EXECUTION_DATE='2024-09-03T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-09-03T00:00:00+00:00'
[2024-09-04T19:01:01.505+0000] {logger.py:11} INFO - ====== WebDriver manager ======
[2024-09-04T19:01:01.611+0000] {logger.py:11} INFO - Get LATEST chromedriver version for google-chrome
[2024-09-04T19:01:01.792+0000] {logger.py:11} INFO - About to download new driver from https://chromedriver.storage.googleapis.com/114.0.5735.90/chromedriver_linux64.zip
[2024-09-04T19:01:01.972+0000] {logger.py:11} INFO - Driver downloading response is 200
[2024-09-04T19:01:05.221+0000] {logger.py:11} INFO - Get LATEST chromedriver version for google-chrome
[2024-09-04T19:01:05.524+0000] {logger.py:11} INFO - Get LATEST chromedriver version for google-chrome
[2024-09-04T19:01:05.718+0000] {logger.py:11} INFO - Driver has been saved in cache [/home/***/.wdm/drivers/chromedriver/linux64/114.0.5735.90]
[2024-09-04T19:01:05.739+0000] {taskinstance.py:2699} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/usr/local/airflow/custom_pasta/operators/OperatorWebScraping.py", line 82, in execute
    result=self.ExtractDates()
  File "/usr/local/airflow/custom_pasta/operators/OperatorWebScraping.py", line 68, in ExtractDates
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/home/airflow/.local/lib/python3.8/site-packages/selenium/webdriver/chromium/webdriver.py", line 55, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.8/site-packages/selenium/webdriver/common/service.py", line 102, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.8/site-packages/selenium/webdriver/common/service.py", line 115, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /home/airflow/.wdm/drivers/chromedriver/linux64/114.0.5735.90/chromedriver unexpectedly exited. Status code was: 127

[2024-09-04T19:01:05.753+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=SitesWebScraping, task_id=WebScrapint, execution_date=20240903T000000, start_date=20240904T190101, end_date=20240904T190105
[2024-09-04T19:01:05.769+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 379 for task WebScrapint (Message: Service /home/airflow/.wdm/drivers/chromedriver/linux64/114.0.5735.90/chromedriver unexpectedly exited. Status code was: 127
; 144)
[2024-09-04T19:01:05.779+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-09-04T19:01:05.794+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
