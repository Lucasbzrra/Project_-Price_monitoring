[2024-08-24T17:33:53.618+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ApiExec.ApiExec_dataScience scheduled__2024-08-22T00:00:00+00:00 [queued]>
[2024-08-24T17:33:53.625+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ApiExec.ApiExec_dataScience scheduled__2024-08-22T00:00:00+00:00 [queued]>
[2024-08-24T17:33:53.626+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 1
[2024-08-24T17:33:53.642+0000] {taskinstance.py:2192} INFO - Executing <Task(ApiExternaOperator): ApiExec_dataScience> on 2024-08-22 00:00:00+00:00
[2024-08-24T17:33:53.650+0000] {standard_task_runner.py:60} INFO - Started process 87 to run task
[2024-08-24T17:33:53.654+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ApiExec', 'ApiExec_dataScience', 'scheduled__2024-08-22T00:00:00+00:00', '--job-id', '225', '--raw', '--subdir', 'DAGS_FOLDER/ApiExecDag.py', '--cfg-path', '/tmp/tmprlo3uogp']
[2024-08-24T17:33:53.657+0000] {standard_task_runner.py:88} INFO - Job 225: Subtask ApiExec_dataScience
[2024-08-24T17:33:53.707+0000] {task_command.py:423} INFO - Running <TaskInstance: ApiExec.ApiExec_dataScience scheduled__2024-08-22T00:00:00+00:00 [running]> on host 094085adac4a
[2024-08-24T17:33:53.759+0000] {abstractoperator.py:708} ERROR - Exception rendering Jinja template for task 'ApiExec_dataScience', field 'start_time'. Template: "{{data_interval_start.stftime('%Y-%m-%dT%H:%M:%S.00Z')}}"
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/abstractoperator.py", line 700, in _do_render_template_fields
    rendered_content = self.render_template(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/template/templater.py", line 174, in render_template
    return self._render(template, context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/abstractoperator.py", line 654, in _render
    return super()._render(template, context, dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/template/templater.py", line 131, in _render
    return render_template_to_string(template, context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/helpers.py", line 289, in render_template_to_string
    return render_template(template, cast(MutableMapping[str, Any], context), native=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/helpers.py", line 284, in render_template
    return "".join(nodes)
  File "<template>", line 12, in root
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/sandbox.py", line 391, in call
    if not __self.is_safe_callable(__obj):
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/sandbox.py", line 275, in is_safe_callable
    getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/runtime.py", line 859, in __getattr__
    return self._fail_with_undefined_error()
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/runtime.py", line 852, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: 'pendulum.datetime.DateTime object' has no attribute 'stftime'
[2024-08-24T17:33:53.762+0000] {taskinstance.py:2699} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2335, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2466, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2878, in render_templates
    original_task.render_template_fields(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1248, in render_template_fields
    self._do_render_template_fields(self, self.template_fields, context, jinja_env, set())
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/abstractoperator.py", line 700, in _do_render_template_fields
    rendered_content = self.render_template(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/template/templater.py", line 174, in render_template
    return self._render(template, context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/abstractoperator.py", line 654, in _render
    return super()._render(template, context, dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/template/templater.py", line 131, in _render
    return render_template_to_string(template, context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/helpers.py", line 289, in render_template_to_string
    return render_template(template, cast(MutableMapping[str, Any], context), native=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/helpers.py", line 284, in render_template
    return "".join(nodes)
  File "<template>", line 12, in root
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/sandbox.py", line 391, in call
    if not __self.is_safe_callable(__obj):
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/sandbox.py", line 275, in is_safe_callable
    getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/runtime.py", line 859, in __getattr__
    return self._fail_with_undefined_error()
  File "/home/airflow/.local/lib/python3.8/site-packages/jinja2/runtime.py", line 852, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: 'pendulum.datetime.DateTime object' has no attribute 'stftime'
[2024-08-24T17:33:53.774+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=ApiExec, task_id=ApiExec_dataScience, execution_date=20240822T000000, start_date=20240824T173353, end_date=20240824T173353
[2024-08-24T17:33:53.789+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 225 for task ApiExec_dataScience ('pendulum.datetime.DateTime object' has no attribute 'stftime'; 87)
[2024-08-24T17:33:53.827+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-08-24T17:33:53.842+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-08-24T17:39:28.279+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ApiExec.ApiExec_dataScience scheduled__2024-08-22T00:00:00+00:00 [queued]>
[2024-08-24T17:39:28.290+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ApiExec.ApiExec_dataScience scheduled__2024-08-22T00:00:00+00:00 [queued]>
[2024-08-24T17:39:28.291+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 1
[2024-08-24T17:39:28.306+0000] {taskinstance.py:2192} INFO - Executing <Task(ApiExternaOperator): ApiExec_dataScience> on 2024-08-22 00:00:00+00:00
[2024-08-24T17:39:28.314+0000] {standard_task_runner.py:60} INFO - Started process 82 to run task
[2024-08-24T17:39:28.317+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ApiExec', 'ApiExec_dataScience', 'scheduled__2024-08-22T00:00:00+00:00', '--job-id', '228', '--raw', '--subdir', 'DAGS_FOLDER/ApiExecDag.py', '--cfg-path', '/tmp/tmp8_vr4gv9']
[2024-08-24T17:39:28.323+0000] {standard_task_runner.py:88} INFO - Job 228: Subtask ApiExec_dataScience
[2024-08-24T17:39:28.384+0000] {task_command.py:423} INFO - Running <TaskInstance: ApiExec.ApiExec_dataScience scheduled__2024-08-22T00:00:00+00:00 [running]> on host 094085adac4a
[2024-08-24T17:39:28.482+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ApiExec' AIRFLOW_CTX_TASK_ID='ApiExec_dataScience' AIRFLOW_CTX_EXECUTION_DATE='2024-08-22T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-22T00:00:00+00:00'
[2024-08-24T17:39:28.494+0000] {base.py:83} INFO - Using connection ID 'Api_Externa' for task execution.
[2024-08-24T17:39:28.496+0000] {ApiExterna.py:33} INFO - URL: https://labdados.com/2/tweets/search/recent?query=&tweet.fields=author_id,conversation_id,created_at,id,in_reply_to_user_id,public_metrics,lang,text&expansions=author_id&user.fields=id,name,username,created_at&start_time=2024-08-22T00:00:00.00Z&end_time=2024-08-23T00:00:00.00Z
[2024-08-24T17:39:29.054+0000] {ApiExterna.py:33} INFO - URL: https://labdados.com/2/tweets/search/recent?query=&tweet.fields=author_id,conversation_id,created_at,id,in_reply_to_user_id,public_metrics,lang,text&expansions=author_id&user.fields=id,name,username,created_at&start_time=2024-08-22T00:00:00.00Z&end_time=2024-08-23T00:00:00.00Z&next_token=1234567890abcdef
[2024-08-24T17:39:29.195+0000] {ApiExterna.py:33} INFO - URL: https://labdados.com/2/tweets/search/recent?query=&tweet.fields=author_id,conversation_id,created_at,id,in_reply_to_user_id,public_metrics,lang,text&expansions=author_id&user.fields=id,name,username,created_at&start_time=2024-08-22T00:00:00.00Z&end_time=2024-08-23T00:00:00.00Z&next_token=1234567890abcdef
[2024-08-24T17:39:29.336+0000] {ApiExterna.py:33} INFO - URL: https://labdados.com/2/tweets/search/recent?query=&tweet.fields=author_id,conversation_id,created_at,id,in_reply_to_user_id,public_metrics,lang,text&expansions=author_id&user.fields=id,name,username,created_at&start_time=2024-08-22T00:00:00.00Z&end_time=2024-08-23T00:00:00.00Z&next_token=1234567890abcdef
[2024-08-24T17:39:29.484+0000] {ApiExterna.py:33} INFO - URL: https://labdados.com/2/tweets/search/recent?query=&tweet.fields=author_id,conversation_id,created_at,id,in_reply_to_user_id,public_metrics,lang,text&expansions=author_id&user.fields=id,name,username,created_at&start_time=2024-08-22T00:00:00.00Z&end_time=2024-08-23T00:00:00.00Z&next_token=1234567890abcdef
[2024-08-24T17:39:29.624+0000] {ApiExterna.py:33} INFO - URL: https://labdados.com/2/tweets/search/recent?query=&tweet.fields=author_id,conversation_id,created_at,id,in_reply_to_user_id,public_metrics,lang,text&expansions=author_id&user.fields=id,name,username,created_at&start_time=2024-08-22T00:00:00.00Z&end_time=2024-08-23T00:00:00.00Z&next_token=1234567890abcdef
[2024-08-24T17:39:29.774+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=ApiExec, task_id=ApiExec_dataScience, execution_date=20240822T000000, start_date=20240824T173928, end_date=20240824T173929
[2024-08-24T17:39:29.817+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-08-24T17:39:29.831+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
